L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c"
N/*
N *  drivers/mtd/nand.c
N *
N *  Overview:
N *   This is the generic MTD driver for NAND flash devices. It should be
N *   capable of working with almost all NAND chips currently available.
N *   Basic support for AG-AND chips is provided.
N *
N *	Additional technical information is available on
N *	http://www.linux-mtd.infradead.org/doc/nand.html
N *
N *  Copyright (C) 2000 Steven J. Hill (sjhill@realitydiluted.com)
N *		  2002-2006 Thomas Gleixner (tglx@linutronix.de)
N *
N *  Credits:
N *	David Woodhouse for adding multichip support
N *
N *	Aleph One Ltd. and Toby Churchill Ltd. for supporting the
N *	rework for 2K page size chips
N *
N *  TODO:
N *	Enable cached programming for 2k page size chips
N *	Check, if mtd->ecctype should be set to MTD_ECC_HW
N *	if we have HW ecc support.
N *	The AG-AND chips have nice features for speed improvement,
N *	which are not supported yet. Read / program 4 pages in one go.
N *	BBT table is not serialized, has to be fixed
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License version 2 as
N * published by the Free Software Foundation.
N *
N */
N
N#include "common.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\common.h" 1
N/*
N * (C) Copyright 2000-2009
N * Wolfgang Denk, DENX Software Engineering, wd@denx.de.
N *
N * See file CREDITS for list of people who contributed to this
N * project.
N *
N * This program is free software; you can redistribute it and/or
N * modify it under the terms of the GNU General Public License as
N * published by the Free Software Foundation; either version 2 of
N * the License, or (at your option) any later version.
N *
N * This program is distributed in the hope that it will be useful,
N * but WITHOUT ANY WARRANTY; without even the implied warranty of
N * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	 See the
N * GNU General Public License for more details.
N *
N * You should have received a copy of the GNU General Public License
N * along with this program; if not, write to the Free Software
N * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
N * MA 02111-1307 USA
N */
N#if 0
S
S#ifndef __COMMON_H_
S#define __COMMON_H_	1
S
S#undef	_LINUX_CONFIG_H
S#define _LINUX_CONFIG_H 1	/* avoid reading Linux autoconf.h file	*/
S
S#ifndef __ASSEMBLY__		/* put C only stuff in this section */
S
Stypedef unsigned char		uchar;
Stypedef volatile unsigned long	vu_long;
Stypedef volatile unsigned short vu_short;
Stypedef volatile unsigned char	vu_char;
S
S#include "config.h"
S//#include <asm-offsets.h>
S#include <linux/bitops.h>
S#include <linux/types.h>
S#include <linux/string.h>
S#include <linux/stringify.h>
S#include <asm/ptrace.h>
S#include <stdarg.h>
S#if defined(CONFIG_PCI) && defined(CONFIG_4xx)
S#include <pci.h>
S#endif
S#if defined(CONFIG_8xx)
S#include <asm/8xx_immap.h>
S#if defined(CONFIG_MPC852)	|| defined(CONFIG_MPC852T)	|| \
S    defined(CONFIG_MPC859)	|| defined(CONFIG_MPC859T)	|| \
S    defined(CONFIG_MPC859DSL)	|| \
S    defined(CONFIG_MPC866)	|| defined(CONFIG_MPC866T)	|| \
S    defined(CONFIG_MPC866P)
X#if defined(CONFIG_MPC852)	|| defined(CONFIG_MPC852T)	||     defined(CONFIG_MPC859)	|| defined(CONFIG_MPC859T)	||     defined(CONFIG_MPC859DSL)	||     defined(CONFIG_MPC866)	|| defined(CONFIG_MPC866T)	||     defined(CONFIG_MPC866P)
S# define CONFIG_MPC866_FAMILY 1
S#elif defined(CONFIG_MPC870) \
S   || defined(CONFIG_MPC875) \
S   || defined(CONFIG_MPC880) \
S   || defined(CONFIG_MPC885)
X#elif defined(CONFIG_MPC870)    || defined(CONFIG_MPC875)    || defined(CONFIG_MPC880)    || defined(CONFIG_MPC885)
S# define CONFIG_MPC885_FAMILY   1
S#endif
S#if   defined(CONFIG_MPC860)	   \
S   || defined(CONFIG_MPC860T)	   \
S   || defined(CONFIG_MPC866_FAMILY) \
S   || defined(CONFIG_MPC885_FAMILY)
X#if   defined(CONFIG_MPC860)	      || defined(CONFIG_MPC860T)	      || defined(CONFIG_MPC866_FAMILY)    || defined(CONFIG_MPC885_FAMILY)
S# define CONFIG_MPC86x 1
S#endif
S#elif defined(CONFIG_5xx)
S#include <asm/5xx_immap.h>
S#elif defined(CONFIG_MPC5xxx)
S#include <mpc5xxx.h>
S#elif defined(CONFIG_MPC512X)
S#include <asm/immap_512x.h>
S#elif defined(CONFIG_MPC8220)
S#include <asm/immap_8220.h>
S#elif defined(CONFIG_8260)
S#if   defined(CONFIG_MPC8247) \
S   || defined(CONFIG_MPC8248) \
S   || defined(CONFIG_MPC8271) \
S   || defined(CONFIG_MPC8272)
X#if   defined(CONFIG_MPC8247)    || defined(CONFIG_MPC8248)    || defined(CONFIG_MPC8271)    || defined(CONFIG_MPC8272)
S#define CONFIG_MPC8272_FAMILY	1
S#endif
S#if defined(CONFIG_MPC8272_FAMILY)
S#define CONFIG_MPC8260	1
S#endif
S#include <asm/immap_8260.h>
S#endif
S#ifdef CONFIG_MPC86xx
S#include <mpc86xx.h>
S#include <asm/immap_86xx.h>
S#endif
S#ifdef CONFIG_MPC85xx
S#include <mpc85xx.h>
S#include <asm/immap_85xx.h>
S#endif
S#ifdef CONFIG_MPC83xx
S#include <mpc83xx.h>
S#include <asm/immap_83xx.h>
S#endif
S#ifdef	CONFIG_4xx
S#include <asm/ppc4xx.h>
S#endif
S#ifdef CONFIG_HYMOD
S#include <board/hymod/hymod.h>
S#endif
S#ifdef CONFIG_ARM
S#define asmlinkage	/* nothing */
S#endif
S#ifdef CONFIG_BLACKFIN
S#include <asm/blackfin.h>
S#endif
S#ifdef CONFIG_SOC_DA8XX
S#include <asm/arch/hardware.h>
S#endif
S
S#include "part.h"
S#include "flash.h"
S#include "image.h"
S
S#ifdef DEBUG
S#define _DEBUG	1
S#else
S#define _DEBUG	0
S#endif
S
S/*
S * Output a debug text when condition "cond" is met. The "cond" should be
S * computed by a preprocessor in the best case, allowing for the best
S * optimization.
S */
S#define debug_cond(cond, fmt, args...)		\
S	do {					\
S		if (cond)			\
S			sysprintf(fmt, ##args);	\
S	} while (0)
X#define debug_cond(cond, fmt, args...)			do {							if (cond)						sysprintf(fmt, ##args);		} while (0)
S
S#define debug(fmt, args...)			\
S	debug_cond(_DEBUG, fmt, ##args)
X#define debug(fmt, args...)				debug_cond(_DEBUG, fmt, ##args)
S
S/*
S * An assertion is run-time check done in debug mode only. If DEBUG is not
S * defined then it is skipped. If DEBUG is defined and the assertion fails,
S * then it calls panic*( which may or may not reset/halt U-Boot (see
S * CONFIG_PANIC_HANG), It is hoped that all failing assertions are found
S * before release, and after release it is hoped that they don't matter. But
S * in any case these failing assertions cannot be fixed with a reset (which
S * may just do the same assertion again).
S */
Svoid __assert_fail(const char *assertion, const char *file, unsigned line,
S		   const char *function);
S#define assert(x) \
S	({ if (!(x) && _DEBUG) \
S		__assert_fail(#x, __FILE__, __LINE__, __func__); })
X#define assert(x) 	({ if (!(x) && _DEBUG) 		__assert_fail(#x, __FILE__, __LINE__, __func__); })
S
S#define error(fmt, args...) do {					\
S		sysprintf("ERROR: " fmt "\nat %s:%d/%s()\n",		\
S			##args, __FILE__, __LINE__, __func__);		\
S} while (0)
X#define error(fmt, args...) do {							sysprintf("ERROR: " fmt "\nat %s:%d/%s()\n",					##args, __FILE__, __LINE__, __func__);		} while (0)
S
S#ifndef BUG
S#define BUG() do { \
S	sysprintf("BUG: failure at %s:%d/%s()!\n", __FILE__, __LINE__, __FUNCTION__); \
S	panic("BUG!"); \
S} while (0)
X#define BUG() do { 	sysprintf("BUG: failure at %s:%d/%s()!\n", __FILE__, __LINE__, __FUNCTION__); 	panic("BUG!"); } while (0)
S#define BUG_ON(condition) do { if (unlikely((condition)!=0)) BUG(); } while(0)
S#endif /* BUG */
S
S/* Force a compilation error if condition is true */
S#define BUILD_BUG_ON(condition) ((void)sizeof(char[1 - 2*!!(condition)]))
S
Stypedef void (interrupt_handler_t)(void *);
S
S#include <asm/u-boot.h> /* boot information for Linux kernel */
S#include <asm/global_data.h>	/* global data used for startup functions */
S
S/*
S * enable common handling for all TQM8xxL/M boards:
S * - CONFIG_TQM8xxM will be defined for all TQM8xxM boards
S * - CONFIG_TQM8xxL will be defined for all TQM8xxL _and_ TQM8xxM boards
S *                  and for the TQM885D board
S */
S#if defined(CONFIG_TQM823M) || defined(CONFIG_TQM850M) || \
S    defined(CONFIG_TQM855M) || defined(CONFIG_TQM860M) || \
S    defined(CONFIG_TQM862M) || defined(CONFIG_TQM866M)
X#if defined(CONFIG_TQM823M) || defined(CONFIG_TQM850M) ||     defined(CONFIG_TQM855M) || defined(CONFIG_TQM860M) ||     defined(CONFIG_TQM862M) || defined(CONFIG_TQM866M)
S# ifndef CONFIG_TQM8xxM
S#  define CONFIG_TQM8xxM
S# endif
S#endif
S#if defined(CONFIG_TQM823L) || defined(CONFIG_TQM850L) || \
S    defined(CONFIG_TQM855L) || defined(CONFIG_TQM860L) || \
S    defined(CONFIG_TQM862L) || defined(CONFIG_TQM8xxM) || \
S    defined(CONFIG_TQM885D)
X#if defined(CONFIG_TQM823L) || defined(CONFIG_TQM850L) ||     defined(CONFIG_TQM855L) || defined(CONFIG_TQM860L) ||     defined(CONFIG_TQM862L) || defined(CONFIG_TQM8xxM) ||     defined(CONFIG_TQM885D)
S# ifndef CONFIG_TQM8xxL
S#  define CONFIG_TQM8xxL
S# endif
S#endif
S
S/*
S * General Purpose Utilities
S */
S#define min(X, Y)				\
S	({ typeof (X) __x = (X);		\
S		typeof (Y) __y = (Y);		\
S		(__x < __y) ? __x : __y; })
X#define min(X, Y)					({ typeof (X) __x = (X);				typeof (Y) __y = (Y);				(__x < __y) ? __x : __y; })
S
S#define max(X, Y)				\
S	({ typeof (X) __x = (X);		\
S		typeof (Y) __y = (Y);		\
S		(__x > __y) ? __x : __y; })
X#define max(X, Y)					({ typeof (X) __x = (X);				typeof (Y) __y = (Y);				(__x > __y) ? __x : __y; })
S
S#define MIN(x, y)  min(x, y)
S#define MAX(x, y)  max(x, y)
S
S/*
S * Return the absolute value of a number.
S *
S * This handles unsigned and signed longs, ints, shorts and chars.  For all
S * input types abs() returns a signed long.
S *
S * For 64-bit types, use abs64()
S */
S#define abs(x) ({						\
S		long ret;					\
S		if (sizeof(x) == sizeof(long)) {		\
S			long __x = (x);				\
S			ret = (__x < 0) ? -__x : __x;		\
S		} else {					\
S			int __x = (x);				\
S			ret = (__x < 0) ? -__x : __x;		\
S		}						\
S		ret;						\
S	})
X#define abs(x) ({								long ret;							if (sizeof(x) == sizeof(long)) {					long __x = (x);							ret = (__x < 0) ? -__x : __x;				} else {								int __x = (x);							ret = (__x < 0) ? -__x : __x;				}								ret;							})
S
S#define abs64(x) ({				\
S		s64 __x = (x);			\
S		(__x < 0) ? -__x : __x;		\
S	})
X#define abs64(x) ({						s64 __x = (x);					(__x < 0) ? -__x : __x;			})
S
S#if defined(CONFIG_ENV_IS_EMBEDDED)
S#define TOTAL_MALLOC_LEN	CONFIG_SYS_MALLOC_LEN
S#elif ( ((CONFIG_ENV_ADDR+CONFIG_ENV_SIZE) < CONFIG_SYS_MONITOR_BASE) || \
S	(CONFIG_ENV_ADDR >= (CONFIG_SYS_MONITOR_BASE + CONFIG_SYS_MONITOR_LEN)) ) || \
S      defined(CONFIG_ENV_IS_IN_NVRAM)
X#elif ( ((CONFIG_ENV_ADDR+CONFIG_ENV_SIZE) < CONFIG_SYS_MONITOR_BASE) || 	(CONFIG_ENV_ADDR >= (CONFIG_SYS_MONITOR_BASE + CONFIG_SYS_MONITOR_LEN)) ) ||       defined(CONFIG_ENV_IS_IN_NVRAM)
S#define	TOTAL_MALLOC_LEN	(CONFIG_SYS_MALLOC_LEN + CONFIG_ENV_SIZE)
S#else
S#define	TOTAL_MALLOC_LEN	CONFIG_SYS_MALLOC_LEN
S#endif
S
S/**
S * container_of - cast a member of a structure out to the containing structure
S * @ptr:	the pointer to the member.
S * @type:	the type of the container struct this is embedded in.
S * @member:	the name of the member within the struct.
S *
S */
S#define container_of(ptr, type, member) ({			\
S	const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
S	(type *)( (char *)__mptr - offsetof(type,member) );})
X#define container_of(ptr, type, member) ({				const typeof( ((type *)0)->member ) *__mptr = (ptr);		(type *)( (char *)__mptr - offsetof(type,member) );})
S
S/*
S * Function Prototypes
S */
S
Svoid	hang		(void) __attribute__ ((noreturn));
S
Sint	timer_init(void);
Sint	cpu_init(void);
S
S/* */
S// phys_size_t initdram (int);
Sint	display_options (void);
Svoid	print_size(unsigned long long, const char *);
Sint print_buffer(ulong addr, const void *data, uint width, uint count,
S		 uint linelen);
S
S/* common/main.c */
Svoid	main_loop	(void);
Sint run_command(const char *cmd, int flag);
S
S/**
S * Run a list of commands separated by ; or even \0
S *
S * Note that if 'len' is not -1, then the command does not need to be nul
S * terminated, Memory will be allocated for the command in that case.
S *
S * @param cmd	List of commands to run, each separated bu semicolon
S * @param len	Length of commands excluding terminator if known (-1 if not)
S * @param flag	Execution flags (CMD_FLAG_...)
S * @return 0 on success, or != 0 on error.
S */
Sint run_command_list(const char *cmd, int len, int flag);
Sint	readline	(const char *const prompt);
Sint	readline_into_buffer(const char *const prompt, char *buffer,
S			int timeout);
Sint	parse_line (char *, char *[]);
Svoid	init_cmd_timeout(void);
Svoid	reset_cmd_timeout(void);
S#ifdef CONFIG_MENU
Sint	abortboot(int bootdelay);
S#endif
Sextern char console_buffer[];
S
S/* arch/$(ARCH)/lib/board.c */
S// void	board_init_f(ulong);
S// void	board_init_r  (gd_t *, ulong) __attribute__ ((noreturn));
S// int	checkboard    (void);
S// int	checkflash    (void);
S// int	checkdram     (void);
S// int	last_stage_init(void);
S// extern ulong monitor_flash_len;
S// int mac_read_from_eeprom(void);
S// extern u8 _binary_dt_dtb_start[];	/* embedded device tree blob */
S// int set_cpu_clk_info(void);
S// int print_cpuinfo(void);
S// int update_flash_size(int flash_size);
S
S/**
S * Show the DRAM size in a board-specific way
S *
S * This is used by boards to display DRAM information in their own way.
S *
S * @param size	Size of DRAM (which should be displayed along with other info)
S */
Svoid board_show_dram(ulong size);
S
S/* common/flash.c */
Svoid flash_perror (int);
S
S/* common/cmd_source.c */
Sint	source (ulong addr, const char *fit_uname);
S
Sextern ulong load_addr;		/* Default Load Address */
Sextern ulong save_addr;		/* Default Save Address */
Sextern ulong save_size;		/* Default Save Size */
S
S/* common/cmd_doc.c */
S// void	doc_probe(unsigned long physadr);
S
S/* common/cmd_net.c */
S// int do_tftpb(cmd_tbl_t *cmdtp, int flag, int argc, char * const argv[]);
S
S/* common/cmd_fat.c */
S// int do_fat_fsload(cmd_tbl_t *, int, int, char * const []);
S
S/* common/cmd_ext2.c */
S// int do_ext2load(cmd_tbl_t *, int, int, char * const []);
S
S/* common/cmd_nvedit.c */
S// int	env_init     (void);
S// void	env_relocate (void);
S// int	envmatch     (uchar *, int);
S// char	*getenv	     (const char *);
S// int	getenv_f     (const char *name, char *buf, unsigned len);
S// ulong getenv_ulong(const char *name, int base, ulong default_val);
S/*
S * Read an environment variable as a boolean
S * Return -1 if variable does not exist (default to true)
S */
Sint getenv_yesno(const char *var);
Sint	saveenv	     (void);
Sint	setenv	     (const char *, const char *);
Sint setenv_ulong(const char *varname, ulong value);
Sint setenv_hex(const char *varname, ulong value);
S/**
S * setenv_addr - Set an environment variable to an address in hex
S *
S * @varname:	Environmet variable to set
S * @addr:	Value to set it to
S * @return 0 if ok, 1 on error
S */
Sstatic __inline int setenv_addr(const char *varname, const void *addr)
S{
S	return setenv_hex(varname, (ulong)addr);
S}
S
S#ifdef CONFIG_ARM
S# include <asm/mach-types.h>
S# include <asm/setup.h>
S# include <asm/u-boot-arm.h>	/* ARM version to be fixed! */
S#endif /* CONFIG_ARM */
S#ifdef CONFIG_X86		/* x86 version to be fixed! */
S# include <asm/u-boot-x86.h>
S#endif /* CONFIG_X86 */
S#ifdef CONFIG_SANDBOX
S# include <asm/u-boot-sandbox.h>	/* TODO(sjg) what needs to be fixed? */
S#endif
S#ifdef CONFIG_NDS32
S# include <asm/mach-types.h>
S# include <asm/u-boot-nds32.h>
S#endif /* CONFIG_NDS32 */
S#ifdef CONFIG_MIPS
S# include <asm/u-boot-mips.h>
S#endif /* CONFIG_MIPS */
S
S#ifdef CONFIG_AUTO_COMPLETE
Sint env_complete(char *var, int maxv, char *cmdv[], int maxsz, char *buf);
S#endif
Sint get_env_id (void);
S
Svoid	pci_init      (void);
Svoid	pci_init_board(void);
Svoid	pciinfo	      (int, int);
S
S#if defined(CONFIG_PCI) && defined(CONFIG_4xx)
S    int	   pci_pre_init	       (struct pci_controller *);
S    int	   is_pci_host	       (struct pci_controller *);
S#endif
S
S#if defined(CONFIG_PCI) && (defined(CONFIG_440) || defined(CONFIG_405EX))
S#   if defined(CONFIG_SYS_PCI_TARGET_INIT)
S	void	pci_target_init	     (struct pci_controller *);
S#   endif
S#   if defined(CONFIG_SYS_PCI_MASTER_INIT)
S	void	pci_master_init	     (struct pci_controller *);
S#   endif
S#if defined(CONFIG_440SPE) || \
S    defined(CONFIG_460EX) || defined(CONFIG_460GT) || \
S    defined(CONFIG_405EX)
X#if defined(CONFIG_440SPE) ||     defined(CONFIG_460EX) || defined(CONFIG_460GT) ||     defined(CONFIG_405EX)
S   void pcie_setup_hoses(int busno);
S#endif
S#endif
S
Sint	misc_init_f   (void);
Sint	misc_init_r   (void);
S
S/* common/exports.c */
Svoid	jumptable_init(void);
S
S/* common/kallsysm.c */
Sconst char *symbol_lookup(unsigned long addr, unsigned long *caddr);
S
S/* api/api.c */
Svoid	api_init (void);
S
S/* common/memsize.c */
Slong	get_ram_size  (long *, long);
S
S/* $(BOARD)/$(BOARD).c */
Svoid	reset_phy     (void);
Svoid	fdc_hw_init   (void);
S
S/* $(BOARD)/eeprom.c */
Svoid eeprom_init  (void);
S#ifndef CONFIG_SPI
Sint  eeprom_probe (unsigned dev_addr, unsigned offset);
S#endif
Sint  eeprom_read  (unsigned dev_addr, unsigned offset, uchar *buffer, unsigned cnt);
Sint  eeprom_write (unsigned dev_addr, unsigned offset, uchar *buffer, unsigned cnt);
S#ifdef CONFIG_LWMON
Sextern uchar pic_read  (uchar reg);
Sextern void  pic_write (uchar reg, uchar val);
S#endif
S
S/*
S * Set this up regardless of board
S * type, to prevent errors.
S */
S#if defined(CONFIG_SPI) || !defined(CONFIG_SYS_I2C_EEPROM_ADDR)
S# define CONFIG_SYS_DEF_EEPROM_ADDR 0
S#else
S#if !defined(CONFIG_ENV_EEPROM_IS_ON_I2C)
S# define CONFIG_SYS_DEF_EEPROM_ADDR CONFIG_SYS_I2C_EEPROM_ADDR
S#endif
S#endif /* CONFIG_SPI || !defined(CONFIG_SYS_I2C_EEPROM_ADDR) */
S
S#if defined(CONFIG_SPI)
Sextern void spi_init_f (void);
Sextern void spi_init_r (void);
Sextern ssize_t spi_read	 (uchar *, int, uchar *, int);
Sextern ssize_t spi_write (uchar *, int, uchar *, int);
S#endif
S
S#ifdef CONFIG_RPXCLASSIC
Svoid rpxclassic_init (void);
S#endif
S
Svoid rpxlite_init (void);
S
S#ifdef CONFIG_MBX
S/* $(BOARD)/mbx8xx.c */
Svoid	mbx_init (void);
Svoid	board_serial_init (void);
Svoid	board_ether_init (void);
S#endif
S
S#ifdef CONFIG_HERMES
S/* $(BOARD)/hermes.c */
Svoid hermes_start_lxt980 (int speed);
S#endif
S
S#ifdef CONFIG_EVB64260
Svoid  evb64260_init(void);
Svoid  debug_led(int, int);
Svoid  display_mem_map(void);
Svoid  perform_soft_reset(void);
S#endif
S
S/* $(BOARD)/$(BOARD).c */
Sint board_early_init_f (void);
Sint board_late_init (void);
Sint board_postclk_init (void); /* after clocks/timebase, before env/serial */
Sint board_early_init_r (void);
Svoid board_poweroff (void);
S
S#if defined(CONFIG_SYS_DRAM_TEST)
Sint testdram(void);
S#endif /* CONFIG_SYS_DRAM_TEST */
S
S/* $(CPU)/start.S */
S#if defined(CONFIG_5xx) || \
S    defined(CONFIG_8xx)
X#if defined(CONFIG_5xx) ||     defined(CONFIG_8xx)
Suint	get_immr      (uint);
S#endif
Suint	get_pir	      (void);
S#if defined(CONFIG_MPC5xxx)
Suint	get_svr       (void);
S#endif
Suint	get_pvr	      (void);
Suint	get_svr	      (void);
Suint	rd_ic_cst     (void);
Svoid	wr_ic_cst     (uint);
Svoid	wr_ic_adr     (uint);
Suint	rd_dc_cst     (void);
Svoid	wr_dc_cst     (uint);
Svoid	wr_dc_adr     (uint);
Sint	icache_status (void);
Svoid	icache_enable (void);
Svoid	icache_disable(void);
Sint	dcache_status (void);
Svoid	dcache_enable (void);
Svoid	dcache_disable(void);
Svoid	mmu_disable(void);
Svoid	relocate_code (ulong, gd_t *, ulong) __attribute__ ((noreturn));
Sulong	get_endaddr   (void);
Svoid	trap_init     (ulong);
S#if defined (CONFIG_4xx)	|| \
S    defined (CONFIG_MPC5xxx)	|| \
S    defined (CONFIG_74xx_7xx)	|| \
S    defined (CONFIG_74x)	|| \
S    defined (CONFIG_75x)	|| \
S    defined (CONFIG_74xx)	|| \
S    defined (CONFIG_MPC8220)	|| \
S    defined (CONFIG_MPC85xx)	|| \
S    defined (CONFIG_MPC86xx)	|| \
S    defined (CONFIG_MPC83xx)
X#if defined (CONFIG_4xx)	||     defined (CONFIG_MPC5xxx)	||     defined (CONFIG_74xx_7xx)	||     defined (CONFIG_74x)	||     defined (CONFIG_75x)	||     defined (CONFIG_74xx)	||     defined (CONFIG_MPC8220)	||     defined (CONFIG_MPC85xx)	||     defined (CONFIG_MPC86xx)	||     defined (CONFIG_MPC83xx)
Sunsigned char	in8(unsigned int);
Svoid		out8(unsigned int, unsigned char);
Sunsigned short	in16(unsigned int);
Sunsigned short	in16r(unsigned int);
Svoid		out16(unsigned int, unsigned short value);
Svoid		out16r(unsigned int, unsigned short value);
Sunsigned long	in32(unsigned int);
Sunsigned long	in32r(unsigned int);
Svoid		out32(unsigned int, unsigned long value);
Svoid		out32r(unsigned int, unsigned long value);
Svoid		ppcDcbf(unsigned long value);
Svoid		ppcDcbi(unsigned long value);
Svoid		ppcSync(void);
Svoid		ppcDcbz(unsigned long value);
S#endif
S#if defined (CONFIG_MICROBLAZE)
Sunsigned short	in16(unsigned int);
Svoid		out16(unsigned int, unsigned short value);
S#endif
S
S#if defined (CONFIG_MPC83xx)
Svoid		ppcDWload(unsigned int *addr, unsigned int *ret);
Svoid		ppcDWstore(unsigned int *addr, unsigned int *value);
Svoid disable_addr_trans(void);
Svoid enable_addr_trans(void);
S#if defined(CONFIG_DDR_ECC) && !defined(CONFIG_ECC_INIT_VIA_DDRCONTROLLER)
Svoid ddr_enable_ecc(unsigned int dram_size);
S#endif
S#endif
S
S/* $(CPU)/cpu.c */
Sstatic __inline int cpumask_next(int cpu, unsigned int mask)
S{
S	for (cpu++; !((1 << cpu) & mask); cpu++)
S		;
S
S	return cpu;
S}
S
S#define for_each_cpu(iter, cpu, num_cpus, mask) \
S	for (iter = 0, cpu = cpumask_next(-1, mask); \
S		iter < num_cpus; \
S		iter++, cpu = cpumask_next(cpu, mask)) \
S
X#define for_each_cpu(iter, cpu, num_cpus, mask) 	for (iter = 0, cpu = cpumask_next(-1, mask); 		iter < num_cpus; 		iter++, cpu = cpumask_next(cpu, mask)) 
Sint	cpu_numcores  (void);
Su32	cpu_mask      (void);
Sint	is_core_valid (unsigned int);
Sint	probecpu      (void);
Sint	checkcpu      (void);
Sint	checkicache   (void);
Sint	checkdcache   (void);
Svoid	upmconfig     (unsigned int, unsigned int *, unsigned int);
Sulong	get_tbclk     (void);
Svoid	reset_cpu     (ulong addr);
S#if defined (CONFIG_OF_LIBFDT) && defined (CONFIG_OF_BOARD_SETUP)
Svoid ft_cpu_setup(void *blob, bd_t *bd);
S#ifdef CONFIG_PCI
Svoid ft_pci_setup(void *blob, bd_t *bd);
S#endif
S#endif
S
S
S/* $(CPU)/serial.c */
Sint	serial_init   (void);
Svoid	serial_setbrg (void);
Svoid	serial_putc   (const char);
Svoid	serial_putc_raw(const char);
Svoid	serial_puts   (const char *);
Sint	serial_getc   (void);
Sint	serial_tstc   (void);
S
Svoid	_serial_setbrg (const int);
Svoid	_serial_putc   (const char, const int);
Svoid	_serial_putc_raw(const char, const int);
Svoid	_serial_puts   (const char *, const int);
Sint	_serial_getc   (const int);
Sint	_serial_tstc   (const int);
S
S/* $(CPU)/speed.c */
Sint	get_clocks (void);
Sint	get_clocks_866 (void);
Sint	sdram_adjust_866 (void);
Sint	adjust_sdram_tbs_8xx (void);
S#if defined(CONFIG_8260)
Sint	prt_8260_clks (void);
S#elif defined(CONFIG_MPC5xxx)
Sint	prt_mpc5xxx_clks (void);
S#endif
S#if defined(CONFIG_MPC512X)
Sint	prt_mpc512xxx_clks (void);
S#endif
S#if defined(CONFIG_MPC8220)
Sint	prt_mpc8220_clks (void);
S#endif
S#ifdef CONFIG_4xx
Sulong	get_OPB_freq (void);
Sulong	get_PCI_freq (void);
S#endif
S#if defined(CONFIG_S3C24X0) || \
S    defined(CONFIG_LH7A40X) || \
S    defined(CONFIG_S3C6400) || \
S    defined(CONFIG_EP93XX)
X#if defined(CONFIG_S3C24X0) ||     defined(CONFIG_LH7A40X) ||     defined(CONFIG_S3C6400) ||     defined(CONFIG_EP93XX)
Sulong	get_FCLK (void);
Sulong	get_HCLK (void);
Sulong	get_PCLK (void);
Sulong	get_UCLK (void);
S#endif
S#if defined(CONFIG_LH7A40X)
Sulong	get_PLLCLK (void);
S#endif
S#if defined CONFIG_INCA_IP
Suint	incaip_get_cpuclk (void);
S#endif
S#if defined(CONFIG_IMX)
Sulong get_systemPLLCLK(void);
Sulong get_FCLK(void);
Sulong get_HCLK(void);
Sulong get_BCLK(void);
Sulong get_PERCLK1(void);
Sulong get_PERCLK2(void);
Sulong get_PERCLK3(void);
S#endif
Sulong	get_bus_freq  (ulong);
Sint get_serial_clock(void);
S
S#if defined(CONFIG_MPC83xx) || defined(CONFIG_MPC85xx)
Sulong get_ddr_freq(ulong);
S#endif
S#if defined(CONFIG_MPC85xx)
Stypedef MPC85xx_SYS_INFO sys_info_t;
Svoid	get_sys_info  ( sys_info_t * );
S#endif
S#if defined(CONFIG_MPC86xx)
Stypedef MPC86xx_SYS_INFO sys_info_t;
Svoid   get_sys_info  ( sys_info_t * );
Sstatic __inline ulong get_ddr_freq(ulong dummy)
S{
S	return get_bus_freq(dummy);
S}
S#endif
S
S#if defined(CONFIG_4xx)
S#  if defined(CONFIG_440)
S#	if defined(CONFIG_440SPE)
S	 unsigned long determine_sysper(void);
S	 unsigned long determine_pci_clock_per(void);
S#	endif
S#  endif
Stypedef PPC4xx_SYS_INFO sys_info_t;
Sint	ppc440spe_revB(void);
Svoid	get_sys_info  ( sys_info_t * );
S#endif
S
S/* $(CPU)/cpu_init.c */
S#if defined(CONFIG_8xx) || defined(CONFIG_8260)
Svoid	cpu_init_f    (volatile immap_t *immr);
S#endif
S#if defined(CONFIG_4xx) || defined(CONFIG_MPC85xx) || defined(CONFIG_MCF52x2) ||defined(CONFIG_MPC86xx)
Svoid	cpu_init_f    (void);
S#endif
S
Sint	cpu_init_r    (void);
S#if defined(CONFIG_8260)
Sint	prt_8260_rsr  (void);
S#elif defined(CONFIG_MPC83xx)
Sint	prt_83xx_rsr  (void);
S#endif
S
S/* $(CPU)/interrupts.c */
Sint	interrupt_init	   (void);
Svoid	timer_interrupt	   (struct pt_regs *);
Svoid	external_interrupt (struct pt_regs *);
Svoid	irq_install_handler(int, interrupt_handler_t *, void *);
Svoid	irq_free_handler   (int);
Svoid	reset_timer	   (void);
Sulong	get_timer	   (ulong base);
Svoid	enable_interrupts  (void);
Sint	disable_interrupts (void);
S
S/* $(CPU)/.../commproc.c */
Sint	dpram_init (void);
Suint	dpram_base(void);
Suint	dpram_base_align(uint align);
Suint	dpram_alloc(uint size);
Suint	dpram_alloc_align(uint size,uint align);
Svoid	bootcount_store (ulong);
Sulong	bootcount_load (void);
S#define BOOTCOUNT_MAGIC		0xB001C041
S
S/* $(CPU)/.../<eth> */
Svoid mii_init (void);
S
S/* $(CPU)/.../lcd.c */
Sulong	lcd_setmem (ulong);
S
S/* $(CPU)/.../video.c */
Sulong	video_setmem (ulong);
S
S/* arch/$(ARCH)/lib/cache.c */
Svoid	enable_caches(void);
Svoid	flush_cache   (unsigned long, unsigned long);
Svoid	flush_dcache_all(void);
Svoid	flush_dcache_range(unsigned long start, unsigned long stop);
Svoid	invalidate_dcache_range(unsigned long start, unsigned long stop);
Svoid	invalidate_dcache_all(void);
Svoid	invalidate_icache_all(void);
S
S/* arch/$(ARCH)/lib/ticks.S */
Sunsigned long long get_ticks(void);
Svoid	wait_ticks    (unsigned long);
S
S/* arch/$(ARCH)/lib/time.c */
Svoid	__udelay      (unsigned long);
Sulong	usec2ticks    (unsigned long usec);
Sulong	ticks2usec    (unsigned long ticks);
Sint	init_timebase (void);
S
S/* lib/gunzip.c */
Sint gunzip(void *, int, unsigned char *, unsigned long *);
Sint zunzip(void *dst, int dstlen, unsigned char *src, unsigned long *lenp,
S						int stoponerr, int offset);
S
S/* lib/qsort.c */
Svoid qsort(void *base, size_t nmemb, size_t size,
S	   int(*compar)(const void *, const void *));
Sint strcmp_compar(const void *, const void *);
S
S/* lib/time.c */
Svoid	udelay        (unsigned long);
Svoid mdelay(unsigned long);
S
S/* lib/uuid.c */
Svoid uuid_str_to_bin(const char *uuid, unsigned char *out);
Sint uuid_str_valid(const char *uuid);
S
S/* lib/vsprintf.c */
S#include "vsprintf.h"
S
S/* lib/strmhz.c */
Schar *	strmhz(char *buf, unsigned long hz);
S
S/* lib/crc32.c */
S#include "crc.h"
S
S/* lib/rand.c */
S#if defined(CONFIG_RANDOM_MACADDR) || \
S	defined(CONFIG_BOOTP_RANDOM_DELAY) || \
S	defined(CONFIG_CMD_LINK_LOCAL)
X#if defined(CONFIG_RANDOM_MACADDR) || 	defined(CONFIG_BOOTP_RANDOM_DELAY) || 	defined(CONFIG_CMD_LINK_LOCAL)
S#define RAND_MAX -1U
Svoid srand(unsigned int seed);
Sunsigned int rand(void);
Sunsigned int rand_r(unsigned int *seedp);
S#endif
S
S/* common/console.c */
Sint	console_init_f(void);	/* Before relocation; uses the serial  stuff	*/
Sint	console_init_r(void);	/* After  relocation; uses the console stuff	*/
Sint	console_assign(int file, const char *devname);	/* Assign the console	*/
Sint	ctrlc (void);
Sint	had_ctrlc (void);	/* have we had a Control-C since last clear? */
Svoid	clear_ctrlc (void);	/* clear the Control-C condition */
Sint	disable_ctrlc (int);	/* 1 to disable, 0 to enable Control-C detect */
S
S/*
S * STDIO based functions (can always be used)
S */
S/* serial stuff */
Sint	serial_printf (const char *fmt, ...)
S		__attribute__ ((format (__printf__, 1, 2)));
S/* stdin */
S// int	getc(void);
S// int	tstc(void);
S
S/* stdout */
S// void	putc(const char c);
S// void	puts(const char *s);
S// int	printf(const char *fmt, ...)
S// 		__attribute__ ((format (__printf__, 1, 2)));
Sint	vprintf(const char *fmt, va_list args);
S
S/* stderr */
S#define eputc(c)		fputc(stderr, c)
S#define eputs(s)		fputs(stderr, s)
S#define eprintf(fmt,args...)	fprintf(stderr,fmt ,##args)
S
S/*
S * FILE based functions (can only be used AFTER relocation!)
S */
S#define stdin		0
S#define stdout		1
S#define stderr		2
S#define MAX_FILES	3
S
Sint	fprintf(int file, const char *fmt, ...)
S		__attribute__ ((format (__printf__, 2, 3)));
Svoid	fputs(int file, const char *s);
Svoid	fputc(int file, const char c);
Sint	ftstc(int file);
Sint	fgetc(int file);
S
S/* lib/gzip.c */
Sint gzip(void *dst, unsigned long *lenp,
S		unsigned char *src, unsigned long srclen);
Sint zzip(void *dst, unsigned long *lenp, unsigned char *src,
S		unsigned long srclen, int stoponerr,
S		int (*func)(unsigned long, unsigned long));
S
S/* lib/net_utils.c */
S// #include <net.h>
S// static __inline IPaddr_t getenv_IPaddr(char *var)
S// {
S// 	return string_to_ip(getenv(var));
S// }
S
S/*
S * CONSOLE multiplexing.
S */
S#ifdef CONFIG_CONSOLE_MUX
S#include <iomux.h>
S#endif
S
Sint	pcmcia_init (void);
S
S#ifdef CONFIG_STATUS_LED
S# include <status_led.h>
S#endif
S
S#include "bootstage.h"
S
S#ifdef CONFIG_SHOW_ACTIVITY
Svoid show_activity(int arg);
S#endif
S
S/* Multicore arch functions */
S#ifdef CONFIG_MP
Sint cpu_status(int nr);
Sint cpu_reset(int nr);
Sint cpu_disable(int nr);
Sint cpu_release(int nr, int argc, char * const argv[]);
S#endif
S
S/* Define a null map_sysmem() if the architecture doesn't use it */
S# ifndef CONFIG_ARCH_MAP_SYSMEM
Sstatic __inline void *map_sysmem(phys_addr_t paddr, unsigned long len)
S{
S	return (void *)(uintptr_t)paddr;
S}
S
Sstatic __inline void unmap_sysmem(const void *vaddr)
S{
S}
S# endif
S
S#endif /* __ASSEMBLY__ */
S
S#ifdef CONFIG_PPC
S/*
S * Has to be included outside of the #ifndef __ASSEMBLY__ section.
S * Otherwise might lead to compilation errors in assembler files.
S */
S#include <asm/cache.h>
S#endif
S
S/* Put only stuff here that the assembler can digest */
S
S#ifdef CONFIG_POST
S#define CONFIG_HAS_POST
S#ifndef CONFIG_POST_ALT_LIST
S#define CONFIG_POST_STD_LIST
S#endif
S#endif
S
S#ifdef CONFIG_INIT_CRITICAL
S#error CONFIG_INIT_CRITICAL is deprecated!
S#error Read section CONFIG_SKIP_LOWLEVEL_INIT in README.
S#endif
S
S#define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))
S
S#define ROUND(a,b)		(((a) + (b) - 1) & ~((b) - 1))
S#define DIV_ROUND(n,d)		(((n) + ((d)/2)) / (d))
S#define DIV_ROUND_UP(n,d)	(((n) + (d) - 1) / (d))
S#define roundup(x, y)		((((x) + ((y) - 1)) / (y)) * (y))
S
S#define ALIGN(x,a)		__ALIGN_MASK((x),(typeof(x))(a)-1)
S#define __ALIGN_MASK(x,mask)	(((x)+(mask))&~(mask))
S
S/*
S * ARCH_DMA_MINALIGN is defined in asm/cache.h for each architecture.  It
S * is used to align DMA buffers.
S */
S#ifndef __ASSEMBLY__
S#include "asm/cache.h"
S#endif
S
S/*
S * The ALLOC_CACHE_ALIGN_BUFFER macro is used to allocate a buffer on the
S * stack that meets the minimum architecture alignment requirements for DMA.
S * Such a buffer is useful for DMA operations where flushing and invalidating
S * the cache before and after a read and/or write operation is required for
S * correct operations.
S *
S * When called the macro creates an array on the stack that is sized such
S * that:
S *
S * 1) The beginning of the array can be advanced enough to be aligned.
S *
S * 2) The size of the aligned portion of the array is a multiple of the minimum
S *    architecture alignment required for DMA.
S *
S * 3) The aligned portion contains enough space for the original number of
S *    elements requested.
S *
S * The macro then creates a pointer to the aligned portion of this array and
S * assigns to the pointer the address of the first element in the aligned
S * portion of the array.
S *
S * Calling the macro as:
S *
S *     ALLOC_CACHE_ALIGN_BUFFER(uint32_t, buffer, 1024);
S *
S * Will result in something similar to saying:
S *
S *     uint32_t    buffer[1024];
S *
S * The following differences exist:
S *
S * 1) The resulting buffer is guaranteed to be aligned to the value of
S *    ARCH_DMA_MINALIGN.
S *
S * 2) The buffer variable created by the macro is a pointer to the specified
S *    type, and NOT an array of the specified type.  This can be very important
S *    if you want the address of the buffer, which you probably do, to pass it
S *    to the DMA hardware.  The value of &buffer is different in the two cases.
S *    In the macro case it will be the address of the pointer, not the address
S *    of the space reserved for the buffer.  However, in the second case it
S *    would be the address of the buffer.  So if you are replacing hard coded
S *    stack buffers with this macro you need to make sure you remove the & from
S *    the locations where you are taking the address of the buffer.
S *
S * Note that the size parameter is the number of array elements to allocate,
S * not the number of bytes.
S *
S * This macro can not be used outside of function scope, or for the creation
S * of a function scoped static buffer.  It can not be used to create a cache
S * line aligned global buffer.
S */
S#define ALLOC_ALIGN_BUFFER(type, name, size, align)			\
S	char __##name[ROUND(size * sizeof(type), align) + (align - 1)];	\
S									\
S	type *name = (type *) ALIGN((uintptr_t)__##name, align)
X#define ALLOC_ALIGN_BUFFER(type, name, size, align)				char __##name[ROUND(size * sizeof(type), align) + (align - 1)];											type *name = (type *) ALIGN((uintptr_t)__##name, align)
S#define ALLOC_CACHE_ALIGN_BUFFER(type, name, size)			\
S	ALLOC_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
X#define ALLOC_CACHE_ALIGN_BUFFER(type, name, size)				ALLOC_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
S
S/*
S * DEFINE_CACHE_ALIGN_BUFFER() is similar to ALLOC_CACHE_ALIGN_BUFFER, but it's
S * purpose is to allow allocating aligned buffers outside of function scope.
S * Usage of this macro shall be avoided or used with extreme care!
S */
S#define DEFINE_ALIGN_BUFFER(type, name, size, align)			\
S	static char __##name[roundup(size * sizeof(type), align)]	\
S			__attribute__((aligned(align)));				\
S									\
S	static type *name = (type *)__##name
X#define DEFINE_ALIGN_BUFFER(type, name, size, align)				static char __##name[roundup(size * sizeof(type), align)]				__attribute__((aligned(align)));														static type *name = (type *)__##name
S#define DEFINE_CACHE_ALIGN_BUFFER(type, name, size)			\
S	DEFINE_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
X#define DEFINE_CACHE_ALIGN_BUFFER(type, name, size)				DEFINE_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
S
S/* Pull in stuff for the build system */
S#ifdef DO_DEPS_ONLY
S# include <environment.h>
S#endif
S
S#endif	/* __COMMON_H_ */
N#endif // if 0
L 36 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N
N#define ENOTSUPP	524	/* Operation is not supported */
N
N#include "malloc.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\malloc.h" 1
N/*
N  A version of malloc/free/realloc written by Doug Lea and released to the
N  public domain.  Send questions/comments/complaints/performance data
N  to dl@cs.oswego.edu
N
N* VERSION 2.6.6  Sun Mar  5 19:10:03 2000  Doug Lea  (dl at gee)
N
N   Note: There may be an updated version of this malloc obtainable at
N	   ftp://g.oswego.edu/pub/misc/malloc.c
N	 Check before installing!
N
N* Why use this malloc?
N
N  This is not the fastest, most space-conserving, most portable, or
N  most tunable malloc ever written. However it is among the fastest
N  while also being among the most space-conserving, portable and tunable.
N  Consistent balance across these factors results in a good general-purpose
N  allocator. For a high-level description, see
N     http://g.oswego.edu/dl/html/malloc.html
N
N* Synopsis of public routines
N
N  (Much fuller descriptions are contained in the program documentation below.)
N
N  malloc(size_t n);
N     Return a pointer to a newly allocated chunk of at least n bytes, or null
N     if no space is available.
N  free(Void_t* p);
N     Release the chunk of memory pointed to by p, or no effect if p is null.
N  realloc(Void_t* p, size_t n);
N     Return a pointer to a chunk of size n that contains the same data
N     as does chunk p up to the minimum of (n, p's size) bytes, or null
N     if no space is available. The returned pointer may or may not be
N     the same as p. If p is null, equivalent to malloc.  Unless the
N     #define REALLOC_ZERO_BYTES_FREES below is set, realloc with a
N     size argument of zero (re)allocates a minimum-sized chunk.
N  memalign(size_t alignment, size_t n);
N     Return a pointer to a newly allocated chunk of n bytes, aligned
N     in accord with the alignment argument, which must be a power of
N     two.
N  valloc(size_t n);
N     Equivalent to memalign(pagesize, n), where pagesize is the page
N     size of the system (or as near to this as can be figured out from
N     all the includes/defines below.)
N  pvalloc(size_t n);
N     Equivalent to valloc(minimum-page-that-holds(n)), that is,
N     round up n to nearest pagesize.
N  calloc(size_t unit, size_t quantity);
N     Returns a pointer to quantity * unit bytes, with all locations
N     set to zero.
N  cfree(Void_t* p);
N     Equivalent to free(p).
N  malloc_trim(size_t pad);
N     Release all but pad bytes of freed top-most memory back
N     to the system. Return 1 if successful, else 0.
N  malloc_usable_size(Void_t* p);
N     Report the number usable allocated bytes associated with allocated
N     chunk p. This may or may not report more bytes than were requested,
N     due to alignment and minimum size constraints.
N  malloc_stats();
N     Prints brief summary statistics on stderr.
N  mallinfo()
N     Returns (by copy) a struct containing various summary statistics.
N  mallopt(int parameter_number, int parameter_value)
N     Changes one of the tunable parameters described below. Returns
N     1 if successful in changing the parameter, else 0.
N
N* Vital statistics:
N
N  Alignment:                            8-byte
N       8 byte alignment is currently hardwired into the design.  This
N       seems to suffice for all current machines and C compilers.
N
N  Assumed pointer representation:       4 or 8 bytes
N       Code for 8-byte pointers is untested by me but has worked
N       reliably by Wolfram Gloger, who contributed most of the
N       changes supporting this.
N
N  Assumed size_t  representation:       4 or 8 bytes
N       Note that size_t is allowed to be 4 bytes even if pointers are 8.
N
N  Minimum overhead per allocated chunk: 4 or 8 bytes
N       Each malloced chunk has a hidden overhead of 4 bytes holding size
N       and status information.
N
N  Minimum allocated size: 4-byte ptrs:  16 bytes    (including 4 overhead)
N			  8-byte ptrs:  24/32 bytes (including, 4/8 overhead)
N
N       When a chunk is freed, 12 (for 4byte ptrs) or 20 (for 8 byte
N       ptrs but 4 byte size) or 24 (for 8/8) additional bytes are
N       needed; 4 (8) for a trailing size field
N       and 8 (16) bytes for free list pointers. Thus, the minimum
N       allocatable size is 16/24/32 bytes.
N
N       Even a request for zero bytes (i.e., malloc(0)) returns a
N       pointer to something of the minimum allocatable size.
N
N  Maximum allocated size: 4-byte size_t: 2^31 -  8 bytes
N			  8-byte size_t: 2^63 - 16 bytes
N
N       It is assumed that (possibly signed) size_t bit values suffice to
N       represent chunk sizes. `Possibly signed' is due to the fact
N       that `size_t' may be defined on a system as either a signed or
N       an unsigned type. To be conservative, values that would appear
N       as negative numbers are avoided.
N       Requests for sizes with a negative sign bit when the request
N       size is treaded as a long will return null.
N
N  Maximum overhead wastage per allocated chunk: normally 15 bytes
N
N       Alignnment demands, plus the minimum allocatable size restriction
N       make the normal worst-case wastage 15 bytes (i.e., up to 15
N       more bytes will be allocated than were requested in malloc), with
N       two exceptions:
N	 1. Because requests for zero bytes allocate non-zero space,
N	    the worst case wastage for a request of zero bytes is 24 bytes.
N	 2. For requests >= mmap_threshold that are serviced via
N	    mmap(), the worst case wastage is 8 bytes plus the remainder
N	    from a system page (the minimal mmap unit); typically 4096 bytes.
N
N* Limitations
N
N    Here are some features that are NOT currently supported
N
N    * No user-definable hooks for callbacks and the like.
N    * No automated mechanism for fully checking that all accesses
N      to malloced memory stay within their bounds.
N    * No support for compaction.
N
N* Synopsis of compile-time options:
N
N    People have reported using previous versions of this malloc on all
N    versions of Unix, sometimes by tweaking some of the defines
N    below. It has been tested most extensively on Solaris and
N    Linux. It is also reported to work on WIN32 platforms.
N    People have also reported adapting this malloc for use in
N    stand-alone embedded systems.
N
N    The implementation is in straight, hand-tuned ANSI C.  Among other
N    consequences, it uses a lot of macros.  Because of this, to be at
N    all usable, this code should be compiled using an optimizing compiler
N    (for example gcc -O2) that can simplify expressions and control
N    paths.
N
N  __STD_C                  (default: derived from C compiler defines)
N     Nonzero if using ANSI-standard C compiler, a C++ compiler, or
N     a C compiler sufficiently close to ANSI to get away with it.
N  DEBUG                    (default: NOT defined)
N     Define to enable debugging. Adds fairly extensive assertion-based
N     checking to help track down memory errors, but noticeably slows down
N     execution.
N  REALLOC_ZERO_BYTES_FREES (default: NOT defined)
N     Define this if you think that realloc(p, 0) should be equivalent
N     to free(p). Otherwise, since malloc returns a unique pointer for
N     malloc(0), so does realloc(p, 0).
N  HAVE_MEMCPY               (default: defined)
N     Define if you are not otherwise using ANSI STD C, but still
N     have memcpy and memset in your C library and want to use them.
N     Otherwise, simple internal versions are supplied.
N  USE_MEMCPY               (default: 1 if HAVE_MEMCPY is defined, 0 otherwise)
N     Define as 1 if you want the C library versions of memset and
N     memcpy called in realloc and calloc (otherwise macro versions are used).
N     At least on some platforms, the simple macro versions usually
N     outperform libc versions.
N  HAVE_MMAP                 (default: defined as 1)
N     Define to non-zero to optionally make malloc() use mmap() to
N     allocate very large blocks.
N  HAVE_MREMAP                 (default: defined as 0 unless Linux libc set)
N     Define to non-zero to optionally make realloc() use mremap() to
N     reallocate very large blocks.
N  malloc_getpagesize        (default: derived from system #includes)
N     Either a constant or routine call returning the system page size.
N  HAVE_USR_INCLUDE_MALLOC_H (default: NOT defined)
N     Optionally define if you are on a system with a /usr/include/malloc.h
N     that declares struct mallinfo. It is not at all necessary to
N     define this even if you do, but will ensure consistency.
N  INTERNAL_SIZE_T           (default: size_t)
N     Define to a 32-bit type (probably `unsigned int') if you are on a
N     64-bit machine, yet do not want or need to allow malloc requests of
N     greater than 2^31 to be handled. This saves space, especially for
N     very small chunks.
N  INTERNAL_LINUX_C_LIB      (default: NOT defined)
N     Defined only when compiled as part of Linux libc.
N     Also note that there is some odd internal name-mangling via defines
N     (for example, internally, `malloc' is named `mALLOc') needed
N     when compiling in this case. These look funny but don't otherwise
N     affect anything.
N  WIN32                     (default: undefined)
N     Define this on MS win (95, nt) platforms to compile in sbrk emulation.
N  LACKS_UNISTD_H            (default: undefined if not WIN32)
N     Define this if your system does not have a <unistd.h>.
N  LACKS_SYS_PARAM_H         (default: undefined if not WIN32)
N     Define this if your system does not have a <sys/param.h>.
N  MORECORE                  (default: sbrk)
N     The name of the routine to call to obtain more memory from the system.
N  MORECORE_FAILURE          (default: -1)
N     The value returned upon failure of MORECORE.
N  MORECORE_CLEARS           (default 1)
N     true (1) if the routine mapped to MORECORE zeroes out memory (which
N     holds for sbrk).
N  DEFAULT_TRIM_THRESHOLD
N  DEFAULT_TOP_PAD
N  DEFAULT_MMAP_THRESHOLD
N  DEFAULT_MMAP_MAX
N     Default values of tunable parameters (described in detail below)
N     controlling interaction with host system routines (sbrk, mmap, etc).
N     These values may also be changed dynamically via mallopt(). The
N     preset defaults are those that give best performance for typical
N     programs/systems.
N  USE_DL_PREFIX             (default: undefined)
N     Prefix all public routines with the string 'dl'.  Useful to
N     quickly avoid procedure declaration conflicts and linker symbol
N     conflicts with existing memory allocation routines.
N
N
N*/
N
N
N#ifndef __MALLOC_H__
N#define __MALLOC_H__
N
N/* Preliminaries */
N
N#ifndef __STD_C
N#ifdef __STDC__
N#define __STD_C     1
N#else
S#if __cplusplus
S#define __STD_C     1
S#else
S#define __STD_C     0
S#endif /*__cplusplus*/
N#endif /*__STDC__*/
N#endif /*__STD_C*/
N
N#ifndef Void_t
N#if (__STD_C || defined(WIN32))
X#if (1 || 0L)
N#define Void_t      void
N#else
S#define Void_t      char
N#endif
N#endif /*Void_t*/
N
N#if __STD_C
X#if 1
N#include <linux/stddef.h>	/* for size_t */
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/stddef.h" 1
N#ifndef _LINUX_STDDEF_H
N#define _LINUX_STDDEF_H
N
N#undef NULL
N#if defined(__cplusplus)
X#if 0L
S#define NULL 0
N#else
N#define NULL ((void *)0)
N#endif
N
N#ifndef _SIZE_T
N#include "linux\types.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\types.h" 1
N#ifndef _LINUX_TYPES_H
N#define _LINUX_TYPES_H
N
N#ifdef	__KERNEL__
S#include <linux/config.h>
N#endif
N
N#include "linux\posix_types.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\posix_types.h" 1
N#ifndef _LINUX_POSIX_TYPES_H
N#define _LINUX_POSIX_TYPES_H
N
N#include <linux/stddef.h>
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/stddef.h" 1
N#ifndef _LINUX_STDDEF_H
S#define _LINUX_STDDEF_H
S
S#undef NULL
S#if defined(__cplusplus)
S#define NULL 0
S#else
S#define NULL ((void *)0)
S#endif
S
S#ifndef _SIZE_T
S#include "linux\types.h"
S#endif
S
S#ifndef __CHECKER__
S#undef offsetof
S#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
S#endif
S
N#endif
L 5 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\posix_types.h" 2
N
N/*
N * This allows for 1024 file descriptors: if NR_OPEN is ever grown
N * beyond that you'll have to change this too. But 1024 fd's seem to be
N * enough even for such "real" unices like OSF/1, so hopefully this is
N * one limit that doesn't have to be changed [again].
N *
N * Note that POSIX wants the FD_CLEAR(fd,fdsetp) defines to be in
N * <sys/time.h> (and thus <linux/time.h>) - but this is a more logical
N * place for them. Solved by having dummy defines in <sys/time.h>.
N */
N
N/*
N * Those macros may have been defined in <gnu/types.h>. But we always
N * use the ones here.
N */
N#undef __NFDBITS
N#define __NFDBITS	(8 * sizeof(unsigned long))
N
N#undef __FD_SETSIZE
N#define __FD_SETSIZE	1024
N
N#undef __FDSET_LONGS
N#define __FDSET_LONGS	(__FD_SETSIZE/__NFDBITS)
N
N#undef __FDELT
N#define	__FDELT(d)	((d) / __NFDBITS)
N
N#undef __FDMASK
N#define	__FDMASK(d)	(1UL << ((d) % __NFDBITS))
N
Ntypedef struct {
N	unsigned long fds_bits [__FDSET_LONGS];
X	unsigned long fds_bits [(1024/(8 * sizeof(unsigned long)))];
N} __kernel_fd_set;
N
N/* Type of a signal handler.  */
Ntypedef void (*__kernel_sighandler_t)(int);
N
N/* Type of a SYSV IPC key.  */
Ntypedef int __kernel_key_t;
N
N#include <asm/posix_types.h>
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm/posix_types.h" 1
N/*
N *  linux/include/asm-arm/posix_types.h
N *
N *  Copyright (C) 1996-1998 Russell King.
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License version 2 as
N * published by the Free Software Foundation.
N *
N *  Changelog:
N *   27-06-1996	RMK	Created
N */
N#ifndef __ARCH_ARM_POSIX_TYPES_H
N#define __ARCH_ARM_POSIX_TYPES_H
N
N/*
N * This file is generally used by user-level software, so you need to
N * be a little careful about namespace pollution etc.  Also, we cannot
N * assume GCC is being used.
N */
N
Ntypedef unsigned short		__kernel_dev_t;
Ntypedef unsigned long		__kernel_ino_t;
Ntypedef unsigned short		__kernel_mode_t;
Ntypedef unsigned short		__kernel_nlink_t;
Ntypedef long			__kernel_off_t;
Ntypedef int			__kernel_pid_t;
Ntypedef unsigned short		__kernel_ipc_pid_t;
Ntypedef unsigned short		__kernel_uid_t;
Ntypedef unsigned short		__kernel_gid_t;
Ntypedef unsigned int		__kernel_size_t;
Ntypedef int			__kernel_ssize_t;
Ntypedef int			__kernel_ptrdiff_t;
Ntypedef long			__kernel_time_t;
Ntypedef long			__kernel_suseconds_t;
Ntypedef long			__kernel_clock_t;
Ntypedef int			__kernel_daddr_t;
Ntypedef char *			__kernel_caddr_t;
Ntypedef unsigned short		__kernel_uid16_t;
Ntypedef unsigned short		__kernel_gid16_t;
Ntypedef unsigned int		__kernel_uid32_t;
Ntypedef unsigned int		__kernel_gid32_t;
N
Ntypedef unsigned short		__kernel_old_uid_t;
Ntypedef unsigned short		__kernel_old_gid_t;
N
N#ifdef __GNUC__
Stypedef long long		__kernel_loff_t;
N#endif
N
Ntypedef struct {
N#if defined(__KERNEL__) || defined(__USE_ALL)
X#if 0L || 0L
S	int	val[2];
N#else /* !defined(__KERNEL__) && !defined(__USE_ALL) */
N	int	__val[2];
N#endif /* !defined(__KERNEL__) && !defined(__USE_ALL) */
N} __kernel_fsid_t;
N
N#if defined(__KERNEL__) || !defined(__GLIBC__) || (__GLIBC__ < 2)
X#if 0L || !0L || (__GLIBC__ < 2)
N
N#undef	__FD_SET
N#define __FD_SET(fd, fdsetp) \
N		(((fd_set *)fdsetp)->fds_bits[fd >> 5] |= (1<<(fd & 31)))
X#define __FD_SET(fd, fdsetp) 		(((fd_set *)fdsetp)->fds_bits[fd >> 5] |= (1<<(fd & 31)))
N
N#undef	__FD_CLR
N#define __FD_CLR(fd, fdsetp) \
N		(((fd_set *)fdsetp)->fds_bits[fd >> 5] &= ~(1<<(fd & 31)))
X#define __FD_CLR(fd, fdsetp) 		(((fd_set *)fdsetp)->fds_bits[fd >> 5] &= ~(1<<(fd & 31)))
N
N#undef	__FD_ISSET
N#define __FD_ISSET(fd, fdsetp) \
N		((((fd_set *)fdsetp)->fds_bits[fd >> 5] & (1<<(fd & 31))) != 0)
X#define __FD_ISSET(fd, fdsetp) 		((((fd_set *)fdsetp)->fds_bits[fd >> 5] & (1<<(fd & 31))) != 0)
N
N#undef	__FD_ZERO
N#define __FD_ZERO(fdsetp) \
N		(memset (fdsetp, 0, sizeof (*(fd_set *)fdsetp)))
X#define __FD_ZERO(fdsetp) 		(memset (fdsetp, 0, sizeof (*(fd_set *)fdsetp)))
N
N#endif
N
N#endif
L 47 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\posix_types.h" 2
N
N#endif /* _LINUX_POSIX_TYPES_H */
L 9 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\types.h" 2
N#include "asm\types.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm\types.h" 1
N#ifndef __ASM_ARM_TYPES_H
N#define __ASM_ARM_TYPES_H
N
Ntypedef unsigned short umode_t;
N
N/*
N * __xx is ok: it doesn't pollute the POSIX namespace. Use these in the
N * header files exported to user space
N */
N
Ntypedef char __s8;
Ntypedef unsigned char __u8;
N
Ntypedef short __s16;
Ntypedef unsigned short __u16;
N
Ntypedef int __s32;
Ntypedef unsigned int __u32;
N
Ntypedef long long __s64;
Ntypedef unsigned long long __u64;
N
N#if defined(__GNUC__)
X#if 0L
S__extension__ typedef __signed__ long long __s64;
S__extension__ typedef unsigned long long __u64;
N#endif
N
N/*
N * These aren't exported outside the kernel to avoid name space clashes
N */
N// #ifdef __KERNEL__
N
Ntypedef signed char s8;
Ntypedef unsigned char u8;
N
Ntypedef signed short s16;
Ntypedef unsigned short u16;
N
Ntypedef signed int s32;
Ntypedef unsigned int u32;
N
Ntypedef signed long long s64;
Ntypedef unsigned long long u64;
N
N#define BITS_PER_LONG 32
N
N/* Dma addresses are 32-bits wide.  */
N
Ntypedef u32 dma_addr_t;
N
Ntypedef unsigned long phys_addr_t;
Ntypedef unsigned long phys_size_t;
N
N// #endif /* __KERNEL__ */
N
N#endif
L 10 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\types.h" 2
N//#include "stdbool.h"
N
N#ifndef __KERNEL_STRICT_NAMES
N
Ntypedef __kernel_fd_set		fd_set;
Ntypedef __kernel_dev_t		dev_t;
Ntypedef __kernel_ino_t		ino_t;
Ntypedef __kernel_mode_t		mode_t;
Ntypedef __kernel_nlink_t	nlink_t;
Ntypedef __kernel_off_t		off_t;
Ntypedef __kernel_pid_t		pid_t;
Ntypedef __kernel_daddr_t	daddr_t;
Ntypedef __kernel_key_t		key_t;
Ntypedef __kernel_suseconds_t	suseconds_t;
N
N#ifdef __KERNEL__
Stypedef __kernel_uid32_t	uid_t;
Stypedef __kernel_gid32_t	gid_t;
Stypedef __kernel_uid16_t        uid16_t;
Stypedef __kernel_gid16_t        gid16_t;
S
S#ifdef CONFIG_UID16
S/* This is defined by include/asm-{arch}/posix_types.h */
Stypedef __kernel_old_uid_t	old_uid_t;
Stypedef __kernel_old_gid_t	old_gid_t;
S#endif /* CONFIG_UID16 */
S
S/* libc5 includes this file to define uid_t, thus uid_t can never change
S * when it is included by non-kernel code
S */
N#else
Ntypedef __kernel_uid_t		uid_t;
Ntypedef __kernel_gid_t		gid_t;
N#endif /* __KERNEL__ */
N
N#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
X#if 0L && !0L
Stypedef __kernel_loff_t		loff_t;
N#endif
Ntypedef long long		loff_t;
N
N/*
N * The following typedefs are also protected by individual ifdefs for
N * historical reasons:
N */
N#ifndef _SIZE_T
N#define _SIZE_T
Ntypedef __kernel_size_t		size_t;
N#endif
N
N#ifndef _SSIZE_T
N#define _SSIZE_T
Ntypedef __kernel_ssize_t	ssize_t;
N#endif
N
N#ifndef _PTRDIFF_T
N#define _PTRDIFF_T
Ntypedef __kernel_ptrdiff_t	ptrdiff_t;
N#endif
N
N#ifndef _TIME_T
N#define _TIME_T
Ntypedef __kernel_time_t		time_t;
N#endif
N
N#ifndef _CLOCK_T
N#define _CLOCK_T
Ntypedef __kernel_clock_t	clock_t;
N#endif
N
N#ifndef _CADDR_T
N#define _CADDR_T
Ntypedef __kernel_caddr_t	caddr_t;
N#endif
N
N/* bsd */
Ntypedef unsigned char		u_char;
Ntypedef unsigned short		u_short;
Ntypedef unsigned int		u_int;
Ntypedef unsigned long		u_long;
N
N/* sysv */
Ntypedef unsigned char		unchar;
Ntypedef unsigned short		ushort;
Ntypedef unsigned int		uint;
Ntypedef unsigned long		ulong;
N
N#ifndef __BIT_TYPES_DEFINED__
N#define __BIT_TYPES_DEFINED__
N
Ntypedef		__u8		u_int8_t;
N// typedef		__s8		int8_t;
Ntypedef		__u16		u_int16_t;
N// typedef		__s16		int16_t;
Ntypedef		__u32		u_int32_t;
N// typedef		__s32		int32_t;
N
N#endif /* !(__BIT_TYPES_DEFINED__) */
N
N// typedef		__u8		uint8_t;
N// typedef		__u16		uint16_t;
N// typedef		__u32		uint32_t;
N
N// #if defined(__GNUC__) && !defined(__STRICT_ANSI__)
Ntypedef		__u64		uint64_t;
Ntypedef		__u64		u_int64_t;
Ntypedef		__s64		int64_t;
N// #endif
N
N#endif /* __KERNEL_STRICT_NAMES */
N
N/*
N * Below are truly Linux-specific types that should never collide with
N * any application/library that wants linux/types.h.
N */
N#ifdef __CHECKER__
S#define __bitwise__ __attribute__((bitwise))
N#else
N#define __bitwise__
N#endif
N#ifdef __CHECK_ENDIAN__
S#define __bitwise __bitwise__
N#else
N#define __bitwise
N#endif
N
Ntypedef __u16 __bitwise __le16;
Xtypedef __u16  __le16;
Ntypedef __u16 __bitwise __be16;
Xtypedef __u16  __be16;
Ntypedef __u32 __bitwise __le32;
Xtypedef __u32  __le32;
Ntypedef __u32 __bitwise __be32;
Xtypedef __u32  __be32;
N// #if defined(__GNUC__)
Ntypedef __u64 __bitwise __le64;
Xtypedef __u64  __le64;
Ntypedef __u64 __bitwise __be64;
Xtypedef __u64  __be64;
N// #endif
Ntypedef __u16 __bitwise __sum16;
Xtypedef __u16  __sum16;
Ntypedef __u32 __bitwise __wsum;
Xtypedef __u32  __wsum;
N
N
Ntypedef unsigned __bitwise__	gfp_t;
Xtypedef unsigned 	gfp_t;
N
Nstruct ustat {
N	__kernel_daddr_t	f_tfree;
N	__kernel_ino_t		f_tinode;
N	char			f_fname[6];
N	char			f_fpack[6];
N};
N
N#endif /* _LINUX_TYPES_H */
L 13 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/stddef.h" 2
N#endif
N
N#ifndef __CHECKER__
N#undef offsetof
N#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
N#endif
N
N#endif
L 246 "..\..\common\src\BSP\ThirdParty\yaffs2\include\malloc.h" 2
N#else
S#include <sys/types.h>
N#endif	/* __STD_C */
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N#if 0	/* not for U-Boot */
S#include <stdio.h>	/* needed for malloc_stats */
N#endif
N
N
N/*
N  Compile-time options
N*/
N
N
N/*
N    Debugging:
N
N    Because freed chunks may be overwritten with link fields, this
N    malloc will often die when freed memory is overwritten by user
N    programs.  This can be very effective (albeit in an annoying way)
N    in helping track down dangling pointers.
N
N    If you compile with -DDEBUG, a number of assertion checks are
N    enabled that will catch more memory errors. You probably won't be
N    able to make much sense of the actual assertion errors, but they
N    should help you locate incorrectly overwritten memory.  The
N    checking is fairly extensive, and will slow down execution
N    noticeably. Calling malloc_stats or mallinfo with DEBUG set will
N    attempt to check every non-mmapped allocated and free chunk in the
N    course of computing the summmaries. (By nature, mmapped regions
N    cannot be checked very much automatically.)
N
N    Setting DEBUG may also be helpful if you are trying to modify
N    this code. The assertions in the check routines spell out in more
N    detail the assumptions and invariants underlying the algorithms.
N
N*/
N
N/*
N  INTERNAL_SIZE_T is the word-size used for internal bookkeeping
N  of chunk sizes. On a 64-bit machine, you can reduce malloc
N  overhead by defining INTERNAL_SIZE_T to be a 32 bit `unsigned int'
N  at the expense of not being able to handle requests greater than
N  2^31. This limitation is hardly ever a concern; you are encouraged
N  to set this. However, the default version is the same as size_t.
N*/
N
N#ifndef INTERNAL_SIZE_T
N#define INTERNAL_SIZE_T size_t
N#endif
N
N/*
N  REALLOC_ZERO_BYTES_FREES should be set if a call to
N  realloc with zero bytes should be the same as a call to free.
N  Some people think it should. Otherwise, since this malloc
N  returns a unique pointer for malloc(0), so does realloc(p, 0).
N*/
N
N
N/*   #define REALLOC_ZERO_BYTES_FREES */
N
N
N/*
N  WIN32 causes an emulation of sbrk to be compiled in
N  mmap-based options are not currently supported in WIN32.
N*/
N
N/* #define WIN32 */
N#ifdef WIN32
S#define MORECORE wsbrk
S#define HAVE_MMAP 0
S
S#define LACKS_UNISTD_H
S#define LACKS_SYS_PARAM_H
S
S/*
S  Include 'windows.h' to get the necessary declarations for the
S  Microsoft Visual C++ data structures and routines used in the 'sbrk'
S  emulation.
S
S  Define WIN32_LEAN_AND_MEAN so that only the essential Microsoft
S  Visual C++ header files are included.
S*/
S#define WIN32_LEAN_AND_MEAN
S#include <windows.h>
N#endif
N
N
N/*
N  HAVE_MEMCPY should be defined if you are not otherwise using
N  ANSI STD C, but still have memcpy and memset in your C library
N  and want to use them in calloc and realloc. Otherwise simple
N  macro versions are defined here.
N
N  USE_MEMCPY should be defined as 1 if you actually want to
N  have memset and memcpy called. People report that the macro
N  versions are often enough faster than libc versions on many
N  systems that it is better to use them.
N
N*/
N
N#define HAVE_MEMCPY
N
N#ifndef USE_MEMCPY
N#ifdef HAVE_MEMCPY
N#define USE_MEMCPY 1
N#else
S#define USE_MEMCPY 0
N#endif
N#endif
N
N#if (__STD_C || defined(HAVE_MEMCPY))
X#if (1 || 1L)
N
N#if __STD_C
X#if 1
Nvoid* memset(void*, int, size_t);
Nvoid* memcpy(void*, const void*, size_t);
N#else
S#ifdef WIN32
S/* On Win32 platforms, 'memset()' and 'memcpy()' are already declared in */
S/* 'windows.h' */
S#else
SVoid_t* memset();
SVoid_t* memcpy();
S#endif
N#endif
N#endif
N
N#if USE_MEMCPY
X#if 1
N
N/* The following macros are only invoked with (2n+1)-multiples of
N   INTERNAL_SIZE_T units, with a positive integer n. This is exploited
N   for fast inline execution when n is small. */
N
N#define MALLOC_ZERO(charp, nbytes)                                            \
Ndo {                                                                          \
N  INTERNAL_SIZE_T mzsz = (nbytes);                                            \
N  if(mzsz <= 9*sizeof(mzsz)) {                                                \
N    INTERNAL_SIZE_T* mz = (INTERNAL_SIZE_T*) (charp);                         \
N    if(mzsz >= 5*sizeof(mzsz)) {     *mz++ = 0;                               \
N				     *mz++ = 0;                               \
N      if(mzsz >= 7*sizeof(mzsz)) {   *mz++ = 0;                               \
N				     *mz++ = 0;                               \
N	if(mzsz >= 9*sizeof(mzsz)) { *mz++ = 0;                               \
N				     *mz++ = 0; }}}                           \
N				     *mz++ = 0;                               \
N				     *mz++ = 0;                               \
N				     *mz   = 0;                               \
N  } else memset((charp), 0, mzsz);                                            \
N} while(0)
X#define MALLOC_ZERO(charp, nbytes)                                            do {                                                                            INTERNAL_SIZE_T mzsz = (nbytes);                                              if(mzsz <= 9*sizeof(mzsz)) {                                                    INTERNAL_SIZE_T* mz = (INTERNAL_SIZE_T*) (charp);                             if(mzsz >= 5*sizeof(mzsz)) {     *mz++ = 0;                               				     *mz++ = 0;                                     if(mzsz >= 7*sizeof(mzsz)) {   *mz++ = 0;                               				     *mz++ = 0;                               	if(mzsz >= 9*sizeof(mzsz)) { *mz++ = 0;                               				     *mz++ = 0; }}}                           				     *mz++ = 0;                               				     *mz++ = 0;                               				     *mz   = 0;                                 } else memset((charp), 0, mzsz);                                            } while(0)
N
N#define MALLOC_COPY(dest,src,nbytes)                                          \
Ndo {                                                                          \
N  INTERNAL_SIZE_T mcsz = (nbytes);                                            \
N  if(mcsz <= 9*sizeof(mcsz)) {                                                \
N    INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) (src);                        \
N    INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) (dest);                       \
N    if(mcsz >= 5*sizeof(mcsz)) {     *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++;                     \
N      if(mcsz >= 7*sizeof(mcsz)) {   *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++;                     \
N	if(mcsz >= 9*sizeof(mcsz)) { *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++; }}}                 \
N				     *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++;                     \
N				     *mcdst   = *mcsrc  ;                     \
N  } else memcpy(dest, src, mcsz);                                             \
N} while(0)
X#define MALLOC_COPY(dest,src,nbytes)                                          do {                                                                            INTERNAL_SIZE_T mcsz = (nbytes);                                              if(mcsz <= 9*sizeof(mcsz)) {                                                    INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) (src);                            INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) (dest);                           if(mcsz >= 5*sizeof(mcsz)) {     *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++;                           if(mcsz >= 7*sizeof(mcsz)) {   *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++;                     	if(mcsz >= 9*sizeof(mcsz)) { *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++; }}}                 				     *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++;                     				     *mcdst   = *mcsrc  ;                       } else memcpy(dest, src, mcsz);                                             } while(0)
N
N#else /* !USE_MEMCPY */
S
S/* Use Duff's device for good zeroing/copying performance. */
S
S#define MALLOC_ZERO(charp, nbytes)                                            \
Sdo {                                                                          \
S  INTERNAL_SIZE_T* mzp = (INTERNAL_SIZE_T*)(charp);                           \
S  long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                         \
S  if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }             \
S  switch (mctmp) {                                                            \
S    case 0: for(;;) { *mzp++ = 0;                                             \
S    case 7:           *mzp++ = 0;                                             \
S    case 6:           *mzp++ = 0;                                             \
S    case 5:           *mzp++ = 0;                                             \
S    case 4:           *mzp++ = 0;                                             \
S    case 3:           *mzp++ = 0;                                             \
S    case 2:           *mzp++ = 0;                                             \
S    case 1:           *mzp++ = 0; if(mcn <= 0) break; mcn--; }                \
S  }                                                                           \
S} while(0)
X#define MALLOC_ZERO(charp, nbytes)                                            do {                                                                            INTERNAL_SIZE_T* mzp = (INTERNAL_SIZE_T*)(charp);                             long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                           if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }               switch (mctmp) {                                                                case 0: for(;;) { *mzp++ = 0;                                                 case 7:           *mzp++ = 0;                                                 case 6:           *mzp++ = 0;                                                 case 5:           *mzp++ = 0;                                                 case 4:           *mzp++ = 0;                                                 case 3:           *mzp++ = 0;                                                 case 2:           *mzp++ = 0;                                                 case 1:           *mzp++ = 0; if(mcn <= 0) break; mcn--; }                  }                                                                           } while(0)
S
S#define MALLOC_COPY(dest,src,nbytes)                                          \
Sdo {                                                                          \
S  INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) src;                            \
S  INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) dest;                           \
S  long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                         \
S  if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }             \
S  switch (mctmp) {                                                            \
S    case 0: for(;;) { *mcdst++ = *mcsrc++;                                    \
S    case 7:           *mcdst++ = *mcsrc++;                                    \
S    case 6:           *mcdst++ = *mcsrc++;                                    \
S    case 5:           *mcdst++ = *mcsrc++;                                    \
S    case 4:           *mcdst++ = *mcsrc++;                                    \
S    case 3:           *mcdst++ = *mcsrc++;                                    \
S    case 2:           *mcdst++ = *mcsrc++;                                    \
S    case 1:           *mcdst++ = *mcsrc++; if(mcn <= 0) break; mcn--; }       \
S  }                                                                           \
S} while(0)
X#define MALLOC_COPY(dest,src,nbytes)                                          do {                                                                            INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) src;                              INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) dest;                             long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                           if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }               switch (mctmp) {                                                                case 0: for(;;) { *mcdst++ = *mcsrc++;                                        case 7:           *mcdst++ = *mcsrc++;                                        case 6:           *mcdst++ = *mcsrc++;                                        case 5:           *mcdst++ = *mcsrc++;                                        case 4:           *mcdst++ = *mcsrc++;                                        case 3:           *mcdst++ = *mcsrc++;                                        case 2:           *mcdst++ = *mcsrc++;                                        case 1:           *mcdst++ = *mcsrc++; if(mcn <= 0) break; mcn--; }         }                                                                           } while(0)
S
N#endif
N
N
N/*
N  Define HAVE_MMAP to optionally make malloc() use mmap() to
N  allocate very large blocks.  These will be returned to the
N  operating system immediately after a free().
N*/
N
N/***
N#ifndef HAVE_MMAP
N#define HAVE_MMAP 1
N#endif
N***/
N#undef	HAVE_MMAP	/* Not available for U-Boot */
N
N/*
N  Define HAVE_MREMAP to make realloc() use mremap() to re-allocate
N  large blocks.  This is currently only possible on Linux with
N  kernel versions newer than 1.3.77.
N*/
N
N/***
N#ifndef HAVE_MREMAP
N#ifdef INTERNAL_LINUX_C_LIB
N#define HAVE_MREMAP 1
N#else
N#define HAVE_MREMAP 0
N#endif
N#endif
N***/
N#undef	HAVE_MREMAP	/* Not available for U-Boot */
N
N#ifdef HAVE_MMAP
S
S#include <unistd.h>
S#include <fcntl.h>
S#include <sys/mman.h>
S
S#if !defined(MAP_ANONYMOUS) && defined(MAP_ANON)
S#define MAP_ANONYMOUS MAP_ANON
S#endif
S
N#endif /* HAVE_MMAP */
N
N/*
N  Access to system page size. To the extent possible, this malloc
N  manages memory from the system in page-size units.
N
N  The following mechanics for getpagesize were adapted from
N  bsd/gnu getpagesize.h
N*/
N
N#define	LACKS_UNISTD_H	/* Shortcut for U-Boot */
N#define	malloc_getpagesize	4096
N
N#ifndef LACKS_UNISTD_H
S#  include <unistd.h>
N#endif
N
N#ifndef malloc_getpagesize
S#  ifdef _SC_PAGESIZE         /* some SVR4 systems omit an underscore */
S#    ifndef _SC_PAGE_SIZE
S#      define _SC_PAGE_SIZE _SC_PAGESIZE
S#    endif
S#  endif
S#  ifdef _SC_PAGE_SIZE
S#    define malloc_getpagesize sysconf(_SC_PAGE_SIZE)
S#  else
S#    if defined(BSD) || defined(DGUX) || defined(HAVE_GETPAGESIZE)
S       extern size_t getpagesize();
S#      define malloc_getpagesize getpagesize()
S#    else
S#      ifdef WIN32
S#        define malloc_getpagesize (4096) /* TBD: Use 'GetSystemInfo' instead */
S#      else
S#        ifndef LACKS_SYS_PARAM_H
S#          include <sys/param.h>
S#        endif
S#        ifdef EXEC_PAGESIZE
S#          define malloc_getpagesize EXEC_PAGESIZE
S#        else
S#          ifdef NBPG
S#            ifndef CLSIZE
S#              define malloc_getpagesize NBPG
S#            else
S#              define malloc_getpagesize (NBPG * CLSIZE)
S#            endif
S#          else
S#            ifdef NBPC
S#              define malloc_getpagesize NBPC
S#            else
S#              ifdef PAGESIZE
S#                define malloc_getpagesize PAGESIZE
S#              else
S#                define malloc_getpagesize (4096) /* just guess */
S#              endif
S#            endif
S#          endif
S#        endif
S#      endif
S#    endif
S#  endif
N#endif
N
N
N/*
N
N  This version of malloc supports the standard SVID/XPG mallinfo
N  routine that returns a struct containing the same kind of
N  information you can get from malloc_stats. It should work on
N  any SVID/XPG compliant system that has a /usr/include/malloc.h
N  defining struct mallinfo. (If you'd like to install such a thing
N  yourself, cut out the preliminary declarations as described above
N  and below and save them in a malloc.h file. But there's no
N  compelling reason to bother to do this.)
N
N  The main declaration needed is the mallinfo struct that is returned
N  (by-copy) by mallinfo().  The SVID/XPG malloinfo struct contains a
N  bunch of fields, most of which are not even meaningful in this
N  version of malloc. Some of these fields are are instead filled by
N  mallinfo() with other numbers that might possibly be of interest.
N
N  HAVE_USR_INCLUDE_MALLOC_H should be set if you have a
N  /usr/include/malloc.h file that includes a declaration of struct
N  mallinfo.  If so, it is included; else an SVID2/XPG2 compliant
N  version is declared below.  These must be precisely the same for
N  mallinfo() to work.
N
N*/
N
N/* #define HAVE_USR_INCLUDE_MALLOC_H */
N
N#ifdef HAVE_USR_INCLUDE_MALLOC_H
S#include "/usr/include/malloc.h"
N#else
N
N/* SVID2/XPG mallinfo structure */
N
Nstruct mallinfo {
N  int arena;    /* total space allocated from system */
N  int ordblks;  /* number of non-inuse chunks */
N  int smblks;   /* unused -- always zero */
N  int hblks;    /* number of mmapped regions */
N  int hblkhd;   /* total space in mmapped regions */
N  int usmblks;  /* unused -- always zero */
N  int fsmblks;  /* unused -- always zero */
N  int uordblks; /* total allocated space */
N  int fordblks; /* total non-inuse space */
N  int keepcost; /* top-most, releasable (via malloc_trim) space */
N};
N
N/* SVID2/XPG mallopt options */
N
N#define M_MXFAST  1    /* UNUSED in this malloc */
N#define M_NLBLKS  2    /* UNUSED in this malloc */
N#define M_GRAIN   3    /* UNUSED in this malloc */
N#define M_KEEP    4    /* UNUSED in this malloc */
N
N#endif
N
N/* mallopt options that actually do something */
N
N#define M_TRIM_THRESHOLD    -1
N#define M_TOP_PAD           -2
N#define M_MMAP_THRESHOLD    -3
N#define M_MMAP_MAX          -4
N
N
N#ifndef DEFAULT_TRIM_THRESHOLD
N#define DEFAULT_TRIM_THRESHOLD (128 * 1024)
N#endif
N
N/*
N    M_TRIM_THRESHOLD is the maximum amount of unused top-most memory
N      to keep before releasing via malloc_trim in free().
N
N      Automatic trimming is mainly useful in long-lived programs.
N      Because trimming via sbrk can be slow on some systems, and can
N      sometimes be wasteful (in cases where programs immediately
N      afterward allocate more large chunks) the value should be high
N      enough so that your overall system performance would improve by
N      releasing.
N
N      The trim threshold and the mmap control parameters (see below)
N      can be traded off with one another. Trimming and mmapping are
N      two different ways of releasing unused memory back to the
N      system. Between these two, it is often possible to keep
N      system-level demands of a long-lived program down to a bare
N      minimum. For example, in one test suite of sessions measuring
N      the XF86 X server on Linux, using a trim threshold of 128K and a
N      mmap threshold of 192K led to near-minimal long term resource
N      consumption.
N
N      If you are using this malloc in a long-lived program, it should
N      pay to experiment with these values.  As a rough guide, you
N      might set to a value close to the average size of a process
N      (program) running on your system.  Releasing this much memory
N      would allow such a process to run in memory.  Generally, it's
N      worth it to tune for trimming rather tham memory mapping when a
N      program undergoes phases where several large chunks are
N      allocated and released in ways that can reuse each other's
N      storage, perhaps mixed with phases where there are no such
N      chunks at all.  And in well-behaved long-lived programs,
N      controlling release of large blocks via trimming versus mapping
N      is usually faster.
N
N      However, in most programs, these parameters serve mainly as
N      protection against the system-level effects of carrying around
N      massive amounts of unneeded memory. Since frequent calls to
N      sbrk, mmap, and munmap otherwise degrade performance, the default
N      parameters are set to relatively high values that serve only as
N      safeguards.
N
N      The default trim value is high enough to cause trimming only in
N      fairly extreme (by current memory consumption standards) cases.
N      It must be greater than page size to have any useful effect.  To
N      disable trimming completely, you can set to (unsigned long)(-1);
N
N
N*/
N
N
N#ifndef DEFAULT_TOP_PAD
N#define DEFAULT_TOP_PAD        (0)
N#endif
N
N/*
N    M_TOP_PAD is the amount of extra `padding' space to allocate or
N      retain whenever sbrk is called. It is used in two ways internally:
N
N      * When sbrk is called to extend the top of the arena to satisfy
N	a new malloc request, this much padding is added to the sbrk
N	request.
N
N      * When malloc_trim is called automatically from free(),
N	it is used as the `pad' argument.
N
N      In both cases, the actual amount of padding is rounded
N      so that the end of the arena is always a system page boundary.
N
N      The main reason for using padding is to avoid calling sbrk so
N      often. Having even a small pad greatly reduces the likelihood
N      that nearly every malloc request during program start-up (or
N      after trimming) will invoke sbrk, which needlessly wastes
N      time.
N
N      Automatic rounding-up to page-size units is normally sufficient
N      to avoid measurable overhead, so the default is 0.  However, in
N      systems where sbrk is relatively slow, it can pay to increase
N      this value, at the expense of carrying around more memory than
N      the program needs.
N
N*/
N
N
N#ifndef DEFAULT_MMAP_THRESHOLD
N#define DEFAULT_MMAP_THRESHOLD (128 * 1024)
N#endif
N
N/*
N
N    M_MMAP_THRESHOLD is the request size threshold for using mmap()
N      to service a request. Requests of at least this size that cannot
N      be allocated using already-existing space will be serviced via mmap.
N      (If enough normal freed space already exists it is used instead.)
N
N      Using mmap segregates relatively large chunks of memory so that
N      they can be individually obtained and released from the host
N      system. A request serviced through mmap is never reused by any
N      other request (at least not directly; the system may just so
N      happen to remap successive requests to the same locations).
N
N      Segregating space in this way has the benefit that mmapped space
N      can ALWAYS be individually released back to the system, which
N      helps keep the system level memory demands of a long-lived
N      program low. Mapped memory can never become `locked' between
N      other chunks, as can happen with normally allocated chunks, which
N      menas that even trimming via malloc_trim would not release them.
N
N      However, it has the disadvantages that:
N
N	 1. The space cannot be reclaimed, consolidated, and then
N	    used to service later requests, as happens with normal chunks.
N	 2. It can lead to more wastage because of mmap page alignment
N	    requirements
N	 3. It causes malloc performance to be more dependent on host
N	    system memory management support routines which may vary in
N	    implementation quality and may impose arbitrary
N	    limitations. Generally, servicing a request via normal
N	    malloc steps is faster than going through a system's mmap.
N
N      All together, these considerations should lead you to use mmap
N      only for relatively large requests.
N
N
N*/
N
N
N#ifndef DEFAULT_MMAP_MAX
N#ifdef HAVE_MMAP
S#define DEFAULT_MMAP_MAX       (64)
N#else
N#define DEFAULT_MMAP_MAX       (0)
N#endif
N#endif
N
N/*
N    M_MMAP_MAX is the maximum number of requests to simultaneously
N      service using mmap. This parameter exists because:
N
N	 1. Some systems have a limited number of internal tables for
N	    use by mmap.
N	 2. In most systems, overreliance on mmap can degrade overall
N	    performance.
N	 3. If a program allocates many large regions, it is probably
N	    better off using normal sbrk-based allocation routines that
N	    can reclaim and reallocate normal heap memory. Using a
N	    small value allows transition into this mode after the
N	    first few allocations.
N
N      Setting to 0 disables all use of mmap.  If HAVE_MMAP is not set,
N      the default value is 0, and attempts to set it to non-zero values
N      in mallopt will fail.
N*/
N
N
N/*
N    USE_DL_PREFIX will prefix all public routines with the string 'dl'.
N      Useful to quickly avoid procedure declaration conflicts and linker
N      symbol conflicts with existing memory allocation routines.
N
N*/
N
N/* #define USE_DL_PREFIX */
N
N
N/*
N
N  Special defines for linux libc
N
N  Except when compiled using these special defines for Linux libc
N  using weak aliases, this malloc is NOT designed to work in
N  multithreaded applications.  No semaphores or other concurrency
N  control are provided to ensure that multiple malloc or free calls
N  don't run at the same time, which could be disasterous. A single
N  semaphore could be used across malloc, realloc, and free (which is
N  essentially the effect of the linux weak alias approach). It would
N  be hard to obtain finer granularity.
N
N*/
N
N
N#ifdef INTERNAL_LINUX_C_LIB
S
S#if __STD_C
S
SVoid_t * __default_morecore_init (ptrdiff_t);
SVoid_t *(*__morecore)(ptrdiff_t) = __default_morecore_init;
S
S#else
S
SVoid_t * __default_morecore_init ();
SVoid_t *(*__morecore)() = __default_morecore_init;
S
S#endif
S
S#define MORECORE (*__morecore)
S#define MORECORE_FAILURE 0
S#define MORECORE_CLEARS 1
S
N#else /* INTERNAL_LINUX_C_LIB */
N
N#if __STD_C
X#if 1
Nextern Void_t*     sbrk(ptrdiff_t);
Xextern void*     sbrk(ptrdiff_t);
N#else
Sextern Void_t*     sbrk();
N#endif
N
N#ifndef MORECORE
N#define MORECORE sbrk
N#endif
N
N#ifndef MORECORE_FAILURE
N#define MORECORE_FAILURE -1
N#endif
N
N#ifndef MORECORE_CLEARS
N#define MORECORE_CLEARS 1
N#endif
N
N#endif /* INTERNAL_LINUX_C_LIB */
N
N#if defined(INTERNAL_LINUX_C_LIB) && defined(__ELF__)
X#if 0L && 0L
S
S#define cALLOc		__libc_calloc
S#define fREe		__libc_free
S#define mALLOc		__libc_malloc
S#define mEMALIGn	__libc_memalign
S#define rEALLOc		__libc_realloc
S#define vALLOc		__libc_valloc
S#define pvALLOc		__libc_pvalloc
S#define mALLINFo	__libc_mallinfo
S#define mALLOPt		__libc_mallopt
S
S#pragma weak calloc = __libc_calloc
S#pragma weak free = __libc_free
S#pragma weak cfree = __libc_free
S#pragma weak malloc = __libc_malloc
S#pragma weak memalign = __libc_memalign
S#pragma weak realloc = __libc_realloc
S#pragma weak valloc = __libc_valloc
S#pragma weak pvalloc = __libc_pvalloc
S#pragma weak mallinfo = __libc_mallinfo
S#pragma weak mallopt = __libc_mallopt
S
N#else
N
N#ifdef USE_DL_PREFIX
S#define cALLOc		dlcalloc
S#define fREe		dlfree
S#define mALLOc		dlmalloc
S#define mEMALIGn	dlmemalign
S#define rEALLOc		dlrealloc
S#define vALLOc		dlvalloc
S#define pvALLOc		dlpvalloc
S#define mALLINFo	dlmallinfo
S#define mALLOPt		dlmallopt
N#else /* USE_DL_PREFIX */
N#define cALLOc		calloc
N#define fREe		free
N#define mALLOc		malloc
N#define mEMALIGn	memalign
N#define rEALLOc		realloc
N#define vALLOc		valloc
N#define pvALLOc		pvalloc
N#define mALLINFo	mallinfo
N#define mALLOPt		mallopt
N#endif /* USE_DL_PREFIX */
N
N#endif
N
N/* Public routines */
N
N#if __STD_C
X#if 1
N
NVoid_t* mALLOc(size_t);
Xvoid* malloc(size_t);
Nvoid    fREe(Void_t*);
Xvoid    free(void*);
NVoid_t* rEALLOc(Void_t*, size_t);
Xvoid* realloc(void*, size_t);
NVoid_t* mEMALIGn(size_t, size_t);
Xvoid* memalign(size_t, size_t);
NVoid_t* vALLOc(size_t);
Xvoid* valloc(size_t);
NVoid_t* pvALLOc(size_t);
Xvoid* pvalloc(size_t);
NVoid_t* cALLOc(size_t, size_t);
Xvoid* calloc(size_t, size_t);
Nvoid    cfree(Void_t*);
Xvoid    cfree(void*);
Nint     malloc_trim(size_t);
Nsize_t  malloc_usable_size(Void_t*);
Xsize_t  malloc_usable_size(void*);
Nvoid    malloc_stats(void);
Nint     mALLOPt(int, int);
Xint     mallopt(int, int);
Nstruct mallinfo mALLINFo(void);
Xstruct mallinfo mallinfo(void);
N#else
SVoid_t* mALLOc();
Svoid    fREe();
SVoid_t* rEALLOc();
SVoid_t* mEMALIGn();
SVoid_t* vALLOc();
SVoid_t* pvALLOc();
SVoid_t* cALLOc();
Svoid    cfree();
Sint     malloc_trim();
Ssize_t  malloc_usable_size();
Svoid    malloc_stats();
Sint     mALLOPt();
Sstruct mallinfo mALLINFo();
N#endif
N
N/*
N * Begin and End of memory area for malloc(), and current "brk"
N */
Nextern ulong mem_malloc_start;
Nextern ulong mem_malloc_end;
Nextern ulong mem_malloc_brk;
N
Nvoid mem_malloc_init(ulong start, ulong size);
N
N#ifdef __cplusplus
S};  /* end of extern "C" */
N#endif
N
N#endif /* __MALLOC_H__ */
L 40 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "linux\err.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\err.h" 1
N#ifndef _LINUX_ERR_H
N#define _LINUX_ERR_H
N
N#include "asm\errno.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm\errno.h" 1
N/*
N * U-boot - errno.h Error number defines
N *
N * Copyright (c) 2005-2007 Analog Devices Inc.
N *
N * See file CREDITS for list of people who contributed to this
N * project.
N *
N * This program is free software; you can redistribute it and/or
N * modify it under the terms of the GNU General Public License as
N * published by the Free Software Foundation; either version 2 of
N * the License, or (at your option) any later version.
N *
N * This program is distributed in the hope that it will be useful,
N * but WITHOUT ANY WARRANTY; without even the implied warranty of
N * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
N * GNU General Public License for more details.
N *
N * You should have received a copy of the GNU General Public License
N * along with this program; if not, write to the Free Software
N * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
N * MA 02110-1301 USA
N */
N
N#ifndef _GENERIC_ERRNO_H
N#define _GENERIC_ERRNO_H
N
N#define	EPERM		1	/* Operation not permitted */
N#define	ENOENT		2	/* No such file or directory */
N#define	ESRCH		3	/* No such process */
N#define	EINTR		4	/* Interrupted system call */
N#define	EIO		5	/* I/O error */
N#define	ENXIO		6	/* No such device or address */
N#define	E2BIG		7	/* Argument list too long */
N#define	ENOEXEC		8	/* Exec format error */
N#define	EBADF		9	/* Bad file number */
N#define	ECHILD		10	/* No child processes */
N#define	EAGAIN		11	/* Try again */
N#define	ENOMEM		12	/* Out of memory */
N#define	EACCES		13	/* Permission denied */
N#define	EFAULT		14	/* Bad address */
N#define	ENOTBLK		15	/* Block device required */
N#define	EBUSY		16	/* Device or resource busy */
N#define	EEXIST		17	/* File exists */
N#define	EXDEV		18	/* Cross-device link */
N#define	ENODEV		19	/* No such device */
N#define	ENOTDIR		20	/* Not a directory */
N#define	EISDIR		21	/* Is a directory */
N#define	EINVAL		22	/* Invalid argument */
N#define	ENFILE		23	/* File table overflow */
N#define	EMFILE		24	/* Too many open files */
N#define	ENOTTY		25	/* Not a typewriter */
N#define	ETXTBSY		26	/* Text file busy */
N#define	EFBIG		27	/* File too large */
N#define	ENOSPC		28	/* No space left on device */
N#define	ESPIPE		29	/* Illegal seek */
N#define	EROFS		30	/* Read-only file system */
N#define	EMLINK		31	/* Too many links */
N#define	EPIPE		32	/* Broken pipe */
N#define	EDOM		33	/* Math argument out of domain of func */
N#define	ERANGE		34	/* Math result not representable */
N#define	EDEADLK		35	/* Resource deadlock would occur */
N#define	ENAMETOOLONG	36	/* File name too long */
N#define	ENOLCK		37	/* No record locks available */
N#define	ENOSYS		38	/* Function not implemented */
N#define	ENOTEMPTY	39	/* Directory not empty */
N#define	ELOOP		40	/* Too many symbolic links encountered */
N#define	EWOULDBLOCK	EAGAIN	/* Operation would block */
N#define	ENOMSG		42	/* No message of desired type */
N#define	EIDRM		43	/* Identifier removed */
N#define	ECHRNG		44	/* Channel number out of range */
N#define	EL2NSYNC	45	/* Level 2 not synchronized */
N#define	EL3HLT		46	/* Level 3 halted */
N#define	EL3RST		47	/* Level 3 reset */
N#define	ELNRNG		48	/* Link number out of range */
N#define	EUNATCH		49	/* Protocol driver not attached */
N#define	ENOCSI		50	/* No CSI structure available */
N#define	EL2HLT		51	/* Level 2 halted */
N#define	EBADE		52	/* Invalid exchange */
N#define	EBADR		53	/* Invalid request descriptor */
N#define	EXFULL		54	/* Exchange full */
N#define	ENOANO		55	/* No anode */
N#define	EBADRQC		56	/* Invalid request code */
N#define	EBADSLT		57	/* Invalid slot */
N
N#define	EDEADLOCK	EDEADLK
N
N#define	EBFONT		59	/* Bad font file format */
N#define	ENOSTR		60	/* Device not a stream */
N#define	ENODATA		61	/* No data available */
N#define	ETIME		62	/* Timer expired */
N#define	ENOSR		63	/* Out of streams resources */
N#define	ENONET		64	/* Machine is not on the network */
N#define	ENOPKG		65	/* Package not installed */
N#define	EREMOTE		66	/* Object is remote */
N#define	ENOLINK		67	/* Link has been severed */
N#define	EADV		68	/* Advertise error */
N#define	ESRMNT		69	/* Srmount error */
N#define	ECOMM		70	/* Communication error on send */
N#define	EPROTO		71	/* Protocol error */
N#define	EMULTIHOP	72	/* Multihop attempted */
N#define	EDOTDOT		73	/* RFS specific error */
N#define	EBADMSG		74	/* Not a data message */
N#define	EOVERFLOW	75	/* Value too large for defined data type */
N#define	ENOTUNIQ	76	/* Name not unique on network */
N#define	EBADFD		77	/* File descriptor in bad state */
N#define	EREMCHG		78	/* Remote address changed */
N#define	ELIBACC		79	/* Can not access a needed shared library */
N#define	ELIBBAD		80	/* Accessing a corrupted shared library */
N#define	ELIBSCN		81	/* .lib section in a.out corrupted */
N#define	ELIBMAX		82	/* Attempting to link in too many shared libraries */
N#define	ELIBEXEC	83	/* Cannot exec a shared library directly */
N#define	EILSEQ		84	/* Illegal byte sequence */
N#define	ERESTART	85	/* Interrupted system call should be restarted */
N#define	ESTRPIPE	86	/* Streams pipe error */
N#define	EUSERS		87	/* Too many users */
N#define	ENOTSOCK	88	/* Socket operation on non-socket */
N#define	EDESTADDRREQ	89	/* Destination address required */
N#define	EMSGSIZE	90	/* Message too long */
N#define	EPROTOTYPE	91	/* Protocol wrong type for socket */
N#define	ENOPROTOOPT	92	/* Protocol not available */
N#define	EPROTONOSUPPORT	93	/* Protocol not supported */
N#define	ESOCKTNOSUPPORT	94	/* Socket type not supported */
N#define	EOPNOTSUPP	95	/* Operation not supported on transport endpoint */
N#define	EPFNOSUPPORT	96	/* Protocol family not supported */
N#define	EAFNOSUPPORT	97	/* Address family not supported by protocol */
N#define	EADDRINUSE	98	/* Address already in use */
N#define	EADDRNOTAVAIL	99	/* Cannot assign requested address */
N#define	ENETDOWN	100	/* Network is down */
N#define	ENETUNREACH	101	/* Network is unreachable */
N#define	ENETRESET	102	/* Network dropped connection because of reset */
N#define	ECONNABORTED	103	/* Software caused connection abort */
N#define	ECONNRESET	104	/* Connection reset by peer */
N#define	ENOBUFS		105	/* No buffer space available */
N#define	EISCONN		106	/* Transport endpoint is already connected */
N#define	ENOTCONN	107	/* Transport endpoint is not connected */
N#define	ESHUTDOWN	108	/* Cannot send after transport endpoint shutdown */
N#define	ETOOMANYREFS	109	/* Too many references: cannot splice */
N#define	ETIMEDOUT	110	/* Connection timed out */
N#define	ECONNREFUSED	111	/* Connection refused */
N#define	EHOSTDOWN	112	/* Host is down */
N#define	EHOSTUNREACH	113	/* No route to host */
N#define	EALREADY	114	/* Operation already in progress */
N#define	EINPROGRESS	115	/* Operation now in progress */
N#define	ESTALE		116	/* Stale NFS file handle */
N#define	EUCLEAN		117	/* Structure needs cleaning */
N#define	ENOTNAM		118	/* Not a XENIX named type file */
N#define	ENAVAIL		119	/* No XENIX semaphores available */
N#define	EISNAM		120	/* Is a named type file */
N#define	EREMOTEIO	121	/* Remote I/O error */
N#define	EDQUOT		122	/* Quota exceeded */
N#define	ENOMEDIUM	123	/* No medium found */
N#define	EMEDIUMTYPE	124	/* Wrong medium type */
N
N#endif
L 5 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\err.h" 2
N
N
N/*
N * Kernel pointers have redundant information, so we can use a
N * scheme where we can return either an error code or a dentry
N * pointer with the same return value.
N *
N * This should be a per-architecture thing, to allow different
N * error and pointer decisions.
N */
N#define MAX_ERRNO	4095
N
N#ifndef __ASSEMBLY__
N
N#define IS_ERR_VALUE(x) ((x) >= (unsigned long)-MAX_ERRNO)
N
Nstatic __inline void *ERR_PTR(long error)
N{
N	return (void *) error;
N}
N
Nstatic __inline long PTR_ERR(const void *ptr)
N{
N	return (long) ptr;
N}
N
Nstatic __inline long IS_ERR(const void *ptr)
N{
N	return IS_ERR_VALUE((unsigned long)ptr);
X	return (((unsigned long)ptr) >= (unsigned long)-4095);
N}
N
N#endif
N
N#endif /* _LINUX_ERR_H */
L 41 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "linux\compat.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 1
N#ifndef _LINUX_COMPAT_H_
N#define _LINUX_COMPAT_H_
N
N/* Scheduler includes. */
N#include "FreeRTOS.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef INC_FREERTOS_H
N#define INC_FREERTOS_H
N
N/*
N * Include the generic headers required for the FreeRTOS port being used.
N */
N#include <stddef.h>
L 1 "C:\Keil\ARM\ARMCC\bin\..\include\stddef.h" 1
N/* stddef.h: ANSI 'C' (X3J11 Oct 88) library header, section 4.1.4 */
N
N/* Copyright (C) ARM Ltd., 1999
N * All rights reserved
N * RCS $Revision: 178085 $
N * Checkin $Date: 2012-12-11 14:54:17 +0000 (Tue, 11 Dec 2012) $
N * Revising $Author: agrant $
N */
N
N/* Copyright (C) Codemist Ltd., 1988                            */
N/* Copyright 1991 ARM Limited. All rights reserved.             */
N/* version 0.05 */
N
N/*
N * The following types and macros are defined in several headers referred to in
N * the descriptions of the functions declared in that header. They are also
N * defined in this header file.
N */
N
N#ifndef __stddef_h
N#define __stddef_h
N#define __ARMCLIB_VERSION 5030076
N
N  #ifndef __STDDEF_DECLS
N  #define __STDDEF_DECLS
N    #undef __CLIBNS
N    #ifdef __cplusplus
S        namespace std {
S        #define __CLIBNS ::std::
S        extern "C" {
N    #else
N      #define __CLIBNS
N    #endif  /* __cplusplus */
N
Ntypedef signed int ptrdiff_t;
N
N#if defined(__cplusplus) || !defined(__STRICT_ANSI__)
X#if 0L || !0L
N /* unconditional in C++ and non-strict C for consistency of debug info */
N  typedef unsigned int size_t;
N#elif !defined(__size_t)
S  #define __size_t 1
S  typedef unsigned int size_t;   /* others (e.g. <stdio.h>) also define */
S   /* the unsigned integral type of the result of the sizeof operator. */
N#endif
N
N#ifndef __cplusplus  /* wchar_t is a builtin type for C++ */
N  #if !defined(__STRICT_ANSI__)
X  #if !0L
N  /* unconditional in non-strict C for consistency of debug info */
N    #if defined(__WCHAR32)
X    #if 0L
S      typedef unsigned int wchar_t; /* also in <stdlib.h> and <inttypes.h> */
N    #else
N      typedef unsigned short wchar_t; /* also in <stdlib.h> and <inttypes.h> */
N    #endif
N  #elif !defined(__wchar_t)
S    #define __wchar_t 1
S    #if defined(__WCHAR32)
S      typedef unsigned int wchar_t; /* also in <stdlib.h> and <inttypes.h> */
S    #else
S      typedef unsigned short wchar_t; /* also in <stdlib.h> and <inttypes.h> */
S    #endif
S   /*
S    * An integral type whose range of values can represent distinct codes for
S    * all members of the largest extended character set specified among the
S    * supported locales; the null character shall have the code value zero and
S    * each member of the basic character set shall have a code value when used
S    * as the lone character in an integer character constant.
S    */
N  #endif
N#endif
N
N#undef NULL  /* others (e.g. <stdio.h>) also define */
N#define NULL 0
N   /* null pointer constant. */
N
N  /* EDG uses __INTADDR__ to avoid errors when strict */
N  #define offsetof(t, memb) ((__CLIBNS size_t)__INTADDR__(&(((t *)0)->memb)))
N
N    #ifdef __cplusplus
S         }  /* extern "C" */
S      }  /* namespace std */
N    #endif /* __cplusplus */
N  #endif /* __STDDEF_DECLS */
N
N
N  #ifdef __cplusplus
S    #ifndef __STDDEF_NO_EXPORTS
S      using ::std::size_t;
S      using ::std::ptrdiff_t;
S    #endif 
N  #endif /* __cplusplus */
N
N#endif
N
N/* end of stddef.h */
N
L 77 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/*
N * If stdint.h cannot be located then:
N *   + If using GCC ensure the -nostdint options is *not* being used.
N *   + Ensure the project's include path includes the directory in which your
N *     compiler stores stdint.h.
N *   + Set any compiler options necessary for it to support C99, as technically
N *     stdint.h is only mandatory with C99 (FreeRTOS does not require C99 in any
N *     other way).
N *   + The FreeRTOS download includes a simple stdint.h definition that can be
N *     used in cases where none is provided by the compiler.  The files only
N *     contains the typedefs required to build FreeRTOS.  Read the instructions
N *     in FreeRTOS/source/stdint.readme for more information.
N */
N#include <stdint.h> /* READ COMMENT ABOVE. */
L 1 "C:\Keil\ARM\ARMCC\bin\..\include\stdint.h" 1
N/* Copyright (C) ARM Ltd., 1999 */
N/* All rights reserved */
N
N/*
N * RCS $Revision: 178085 $
N * Checkin $Date: 2012-12-11 14:54:17 +0000 (Tue, 11 Dec 2012) $
N * Revising $Author: agrant $
N */
N
N#ifndef __stdint_h
N#define __stdint_h
N#define __ARMCLIB_VERSION 5030076
N
N  #ifndef __STDINT_DECLS
N  #define __STDINT_DECLS
N
N    #undef __CLIBNS
N
N    #ifdef __cplusplus
S      namespace std {
S          #define __CLIBNS std::
S          extern "C" {
N    #else
N      #define __CLIBNS
N    #endif  /* __cplusplus */
N
N
N/*
N * 'signed' is redundant below, except for 'signed char' and if
N * the typedef is used to declare a bitfield.
N * '__int64' is used instead of 'long long' so that this header
N * can be used in --strict mode.
N */
N
N    /* 7.18.1.1 */
N
N    /* exact-width signed integer types */
Ntypedef   signed          char int8_t;
Ntypedef   signed short     int int16_t;
Ntypedef   signed           int int32_t;
Ntypedef   signed       __int64 int64_t;
N
N    /* exact-width unsigned integer types */
Ntypedef unsigned          char uint8_t;
Ntypedef unsigned short     int uint16_t;
Ntypedef unsigned           int uint32_t;
Ntypedef unsigned       __int64 uint64_t;
N
N    /* 7.18.1.2 */
N
N    /* smallest type of at least n bits */
N    /* minimum-width signed integer types */
Ntypedef   signed          char int_least8_t;
Ntypedef   signed short     int int_least16_t;
Ntypedef   signed           int int_least32_t;
Ntypedef   signed       __int64 int_least64_t;
N
N    /* minimum-width unsigned integer types */
Ntypedef unsigned          char uint_least8_t;
Ntypedef unsigned short     int uint_least16_t;
Ntypedef unsigned           int uint_least32_t;
Ntypedef unsigned       __int64 uint_least64_t;
N
N    /* 7.18.1.3 */
N
N    /* fastest minimum-width signed integer types */
Ntypedef   signed           int int_fast8_t;
Ntypedef   signed           int int_fast16_t;
Ntypedef   signed           int int_fast32_t;
Ntypedef   signed       __int64 int_fast64_t;
N
N    /* fastest minimum-width unsigned integer types */
Ntypedef unsigned           int uint_fast8_t;
Ntypedef unsigned           int uint_fast16_t;
Ntypedef unsigned           int uint_fast32_t;
Ntypedef unsigned       __int64 uint_fast64_t;
N
N    /* 7.18.1.4 integer types capable of holding object pointers */
Ntypedef   signed           int intptr_t;
Ntypedef unsigned           int uintptr_t;
N
N    /* 7.18.1.5 greatest-width integer types */
Ntypedef   signed       __int64 intmax_t;
Ntypedef unsigned       __int64 uintmax_t;
N
N
N#if !defined(__cplusplus) || defined(__STDC_LIMIT_MACROS)
X#if !0L || 0L
N
N    /* 7.18.2.1 */
N
N    /* minimum values of exact-width signed integer types */
N#define INT8_MIN                   -128
N#define INT16_MIN                -32768
N#define INT32_MIN          (~0x7fffffff)   /* -2147483648 is unsigned */
N#define INT64_MIN  __ESCAPE__(~0x7fffffffffffffffll) /* -9223372036854775808 is unsigned */
N
N    /* maximum values of exact-width signed integer types */
N#define INT8_MAX                    127
N#define INT16_MAX                 32767
N#define INT32_MAX            2147483647
N#define INT64_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum values of exact-width unsigned integer types */
N#define UINT8_MAX                   255
N#define UINT16_MAX                65535
N#define UINT32_MAX           4294967295u
N#define UINT64_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.2.2 */
N
N    /* minimum values of minimum-width signed integer types */
N#define INT_LEAST8_MIN                   -128
N#define INT_LEAST16_MIN                -32768
N#define INT_LEAST32_MIN          (~0x7fffffff)
N#define INT_LEAST64_MIN  __ESCAPE__(~0x7fffffffffffffffll)
N
N    /* maximum values of minimum-width signed integer types */
N#define INT_LEAST8_MAX                    127
N#define INT_LEAST16_MAX                 32767
N#define INT_LEAST32_MAX            2147483647
N#define INT_LEAST64_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum values of minimum-width unsigned integer types */
N#define UINT_LEAST8_MAX                   255
N#define UINT_LEAST16_MAX                65535
N#define UINT_LEAST32_MAX           4294967295u
N#define UINT_LEAST64_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.2.3 */
N
N    /* minimum values of fastest minimum-width signed integer types */
N#define INT_FAST8_MIN           (~0x7fffffff)
N#define INT_FAST16_MIN          (~0x7fffffff)
N#define INT_FAST32_MIN          (~0x7fffffff)
N#define INT_FAST64_MIN  __ESCAPE__(~0x7fffffffffffffffll)
N
N    /* maximum values of fastest minimum-width signed integer types */
N#define INT_FAST8_MAX             2147483647
N#define INT_FAST16_MAX            2147483647
N#define INT_FAST32_MAX            2147483647
N#define INT_FAST64_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum values of fastest minimum-width unsigned integer types */
N#define UINT_FAST8_MAX            4294967295u
N#define UINT_FAST16_MAX           4294967295u
N#define UINT_FAST32_MAX           4294967295u
N#define UINT_FAST64_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.2.4 */
N
N    /* minimum value of pointer-holding signed integer type */
N#define INTPTR_MIN (~0x7fffffff)
N
N    /* maximum value of pointer-holding signed integer type */
N#define INTPTR_MAX   2147483647
N
N    /* maximum value of pointer-holding unsigned integer type */
N#define UINTPTR_MAX  4294967295u
N
N    /* 7.18.2.5 */
N
N    /* minimum value of greatest-width signed integer type */
N#define INTMAX_MIN  __ESCAPE__(~0x7fffffffffffffffll)
N
N    /* maximum value of greatest-width signed integer type */
N#define INTMAX_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum value of greatest-width unsigned integer type */
N#define UINTMAX_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.3 */
N
N    /* limits of ptrdiff_t */
N#define PTRDIFF_MIN (~0x7fffffff)
N#define PTRDIFF_MAX   2147483647
N
N    /* limits of sig_atomic_t */
N#define SIG_ATOMIC_MIN (~0x7fffffff)
N#define SIG_ATOMIC_MAX   2147483647
N
N    /* limit of size_t */
N#define SIZE_MAX 4294967295u
N
N    /* limits of wchar_t */
N    /* NB we have to undef and redef because they're defined in both
N     * stdint.h and wchar.h */
N#undef WCHAR_MIN
N#undef WCHAR_MAX
N
N#if defined(__WCHAR32)
X#if 0L
S  #define WCHAR_MIN   0
S  #define WCHAR_MAX   0xffffffffU
N#else
N  #define WCHAR_MIN   0
N  #define WCHAR_MAX   65535
N#endif
N
N    /* limits of wint_t */
N#define WINT_MIN (~0x7fffffff)
N#define WINT_MAX 2147483647
N
N#endif /* __STDC_LIMIT_MACROS */
N
N#if !defined(__cplusplus) || defined(__STDC_CONSTANT_MACROS)
X#if !0L || 0L
N
N    /* 7.18.4.1 macros for minimum-width integer constants */
N#define INT8_C(x)   (x)
N#define INT16_C(x)  (x)
N#define INT32_C(x)  (x)
N#define INT64_C(x)  __ESCAPE__(x ## ll)
N
N#define UINT8_C(x)  (x ## u)
N#define UINT16_C(x) (x ## u)
N#define UINT32_C(x) (x ## u)
N#define UINT64_C(x) __ESCAPE__(x ## ull)
N
N    /* 7.18.4.2 macros for greatest-width integer constants */
N#define INTMAX_C(x)  __ESCAPE__(x ## ll)
N#define UINTMAX_C(x) __ESCAPE__(x ## ull)
N
N#endif /* __STDC_CONSTANT_MACROS */
N
N    #ifdef __cplusplus
S         }  /* extern "C" */
S      }  /* namespace std */
N    #endif /* __cplusplus */
N  #endif /* __STDINT_DECLS */
N
N  #ifdef __cplusplus
S    #ifndef __STDINT_NO_EXPORTS
S      using ::std::int8_t;
S      using ::std::int16_t;
S      using ::std::int32_t;
S      using ::std::int64_t;
S      using ::std::uint8_t;
S      using ::std::uint16_t;
S      using ::std::uint32_t;
S      using ::std::uint64_t;
S      using ::std::int_least8_t;
S      using ::std::int_least16_t;
S      using ::std::int_least32_t;
S      using ::std::int_least64_t;
S      using ::std::uint_least8_t;
S      using ::std::uint_least16_t;
S      using ::std::uint_least32_t;
S      using ::std::uint_least64_t;
S      using ::std::int_fast8_t;
S      using ::std::int_fast16_t;
S      using ::std::int_fast32_t;
S      using ::std::int_fast64_t;
S      using ::std::uint_fast8_t;
S      using ::std::uint_fast16_t;
S      using ::std::uint_fast32_t;
S      using ::std::uint_fast64_t;
S      using ::std::intptr_t;
S      using ::std::uintptr_t;
S      using ::std::intmax_t;
S      using ::std::uintmax_t;
S    #endif 
N  #endif /* __cplusplus */
N
N#endif /* __stdint_h */
N
N/* end of stdint.h */
N
N
N
L 92 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N/* Application specific configuration options. */
N#include "FreeRTOSConfig.h"
L 1 "..\..\common\src\FreeRTOS\FreeRTOSConfig.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef FREERTOS_CONFIG_H
N#define FREERTOS_CONFIG_H
N
N/*-----------------------------------------------------------
N * Application specific definitions.
N *
N * These definitions should be adjusted for your particular hardware and
N * application requirements.
N *
N * THESE PARAMETERS ARE DESCRIBED WITHIN THE 'CONFIGURATION' SECTION OF THE
N * FreeRTOS API DOCUMENTATION AVAILABLE ON THE FreeRTOS.org WEB SITE.
N *
N * See http://www.freertos.org/a00110.html.
N *----------------------------------------------------------*/
N#define configUSE_PREEMPTION			1
N#define configUSE_IDLE_HOOK				1
N#define configUSE_TICK_HOOK				1
N#define configCPU_CLOCK_HZ				( ( unsigned long ) 300000000 )
N//#define configTICK_RATE_HZ				( ( TickType_t ) 1000 )
N#define configTICK_RATE_HZ				( ( TickType_t ) 100 )
N#define configMAX_PRIORITIES			( 16 )
N#define configMINIMAL_STACK_SIZE		( ( unsigned short ) 1024 )
N#define configTOTAL_HEAP_SIZE			( ( size_t ) 1024*1024*16 )
N#define configMAX_TASK_NAME_LEN			( 16 )
N#define configUSE_TRACE_FACILITY		1
N#define configUSE_16_BIT_TICKS			0
N#define configIDLE_SHOULD_YIELD			1
N#define configUSE_MUTEXES				1
N#define configCHECK_FOR_STACK_OVERFLOW  1
N#define configUSE_MALLOC_FAILED_HOOK    1
N
N#define configSUPPORT_DYNAMIC_ALLOCATION 1
N#define configUSE_COUNTING_SEMAPHORES   1
N
N/* Co-routine definitions. */
N#define configUSE_CO_ROUTINES 			0
N#define configMAX_CO_ROUTINE_PRIORITIES ( 2 )
N
N/* Set the following definitions to 1 to include the API function, or zero
Nto exclude the API function. */
N
N#define INCLUDE_vTaskPrioritySet				0//1
N#define INCLUDE_uxTaskPriorityGet				1
N#define INCLUDE_vTaskDelete						1
N#define INCLUDE_vTaskCleanUpResources			0
N#define INCLUDE_vTaskSuspend					1
N#define INCLUDE_vTaskDelayUntil					1
N#define INCLUDE_vTaskDelay						1
N#define INCLUDE_xTaskGetCurrentTaskHandle 		1
N#define INCLUDE_uxTaskGetStackHighWaterMark     1
N
N/* This demo makes use of one or more example stats formatting functions.  These
Nformat the raw data provided by the uxTaskGetSystemState() function in to human
Nreadable ASCII form.  See the notes in the implementation of vTaskList() within 
NFreeRTOS/Source/tasks.c for limitations. */
N#define configUSE_STATS_FORMATTING_FUNCTIONS	1
N
N#endif /* FREERTOS_CONFIG_H */
L 99 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/* Basic FreeRTOS definitions. */
N#include "projdefs.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\projdefs.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef PROJDEFS_H
N#define PROJDEFS_H
N
N/*
N * Defines the prototype to which task functions must conform.  Defined in this
N * file to ensure the type is known before portable.h is included.
N */
Ntypedef void (*TaskFunction_t)( void * );
N
N/* Converts a time in milliseconds to a time in ticks.  This macro can be
Noverridden by a macro of the same name defined in FreeRTOSConfig.h in case the
Ndefinition here is not suitable for your application. */
N#ifndef pdMS_TO_TICKS
N	#define pdMS_TO_TICKS( xTimeInMs ) ( ( TickType_t ) ( ( ( TickType_t ) ( xTimeInMs ) * ( TickType_t ) configTICK_RATE_HZ ) / ( TickType_t ) 1000 ) )
N#endif
N
N#define pdFALSE			( ( BaseType_t ) 0 )
N#define pdTRUE			( ( BaseType_t ) 1 )
N
N#define pdPASS			( pdTRUE )
N#define pdFAIL			( pdFALSE )
N#define errQUEUE_EMPTY	( ( BaseType_t ) 0 )
N#define errQUEUE_FULL	( ( BaseType_t ) 0 )
N
N/* FreeRTOS error definitions. */
N#define errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY	( -1 )
N#define errQUEUE_BLOCKED						( -4 )
N#define errQUEUE_YIELD							( -5 )
N
N/* Macros used for basic data corruption checks. */
N#ifndef configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES
N	#define configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES 0
N#endif
N
N#if( configUSE_16_BIT_TICKS == 1 )
X#if( 0 == 1 )
S	#define pdINTEGRITY_CHECK_VALUE 0x5a5a
N#else
N	#define pdINTEGRITY_CHECK_VALUE 0x5a5a5a5aUL
N#endif
N
N/* The following errno values are used by FreeRTOS+ components, not FreeRTOS
Nitself. */
N#define pdFREERTOS_ERRNO_NONE			0	/* No errors */
N#define	pdFREERTOS_ERRNO_ENOENT			2	/* No such file or directory */
N#define	pdFREERTOS_ERRNO_EINTR			4	/* Interrupted system call */
N#define	pdFREERTOS_ERRNO_EIO			5	/* I/O error */
N#define	pdFREERTOS_ERRNO_ENXIO			6	/* No such device or address */
N#define	pdFREERTOS_ERRNO_EBADF			9	/* Bad file number */
N#define	pdFREERTOS_ERRNO_EAGAIN			11	/* No more processes */
N#define	pdFREERTOS_ERRNO_EWOULDBLOCK	11	/* Operation would block */
N#define	pdFREERTOS_ERRNO_ENOMEM			12	/* Not enough memory */
N#define	pdFREERTOS_ERRNO_EACCES			13	/* Permission denied */
N#define	pdFREERTOS_ERRNO_EFAULT			14	/* Bad address */
N#define	pdFREERTOS_ERRNO_EBUSY			16	/* Mount device busy */
N#define	pdFREERTOS_ERRNO_EEXIST			17	/* File exists */
N#define	pdFREERTOS_ERRNO_EXDEV			18	/* Cross-device link */
N#define	pdFREERTOS_ERRNO_ENODEV			19	/* No such device */
N#define	pdFREERTOS_ERRNO_ENOTDIR		20	/* Not a directory */
N#define	pdFREERTOS_ERRNO_EISDIR			21	/* Is a directory */
N#define	pdFREERTOS_ERRNO_EINVAL			22	/* Invalid argument */
N#define	pdFREERTOS_ERRNO_ENOSPC			28	/* No space left on device */
N#define	pdFREERTOS_ERRNO_ESPIPE			29	/* Illegal seek */
N#define	pdFREERTOS_ERRNO_EROFS			30	/* Read only file system */
N#define	pdFREERTOS_ERRNO_EUNATCH		42	/* Protocol driver not attached */
N#define	pdFREERTOS_ERRNO_EBADE			50	/* Invalid exchange */
N#define	pdFREERTOS_ERRNO_EFTYPE			79	/* Inappropriate file type or format */
N#define	pdFREERTOS_ERRNO_ENMFILE		89	/* No more files */
N#define	pdFREERTOS_ERRNO_ENOTEMPTY		90	/* Directory not empty */
N#define	pdFREERTOS_ERRNO_ENAMETOOLONG 	91	/* File or path name too long */
N#define	pdFREERTOS_ERRNO_EOPNOTSUPP		95	/* Operation not supported on transport endpoint */
N#define	pdFREERTOS_ERRNO_ENOBUFS		105	/* No buffer space available */
N#define	pdFREERTOS_ERRNO_ENOPROTOOPT	109	/* Protocol not available */
N#define	pdFREERTOS_ERRNO_EADDRINUSE		112	/* Address already in use */
N#define	pdFREERTOS_ERRNO_ETIMEDOUT		116	/* Connection timed out */
N#define	pdFREERTOS_ERRNO_EINPROGRESS	119	/* Connection already in progress */
N#define	pdFREERTOS_ERRNO_EALREADY		120	/* Socket already connected */
N#define	pdFREERTOS_ERRNO_EADDRNOTAVAIL 	125	/* Address not available */
N#define	pdFREERTOS_ERRNO_EISCONN		127	/* Socket is already connected */
N#define	pdFREERTOS_ERRNO_ENOTCONN		128	/* Socket is not connected */
N#define	pdFREERTOS_ERRNO_ENOMEDIUM		135	/* No medium inserted */
N#define	pdFREERTOS_ERRNO_EILSEQ			138	/* An invalid UTF-16 sequence was encountered. */
N#define	pdFREERTOS_ERRNO_ECANCELED		140	/* Operation canceled. */
N
N/* The following endian values are used by FreeRTOS+ components, not FreeRTOS
Nitself. */
N#define pdFREERTOS_LITTLE_ENDIAN	0
N#define pdFREERTOS_BIG_ENDIAN		1
N
N#endif /* PROJDEFS_H */
N
N
N
L 102 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/* Definitions specific to the port being used. */
N#include "portable.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\portable.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N/*-----------------------------------------------------------
N * Portable layer API.  Each function must be defined for each port.
N *----------------------------------------------------------*/
N
N#ifndef PORTABLE_H
N#define PORTABLE_H
N
N/* Each FreeRTOS port has a unique portmacro.h header file.  Originally a
Npre-processor definition was used to ensure the pre-processor found the correct
Nportmacro.h file for the port being used.  That scheme was deprecated in favour
Nof setting the compiler's include path such that it found the correct
Nportmacro.h file - removing the need for the constant and allowing the
Nportmacro.h file to be located anywhere in relation to the port being used.
NPurely for reasons of backward compatibility the old method is still valid, but
Nto make it clear that new projects should not use it, support for the port
Nspecific constants has been moved into the deprecated_definitions.h header
Nfile. */
N#include "deprecated_definitions.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\deprecated_definitions.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef DEPRECATED_DEFINITIONS_H
N#define DEPRECATED_DEFINITIONS_H
N
N
N/* Each FreeRTOS port has a unique portmacro.h header file.  Originally a
Npre-processor definition was used to ensure the pre-processor found the correct
Nportmacro.h file for the port being used.  That scheme was deprecated in favour
Nof setting the compiler's include path such that it found the correct
Nportmacro.h file - removing the need for the constant and allowing the
Nportmacro.h file to be located anywhere in relation to the port being used.  The
Ndefinitions below remain in the code for backward compatibility only.  New
Nprojects should not use them. */
N
N#ifdef OPEN_WATCOM_INDUSTRIAL_PC_PORT
S	#include "..\..\Source\portable\owatcom\16bitdos\pc\portmacro.h"
S	typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef OPEN_WATCOM_FLASH_LITE_186_PORT
S	#include "..\..\Source\portable\owatcom\16bitdos\flsh186\portmacro.h"
S	typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef GCC_MEGA_AVR
S	#include "../portable/GCC/ATMega323/portmacro.h"
N#endif
N
N#ifdef IAR_MEGA_AVR
S	#include "../portable/IAR/ATMega323/portmacro.h"
N#endif
N
N#ifdef MPLAB_PIC24_PORT
S	#include "../../Source/portable/MPLAB/PIC24_dsPIC/portmacro.h"
N#endif
N
N#ifdef MPLAB_DSPIC_PORT
S	#include "../../Source/portable/MPLAB/PIC24_dsPIC/portmacro.h"
N#endif
N
N#ifdef MPLAB_PIC18F_PORT
S	#include "../../Source/portable/MPLAB/PIC18F/portmacro.h"
N#endif
N
N#ifdef MPLAB_PIC32MX_PORT
S	#include "../../Source/portable/MPLAB/PIC32MX/portmacro.h"
N#endif
N
N#ifdef _FEDPICC
S	#include "libFreeRTOS/Include/portmacro.h"
N#endif
N
N#ifdef SDCC_CYGNAL
S	#include "../../Source/portable/SDCC/Cygnal/portmacro.h"
N#endif
N
N#ifdef GCC_ARM7
S	#include "../../Source/portable/GCC/ARM7_LPC2000/portmacro.h"
N#endif
N
N#ifdef GCC_ARM7_ECLIPSE
S	#include "portmacro.h"
N#endif
N
N#ifdef ROWLEY_LPC23xx
S	#include "../../Source/portable/GCC/ARM7_LPC23xx/portmacro.h"
N#endif
N
N#ifdef IAR_MSP430
S	#include "..\..\Source\portable\IAR\MSP430\portmacro.h"
N#endif
N
N#ifdef GCC_MSP430
S	#include "../../Source/portable/GCC/MSP430F449/portmacro.h"
N#endif
N
N#ifdef ROWLEY_MSP430
S	#include "../../Source/portable/Rowley/MSP430F449/portmacro.h"
N#endif
N
N#ifdef ARM7_LPC21xx_KEIL_RVDS
S	#include "..\..\Source\portable\RVDS\ARM7_LPC21xx\portmacro.h"
N#endif
N
N#ifdef SAM7_GCC
S	#include "../../Source/portable/GCC/ARM7_AT91SAM7S/portmacro.h"
N#endif
N
N#ifdef SAM7_IAR
S	#include "..\..\Source\portable\IAR\AtmelSAM7S64\portmacro.h"
N#endif
N
N#ifdef SAM9XE_IAR
S	#include "..\..\Source\portable\IAR\AtmelSAM9XE\portmacro.h"
N#endif
N
N#ifdef LPC2000_IAR
S	#include "..\..\Source\portable\IAR\LPC2000\portmacro.h"
N#endif
N
N#ifdef STR71X_IAR
S	#include "..\..\Source\portable\IAR\STR71x\portmacro.h"
N#endif
N
N#ifdef STR75X_IAR
S	#include "..\..\Source\portable\IAR\STR75x\portmacro.h"
N#endif
N
N#ifdef STR75X_GCC
S	#include "..\..\Source\portable\GCC\STR75x\portmacro.h"
N#endif
N
N#ifdef STR91X_IAR
S	#include "..\..\Source\portable\IAR\STR91x\portmacro.h"
N#endif
N
N#ifdef GCC_H8S
S	#include "../../Source/portable/GCC/H8S2329/portmacro.h"
N#endif
N
N#ifdef GCC_AT91FR40008
S	#include "../../Source/portable/GCC/ARM7_AT91FR40008/portmacro.h"
N#endif
N
N#ifdef RVDS_ARMCM3_LM3S102
S	#include "../../Source/portable/RVDS/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef GCC_ARMCM3_LM3S102
S	#include "../../Source/portable/GCC/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef GCC_ARMCM3
S	#include "../../Source/portable/GCC/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef IAR_ARM_CM3
S	#include "../../Source/portable/IAR/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef IAR_ARMCM3_LM
S	#include "../../Source/portable/IAR/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef HCS12_CODE_WARRIOR
S	#include "../../Source/portable/CodeWarrior/HCS12/portmacro.h"
N#endif
N
N#ifdef MICROBLAZE_GCC
S	#include "../../Source/portable/GCC/MicroBlaze/portmacro.h"
N#endif
N
N#ifdef TERN_EE
S	#include "..\..\Source\portable\Paradigm\Tern_EE\small\portmacro.h"
N#endif
N
N#ifdef GCC_HCS12
S	#include "../../Source/portable/GCC/HCS12/portmacro.h"
N#endif
N
N#ifdef GCC_MCF5235
S    #include "../../Source/portable/GCC/MCF5235/portmacro.h"
N#endif
N
N#ifdef COLDFIRE_V2_GCC
S	#include "../../../Source/portable/GCC/ColdFire_V2/portmacro.h"
N#endif
N
N#ifdef COLDFIRE_V2_CODEWARRIOR
S	#include "../../Source/portable/CodeWarrior/ColdFire_V2/portmacro.h"
N#endif
N
N#ifdef GCC_PPC405
S	#include "../../Source/portable/GCC/PPC405_Xilinx/portmacro.h"
N#endif
N
N#ifdef GCC_PPC440
S	#include "../../Source/portable/GCC/PPC440_Xilinx/portmacro.h"
N#endif
N
N#ifdef _16FX_SOFTUNE
S	#include "..\..\Source\portable\Softune\MB96340\portmacro.h"
N#endif
N
N#ifdef BCC_INDUSTRIAL_PC_PORT
S	/* A short file name has to be used in place of the normal
S	FreeRTOSConfig.h when using the Borland compiler. */
S	#include "frconfig.h"
S	#include "..\portable\BCC\16BitDOS\PC\prtmacro.h"
S    typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef BCC_FLASH_LITE_186_PORT
S	/* A short file name has to be used in place of the normal
S	FreeRTOSConfig.h when using the Borland compiler. */
S	#include "frconfig.h"
S	#include "..\portable\BCC\16BitDOS\flsh186\prtmacro.h"
S    typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef __GNUC__
S   #ifdef __AVR32_AVR32A__
S	   #include "portmacro.h"
S   #endif
N#endif
N
N#ifdef __ICCAVR32__
S   #ifdef __CORE__
S      #if __CORE__ == __AVR32A__
S	      #include "portmacro.h"
S      #endif
S   #endif
N#endif
N
N#ifdef __91467D
S	#include "portmacro.h"
N#endif
N
N#ifdef __96340
S	#include "portmacro.h"
N#endif
N
N
N#ifdef __IAR_V850ES_Fx3__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Jx3__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Jx3_L__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Jx2__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Hx2__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_78K0R_Kx3__
S	#include "../../Source/portable/IAR/78K0R/portmacro.h"
N#endif
N
N#ifdef __IAR_78K0R_Kx3L__
S	#include "../../Source/portable/IAR/78K0R/portmacro.h"
N#endif
N
N#endif /* DEPRECATED_DEFINITIONS_H */
N
L 88 "..\..\common\src\FreeRTOS\Source\include\portable.h" 2
N
N/* If portENTER_CRITICAL is not defined then including deprecated_definitions.h
Ndid not result in a portmacro.h header file being included - and it should be
Nincluded here.  In this case the path to the correct portmacro.h header file
Nmust be set in the compiler's include path. */
N#ifndef portENTER_CRITICAL
N	#include "portmacro.h"
L 1 "..\..\common\src\FreeRTOS\Source\portable\RVDS\ARM926EJ-S\portmacro.h" 1
N/*
N * It turns out that portmacro.h from the officially supported
N * GCC/ARM7_LPC2000 port can be reused at ARM926EJ-S too.
N * Although the file could remain unmodified, it was slightly modified
N * so interrupt enabling macros do not enable FIQ exceptions that is
N * currently not supported.
N * Additionally all "annoying" tabs have been replaced by spaces.
N *
N * The original file is available under the following license:
N */
N
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N
N#ifndef PORTMACRO_H
N#define PORTMACRO_H
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N    /*-----------------------------------------------------------
N     * Port specific definitions.
N     *
N     * The settings in this file configure FreeRTOS correctly for the
N     * given hardware and compiler.
N     *
N     * These settings should not be altered.
N     *-----------------------------------------------------------
N     */
N#define portCHAR        char
N#define portFLOAT        float
N#define portDOUBLE        double
N#define portLONG        long
N#define portSHORT        short
N#define portSTACK_TYPE    unsigned portLONG
N#define portBASE_TYPE    portLONG
N
N//add by sam
Ntypedef portSTACK_TYPE StackType_t;
Xtypedef unsigned long StackType_t;
Ntypedef long BaseType_t;
Ntypedef unsigned long UBaseType_t;
N
N
N
N#if( configUSE_16_BIT_TICKS == 1 )
X#if( 0 == 1 )
S    typedef unsigned portSHORT portTickType;
S#define portMAX_DELAY ( portTickType ) 0xffff
N#else
N    typedef unsigned portLONG portTickType;
X    typedef unsigned long portTickType;
N#define portMAX_DELAY ( portTickType ) 0xffffffff
N#endif
N
N//add by sam
Ntypedef portTickType TickType_t;
N
N    /*-----------------------------------------------------------*/
N
N    /* Hardware specifics. */
N//#define portSTACK_GROWTH            ( -1 )
N//#define portTICK_RATE_MS            ( ( portTickType ) 1000 / configTICK_RATE_HZ )
N//#define portBYTE_ALIGNMENT            8
N//by sam
N/* Hardware specifics. */
N#define portSTACK_GROWTH			( -1 )
N#define portTICK_PERIOD_MS			( ( TickType_t ) 1000 / configTICK_RATE_HZ )
N#define portBYTE_ALIGNMENT			8
N    /*-----------------------------------------------------------*/
N
N
N#define portEXIT_SWITCHING_ISR(SwitchRequired)                 \
N                        {                                                             \
N                        extern void vTaskSwitchContext(void);                         \
N                                                                                     \
N                                if(SwitchRequired)                                     \
N                                {                                                     \
N                                    vTaskSwitchContext();                             \
N                                }                                                     \
N                        }                                                             \
N
X#define portEXIT_SWITCHING_ISR(SwitchRequired)                                         {                                                                                     extern void vTaskSwitchContext(void);                                                                                                                                              if(SwitchRequired)                                                                     {                                                                                         vTaskSwitchContext();                                                             }                                                                             }                                                             
Nextern void vPortYield2( void );
N#define portYIELD() vPortYield2()
N
N
N    /* Critical section management. */
N
N#define portDISABLE_INTERRUPTS()    __disable_irq()
N#define portENABLE_INTERRUPTS()        __enable_irq()
N
N    extern void vPortEnterCritical( void );
N    extern void vPortExitCritical( void );
N
N#define portENTER_CRITICAL()        vPortEnterCritical();
N#define portEXIT_CRITICAL()            vPortExitCritical();
N    /*-----------------------------------------------------------*/
N
N    /* Compiler specifics. */
N#define inline
N#define register
N#define portNOP()                   __asm{ NOP }
N//#define portYIELD()					__asm{ SWI 0 }//asm ( "SWI 0" )
N    /*-----------------------------------------------------------*/
N
N    /* Task function macros as described on the FreeRTOS.org WEB site. */
N#define portTASK_FUNCTION_PROTO( vFunction, pvParameters )    void vFunction( void *pvParameters )
N#define portTASK_FUNCTION( vFunction, pvParameters )    void vFunction( void *pvParameters )
N
N    //代码中大部分都是声明了一些函数，以及定义了数据类型
N    //真正重要有三个地方
N    //#define portYIELD() vPortYield() ///这个宏告诉os， task如何放弃CPU. vPortYield会在portasm.s 中实现。
N    //#define portDISABLE_INTERRUPTS()    __disable_irq()                     ////实现了关中断 __disable_irq() 和 __enable_irq() 支持的库函数
N    //#define portENABLE_INTERRUPTS()        __enable_irq()           ////实现了开中断
N    //#define portNOP()    __asm{ NOP }                             ////实现了nop
N
N    //以上都是跟硬件相关的。
N
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* PORTMACRO_H */
L 95 "..\..\common\src\FreeRTOS\Source\include\portable.h" 2
N#endif
N
N#if portBYTE_ALIGNMENT == 32
X#if 8 == 32
S	#define portBYTE_ALIGNMENT_MASK ( 0x001f )
N#endif
N
N#if portBYTE_ALIGNMENT == 16
X#if 8 == 16
S	#define portBYTE_ALIGNMENT_MASK ( 0x000f )
N#endif
N
N#if portBYTE_ALIGNMENT == 8
X#if 8 == 8
N	#define portBYTE_ALIGNMENT_MASK ( 0x0007 )
N#endif
N
N#if portBYTE_ALIGNMENT == 4
X#if 8 == 4
S	#define portBYTE_ALIGNMENT_MASK	( 0x0003 )
N#endif
N
N#if portBYTE_ALIGNMENT == 2
X#if 8 == 2
S	#define portBYTE_ALIGNMENT_MASK	( 0x0001 )
N#endif
N
N#if portBYTE_ALIGNMENT == 1
X#if 8 == 1
S	#define portBYTE_ALIGNMENT_MASK	( 0x0000 )
N#endif
N
N#ifndef portBYTE_ALIGNMENT_MASK
S	#error "Invalid portBYTE_ALIGNMENT definition"
N#endif
N
N#ifndef portNUM_CONFIGURABLE_REGIONS
N	#define portNUM_CONFIGURABLE_REGIONS 1
N#endif
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N#include "mpu_wrappers.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\mpu_wrappers.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef MPU_WRAPPERS_H
N#define MPU_WRAPPERS_H
N
N/* This file redefines API functions to be called through a wrapper macro, but
Nonly for ports that are using the MPU. */
N#ifdef portUSING_MPU_WRAPPERS
S
S	/* MPU_WRAPPERS_INCLUDED_FROM_API_FILE will be defined when this file is
S	included from queue.c or task.c to prevent it from having an effect within
S	those files. */
S	#ifndef MPU_WRAPPERS_INCLUDED_FROM_API_FILE
S
S		/*
S		 * Map standard (non MPU) API functions to equivalents that start
S		 * "MPU_".  This will cause the application code to call the MPU_
S		 * version, which wraps the non-MPU version with privilege promoting
S		 * then demoting code, so the kernel code always runs will full
S		 * privileges.
S		 */
S
S		/* Map standard tasks.h API functions to the MPU equivalents. */
S		#define xTaskCreate								MPU_xTaskCreate
S		#define xTaskCreateStatic						MPU_xTaskCreateStatic
S		#define xTaskCreateRestricted					MPU_xTaskCreateRestricted
S		#define vTaskAllocateMPURegions					MPU_vTaskAllocateMPURegions
S		#define vTaskDelete								MPU_vTaskDelete
S		#define vTaskDelay								MPU_vTaskDelay
S		#define vTaskDelayUntil							MPU_vTaskDelayUntil
S		#define xTaskAbortDelay							MPU_xTaskAbortDelay
S		#define uxTaskPriorityGet						MPU_uxTaskPriorityGet
S		#define eTaskGetState							MPU_eTaskGetState
S		#define vTaskGetInfo							MPU_vTaskGetInfo
S		#define vTaskPrioritySet						MPU_vTaskPrioritySet
S		#define vTaskSuspend							MPU_vTaskSuspend
S		#define vTaskResume								MPU_vTaskResume
S		#define vTaskSuspendAll							MPU_vTaskSuspendAll
S		#define xTaskResumeAll							MPU_xTaskResumeAll
S		#define xTaskGetTickCount						MPU_xTaskGetTickCount
S		#define uxTaskGetNumberOfTasks					MPU_uxTaskGetNumberOfTasks
S		#define pcTaskGetName							MPU_pcTaskGetName
S		#define xTaskGetHandle							MPU_xTaskGetHandle
S		#define uxTaskGetStackHighWaterMark				MPU_uxTaskGetStackHighWaterMark
S		#define vTaskSetApplicationTaskTag				MPU_vTaskSetApplicationTaskTag
S		#define xTaskGetApplicationTaskTag				MPU_xTaskGetApplicationTaskTag
S		#define vTaskSetThreadLocalStoragePointer		MPU_vTaskSetThreadLocalStoragePointer
S		#define pvTaskGetThreadLocalStoragePointer		MPU_pvTaskGetThreadLocalStoragePointer
S		#define xTaskCallApplicationTaskHook			MPU_xTaskCallApplicationTaskHook
S		#define xTaskGetIdleTaskHandle					MPU_xTaskGetIdleTaskHandle
S		#define uxTaskGetSystemState					MPU_uxTaskGetSystemState
S		#define vTaskList								MPU_vTaskList
S		#define vTaskGetRunTimeStats					MPU_vTaskGetRunTimeStats
S		#define xTaskGenericNotify						MPU_xTaskGenericNotify
S		#define xTaskNotifyWait							MPU_xTaskNotifyWait
S		#define ulTaskNotifyTake						MPU_ulTaskNotifyTake
S		#define xTaskNotifyStateClear					MPU_xTaskNotifyStateClear
S
S		#define xTaskGetCurrentTaskHandle				MPU_xTaskGetCurrentTaskHandle
S		#define vTaskSetTimeOutState					MPU_vTaskSetTimeOutState
S		#define xTaskCheckForTimeOut					MPU_xTaskCheckForTimeOut
S		#define xTaskGetSchedulerState					MPU_xTaskGetSchedulerState
S
S		/* Map standard queue.h API functions to the MPU equivalents. */
S		#define xQueueGenericSend						MPU_xQueueGenericSend
S		#define xQueueGenericReceive					MPU_xQueueGenericReceive
S		#define uxQueueMessagesWaiting					MPU_uxQueueMessagesWaiting
S		#define uxQueueSpacesAvailable					MPU_uxQueueSpacesAvailable
S		#define vQueueDelete							MPU_vQueueDelete
S		#define xQueueCreateMutex						MPU_xQueueCreateMutex
S		#define xQueueCreateMutexStatic					MPU_xQueueCreateMutexStatic
S		#define xQueueCreateCountingSemaphore			MPU_xQueueCreateCountingSemaphore
S		#define xQueueCreateCountingSemaphoreStatic		MPU_xQueueCreateCountingSemaphoreStatic
S		#define xQueueGetMutexHolder					MPU_xQueueGetMutexHolder
S		#define xQueueTakeMutexRecursive				MPU_xQueueTakeMutexRecursive
S		#define xQueueGiveMutexRecursive				MPU_xQueueGiveMutexRecursive
S		#define xQueueGenericCreate						MPU_xQueueGenericCreate
S		#define xQueueGenericCreateStatic				MPU_xQueueGenericCreateStatic
S		#define xQueueCreateSet							MPU_xQueueCreateSet
S		#define xQueueAddToSet							MPU_xQueueAddToSet
S		#define xQueueRemoveFromSet						MPU_xQueueRemoveFromSet
S		#define xQueueSelectFromSet						MPU_xQueueSelectFromSet
S		#define xQueueGenericReset						MPU_xQueueGenericReset
S
S		#if( configQUEUE_REGISTRY_SIZE > 0 )
S			#define vQueueAddToRegistry						MPU_vQueueAddToRegistry
S			#define vQueueUnregisterQueue					MPU_vQueueUnregisterQueue
S			#define pcQueueGetName							MPU_pcQueueGetName
S		#endif
S
S		/* Map standard timer.h API functions to the MPU equivalents. */
S		#define xTimerCreate							MPU_xTimerCreate
S		#define xTimerCreateStatic						MPU_xTimerCreateStatic
S		#define pvTimerGetTimerID						MPU_pvTimerGetTimerID
S		#define vTimerSetTimerID						MPU_vTimerSetTimerID
S		#define xTimerIsTimerActive						MPU_xTimerIsTimerActive
S		#define xTimerGetTimerDaemonTaskHandle			MPU_xTimerGetTimerDaemonTaskHandle
S		#define xTimerPendFunctionCall					MPU_xTimerPendFunctionCall
S		#define pcTimerGetName							MPU_pcTimerGetName
S		#define xTimerGetPeriod							MPU_xTimerGetPeriod
S		#define xTimerGetExpiryTime						MPU_xTimerGetExpiryTime
S		#define xTimerGenericCommand					MPU_xTimerGenericCommand
S
S		/* Map standard event_group.h API functions to the MPU equivalents. */
S		#define xEventGroupCreate						MPU_xEventGroupCreate
S		#define xEventGroupCreateStatic					MPU_xEventGroupCreateStatic
S		#define xEventGroupWaitBits						MPU_xEventGroupWaitBits
S		#define xEventGroupClearBits					MPU_xEventGroupClearBits
S		#define xEventGroupSetBits						MPU_xEventGroupSetBits
S		#define xEventGroupSync							MPU_xEventGroupSync
S		#define vEventGroupDelete						MPU_vEventGroupDelete
S
S		/* Remove the privileged function macro. */
S		#define PRIVILEGED_FUNCTION
S
S	#else /* MPU_WRAPPERS_INCLUDED_FROM_API_FILE */
S
S		/* Ensure API functions go in the privileged execution section. */
S		#define PRIVILEGED_FUNCTION __attribute__((section("privileged_functions")))
S		#define PRIVILEGED_DATA __attribute__((section("privileged_data")))
S
S	#endif /* MPU_WRAPPERS_INCLUDED_FROM_API_FILE */
S
N#else /* portUSING_MPU_WRAPPERS */
N
N	#define PRIVILEGED_FUNCTION
N	#define PRIVILEGED_DATA
N	#define portUSING_MPU_WRAPPERS 0
N
N#endif /* portUSING_MPU_WRAPPERS */
N
N
N#endif /* MPU_WRAPPERS_H */
N
L 134 "..\..\common\src\FreeRTOS\Source\include\portable.h" 2
N
N/*
N * Setup the stack of a new task so it is ready to be placed under the
N * scheduler control.  The registers have to be placed on the stack in
N * the order that the port expects to find them.
N *
N */
N#if( portUSING_MPU_WRAPPERS == 1 )
X#if( 0 == 1 )
S	StackType_t *pxPortInitialiseStack( StackType_t *pxTopOfStack, TaskFunction_t pxCode, void *pvParameters, BaseType_t xRunPrivileged ) PRIVILEGED_FUNCTION;
N#else
N	StackType_t *pxPortInitialiseStack( StackType_t *pxTopOfStack, TaskFunction_t pxCode, void *pvParameters ) PRIVILEGED_FUNCTION;
X	StackType_t *pxPortInitialiseStack( StackType_t *pxTopOfStack, TaskFunction_t pxCode, void *pvParameters ) ;
N#endif
N
N/* Used by heap_5.c. */
Ntypedef struct HeapRegion
N{
N	uint8_t *pucStartAddress;
N	size_t xSizeInBytes;
N} HeapRegion_t;
N
N/*
N * Used to define multiple heap regions for use by heap_5.c.  This function
N * must be called before any calls to pvPortMalloc() - not creating a task,
N * queue, semaphore, mutex, software timer, event group, etc. will result in
N * pvPortMalloc being called.
N *
N * pxHeapRegions passes in an array of HeapRegion_t structures - each of which
N * defines a region of memory that can be used as the heap.  The array is
N * terminated by a HeapRegions_t structure that has a size of 0.  The region
N * with the lowest start address must appear first in the array.
N */
Nvoid vPortDefineHeapRegions( const HeapRegion_t * const pxHeapRegions ) PRIVILEGED_FUNCTION;
Xvoid vPortDefineHeapRegions( const HeapRegion_t * const pxHeapRegions ) ;
N
N
N/*
N * Map to the memory management routines required for the port.
N */
Nvoid *pvPortMalloc( size_t xSize ) PRIVILEGED_FUNCTION;
Xvoid *pvPortMalloc( size_t xSize ) ;
Nvoid vPortFree( void *pv ) PRIVILEGED_FUNCTION;
Xvoid vPortFree( void *pv ) ;
Nvoid vPortInitialiseBlocks( void ) PRIVILEGED_FUNCTION;
Xvoid vPortInitialiseBlocks( void ) ;
Nsize_t xPortGetFreeHeapSize( void ) PRIVILEGED_FUNCTION;
Xsize_t xPortGetFreeHeapSize( void ) ;
Nsize_t xPortGetMinimumEverFreeHeapSize( void ) PRIVILEGED_FUNCTION;
Xsize_t xPortGetMinimumEverFreeHeapSize( void ) ;
N
N/*
N * Setup the hardware ready for the scheduler to take control.  This generally
N * sets up a tick interrupt and sets timers for the correct tick frequency.
N */
NBaseType_t xPortStartScheduler( void ) PRIVILEGED_FUNCTION;
XBaseType_t xPortStartScheduler( void ) ;
N
N/*
N * Undo any hardware/ISR setup that was performed by xPortStartScheduler() so
N * the hardware is left in its original condition after the scheduler stops
N * executing.
N */
Nvoid vPortEndScheduler( void ) PRIVILEGED_FUNCTION;
Xvoid vPortEndScheduler( void ) ;
N
N/*
N * The structures and methods of manipulating the MPU are contained within the
N * port layer.
N *
N * Fills the xMPUSettings structure with the memory region information
N * contained in xRegions.
N */
N#if( portUSING_MPU_WRAPPERS == 1 )
X#if( 0 == 1 )
S	struct xMEMORY_REGION;
S	void vPortStoreTaskMPUSettings( xMPU_SETTINGS *xMPUSettings, const struct xMEMORY_REGION * const xRegions, StackType_t *pxBottomOfStack, uint32_t ulStackDepth ) PRIVILEGED_FUNCTION;
N#endif
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* PORTABLE_H */
N
L 105 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/* Must be defaulted before configUSE_NEWLIB_REENTRANT is used below. */
N#ifndef configUSE_NEWLIB_REENTRANT
N	#define configUSE_NEWLIB_REENTRANT 0
N#endif
N
N/* Required if struct _reent is used. */
N#if ( configUSE_NEWLIB_REENTRANT == 1 )
X#if ( 0 == 1 )
S	#include <reent.h>
N#endif
N/*
N * Check all the required application specific macros have been defined.
N * These macros are application specific and (as downloaded) are defined
N * within FreeRTOSConfig.h.
N */
N
N#ifndef configMINIMAL_STACK_SIZE
S	#error Missing definition:  configMINIMAL_STACK_SIZE must be defined in FreeRTOSConfig.h.  configMINIMAL_STACK_SIZE defines the size (in words) of the stack allocated to the idle task.  Refer to the demo project provided for your port for a suitable value.
N#endif
N
N#ifndef configMAX_PRIORITIES
S	#error Missing definition:  configMAX_PRIORITIES must be defined in FreeRTOSConfig.h.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#if configMAX_PRIORITIES < 1
X#if ( 16 ) < 1
S	#error configMAX_PRIORITIES must be defined to be greater than or equal to 1.
N#endif
N
N#ifndef configUSE_PREEMPTION
S	#error Missing definition:  configUSE_PREEMPTION must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_IDLE_HOOK
S	#error Missing definition:  configUSE_IDLE_HOOK must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_TICK_HOOK
S	#error Missing definition:  configUSE_TICK_HOOK must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_16_BIT_TICKS
S	#error Missing definition:  configUSE_16_BIT_TICKS must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_CO_ROUTINES
S	#define configUSE_CO_ROUTINES 0
N#endif
N
N#ifndef INCLUDE_vTaskPrioritySet
S	#define INCLUDE_vTaskPrioritySet 0
N#endif
N
N#ifndef INCLUDE_uxTaskPriorityGet
S	#define INCLUDE_uxTaskPriorityGet 0
N#endif
N
N#ifndef INCLUDE_vTaskDelete
S	#define INCLUDE_vTaskDelete 0
N#endif
N
N#ifndef INCLUDE_vTaskSuspend
S	#define INCLUDE_vTaskSuspend 0
N#endif
N
N#ifndef INCLUDE_vTaskDelayUntil
S	#define INCLUDE_vTaskDelayUntil 0
N#endif
N
N#ifndef INCLUDE_vTaskDelay
S	#define INCLUDE_vTaskDelay 0
N#endif
N
N#ifndef INCLUDE_xTaskGetIdleTaskHandle
N	#define INCLUDE_xTaskGetIdleTaskHandle 0
N#endif
N
N#ifndef INCLUDE_xTaskAbortDelay
N	#define INCLUDE_xTaskAbortDelay 0
N#endif
N
N#ifndef INCLUDE_xQueueGetMutexHolder
N	#define INCLUDE_xQueueGetMutexHolder 0
N#endif
N
N#ifndef INCLUDE_xSemaphoreGetMutexHolder
N	#define INCLUDE_xSemaphoreGetMutexHolder INCLUDE_xQueueGetMutexHolder
N#endif
N
N#ifndef INCLUDE_xTaskGetHandle
N	#define INCLUDE_xTaskGetHandle 0
N#endif
N
N#ifndef INCLUDE_uxTaskGetStackHighWaterMark
S	#define INCLUDE_uxTaskGetStackHighWaterMark 0
N#endif
N
N#ifndef INCLUDE_eTaskGetState
N	#define INCLUDE_eTaskGetState 0
N#endif
N
N#ifndef INCLUDE_xTaskResumeFromISR
N	#define INCLUDE_xTaskResumeFromISR 1
N#endif
N
N#ifndef INCLUDE_xTimerPendFunctionCall
N	#define INCLUDE_xTimerPendFunctionCall 0
N#endif
N
N#ifndef INCLUDE_xTaskGetSchedulerState
N	#define INCLUDE_xTaskGetSchedulerState 0
N#endif
N
N#ifndef INCLUDE_xTaskGetCurrentTaskHandle
S	#define INCLUDE_xTaskGetCurrentTaskHandle 0
N#endif
N
N#if configUSE_CO_ROUTINES != 0
X#if 0 != 0
S	#ifndef configMAX_CO_ROUTINE_PRIORITIES
S		#error configMAX_CO_ROUTINE_PRIORITIES must be greater than or equal to 1.
S	#endif
N#endif
N
N#ifndef configUSE_DAEMON_TASK_STARTUP_HOOK
N	#define configUSE_DAEMON_TASK_STARTUP_HOOK 0
N#endif
N
N#ifndef configUSE_APPLICATION_TASK_TAG
N	#define configUSE_APPLICATION_TASK_TAG 0
N#endif
N
N#ifndef configNUM_THREAD_LOCAL_STORAGE_POINTERS
N	#define configNUM_THREAD_LOCAL_STORAGE_POINTERS 0
N#endif
N
N#ifndef configUSE_RECURSIVE_MUTEXES
N	#define configUSE_RECURSIVE_MUTEXES 0
N#endif
N
N#ifndef configUSE_MUTEXES
S	#define configUSE_MUTEXES 0
N#endif
N
N#ifndef configUSE_TIMERS
N	#define configUSE_TIMERS 0
N#endif
N
N#ifndef configUSE_COUNTING_SEMAPHORES
S	#define configUSE_COUNTING_SEMAPHORES 0
N#endif
N
N#ifndef configUSE_ALTERNATIVE_API
N	#define configUSE_ALTERNATIVE_API 0
N#endif
N
N#ifndef portCRITICAL_NESTING_IN_TCB
N	#define portCRITICAL_NESTING_IN_TCB 0
N#endif
N
N#ifndef configMAX_TASK_NAME_LEN
S	#define configMAX_TASK_NAME_LEN 16
N#endif
N
N#ifndef configIDLE_SHOULD_YIELD
S	#define configIDLE_SHOULD_YIELD		1
N#endif
N
N#if configMAX_TASK_NAME_LEN < 1
X#if ( 16 ) < 1
S	#error configMAX_TASK_NAME_LEN must be set to a minimum of 1 in FreeRTOSConfig.h
N#endif
N
N#ifndef configASSERT
N	#define configASSERT( x )
N	#define configASSERT_DEFINED 0
N#else
S	#define configASSERT_DEFINED 1
N#endif
N
N/* The timers module relies on xTaskGetSchedulerState(). */
N#if configUSE_TIMERS == 1
X#if 0 == 1
S
S	#ifndef configTIMER_TASK_PRIORITY
S		#error If configUSE_TIMERS is set to 1 then configTIMER_TASK_PRIORITY must also be defined.
S	#endif /* configTIMER_TASK_PRIORITY */
S
S	#ifndef configTIMER_QUEUE_LENGTH
S		#error If configUSE_TIMERS is set to 1 then configTIMER_QUEUE_LENGTH must also be defined.
S	#endif /* configTIMER_QUEUE_LENGTH */
S
S	#ifndef configTIMER_TASK_STACK_DEPTH
S		#error If configUSE_TIMERS is set to 1 then configTIMER_TASK_STACK_DEPTH must also be defined.
S	#endif /* configTIMER_TASK_STACK_DEPTH */
S
N#endif /* configUSE_TIMERS */
N
N#ifndef portSET_INTERRUPT_MASK_FROM_ISR
N	#define portSET_INTERRUPT_MASK_FROM_ISR() 0
N#endif
N
N#ifndef portCLEAR_INTERRUPT_MASK_FROM_ISR
N	#define portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedStatusValue ) ( void ) uxSavedStatusValue
N#endif
N
N#ifndef portCLEAN_UP_TCB
N	#define portCLEAN_UP_TCB( pxTCB ) ( void ) pxTCB
N#endif
N
N#ifndef portPRE_TASK_DELETE_HOOK
N	#define portPRE_TASK_DELETE_HOOK( pvTaskToDelete, pxYieldPending )
N#endif
N
N#ifndef portSETUP_TCB
N	#define portSETUP_TCB( pxTCB ) ( void ) pxTCB
N#endif
N
N#ifndef configQUEUE_REGISTRY_SIZE
N	#define configQUEUE_REGISTRY_SIZE 0U
N#endif
N
N#if ( configQUEUE_REGISTRY_SIZE < 1 )
X#if ( 0U < 1 )
N	#define vQueueAddToRegistry( xQueue, pcName )
N	#define vQueueUnregisterQueue( xQueue )
N	#define pcQueueGetName( xQueue )
N#endif
N
N#ifndef portPOINTER_SIZE_TYPE
N	#define portPOINTER_SIZE_TYPE uint32_t
N#endif
N
N/* Remove any unused trace macros. */
N#ifndef traceSTART
N	/* Used to perform any necessary initialisation - for example, open a file
N	into which trace is to be written. */
N	#define traceSTART()
N#endif
N
N#ifndef traceEND
N	/* Use to close a trace, for example close a file into which trace has been
N	written. */
N	#define traceEND()
N#endif
N
N#ifndef traceTASK_SWITCHED_IN
N	/* Called after a task has been selected to run.  pxCurrentTCB holds a pointer
N	to the task control block of the selected task. */
N	#define traceTASK_SWITCHED_IN()
N#endif
N
N#ifndef traceINCREASE_TICK_COUNT
N	/* Called before stepping the tick count after waking from tickless idle
N	sleep. */
N	#define traceINCREASE_TICK_COUNT( x )
N#endif
N
N#ifndef traceLOW_POWER_IDLE_BEGIN
N	/* Called immediately before entering tickless idle. */
N	#define traceLOW_POWER_IDLE_BEGIN()
N#endif
N
N#ifndef	traceLOW_POWER_IDLE_END
N	/* Called when returning to the Idle task after a tickless idle. */
N	#define traceLOW_POWER_IDLE_END()
N#endif
N
N#ifndef traceTASK_SWITCHED_OUT
N	/* Called before a task has been selected to run.  pxCurrentTCB holds a pointer
N	to the task control block of the task being switched out. */
N	#define traceTASK_SWITCHED_OUT()
N#endif
N
N#ifndef traceTASK_PRIORITY_INHERIT
N	/* Called when a task attempts to take a mutex that is already held by a
N	lower priority task.  pxTCBOfMutexHolder is a pointer to the TCB of the task
N	that holds the mutex.  uxInheritedPriority is the priority the mutex holder
N	will inherit (the priority of the task that is attempting to obtain the
N	muted. */
N	#define traceTASK_PRIORITY_INHERIT( pxTCBOfMutexHolder, uxInheritedPriority )
N#endif
N
N#ifndef traceTASK_PRIORITY_DISINHERIT
N	/* Called when a task releases a mutex, the holding of which had resulted in
N	the task inheriting the priority of a higher priority task.
N	pxTCBOfMutexHolder is a pointer to the TCB of the task that is releasing the
N	mutex.  uxOriginalPriority is the task's configured (base) priority. */
N	#define traceTASK_PRIORITY_DISINHERIT( pxTCBOfMutexHolder, uxOriginalPriority )
N#endif
N
N#ifndef traceBLOCKING_ON_QUEUE_RECEIVE
N	/* Task is about to block because it cannot read from a
N	queue/mutex/semaphore.  pxQueue is a pointer to the queue/mutex/semaphore
N	upon which the read was attempted.  pxCurrentTCB points to the TCB of the
N	task that attempted the read. */
N	#define traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue )
N#endif
N
N#ifndef traceBLOCKING_ON_QUEUE_SEND
N	/* Task is about to block because it cannot write to a
N	queue/mutex/semaphore.  pxQueue is a pointer to the queue/mutex/semaphore
N	upon which the write was attempted.  pxCurrentTCB points to the TCB of the
N	task that attempted the write. */
N	#define traceBLOCKING_ON_QUEUE_SEND( pxQueue )
N#endif
N
N#ifndef configCHECK_FOR_STACK_OVERFLOW
S	#define configCHECK_FOR_STACK_OVERFLOW 0
N#endif
N
N/* The following event macros are embedded in the kernel API calls. */
N
N#ifndef traceMOVED_TASK_TO_READY_STATE
N	#define traceMOVED_TASK_TO_READY_STATE( pxTCB )
N#endif
N
N#ifndef tracePOST_MOVED_TASK_TO_READY_STATE
N	#define tracePOST_MOVED_TASK_TO_READY_STATE( pxTCB )
N#endif
N
N#ifndef traceQUEUE_CREATE
N	#define traceQUEUE_CREATE( pxNewQueue )
N#endif
N
N#ifndef traceQUEUE_CREATE_FAILED
N	#define traceQUEUE_CREATE_FAILED( ucQueueType )
N#endif
N
N#ifndef traceCREATE_MUTEX
N	#define traceCREATE_MUTEX( pxNewQueue )
N#endif
N
N#ifndef traceCREATE_MUTEX_FAILED
N	#define traceCREATE_MUTEX_FAILED()
N#endif
N
N#ifndef traceGIVE_MUTEX_RECURSIVE
N	#define traceGIVE_MUTEX_RECURSIVE( pxMutex )
N#endif
N
N#ifndef traceGIVE_MUTEX_RECURSIVE_FAILED
N	#define traceGIVE_MUTEX_RECURSIVE_FAILED( pxMutex )
N#endif
N
N#ifndef traceTAKE_MUTEX_RECURSIVE
N	#define traceTAKE_MUTEX_RECURSIVE( pxMutex )
N#endif
N
N#ifndef traceTAKE_MUTEX_RECURSIVE_FAILED
N	#define traceTAKE_MUTEX_RECURSIVE_FAILED( pxMutex )
N#endif
N
N#ifndef traceCREATE_COUNTING_SEMAPHORE
N	#define traceCREATE_COUNTING_SEMAPHORE()
N#endif
N
N#ifndef traceCREATE_COUNTING_SEMAPHORE_FAILED
N	#define traceCREATE_COUNTING_SEMAPHORE_FAILED()
N#endif
N
N#ifndef traceQUEUE_SEND
N	#define traceQUEUE_SEND( pxQueue )
N#endif
N
N#ifndef traceQUEUE_SEND_FAILED
N	#define traceQUEUE_SEND_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE
N	#define traceQUEUE_RECEIVE( pxQueue )
N#endif
N
N#ifndef traceQUEUE_PEEK
N	#define traceQUEUE_PEEK( pxQueue )
N#endif
N
N#ifndef traceQUEUE_PEEK_FROM_ISR
N	#define traceQUEUE_PEEK_FROM_ISR( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE_FAILED
N	#define traceQUEUE_RECEIVE_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_SEND_FROM_ISR
N	#define traceQUEUE_SEND_FROM_ISR( pxQueue )
N#endif
N
N#ifndef traceQUEUE_SEND_FROM_ISR_FAILED
N	#define traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE_FROM_ISR
N	#define traceQUEUE_RECEIVE_FROM_ISR( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE_FROM_ISR_FAILED
N	#define traceQUEUE_RECEIVE_FROM_ISR_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_PEEK_FROM_ISR_FAILED
N	#define traceQUEUE_PEEK_FROM_ISR_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_DELETE
N	#define traceQUEUE_DELETE( pxQueue )
N#endif
N
N#ifndef traceTASK_CREATE
N	#define traceTASK_CREATE( pxNewTCB )
N#endif
N
N#ifndef traceTASK_CREATE_FAILED
N	#define traceTASK_CREATE_FAILED()
N#endif
N
N#ifndef traceTASK_DELETE
N	#define traceTASK_DELETE( pxTaskToDelete )
N#endif
N
N#ifndef traceTASK_DELAY_UNTIL
N	#define traceTASK_DELAY_UNTIL( x )
N#endif
N
N#ifndef traceTASK_DELAY
N	#define traceTASK_DELAY()
N#endif
N
N#ifndef traceTASK_PRIORITY_SET
N	#define traceTASK_PRIORITY_SET( pxTask, uxNewPriority )
N#endif
N
N#ifndef traceTASK_SUSPEND
N	#define traceTASK_SUSPEND( pxTaskToSuspend )
N#endif
N
N#ifndef traceTASK_RESUME
N	#define traceTASK_RESUME( pxTaskToResume )
N#endif
N
N#ifndef traceTASK_RESUME_FROM_ISR
N	#define traceTASK_RESUME_FROM_ISR( pxTaskToResume )
N#endif
N
N#ifndef traceTASK_INCREMENT_TICK
N	#define traceTASK_INCREMENT_TICK( xTickCount )
N#endif
N
N#ifndef traceTIMER_CREATE
N	#define traceTIMER_CREATE( pxNewTimer )
N#endif
N
N#ifndef traceTIMER_CREATE_FAILED
N	#define traceTIMER_CREATE_FAILED()
N#endif
N
N#ifndef traceTIMER_COMMAND_SEND
N	#define traceTIMER_COMMAND_SEND( xTimer, xMessageID, xMessageValueValue, xReturn )
N#endif
N
N#ifndef traceTIMER_EXPIRED
N	#define traceTIMER_EXPIRED( pxTimer )
N#endif
N
N#ifndef traceTIMER_COMMAND_RECEIVED
N	#define traceTIMER_COMMAND_RECEIVED( pxTimer, xMessageID, xMessageValue )
N#endif
N
N#ifndef traceMALLOC
N    #define traceMALLOC( pvAddress, uiSize )
N#endif
N
N#ifndef traceFREE
N    #define traceFREE( pvAddress, uiSize )
N#endif
N
N#ifndef traceEVENT_GROUP_CREATE
N	#define traceEVENT_GROUP_CREATE( xEventGroup )
N#endif
N
N#ifndef traceEVENT_GROUP_CREATE_FAILED
N	#define traceEVENT_GROUP_CREATE_FAILED()
N#endif
N
N#ifndef traceEVENT_GROUP_SYNC_BLOCK
N	#define traceEVENT_GROUP_SYNC_BLOCK( xEventGroup, uxBitsToSet, uxBitsToWaitFor )
N#endif
N
N#ifndef traceEVENT_GROUP_SYNC_END
N	#define traceEVENT_GROUP_SYNC_END( xEventGroup, uxBitsToSet, uxBitsToWaitFor, xTimeoutOccurred ) ( void ) xTimeoutOccurred
N#endif
N
N#ifndef traceEVENT_GROUP_WAIT_BITS_BLOCK
N	#define traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor )
N#endif
N
N#ifndef traceEVENT_GROUP_WAIT_BITS_END
N	#define traceEVENT_GROUP_WAIT_BITS_END( xEventGroup, uxBitsToWaitFor, xTimeoutOccurred ) ( void ) xTimeoutOccurred
N#endif
N
N#ifndef traceEVENT_GROUP_CLEAR_BITS
N	#define traceEVENT_GROUP_CLEAR_BITS( xEventGroup, uxBitsToClear )
N#endif
N
N#ifndef traceEVENT_GROUP_CLEAR_BITS_FROM_ISR
N	#define traceEVENT_GROUP_CLEAR_BITS_FROM_ISR( xEventGroup, uxBitsToClear )
N#endif
N
N#ifndef traceEVENT_GROUP_SET_BITS
N	#define traceEVENT_GROUP_SET_BITS( xEventGroup, uxBitsToSet )
N#endif
N
N#ifndef traceEVENT_GROUP_SET_BITS_FROM_ISR
N	#define traceEVENT_GROUP_SET_BITS_FROM_ISR( xEventGroup, uxBitsToSet )
N#endif
N
N#ifndef traceEVENT_GROUP_DELETE
N	#define traceEVENT_GROUP_DELETE( xEventGroup )
N#endif
N
N#ifndef tracePEND_FUNC_CALL
N	#define tracePEND_FUNC_CALL(xFunctionToPend, pvParameter1, ulParameter2, ret)
N#endif
N
N#ifndef tracePEND_FUNC_CALL_FROM_ISR
N	#define tracePEND_FUNC_CALL_FROM_ISR(xFunctionToPend, pvParameter1, ulParameter2, ret)
N#endif
N
N#ifndef traceQUEUE_REGISTRY_ADD
N	#define traceQUEUE_REGISTRY_ADD(xQueue, pcQueueName)
N#endif
N
N#ifndef traceTASK_NOTIFY_TAKE_BLOCK
N	#define traceTASK_NOTIFY_TAKE_BLOCK()
N#endif
N
N#ifndef traceTASK_NOTIFY_TAKE
N	#define traceTASK_NOTIFY_TAKE()
N#endif
N
N#ifndef traceTASK_NOTIFY_WAIT_BLOCK
N	#define traceTASK_NOTIFY_WAIT_BLOCK()
N#endif
N
N#ifndef traceTASK_NOTIFY_WAIT
N	#define traceTASK_NOTIFY_WAIT()
N#endif
N
N#ifndef traceTASK_NOTIFY
N	#define traceTASK_NOTIFY()
N#endif
N
N#ifndef traceTASK_NOTIFY_FROM_ISR
N	#define traceTASK_NOTIFY_FROM_ISR()
N#endif
N
N#ifndef traceTASK_NOTIFY_GIVE_FROM_ISR
N	#define traceTASK_NOTIFY_GIVE_FROM_ISR()
N#endif
N
N#ifndef configGENERATE_RUN_TIME_STATS
N	#define configGENERATE_RUN_TIME_STATS 0
N#endif
N
N#if ( configGENERATE_RUN_TIME_STATS == 1 )
X#if ( 0 == 1 )
S
S	#ifndef portCONFIGURE_TIMER_FOR_RUN_TIME_STATS
S		#error If configGENERATE_RUN_TIME_STATS is defined then portCONFIGURE_TIMER_FOR_RUN_TIME_STATS must also be defined.  portCONFIGURE_TIMER_FOR_RUN_TIME_STATS should call a port layer function to setup a peripheral timer/counter that can then be used as the run time counter time base.
S	#endif /* portCONFIGURE_TIMER_FOR_RUN_TIME_STATS */
S
S	#ifndef portGET_RUN_TIME_COUNTER_VALUE
S		#ifndef portALT_GET_RUN_TIME_COUNTER_VALUE
S			#error If configGENERATE_RUN_TIME_STATS is defined then either portGET_RUN_TIME_COUNTER_VALUE or portALT_GET_RUN_TIME_COUNTER_VALUE must also be defined.  See the examples provided and the FreeRTOS web site for more information.
S		#endif /* portALT_GET_RUN_TIME_COUNTER_VALUE */
S	#endif /* portGET_RUN_TIME_COUNTER_VALUE */
S
N#endif /* configGENERATE_RUN_TIME_STATS */
N
N#ifndef portCONFIGURE_TIMER_FOR_RUN_TIME_STATS
N	#define portCONFIGURE_TIMER_FOR_RUN_TIME_STATS()
N#endif
N
N#ifndef configUSE_MALLOC_FAILED_HOOK
S	#define configUSE_MALLOC_FAILED_HOOK 0
N#endif
N
N#ifndef portPRIVILEGE_BIT
N	#define portPRIVILEGE_BIT ( ( UBaseType_t ) 0x00 )
N#endif
N
N#ifndef portYIELD_WITHIN_API
N	#define portYIELD_WITHIN_API portYIELD
N#endif
N
N#ifndef portSUPPRESS_TICKS_AND_SLEEP
N	#define portSUPPRESS_TICKS_AND_SLEEP( xExpectedIdleTime )
N#endif
N
N#ifndef configEXPECTED_IDLE_TIME_BEFORE_SLEEP
N	#define configEXPECTED_IDLE_TIME_BEFORE_SLEEP 2
N#endif
N
N#if configEXPECTED_IDLE_TIME_BEFORE_SLEEP < 2
X#if 2 < 2
S	#error configEXPECTED_IDLE_TIME_BEFORE_SLEEP must not be less than 2
N#endif
N
N#ifndef configUSE_TICKLESS_IDLE
N	#define configUSE_TICKLESS_IDLE 0
N#endif
N
N#ifndef configPRE_SLEEP_PROCESSING
N	#define configPRE_SLEEP_PROCESSING( x )
N#endif
N
N#ifndef configPOST_SLEEP_PROCESSING
N	#define configPOST_SLEEP_PROCESSING( x )
N#endif
N
N#ifndef configUSE_QUEUE_SETS
N	#define configUSE_QUEUE_SETS 0
N#endif
N
N#ifndef portTASK_USES_FLOATING_POINT
N	#define portTASK_USES_FLOATING_POINT()
N#endif
N
N#ifndef configUSE_TIME_SLICING
N	#define configUSE_TIME_SLICING 1
N#endif
N
N#ifndef configINCLUDE_APPLICATION_DEFINED_PRIVILEGED_FUNCTIONS
N	#define configINCLUDE_APPLICATION_DEFINED_PRIVILEGED_FUNCTIONS 0
N#endif
N
N#ifndef configUSE_STATS_FORMATTING_FUNCTIONS
S	#define configUSE_STATS_FORMATTING_FUNCTIONS 0
N#endif
N
N#ifndef portASSERT_IF_INTERRUPT_PRIORITY_INVALID
N	#define portASSERT_IF_INTERRUPT_PRIORITY_INVALID()
N#endif
N
N#ifndef configUSE_TRACE_FACILITY
S	#define configUSE_TRACE_FACILITY 0
N#endif
N
N#ifndef mtCOVERAGE_TEST_MARKER
N	#define mtCOVERAGE_TEST_MARKER()
N#endif
N
N#ifndef mtCOVERAGE_TEST_DELAY
N	#define mtCOVERAGE_TEST_DELAY()
N#endif
N
N#ifndef portASSERT_IF_IN_ISR
N	#define portASSERT_IF_IN_ISR()
N#endif
N
N#ifndef configUSE_PORT_OPTIMISED_TASK_SELECTION
N	#define configUSE_PORT_OPTIMISED_TASK_SELECTION 0
N#endif
N
N#ifndef configAPPLICATION_ALLOCATED_HEAP
N	#define configAPPLICATION_ALLOCATED_HEAP 0
N#endif
N
N#ifndef configUSE_TASK_NOTIFICATIONS
N	#define configUSE_TASK_NOTIFICATIONS 1
N#endif
N
N#ifndef portTICK_TYPE_IS_ATOMIC
N	#define portTICK_TYPE_IS_ATOMIC 0
N#endif
N
N#ifndef configSUPPORT_STATIC_ALLOCATION
N	/* Defaults to 0 for backward compatibility. */
N	#define configSUPPORT_STATIC_ALLOCATION 0
N#endif
N
N#ifndef configSUPPORT_DYNAMIC_ALLOCATION
S	/* Defaults to 1 for backward compatibility. */
S	#define configSUPPORT_DYNAMIC_ALLOCATION 1
N#endif
N
N/* Sanity check the configuration. */
N#if( configUSE_TICKLESS_IDLE != 0 )
X#if( 0 != 0 )
S	#if( INCLUDE_vTaskSuspend != 1 )
S		#error INCLUDE_vTaskSuspend must be set to 1 if configUSE_TICKLESS_IDLE is not set to 0
S	#endif /* INCLUDE_vTaskSuspend */
N#endif /* configUSE_TICKLESS_IDLE */
N
N#if( ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 0 ) )
X#if( ( 0 == 0 ) && ( 1 == 0 ) )
S	#error configSUPPORT_STATIC_ALLOCATION and configSUPPORT_DYNAMIC_ALLOCATION cannot both be 0, but can both be 1.
N#endif
N
N#if( ( configUSE_RECURSIVE_MUTEXES == 1 ) && ( configUSE_MUTEXES != 1 ) )
X#if( ( 0 == 1 ) && ( 1 != 1 ) )
S	#error configUSE_MUTEXES must be set to 1 to use recursive mutexes
N#endif
N
N#if( portTICK_TYPE_IS_ATOMIC == 0 )
X#if( 0 == 0 )
N	/* Either variables of tick type cannot be read atomically, or
N	portTICK_TYPE_IS_ATOMIC was not set - map the critical sections used when
N	the tick count is returned to the standard critical section macros. */
N	#define portTICK_TYPE_ENTER_CRITICAL() portENTER_CRITICAL()
N	#define portTICK_TYPE_EXIT_CRITICAL() portEXIT_CRITICAL()
N	#define portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR() portSET_INTERRUPT_MASK_FROM_ISR()
N	#define portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( x ) portCLEAR_INTERRUPT_MASK_FROM_ISR( ( x ) )
N#else
S	/* The tick type can be read atomically, so critical sections used when the
S	tick count is returned can be defined away. */
S	#define portTICK_TYPE_ENTER_CRITICAL()
S	#define portTICK_TYPE_EXIT_CRITICAL()
S	#define portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR() 0
S	#define portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( x ) ( void ) x
N#endif
N
N/* Definitions to allow backward compatibility with FreeRTOS versions prior to
NV8 if desired. */
N#ifndef configENABLE_BACKWARD_COMPATIBILITY
N	#define configENABLE_BACKWARD_COMPATIBILITY 1
N#endif
N
N#if configENABLE_BACKWARD_COMPATIBILITY == 1
X#if 1 == 1
N	#define eTaskStateGet eTaskGetState
N	#define portTickType TickType_t
N	#define xTaskHandle TaskHandle_t
N	#define xQueueHandle QueueHandle_t
N	#define xSemaphoreHandle SemaphoreHandle_t
N	#define xQueueSetHandle QueueSetHandle_t
N	#define xQueueSetMemberHandle QueueSetMemberHandle_t
N	#define xTimeOutType TimeOut_t
N	#define xMemoryRegion MemoryRegion_t
N	#define xTaskParameters TaskParameters_t
N	#define xTaskStatusType	TaskStatus_t
N	#define xTimerHandle TimerHandle_t
N	#define xCoRoutineHandle CoRoutineHandle_t
N	#define pdTASK_HOOK_CODE TaskHookFunction_t
N	#define portTICK_RATE_MS portTICK_PERIOD_MS
N	#define pcTaskGetTaskName pcTaskGetName
N	#define pcTimerGetTimerName pcTimerGetName
N	#define pcQueueGetQueueName pcQueueGetName
N	#define vTaskGetTaskInfo vTaskGetInfo
N
N	/* Backward compatibility within the scheduler code only - these definitions
N	are not really required but are included for completeness. */
N	#define tmrTIMER_CALLBACK TimerCallbackFunction_t
N	#define pdTASK_CODE TaskFunction_t
N	#define xListItem ListItem_t
N	#define xList List_t
N#endif /* configENABLE_BACKWARD_COMPATIBILITY */
N
N#if( configUSE_ALTERNATIVE_API != 0 )
X#if( 0 != 0 )
S	#error The alternative API was deprecated some time ago, and was removed in FreeRTOS V9.0 0
N#endif
N
N/* Set configUSE_TASK_FPU_SUPPORT to 0 to omit floating point support even
Nif floating point hardware is otherwise supported by the FreeRTOS port in use.
NThis constant is not supported by all FreeRTOS ports that include floating
Npoint support. */
N#ifndef configUSE_TASK_FPU_SUPPORT
N	#define configUSE_TASK_FPU_SUPPORT 1
N#endif
N
N/*
N * In line with software engineering best practice, FreeRTOS implements a strict
N * data hiding policy, so the real structures used by FreeRTOS to maintain the
N * state of tasks, queues, semaphores, etc. are not accessible to the application
N * code.  However, if the application writer wants to statically allocate such
N * an object then the size of the object needs to be know.  Dummy structures
N * that are guaranteed to have the same size and alignment requirements of the
N * real objects are used for this purpose.  The dummy list and list item
N * structures below are used for inclusion in such a dummy structure.
N */
Nstruct xSTATIC_LIST_ITEM
N{
N	TickType_t xDummy1;
N	void *pvDummy2[ 4 ];
N};
Ntypedef struct xSTATIC_LIST_ITEM StaticListItem_t;
N
N/* See the comments above the struct xSTATIC_LIST_ITEM definition. */
Nstruct xSTATIC_MINI_LIST_ITEM
N{
N	TickType_t xDummy1;
N	void *pvDummy2[ 2 ];
N};
Ntypedef struct xSTATIC_MINI_LIST_ITEM StaticMiniListItem_t;
N
N/* See the comments above the struct xSTATIC_LIST_ITEM definition. */
Ntypedef struct xSTATIC_LIST
N{
N	UBaseType_t uxDummy1;
N	void *pvDummy2;
N	StaticMiniListItem_t xDummy3;
N} StaticList_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the Task structure used internally by
N * FreeRTOS is not accessible to application code.  However, if the application
N * writer wants to statically allocate the memory required to create a task then
N * the size of the task object needs to be know.  The StaticTask_t structure
N * below is provided for this purpose.  Its sizes and alignment requirements are
N * guaranteed to match those of the genuine structure, no matter which
N * architecture is being used, and no matter how the values in FreeRTOSConfig.h
N * are set.  Its contents are somewhat obfuscated in the hope users will
N * recognise that it would be unwise to make direct use of the structure members.
N */
Ntypedef struct xSTATIC_TCB
N{
N	void				*pxDummy1;
N	#if ( portUSING_MPU_WRAPPERS == 1 )
X	#if ( 0 == 1 )
S		xMPU_SETTINGS	xDummy2;
N	#endif
N	StaticListItem_t	xDummy3[ 2 ];
N	UBaseType_t			uxDummy5;
N	void				*pxDummy6;
N	uint8_t				ucDummy7[ configMAX_TASK_NAME_LEN ];
X	uint8_t				ucDummy7[ ( 16 ) ];
N	#if ( portSTACK_GROWTH > 0 )
X	#if ( ( -1 ) > 0 )
S		void			*pxDummy8;
N	#endif
N	#if ( portCRITICAL_NESTING_IN_TCB == 1 )
X	#if ( 0 == 1 )
S		UBaseType_t		uxDummy9;
N	#endif
N	#if ( configUSE_TRACE_FACILITY == 1 )
X	#if ( 1 == 1 )
N		UBaseType_t		uxDummy10[ 2 ];
N	#endif
N	#if ( configUSE_MUTEXES == 1 )
X	#if ( 1 == 1 )
N		UBaseType_t		uxDummy12[ 2 ];
N	#endif
N	#if ( configUSE_APPLICATION_TASK_TAG == 1 )
X	#if ( 0 == 1 )
S		void			*pxDummy14;
N	#endif
N	#if( configNUM_THREAD_LOCAL_STORAGE_POINTERS > 0 )
X	#if( 0 > 0 )
S		void			*pvDummy15[ configNUM_THREAD_LOCAL_STORAGE_POINTERS ];
N	#endif
N	#if ( configGENERATE_RUN_TIME_STATS == 1 )
X	#if ( 0 == 1 )
S		uint32_t		ulDummy16;
N	#endif
N	#if ( configUSE_NEWLIB_REENTRANT == 1 )
X	#if ( 0 == 1 )
S		struct	_reent	xDummy17;
N	#endif
N	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
X	#if ( 1 == 1 )
N		uint32_t 		ulDummy18;
N		uint8_t 		ucDummy19;
N	#endif
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S		uint8_t			uxDummy20;
N	#endif
N
N} StaticTask_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the Queue structure used internally by
N * FreeRTOS is not accessible to application code.  However, if the application
N * writer wants to statically allocate the memory required to create a queue
N * then the size of the queue object needs to be know.  The StaticQueue_t
N * structure below is provided for this purpose.  Its sizes and alignment
N * requirements are guaranteed to match those of the genuine structure, no
N * matter which architecture is being used, and no matter how the values in
N * FreeRTOSConfig.h are set.  Its contents are somewhat obfuscated in the hope
N * users will recognise that it would be unwise to make direct use of the
N * structure members.
N */
Ntypedef struct xSTATIC_QUEUE
N{
N	void *pvDummy1[ 3 ];
N
N	union
N	{
N		void *pvDummy2;
N		UBaseType_t uxDummy2;
N	} u;
N
N	StaticList_t xDummy3[ 2 ];
N	UBaseType_t uxDummy4[ 3 ];
N	uint8_t ucDummy5[ 2 ];
N
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S		uint8_t ucDummy6;
N	#endif
N
N	#if ( configUSE_QUEUE_SETS == 1 )
X	#if ( 0 == 1 )
S		void *pvDummy7;
N	#endif
N
N	#if ( configUSE_TRACE_FACILITY == 1 )
X	#if ( 1 == 1 )
N		UBaseType_t uxDummy8;
N		uint8_t ucDummy9;
N	#endif
N
N} StaticQueue_t;
Ntypedef StaticQueue_t StaticSemaphore_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the event group structure used
N * internally by FreeRTOS is not accessible to application code.  However, if
N * the application writer wants to statically allocate the memory required to
N * create an event group then the size of the event group object needs to be
N * know.  The StaticEventGroup_t structure below is provided for this purpose.
N * Its sizes and alignment requirements are guaranteed to match those of the
N * genuine structure, no matter which architecture is being used, and no matter
N * how the values in FreeRTOSConfig.h are set.  Its contents are somewhat
N * obfuscated in the hope users will recognise that it would be unwise to make
N * direct use of the structure members.
N */
Ntypedef struct xSTATIC_EVENT_GROUP
N{
N	TickType_t xDummy1;
N	StaticList_t xDummy2;
N
N	#if( configUSE_TRACE_FACILITY == 1 )
X	#if( 1 == 1 )
N		UBaseType_t uxDummy3;
N	#endif
N
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S			uint8_t ucDummy4;
N	#endif
N
N} StaticEventGroup_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the software timer structure used
N * internally by FreeRTOS is not accessible to application code.  However, if
N * the application writer wants to statically allocate the memory required to
N * create a software timer then the size of the queue object needs to be know.
N * The StaticTimer_t structure below is provided for this purpose.  Its sizes
N * and alignment requirements are guaranteed to match those of the genuine
N * structure, no matter which architecture is being used, and no matter how the
N * values in FreeRTOSConfig.h are set.  Its contents are somewhat obfuscated in
N * the hope users will recognise that it would be unwise to make direct use of
N * the structure members.
N */
Ntypedef struct xSTATIC_TIMER
N{
N	void				*pvDummy1;
N	StaticListItem_t	xDummy2;
N	TickType_t			xDummy3;
N	UBaseType_t			uxDummy4;
N	void 				*pvDummy5[ 2 ];
N	#if( configUSE_TRACE_FACILITY == 1 )
X	#if( 1 == 1 )
N		UBaseType_t		uxDummy6;
N	#endif
N
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S		uint8_t 		ucDummy7;
N	#endif
N
N} StaticTimer_t;
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* INC_FREERTOS_H */
N
L 6 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N#include "task.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\task.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N
N#ifndef INC_TASK_H
N#define INC_TASK_H
N
N#ifndef INC_FREERTOS_H
S	#error "include FreeRTOS.h must appear in source files before include task.h"
N#endif
N
N#include "list.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\list.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N/*
N * This is the list implementation used by the scheduler.  While it is tailored
N * heavily for the schedulers needs, it is also available for use by
N * application code.
N *
N * list_ts can only store pointers to list_item_ts.  Each ListItem_t contains a
N * numeric value (xItemValue).  Most of the time the lists are sorted in
N * descending item value order.
N *
N * Lists are created already containing one list item.  The value of this
N * item is the maximum possible that can be stored, it is therefore always at
N * the end of the list and acts as a marker.  The list member pxHead always
N * points to this marker - even though it is at the tail of the list.  This
N * is because the tail contains a wrap back pointer to the true head of
N * the list.
N *
N * In addition to it's value, each list item contains a pointer to the next
N * item in the list (pxNext), a pointer to the list it is in (pxContainer)
N * and a pointer to back to the object that contains it.  These later two
N * pointers are included for efficiency of list manipulation.  There is
N * effectively a two way link between the object containing the list item and
N * the list item itself.
N *
N *
N * \page ListIntroduction List Implementation
N * \ingroup FreeRTOSIntro
N */
N
N#ifndef INC_FREERTOS_H
S	#error FreeRTOS.h must be included before list.h
N#endif
N
N#ifndef LIST_H
N#define LIST_H
N
N/*
N * The list structure members are modified from within interrupts, and therefore
N * by rights should be declared volatile.  However, they are only modified in a
N * functionally atomic way (within critical sections of with the scheduler
N * suspended) and are either passed by reference into a function or indexed via
N * a volatile variable.  Therefore, in all use cases tested so far, the volatile
N * qualifier can be omitted in order to provide a moderate performance
N * improvement without adversely affecting functional behaviour.  The assembly
N * instructions generated by the IAR, ARM and GCC compilers when the respective
N * compiler's options were set for maximum optimisation has been inspected and
N * deemed to be as intended.  That said, as compiler technology advances, and
N * especially if aggressive cross module optimisation is used (a use case that
N * has not been exercised to any great extend) then it is feasible that the
N * volatile qualifier will be needed for correct optimisation.  It is expected
N * that a compiler removing essential code because, without the volatile
N * qualifier on the list structure members and with aggressive cross module
N * optimisation, the compiler deemed the code unnecessary will result in
N * complete and obvious failure of the scheduler.  If this is ever experienced
N * then the volatile qualifier can be inserted in the relevant places within the
N * list structures by simply defining configLIST_VOLATILE to volatile in
N * FreeRTOSConfig.h (as per the example at the bottom of this comment block).
N * If configLIST_VOLATILE is not defined then the preprocessor directives below
N * will simply #define configLIST_VOLATILE away completely.
N *
N * To use volatile list structure members then add the following line to
N * FreeRTOSConfig.h (without the quotes):
N * "#define configLIST_VOLATILE volatile"
N */
N#ifndef configLIST_VOLATILE
N	#define configLIST_VOLATILE
N#endif /* configSUPPORT_CROSS_MODULE_OPTIMISATION */
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N/* Macros that can be used to place known values within the list structures,
Nthen check that the known values do not get corrupted during the execution of
Nthe application.   These may catch the list data structures being overwritten in
Nmemory.  They will not catch data errors caused by incorrect configuration or
Nuse of FreeRTOS.*/
N#if( configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES == 0 )
X#if( 0 == 0 )
N	/* Define the macros to do nothing. */
N	#define listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE
N	#define listSECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE
N	#define listFIRST_LIST_INTEGRITY_CHECK_VALUE
N	#define listSECOND_LIST_INTEGRITY_CHECK_VALUE
N	#define listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )
N	#define listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )
N	#define listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList )
N	#define listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList )
N	#define listTEST_LIST_ITEM_INTEGRITY( pxItem )
N	#define listTEST_LIST_INTEGRITY( pxList )
N#else
S	/* Define macros that add new members into the list structures. */
S	#define listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE				TickType_t xListItemIntegrityValue1;
S	#define listSECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE				TickType_t xListItemIntegrityValue2;
S	#define listFIRST_LIST_INTEGRITY_CHECK_VALUE					TickType_t xListIntegrityValue1;
S	#define listSECOND_LIST_INTEGRITY_CHECK_VALUE					TickType_t xListIntegrityValue2;
S
S	/* Define macros that set the new structure members to known values. */
S	#define listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )		( pxItem )->xListItemIntegrityValue1 = pdINTEGRITY_CHECK_VALUE
S	#define listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )	( pxItem )->xListItemIntegrityValue2 = pdINTEGRITY_CHECK_VALUE
S	#define listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList )		( pxList )->xListIntegrityValue1 = pdINTEGRITY_CHECK_VALUE
S	#define listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList )		( pxList )->xListIntegrityValue2 = pdINTEGRITY_CHECK_VALUE
S
S	/* Define macros that will assert if one of the structure members does not
S	contain its expected value. */
S	#define listTEST_LIST_ITEM_INTEGRITY( pxItem )		configASSERT( ( ( pxItem )->xListItemIntegrityValue1 == pdINTEGRITY_CHECK_VALUE ) && ( ( pxItem )->xListItemIntegrityValue2 == pdINTEGRITY_CHECK_VALUE ) )
S	#define listTEST_LIST_INTEGRITY( pxList )			configASSERT( ( ( pxList )->xListIntegrityValue1 == pdINTEGRITY_CHECK_VALUE ) && ( ( pxList )->xListIntegrityValue2 == pdINTEGRITY_CHECK_VALUE ) )
N#endif /* configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES */
N
N
N/*
N * Definition of the only type of object that a list can contain.
N */
Nstruct xLIST_ITEM
N{
N	listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE			/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X				 
N	configLIST_VOLATILE TickType_t xItemValue;			/*< The value being listed.  In most cases this is used to sort the list in descending order. */
X	 TickType_t xItemValue;			 
N	struct xLIST_ITEM * configLIST_VOLATILE pxNext;		/*< Pointer to the next ListItem_t in the list. */
X	struct xLIST_ITEM *  pxNext;		 
N	struct xLIST_ITEM * configLIST_VOLATILE pxPrevious;	/*< Pointer to the previous ListItem_t in the list. */
X	struct xLIST_ITEM *  pxPrevious;	 
N	void * pvOwner;										/*< Pointer to the object (normally a TCB) that contains the list item.  There is therefore a two way link between the object containing the list item and the list item itself. */
N	void * configLIST_VOLATILE pvContainer;				/*< Pointer to the list in which this list item is placed (if any). */
X	void *  pvContainer;				 
N	listSECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE			/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X				 
N};
Ntypedef struct xLIST_ITEM ListItem_t;					/* For some reason lint wants this as two separate definitions. */
N
Nstruct xMINI_LIST_ITEM
N{
N	listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE			/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X				 
N	configLIST_VOLATILE TickType_t xItemValue;
X	 TickType_t xItemValue;
N	struct xLIST_ITEM * configLIST_VOLATILE pxNext;
X	struct xLIST_ITEM *  pxNext;
N	struct xLIST_ITEM * configLIST_VOLATILE pxPrevious;
X	struct xLIST_ITEM *  pxPrevious;
N};
Ntypedef struct xMINI_LIST_ITEM MiniListItem_t;
N
N/*
N * Definition of the type of queue used by the scheduler.
N */
Ntypedef struct xLIST
N{
N	listFIRST_LIST_INTEGRITY_CHECK_VALUE				/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X					 
N	configLIST_VOLATILE UBaseType_t uxNumberOfItems;
X	 UBaseType_t uxNumberOfItems;
N	ListItem_t * configLIST_VOLATILE pxIndex;			/*< Used to walk through the list.  Points to the last item returned by a call to listGET_OWNER_OF_NEXT_ENTRY (). */
X	ListItem_t *  pxIndex;			 
N	MiniListItem_t xListEnd;							/*< List item that contains the maximum possible item value meaning it is always at the end of the list and is therefore used as a marker. */
N	listSECOND_LIST_INTEGRITY_CHECK_VALUE				/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X					 
N} List_t;
N
N/*
N * Access macro to set the owner of a list item.  The owner of a list item
N * is the object (usually a TCB) that contains the list item.
N *
N * \page listSET_LIST_ITEM_OWNER listSET_LIST_ITEM_OWNER
N * \ingroup LinkedList
N */
N#define listSET_LIST_ITEM_OWNER( pxListItem, pxOwner )		( ( pxListItem )->pvOwner = ( void * ) ( pxOwner ) )
N
N/*
N * Access macro to get the owner of a list item.  The owner of a list item
N * is the object (usually a TCB) that contains the list item.
N *
N * \page listSET_LIST_ITEM_OWNER listSET_LIST_ITEM_OWNER
N * \ingroup LinkedList
N */
N#define listGET_LIST_ITEM_OWNER( pxListItem )	( ( pxListItem )->pvOwner )
N
N/*
N * Access macro to set the value of the list item.  In most cases the value is
N * used to sort the list in descending order.
N *
N * \page listSET_LIST_ITEM_VALUE listSET_LIST_ITEM_VALUE
N * \ingroup LinkedList
N */
N#define listSET_LIST_ITEM_VALUE( pxListItem, xValue )	( ( pxListItem )->xItemValue = ( xValue ) )
N
N/*
N * Access macro to retrieve the value of the list item.  The value can
N * represent anything - for example the priority of a task, or the time at
N * which a task should be unblocked.
N *
N * \page listGET_LIST_ITEM_VALUE listGET_LIST_ITEM_VALUE
N * \ingroup LinkedList
N */
N#define listGET_LIST_ITEM_VALUE( pxListItem )	( ( pxListItem )->xItemValue )
N
N/*
N * Access macro to retrieve the value of the list item at the head of a given
N * list.
N *
N * \page listGET_LIST_ITEM_VALUE listGET_LIST_ITEM_VALUE
N * \ingroup LinkedList
N */
N#define listGET_ITEM_VALUE_OF_HEAD_ENTRY( pxList )	( ( ( pxList )->xListEnd ).pxNext->xItemValue )
N
N/*
N * Return the list item at the head of the list.
N *
N * \page listGET_HEAD_ENTRY listGET_HEAD_ENTRY
N * \ingroup LinkedList
N */
N#define listGET_HEAD_ENTRY( pxList )	( ( ( pxList )->xListEnd ).pxNext )
N
N/*
N * Return the list item at the head of the list.
N *
N * \page listGET_NEXT listGET_NEXT
N * \ingroup LinkedList
N */
N#define listGET_NEXT( pxListItem )	( ( pxListItem )->pxNext )
N
N/*
N * Return the list item that marks the end of the list
N *
N * \page listGET_END_MARKER listGET_END_MARKER
N * \ingroup LinkedList
N */
N#define listGET_END_MARKER( pxList )	( ( ListItem_t const * ) ( &( ( pxList )->xListEnd ) ) )
N
N/*
N * Access macro to determine if a list contains any items.  The macro will
N * only have the value true if the list is empty.
N *
N * \page listLIST_IS_EMPTY listLIST_IS_EMPTY
N * \ingroup LinkedList
N */
N#define listLIST_IS_EMPTY( pxList )	( ( BaseType_t ) ( ( pxList )->uxNumberOfItems == ( UBaseType_t ) 0 ) )
N
N/*
N * Access macro to return the number of items in the list.
N */
N#define listCURRENT_LIST_LENGTH( pxList )	( ( pxList )->uxNumberOfItems )
N
N/*
N * Access function to obtain the owner of the next entry in a list.
N *
N * The list member pxIndex is used to walk through a list.  Calling
N * listGET_OWNER_OF_NEXT_ENTRY increments pxIndex to the next item in the list
N * and returns that entry's pxOwner parameter.  Using multiple calls to this
N * function it is therefore possible to move through every item contained in
N * a list.
N *
N * The pxOwner parameter of a list item is a pointer to the object that owns
N * the list item.  In the scheduler this is normally a task control block.
N * The pxOwner parameter effectively creates a two way link between the list
N * item and its owner.
N *
N * @param pxTCB pxTCB is set to the address of the owner of the next list item.
N * @param pxList The list from which the next item owner is to be returned.
N *
N * \page listGET_OWNER_OF_NEXT_ENTRY listGET_OWNER_OF_NEXT_ENTRY
N * \ingroup LinkedList
N */
N#define listGET_OWNER_OF_NEXT_ENTRY( pxTCB, pxList )										\
N{																							\
NList_t * const pxConstList = ( pxList );													\
N	/* Increment the index to the next item and return the item, ensuring */				\
N	/* we don't return the marker used at the end of the list.  */							\
N	( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;							\
N	if( ( void * ) ( pxConstList )->pxIndex == ( void * ) &( ( pxConstList )->xListEnd ) )	\
N	{																						\
N		( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;						\
N	}																						\
N	( pxTCB ) = ( pxConstList )->pxIndex->pvOwner;											\
N}
X#define listGET_OWNER_OF_NEXT_ENTRY( pxTCB, pxList )										{																							List_t * const pxConstList = ( pxList );														 					 								( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;								if( ( void * ) ( pxConstList )->pxIndex == ( void * ) &( ( pxConstList )->xListEnd ) )		{																								( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;							}																							( pxTCB ) = ( pxConstList )->pxIndex->pvOwner;											}
N
N
N/*
N * Access function to obtain the owner of the first entry in a list.  Lists
N * are normally sorted in ascending item value order.
N *
N * This function returns the pxOwner member of the first item in the list.
N * The pxOwner parameter of a list item is a pointer to the object that owns
N * the list item.  In the scheduler this is normally a task control block.
N * The pxOwner parameter effectively creates a two way link between the list
N * item and its owner.
N *
N * @param pxList The list from which the owner of the head item is to be
N * returned.
N *
N * \page listGET_OWNER_OF_HEAD_ENTRY listGET_OWNER_OF_HEAD_ENTRY
N * \ingroup LinkedList
N */
N#define listGET_OWNER_OF_HEAD_ENTRY( pxList )  ( (&( ( pxList )->xListEnd ))->pxNext->pvOwner )
N
N/*
N * Check to see if a list item is within a list.  The list item maintains a
N * "container" pointer that points to the list it is in.  All this macro does
N * is check to see if the container and the list match.
N *
N * @param pxList The list we want to know if the list item is within.
N * @param pxListItem The list item we want to know if is in the list.
N * @return pdTRUE if the list item is in the list, otherwise pdFALSE.
N */
N#define listIS_CONTAINED_WITHIN( pxList, pxListItem ) ( ( BaseType_t ) ( ( pxListItem )->pvContainer == ( void * ) ( pxList ) ) )
N
N/*
N * Return the list a list item is contained within (referenced from).
N *
N * @param pxListItem The list item being queried.
N * @return A pointer to the List_t object that references the pxListItem
N */
N#define listLIST_ITEM_CONTAINER( pxListItem ) ( ( pxListItem )->pvContainer )
N
N/*
N * This provides a crude means of knowing if a list has been initialised, as
N * pxList->xListEnd.xItemValue is set to portMAX_DELAY by the vListInitialise()
N * function.
N */
N#define listLIST_IS_INITIALISED( pxList ) ( ( pxList )->xListEnd.xItemValue == portMAX_DELAY )
N
N/*
N * Must be called before a list is used!  This initialises all the members
N * of the list structure and inserts the xListEnd item into the list as a
N * marker to the back of the list.
N *
N * @param pxList Pointer to the list being initialised.
N *
N * \page vListInitialise vListInitialise
N * \ingroup LinkedList
N */
Nvoid vListInitialise( List_t * const pxList ) PRIVILEGED_FUNCTION;
Xvoid vListInitialise( List_t * const pxList ) ;
N
N/*
N * Must be called before a list item is used.  This sets the list container to
N * null so the item does not think that it is already contained in a list.
N *
N * @param pxItem Pointer to the list item being initialised.
N *
N * \page vListInitialiseItem vListInitialiseItem
N * \ingroup LinkedList
N */
Nvoid vListInitialiseItem( ListItem_t * const pxItem ) PRIVILEGED_FUNCTION;
Xvoid vListInitialiseItem( ListItem_t * const pxItem ) ;
N
N/*
N * Insert a list item into a list.  The item will be inserted into the list in
N * a position determined by its item value (descending item value order).
N *
N * @param pxList The list into which the item is to be inserted.
N *
N * @param pxNewListItem The item that is to be placed in the list.
N *
N * \page vListInsert vListInsert
N * \ingroup LinkedList
N */
Nvoid vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem ) PRIVILEGED_FUNCTION;
Xvoid vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem ) ;
N
N/*
N * Insert a list item into a list.  The item will be inserted in a position
N * such that it will be the last item within the list returned by multiple
N * calls to listGET_OWNER_OF_NEXT_ENTRY.
N *
N * The list member pxIndex is used to walk through a list.  Calling
N * listGET_OWNER_OF_NEXT_ENTRY increments pxIndex to the next item in the list.
N * Placing an item in a list using vListInsertEnd effectively places the item
N * in the list position pointed to by pxIndex.  This means that every other
N * item within the list will be returned by listGET_OWNER_OF_NEXT_ENTRY before
N * the pxIndex parameter again points to the item being inserted.
N *
N * @param pxList The list into which the item is to be inserted.
N *
N * @param pxNewListItem The list item to be inserted into the list.
N *
N * \page vListInsertEnd vListInsertEnd
N * \ingroup LinkedList
N */
Nvoid vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem ) PRIVILEGED_FUNCTION;
Xvoid vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem ) ;
N
N/*
N * Remove an item from a list.  The list item has a pointer to the list that
N * it is in, so only the list item need be passed into the function.
N *
N * @param uxListRemove The item to be removed.  The item will remove itself from
N * the list pointed to by it's pxContainer parameter.
N *
N * @return The number of items that remain in the list after the list item has
N * been removed.
N *
N * \page uxListRemove uxListRemove
N * \ingroup LinkedList
N */
NUBaseType_t uxListRemove( ListItem_t * const pxItemToRemove ) PRIVILEGED_FUNCTION;
XUBaseType_t uxListRemove( ListItem_t * const pxItemToRemove ) ;
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif
N
L 79 "..\..\common\src\FreeRTOS\Source\include\task.h" 2
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N/*-----------------------------------------------------------
N * MACROS AND DEFINITIONS
N *----------------------------------------------------------*/
N
N#define tskKERNEL_VERSION_NUMBER "V9.0.0"
N#define tskKERNEL_VERSION_MAJOR 9
N#define tskKERNEL_VERSION_MINOR 0
N#define tskKERNEL_VERSION_BUILD 0
N
N/**
N * task. h
N *
N * Type by which tasks are referenced.  For example, a call to xTaskCreate
N * returns (via a pointer parameter) an TaskHandle_t variable that can then
N * be used as a parameter to vTaskDelete to delete the task.
N *
N * \defgroup TaskHandle_t TaskHandle_t
N * \ingroup Tasks
N */
Ntypedef void * TaskHandle_t;
N
N/*
N * Defines the prototype to which the application task hook function must
N * conform.
N */
Ntypedef BaseType_t (*TaskHookFunction_t)( void * );
N
N/* Task states returned by eTaskGetState. */
Ntypedef enum
N{
N	eRunning = 0,	/* A task is querying the state of itself, so must be running. */
N	eReady,			/* The task being queried is in a read or pending ready list. */
N	eBlocked,		/* The task being queried is in the Blocked state. */
N	eSuspended,		/* The task being queried is in the Suspended state, or is in the Blocked state with an infinite time out. */
N	eDeleted,		/* The task being queried has been deleted, but its TCB has not yet been freed. */
N	eInvalid			/* Used as an 'invalid state' value. */
N} eTaskState;
N
N/* Actions that can be performed when vTaskNotify() is called. */
Ntypedef enum
N{
N	eNoAction = 0,				/* Notify the task without updating its notify value. */
N	eSetBits,					/* Set bits in the task's notification value. */
N	eIncrement,					/* Increment the task's notification value. */
N	eSetValueWithOverwrite,		/* Set the task's notification value to a specific value even if the previous value has not yet been read by the task. */
N	eSetValueWithoutOverwrite	/* Set the task's notification value if the previous value has been read by the task. */
N} eNotifyAction;
N
N/*
N * Used internally only.
N */
Ntypedef struct xTIME_OUT
N{
N	BaseType_t xOverflowCount;
N	TickType_t xTimeOnEntering;
N} TimeOut_t;
N
N/*
N * Defines the memory ranges allocated to the task when an MPU is used.
N */
Ntypedef struct xMEMORY_REGION
N{
N	void *pvBaseAddress;
N	uint32_t ulLengthInBytes;
N	uint32_t ulParameters;
N} MemoryRegion_t;
N
N/*
N * Parameters required to create an MPU protected task.
N */
Ntypedef struct xTASK_PARAMETERS
N{
N	TaskFunction_t pvTaskCode;
N	const char * const pcName;	/*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N	uint16_t usStackDepth;
N	void *pvParameters;
N	UBaseType_t uxPriority;
N	StackType_t *puxStackBuffer;
N	MemoryRegion_t xRegions[ portNUM_CONFIGURABLE_REGIONS ];
X	MemoryRegion_t xRegions[ 1 ];
N} TaskParameters_t;
N
N/* Used with the uxTaskGetSystemState() function to return the state of each task
Nin the system. */
Ntypedef struct xTASK_STATUS
N{
N	TaskHandle_t xHandle;			/* The handle of the task to which the rest of the information in the structure relates. */
N	const char *pcTaskName;			/* A pointer to the task's name.  This value will be invalid if the task was deleted since the structure was populated! */ /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N	UBaseType_t xTaskNumber;		/* A number unique to the task. */
N	eTaskState eCurrentState;		/* The state in which the task existed when the structure was populated. */
N	UBaseType_t uxCurrentPriority;	/* The priority at which the task was running (may be inherited) when the structure was populated. */
N	UBaseType_t uxBasePriority;		/* The priority to which the task will return if the task's current priority has been inherited to avoid unbounded priority inversion when obtaining a mutex.  Only valid if configUSE_MUTEXES is defined as 1 in FreeRTOSConfig.h. */
N	uint32_t ulRunTimeCounter;		/* The total run time allocated to the task so far, as defined by the run time stats clock.  See http://www.freertos.org/rtos-run-time-stats.html.  Only valid when configGENERATE_RUN_TIME_STATS is defined as 1 in FreeRTOSConfig.h. */
N	StackType_t *pxStackBase;		/* Points to the lowest address of the task's stack area. */
N	uint16_t usStackHighWaterMark;	/* The minimum amount of stack space that has remained for the task since the task was created.  The closer this value is to zero the closer the task has come to overflowing its stack. */
N} TaskStatus_t;
N
N/* Possible return values for eTaskConfirmSleepModeStatus(). */
Ntypedef enum
N{
N	eAbortSleep = 0,		/* A task has been made ready or a context switch pended since portSUPPORESS_TICKS_AND_SLEEP() was called - abort entering a sleep mode. */
N	eStandardSleep,			/* Enter a sleep mode that will not last any longer than the expected idle time. */
N	eNoTasksWaitingTimeout	/* No tasks are waiting for a timeout so it is safe to enter a sleep mode that can only be exited by an external interrupt. */
N} eSleepModeStatus;
N
N/**
N * Defines the priority used by the idle task.  This must not be modified.
N *
N * \ingroup TaskUtils
N */
N#define tskIDLE_PRIORITY			( ( UBaseType_t ) 0U )
N
N/**
N * task. h
N *
N * Macro for forcing a context switch.
N *
N * \defgroup taskYIELD taskYIELD
N * \ingroup SchedulerControl
N */
N#define taskYIELD()					portYIELD()
N
N/**
N * task. h
N *
N * Macro to mark the start of a critical code region.  Preemptive context
N * switches cannot occur when in a critical region.
N *
N * NOTE: This may alter the stack (depending on the portable implementation)
N * so must be used with care!
N *
N * \defgroup taskENTER_CRITICAL taskENTER_CRITICAL
N * \ingroup SchedulerControl
N */
N#define taskENTER_CRITICAL()		portENTER_CRITICAL()
N#define taskENTER_CRITICAL_FROM_ISR() portSET_INTERRUPT_MASK_FROM_ISR()
N
N/**
N * task. h
N *
N * Macro to mark the end of a critical code region.  Preemptive context
N * switches cannot occur when in a critical region.
N *
N * NOTE: This may alter the stack (depending on the portable implementation)
N * so must be used with care!
N *
N * \defgroup taskEXIT_CRITICAL taskEXIT_CRITICAL
N * \ingroup SchedulerControl
N */
N#define taskEXIT_CRITICAL()			portEXIT_CRITICAL()
N#define taskEXIT_CRITICAL_FROM_ISR( x ) portCLEAR_INTERRUPT_MASK_FROM_ISR( x )
N/**
N * task. h
N *
N * Macro to disable all maskable interrupts.
N *
N * \defgroup taskDISABLE_INTERRUPTS taskDISABLE_INTERRUPTS
N * \ingroup SchedulerControl
N */
N#define taskDISABLE_INTERRUPTS()	portDISABLE_INTERRUPTS()
N
N/**
N * task. h
N *
N * Macro to enable microcontroller interrupts.
N *
N * \defgroup taskENABLE_INTERRUPTS taskENABLE_INTERRUPTS
N * \ingroup SchedulerControl
N */
N#define taskENABLE_INTERRUPTS()		portENABLE_INTERRUPTS()
N
N/* Definitions returned by xTaskGetSchedulerState().  taskSCHEDULER_SUSPENDED is
N0 to generate more optimal code when configASSERT() is defined as the constant
Nis used in assert() statements. */
N#define taskSCHEDULER_SUSPENDED		( ( BaseType_t ) 0 )
N#define taskSCHEDULER_NOT_STARTED	( ( BaseType_t ) 1 )
N#define taskSCHEDULER_RUNNING		( ( BaseType_t ) 2 )
N
N
N/*-----------------------------------------------------------
N * TASK CREATION API
N *----------------------------------------------------------*/
N
N/**
N * task. h
N *<pre>
N BaseType_t xTaskCreate(
N							  TaskFunction_t pvTaskCode,
N							  const char * const pcName,
N							  uint16_t usStackDepth,
N							  void *pvParameters,
N							  UBaseType_t uxPriority,
N							  TaskHandle_t *pvCreatedTask
N						  );</pre>
N *
N * Create a new task and add it to the list of tasks that are ready to run.
N *
N * Internally, within the FreeRTOS implementation, tasks use two blocks of
N * memory.  The first block is used to hold the task's data structures.  The
N * second block is used by the task as its stack.  If a task is created using
N * xTaskCreate() then both blocks of memory are automatically dynamically
N * allocated inside the xTaskCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a task is created using
N * xTaskCreateStatic() then the application writer must provide the required
N * memory.  xTaskCreateStatic() therefore allows a task to be created without
N * using any dynamic memory allocation.
N *
N * See xTaskCreateStatic() for a version that does not use any dynamic memory
N * allocation.
N *
N * xTaskCreate() can only be used to create a task that has unrestricted
N * access to the entire microcontroller memory map.  Systems that include MPU
N * support can alternatively create an MPU constrained task using
N * xTaskCreateRestricted().
N *
N * @param pvTaskCode Pointer to the task entry function.  Tasks
N * must be implemented to never return (i.e. continuous loop).
N *
N * @param pcName A descriptive name for the task.  This is mainly used to
N * facilitate debugging.  Max length defined by configMAX_TASK_NAME_LEN - default
N * is 16.
N *
N * @param usStackDepth The size of the task stack specified as the number of
N * variables the stack can hold - not the number of bytes.  For example, if
N * the stack is 16 bits wide and usStackDepth is defined as 100, 200 bytes
N * will be allocated for stack storage.
N *
N * @param pvParameters Pointer that will be used as the parameter for the task
N * being created.
N *
N * @param uxPriority The priority at which the task should run.  Systems that
N * include MPU support can optionally create tasks in a privileged (system)
N * mode by setting bit portPRIVILEGE_BIT of the priority parameter.  For
N * example, to create a privileged task at priority 2 the uxPriority parameter
N * should be set to ( 2 | portPRIVILEGE_BIT ).
N *
N * @param pvCreatedTask Used to pass back a handle by which the created task
N * can be referenced.
N *
N * @return pdPASS if the task was successfully created and added to a ready
N * list, otherwise an error code defined in the file projdefs.h
N *
N * Example usage:
N   <pre>
N // Task to be created.
N void vTaskCode( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N	 }
N }
N
N // Function that creates a task.
N void vOtherFunction( void )
N {
N static uint8_t ucParameterToPass;
N TaskHandle_t xHandle = NULL;
N
N	 // Create the task, storing the handle.  Note that the passed parameter ucParameterToPass
N	 // must exist for the lifetime of the task, so in this case is declared static.  If it was just an
N	 // an automatic stack variable it might no longer exist, or at least have been corrupted, by the time
N	 // the new task attempts to access it.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, &ucParameterToPass, tskIDLE_PRIORITY, &xHandle );
N     configASSERT( xHandle );
N
N	 // Use the handle to delete the task.
N     if( xHandle != NULL )
N     {
N	     vTaskDelete( xHandle );
N     }
N }
N   </pre>
N * \defgroup xTaskCreate xTaskCreate
N * \ingroup Tasks
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
N							const char * const pcName,	/*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N							const uint16_t usStackDepth,
N							void * const pvParameters,
N							UBaseType_t uxPriority,
N							TaskHandle_t * const pxCreatedTask ) PRIVILEGED_FUNCTION;
X							TaskHandle_t * const pxCreatedTask ) ;
N#endif
N
N/**
N * task. h
N *<pre>
N TaskHandle_t xTaskCreateStatic( TaskFunction_t pvTaskCode,
N								 const char * const pcName,
N								 uint32_t ulStackDepth,
N								 void *pvParameters,
N								 UBaseType_t uxPriority,
N								 StackType_t *pxStackBuffer,
N								 StaticTask_t *pxTaskBuffer );</pre>
N *
N * Create a new task and add it to the list of tasks that are ready to run.
N *
N * Internally, within the FreeRTOS implementation, tasks use two blocks of
N * memory.  The first block is used to hold the task's data structures.  The
N * second block is used by the task as its stack.  If a task is created using
N * xTaskCreate() then both blocks of memory are automatically dynamically
N * allocated inside the xTaskCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a task is created using
N * xTaskCreateStatic() then the application writer must provide the required
N * memory.  xTaskCreateStatic() therefore allows a task to be created without
N * using any dynamic memory allocation.
N *
N * @param pvTaskCode Pointer to the task entry function.  Tasks
N * must be implemented to never return (i.e. continuous loop).
N *
N * @param pcName A descriptive name for the task.  This is mainly used to
N * facilitate debugging.  The maximum length of the string is defined by
N * configMAX_TASK_NAME_LEN in FreeRTOSConfig.h.
N *
N * @param ulStackDepth The size of the task stack specified as the number of
N * variables the stack can hold - not the number of bytes.  For example, if
N * the stack is 32-bits wide and ulStackDepth is defined as 100 then 400 bytes
N * will be allocated for stack storage.
N *
N * @param pvParameters Pointer that will be used as the parameter for the task
N * being created.
N *
N * @param uxPriority The priority at which the task will run.
N *
N * @param pxStackBuffer Must point to a StackType_t array that has at least
N * ulStackDepth indexes - the array will then be used as the task's stack,
N * removing the need for the stack to be allocated dynamically.
N *
N * @param pxTaskBuffer Must point to a variable of type StaticTask_t, which will
N * then be used to hold the task's data structures, removing the need for the
N * memory to be allocated dynamically.
N *
N * @return If neither pxStackBuffer or pxTaskBuffer are NULL, then the task will
N * be created and pdPASS is returned.  If either pxStackBuffer or pxTaskBuffer
N * are NULL then the task will not be created and
N * errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY is returned.
N *
N * Example usage:
N   <pre>
N
N    // Dimensions the buffer that the task being created will use as its stack.
N    // NOTE:  This is the number of words the stack will hold, not the number of
N    // bytes.  For example, if each stack item is 32-bits, and this is set to 100,
N    // then 400 bytes (100 * 32-bits) will be allocated.
N    #define STACK_SIZE 200
N
N    // Structure that will hold the TCB of the task being created.
N    StaticTask_t xTaskBuffer;
N
N    // Buffer that the task being created will use as its stack.  Note this is
N    // an array of StackType_t variables.  The size of StackType_t is dependent on
N    // the RTOS port.
N    StackType_t xStack[ STACK_SIZE ];
N
N    // Function that implements the task being created.
N    void vTaskCode( void * pvParameters )
N    {
N        // The parameter value is expected to be 1 as 1 is passed in the
N        // pvParameters value in the call to xTaskCreateStatic().
N        configASSERT( ( uint32_t ) pvParameters == 1UL );
N
N        for( ;; )
N        {
N            // Task code goes here.
N        }
N    }
N
N    // Function that creates a task.
N    void vOtherFunction( void )
N    {
N        TaskHandle_t xHandle = NULL;
N
N        // Create the task without using any dynamic memory allocation.
N        xHandle = xTaskCreateStatic(
N                      vTaskCode,       // Function that implements the task.
N                      "NAME",          // Text name for the task.
N                      STACK_SIZE,      // Stack size in words, not bytes.
N                      ( void * ) 1,    // Parameter passed into the task.
N                      tskIDLE_PRIORITY,// Priority at which the task is created.
N                      xStack,          // Array to use as the task's stack.
N                      &xTaskBuffer );  // Variable to hold the task's data structure.
N
N        // puxStackBuffer and pxTaskBuffer were not NULL, so the task will have
N        // been created, and xHandle will be the task's handle.  Use the handle
N        // to suspend the task.
N        vTaskSuspend( xHandle );
N    }
N   </pre>
N * \defgroup xTaskCreateStatic xTaskCreateStatic
N * \ingroup Tasks
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	TaskHandle_t xTaskCreateStatic(	TaskFunction_t pxTaskCode,
S									const char * const pcName, /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
S									const uint32_t ulStackDepth,
S									void * const pvParameters,
S									UBaseType_t uxPriority,
S									StackType_t * const puxStackBuffer,
S									StaticTask_t * const pxTaskBuffer ) PRIVILEGED_FUNCTION;
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * task. h
N *<pre>
N BaseType_t xTaskCreateRestricted( TaskParameters_t *pxTaskDefinition, TaskHandle_t *pxCreatedTask );</pre>
N *
N * xTaskCreateRestricted() should only be used in systems that include an MPU
N * implementation.
N *
N * Create a new task and add it to the list of tasks that are ready to run.
N * The function parameters define the memory regions and associated access
N * permissions allocated to the task.
N *
N * @param pxTaskDefinition Pointer to a structure that contains a member
N * for each of the normal xTaskCreate() parameters (see the xTaskCreate() API
N * documentation) plus an optional stack buffer and the memory region
N * definitions.
N *
N * @param pxCreatedTask Used to pass back a handle by which the created task
N * can be referenced.
N *
N * @return pdPASS if the task was successfully created and added to a ready
N * list, otherwise an error code defined in the file projdefs.h
N *
N * Example usage:
N   <pre>
N// Create an TaskParameters_t structure that defines the task to be created.
Nstatic const TaskParameters_t xCheckTaskParameters =
N{
N	vATask,		// pvTaskCode - the function that implements the task.
N	"ATask",	// pcName - just a text name for the task to assist debugging.
N	100,		// usStackDepth	- the stack size DEFINED IN WORDS.
N	NULL,		// pvParameters - passed into the task function as the function parameters.
N	( 1UL | portPRIVILEGE_BIT ),// uxPriority - task priority, set the portPRIVILEGE_BIT if the task should run in a privileged state.
N	cStackBuffer,// puxStackBuffer - the buffer to be used as the task stack.
N
N	// xRegions - Allocate up to three separate memory regions for access by
N	// the task, with appropriate access permissions.  Different processors have
N	// different memory alignment requirements - refer to the FreeRTOS documentation
N	// for full information.
N	{
N		// Base address					Length	Parameters
N        { cReadWriteArray,				32,		portMPU_REGION_READ_WRITE },
N        { cReadOnlyArray,				32,		portMPU_REGION_READ_ONLY },
N        { cPrivilegedOnlyAccessArray,	128,	portMPU_REGION_PRIVILEGED_READ_WRITE }
N	}
N};
N
Nint main( void )
N{
NTaskHandle_t xHandle;
N
N	// Create a task from the const structure defined above.  The task handle
N	// is requested (the second parameter is not NULL) but in this case just for
N	// demonstration purposes as its not actually used.
N	xTaskCreateRestricted( &xRegTest1Parameters, &xHandle );
N
N	// Start the scheduler.
N	vTaskStartScheduler();
N
N	// Will only get here if there was insufficient memory to create the idle
N	// and/or timer task.
N	for( ;; );
N}
N   </pre>
N * \defgroup xTaskCreateRestricted xTaskCreateRestricted
N * \ingroup Tasks
N */
N#if( portUSING_MPU_WRAPPERS == 1 )
X#if( 0 == 1 )
S	BaseType_t xTaskCreateRestricted( const TaskParameters_t * const pxTaskDefinition, TaskHandle_t *pxCreatedTask ) PRIVILEGED_FUNCTION;
N#endif
N
N/**
N * task. h
N *<pre>
N void vTaskAllocateMPURegions( TaskHandle_t xTask, const MemoryRegion_t * const pxRegions );</pre>
N *
N * Memory regions are assigned to a restricted task when the task is created by
N * a call to xTaskCreateRestricted().  These regions can be redefined using
N * vTaskAllocateMPURegions().
N *
N * @param xTask The handle of the task being updated.
N *
N * @param xRegions A pointer to an MemoryRegion_t structure that contains the
N * new memory region definitions.
N *
N * Example usage:
N   <pre>
N// Define an array of MemoryRegion_t structures that configures an MPU region
N// allowing read/write access for 1024 bytes starting at the beginning of the
N// ucOneKByte array.  The other two of the maximum 3 definable regions are
N// unused so set to zero.
Nstatic const MemoryRegion_t xAltRegions[ portNUM_CONFIGURABLE_REGIONS ] =
N{
N	// Base address		Length		Parameters
N	{ ucOneKByte,		1024,		portMPU_REGION_READ_WRITE },
N	{ 0,				0,			0 },
N	{ 0,				0,			0 }
N};
N
Nvoid vATask( void *pvParameters )
N{
N	// This task was created such that it has access to certain regions of
N	// memory as defined by the MPU configuration.  At some point it is
N	// desired that these MPU regions are replaced with that defined in the
N	// xAltRegions const struct above.  Use a call to vTaskAllocateMPURegions()
N	// for this purpose.  NULL is used as the task handle to indicate that this
N	// function should modify the MPU regions of the calling task.
N	vTaskAllocateMPURegions( NULL, xAltRegions );
N
N	// Now the task can continue its function, but from this point on can only
N	// access its stack and the ucOneKByte array (unless any other statically
N	// defined or shared regions have been declared elsewhere).
N}
N   </pre>
N * \defgroup xTaskCreateRestricted xTaskCreateRestricted
N * \ingroup Tasks
N */
Nvoid vTaskAllocateMPURegions( TaskHandle_t xTask, const MemoryRegion_t * const pxRegions ) PRIVILEGED_FUNCTION;
Xvoid vTaskAllocateMPURegions( TaskHandle_t xTask, const MemoryRegion_t * const pxRegions ) ;
N
N/**
N * task. h
N * <pre>void vTaskDelete( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_vTaskDelete must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Remove a task from the RTOS real time kernel's management.  The task being
N * deleted will be removed from all ready, blocked, suspended and event lists.
N *
N * NOTE:  The idle task is responsible for freeing the kernel allocated
N * memory from tasks that have been deleted.  It is therefore important that
N * the idle task is not starved of microcontroller processing time if your
N * application makes any calls to vTaskDelete ().  Memory allocated by the
N * task code is not automatically freed, and should be freed before the task
N * is deleted.
N *
N * See the demo application file death.c for sample code that utilises
N * vTaskDelete ().
N *
N * @param xTask The handle of the task to be deleted.  Passing NULL will
N * cause the calling task to be deleted.
N *
N * Example usage:
N   <pre>
N void vOtherFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create the task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // Use the handle to delete the task.
N	 vTaskDelete( xHandle );
N }
N   </pre>
N * \defgroup vTaskDelete vTaskDelete
N * \ingroup Tasks
N */
Nvoid vTaskDelete( TaskHandle_t xTaskToDelete ) PRIVILEGED_FUNCTION;
Xvoid vTaskDelete( TaskHandle_t xTaskToDelete ) ;
N
N/*-----------------------------------------------------------
N * TASK CONTROL API
N *----------------------------------------------------------*/
N
N/**
N * task. h
N * <pre>void vTaskDelay( const TickType_t xTicksToDelay );</pre>
N *
N * Delay a task for a given number of ticks.  The actual time that the
N * task remains blocked depends on the tick rate.  The constant
N * portTICK_PERIOD_MS can be used to calculate real time from the tick
N * rate - with the resolution of one tick period.
N *
N * INCLUDE_vTaskDelay must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N *
N * vTaskDelay() specifies a time at which the task wishes to unblock relative to
N * the time at which vTaskDelay() is called.  For example, specifying a block
N * period of 100 ticks will cause the task to unblock 100 ticks after
N * vTaskDelay() is called.  vTaskDelay() does not therefore provide a good method
N * of controlling the frequency of a periodic task as the path taken through the
N * code, as well as other task and interrupt activity, will effect the frequency
N * at which vTaskDelay() gets called and therefore the time at which the task
N * next executes.  See vTaskDelayUntil() for an alternative API function designed
N * to facilitate fixed frequency execution.  It does this by specifying an
N * absolute time (rather than a relative time) at which the calling task should
N * unblock.
N *
N * @param xTicksToDelay The amount of time, in tick periods, that
N * the calling task should block.
N *
N * Example usage:
N
N void vTaskFunction( void * pvParameters )
N {
N // Block for 500ms.
N const TickType_t xDelay = 500 / portTICK_PERIOD_MS;
N
N	 for( ;; )
N	 {
N		 // Simply toggle the LED every 500ms, blocking between each toggle.
N		 vToggleLED();
N		 vTaskDelay( xDelay );
N	 }
N }
N
N * \defgroup vTaskDelay vTaskDelay
N * \ingroup TaskCtrl
N */
Nvoid vTaskDelay( const TickType_t xTicksToDelay ) PRIVILEGED_FUNCTION;
Xvoid vTaskDelay( const TickType_t xTicksToDelay ) ;
N
N/**
N * task. h
N * <pre>void vTaskDelayUntil( TickType_t *pxPreviousWakeTime, const TickType_t xTimeIncrement );</pre>
N *
N * INCLUDE_vTaskDelayUntil must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Delay a task until a specified time.  This function can be used by periodic
N * tasks to ensure a constant execution frequency.
N *
N * This function differs from vTaskDelay () in one important aspect:  vTaskDelay () will
N * cause a task to block for the specified number of ticks from the time vTaskDelay () is
N * called.  It is therefore difficult to use vTaskDelay () by itself to generate a fixed
N * execution frequency as the time between a task starting to execute and that task
N * calling vTaskDelay () may not be fixed [the task may take a different path though the
N * code between calls, or may get interrupted or preempted a different number of times
N * each time it executes].
N *
N * Whereas vTaskDelay () specifies a wake time relative to the time at which the function
N * is called, vTaskDelayUntil () specifies the absolute (exact) time at which it wishes to
N * unblock.
N *
N * The constant portTICK_PERIOD_MS can be used to calculate real time from the tick
N * rate - with the resolution of one tick period.
N *
N * @param pxPreviousWakeTime Pointer to a variable that holds the time at which the
N * task was last unblocked.  The variable must be initialised with the current time
N * prior to its first use (see the example below).  Following this the variable is
N * automatically updated within vTaskDelayUntil ().
N *
N * @param xTimeIncrement The cycle time period.  The task will be unblocked at
N * time *pxPreviousWakeTime + xTimeIncrement.  Calling vTaskDelayUntil with the
N * same xTimeIncrement parameter value will cause the task to execute with
N * a fixed interface period.
N *
N * Example usage:
N   <pre>
N // Perform an action every 10 ticks.
N void vTaskFunction( void * pvParameters )
N {
N TickType_t xLastWakeTime;
N const TickType_t xFrequency = 10;
N
N	 // Initialise the xLastWakeTime variable with the current time.
N	 xLastWakeTime = xTaskGetTickCount ();
N	 for( ;; )
N	 {
N		 // Wait for the next cycle.
N		 vTaskDelayUntil( &xLastWakeTime, xFrequency );
N
N		 // Perform action here.
N	 }
N }
N   </pre>
N * \defgroup vTaskDelayUntil vTaskDelayUntil
N * \ingroup TaskCtrl
N */
Nvoid vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement ) PRIVILEGED_FUNCTION;
Xvoid vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement ) ;
N
N/**
N * task. h
N * <pre>BaseType_t xTaskAbortDelay( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_xTaskAbortDelay must be defined as 1 in FreeRTOSConfig.h for this
N * function to be available.
N *
N * A task will enter the Blocked state when it is waiting for an event.  The
N * event it is waiting for can be a temporal event (waiting for a time), such
N * as when vTaskDelay() is called, or an event on an object, such as when
N * xQueueReceive() or ulTaskNotifyTake() is called.  If the handle of a task
N * that is in the Blocked state is used in a call to xTaskAbortDelay() then the
N * task will leave the Blocked state, and return from whichever function call
N * placed the task into the Blocked state.
N *
N * @param xTask The handle of the task to remove from the Blocked state.
N *
N * @return If the task referenced by xTask was not in the Blocked state then
N * pdFAIL is returned.  Otherwise pdPASS is returned.
N *
N * \defgroup xTaskAbortDelay xTaskAbortDelay
N * \ingroup TaskCtrl
N */
NBaseType_t xTaskAbortDelay( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskAbortDelay( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>UBaseType_t uxTaskPriorityGet( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_uxTaskPriorityGet must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Obtain the priority of any task.
N *
N * @param xTask Handle of the task to be queried.  Passing a NULL
N * handle results in the priority of the calling task being returned.
N *
N * @return The priority of xTask.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to obtain the priority of the created task.
N	 // It was created with tskIDLE_PRIORITY, but may have changed
N	 // it itself.
N	 if( uxTaskPriorityGet( xHandle ) != tskIDLE_PRIORITY )
N	 {
N		 // The task has changed it's priority.
N	 }
N
N	 // ...
N
N	 // Is our priority higher than the created task?
N	 if( uxTaskPriorityGet( xHandle ) < uxTaskPriorityGet( NULL ) )
N	 {
N		 // Our priority (obtained using NULL handle) is higher.
N	 }
N }
N   </pre>
N * \defgroup uxTaskPriorityGet uxTaskPriorityGet
N * \ingroup TaskCtrl
N */
NUBaseType_t uxTaskPriorityGet( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskPriorityGet( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>UBaseType_t uxTaskPriorityGetFromISR( TaskHandle_t xTask );</pre>
N *
N * A version of uxTaskPriorityGet() that can be used from an ISR.
N */
NUBaseType_t uxTaskPriorityGetFromISR( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskPriorityGetFromISR( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>eTaskState eTaskGetState( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_eTaskGetState must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Obtain the state of any task.  States are encoded by the eTaskState
N * enumerated type.
N *
N * @param xTask Handle of the task to be queried.
N *
N * @return The state of xTask at the time the function was called.  Note the
N * state of the task might change between the function being called, and the
N * functions return value being tested by the calling task.
N */
NeTaskState eTaskGetState( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XeTaskState eTaskGetState( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>void vTaskGetInfo( TaskHandle_t xTask, TaskStatus_t *pxTaskStatus, BaseType_t xGetFreeStackSpace, eTaskState eState );</pre>
N *
N * configUSE_TRACE_FACILITY must be defined as 1 for this function to be
N * available.  See the configuration section for more information.
N *
N * Populates a TaskStatus_t structure with information about a task.
N *
N * @param xTask Handle of the task being queried.  If xTask is NULL then
N * information will be returned about the calling task.
N *
N * @param pxTaskStatus A pointer to the TaskStatus_t structure that will be
N * filled with information about the task referenced by the handle passed using
N * the xTask parameter.
N *
N * @xGetFreeStackSpace The TaskStatus_t structure contains a member to report
N * the stack high water mark of the task being queried.  Calculating the stack
N * high water mark takes a relatively long time, and can make the system
N * temporarily unresponsive - so the xGetFreeStackSpace parameter is provided to
N * allow the high water mark checking to be skipped.  The high watermark value
N * will only be written to the TaskStatus_t structure if xGetFreeStackSpace is
N * not set to pdFALSE;
N *
N * @param eState The TaskStatus_t structure contains a member to report the
N * state of the task being queried.  Obtaining the task state is not as fast as
N * a simple assignment - so the eState parameter is provided to allow the state
N * information to be omitted from the TaskStatus_t structure.  To obtain state
N * information then set eState to eInvalid - otherwise the value passed in
N * eState will be reported as the task state in the TaskStatus_t structure.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N TaskStatus_t xTaskDetails;
N
N    // Obtain the handle of a task from its name.
N    xHandle = xTaskGetHandle( "Task_Name" );
N
N    // Check the handle is not NULL.
N    configASSERT( xHandle );
N
N    // Use the handle to obtain further information about the task.
N    vTaskGetInfo( xHandle,
N                  &xTaskDetails,
N                  pdTRUE, // Include the high water mark in xTaskDetails.
N                  eInvalid ); // Include the task state in xTaskDetails.
N }
N   </pre>
N * \defgroup vTaskGetInfo vTaskGetInfo
N * \ingroup TaskCtrl
N */
Nvoid vTaskGetInfo( TaskHandle_t xTask, TaskStatus_t *pxTaskStatus, BaseType_t xGetFreeStackSpace, eTaskState eState ) PRIVILEGED_FUNCTION;
Xvoid vTaskGetInfo( TaskHandle_t xTask, TaskStatus_t *pxTaskStatus, BaseType_t xGetFreeStackSpace, eTaskState eState ) ;
N
N/**
N * task. h
N * <pre>void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority );</pre>
N *
N * INCLUDE_vTaskPrioritySet must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Set the priority of any task.
N *
N * A context switch will occur before the function returns if the priority
N * being set is higher than the currently executing task.
N *
N * @param xTask Handle to the task for which the priority is being set.
N * Passing a NULL handle results in the priority of the calling task being set.
N *
N * @param uxNewPriority The priority to which the task will be set.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to raise the priority of the created task.
N	 vTaskPrioritySet( xHandle, tskIDLE_PRIORITY + 1 );
N
N	 // ...
N
N	 // Use a NULL handle to raise our priority to the same value.
N	 vTaskPrioritySet( NULL, tskIDLE_PRIORITY + 1 );
N }
N   </pre>
N * \defgroup vTaskPrioritySet vTaskPrioritySet
N * \ingroup TaskCtrl
N */
Nvoid vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority ) PRIVILEGED_FUNCTION;
Xvoid vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority ) ;
N
N/**
N * task. h
N * <pre>void vTaskSuspend( TaskHandle_t xTaskToSuspend );</pre>
N *
N * INCLUDE_vTaskSuspend must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Suspend any task.  When suspended a task will never get any microcontroller
N * processing time, no matter what its priority.
N *
N * Calls to vTaskSuspend are not accumulative -
N * i.e. calling vTaskSuspend () twice on the same task still only requires one
N * call to vTaskResume () to ready the suspended task.
N *
N * @param xTaskToSuspend Handle to the task being suspended.  Passing a NULL
N * handle will cause the calling task to be suspended.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to suspend the created task.
N	 vTaskSuspend( xHandle );
N
N	 // ...
N
N	 // The created task will not run during this period, unless
N	 // another task calls vTaskResume( xHandle ).
N
N	 //...
N
N
N	 // Suspend ourselves.
N	 vTaskSuspend( NULL );
N
N	 // We cannot get here unless another task calls vTaskResume
N	 // with our handle as the parameter.
N }
N   </pre>
N * \defgroup vTaskSuspend vTaskSuspend
N * \ingroup TaskCtrl
N */
Nvoid vTaskSuspend( TaskHandle_t xTaskToSuspend ) PRIVILEGED_FUNCTION;
Xvoid vTaskSuspend( TaskHandle_t xTaskToSuspend ) ;
N
N/**
N * task. h
N * <pre>void vTaskResume( TaskHandle_t xTaskToResume );</pre>
N *
N * INCLUDE_vTaskSuspend must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Resumes a suspended task.
N *
N * A task that has been suspended by one or more calls to vTaskSuspend ()
N * will be made available for running again by a single call to
N * vTaskResume ().
N *
N * @param xTaskToResume Handle to the task being readied.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to suspend the created task.
N	 vTaskSuspend( xHandle );
N
N	 // ...
N
N	 // The created task will not run during this period, unless
N	 // another task calls vTaskResume( xHandle ).
N
N	 //...
N
N
N	 // Resume the suspended task ourselves.
N	 vTaskResume( xHandle );
N
N	 // The created task will once again get microcontroller processing
N	 // time in accordance with its priority within the system.
N }
N   </pre>
N * \defgroup vTaskResume vTaskResume
N * \ingroup TaskCtrl
N */
Nvoid vTaskResume( TaskHandle_t xTaskToResume ) PRIVILEGED_FUNCTION;
Xvoid vTaskResume( TaskHandle_t xTaskToResume ) ;
N
N/**
N * task. h
N * <pre>void xTaskResumeFromISR( TaskHandle_t xTaskToResume );</pre>
N *
N * INCLUDE_xTaskResumeFromISR must be defined as 1 for this function to be
N * available.  See the configuration section for more information.
N *
N * An implementation of vTaskResume() that can be called from within an ISR.
N *
N * A task that has been suspended by one or more calls to vTaskSuspend ()
N * will be made available for running again by a single call to
N * xTaskResumeFromISR ().
N *
N * xTaskResumeFromISR() should not be used to synchronise a task with an
N * interrupt if there is a chance that the interrupt could arrive prior to the
N * task being suspended - as this can lead to interrupts being missed. Use of a
N * semaphore as a synchronisation mechanism would avoid this eventuality.
N *
N * @param xTaskToResume Handle to the task being readied.
N *
N * @return pdTRUE if resuming the task should result in a context switch,
N * otherwise pdFALSE. This is used by the ISR to determine if a context switch
N * may be required following the ISR.
N *
N * \defgroup vTaskResumeFromISR vTaskResumeFromISR
N * \ingroup TaskCtrl
N */
NBaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume ) ;
N
N/*-----------------------------------------------------------
N * SCHEDULER CONTROL
N *----------------------------------------------------------*/
N
N/**
N * task. h
N * <pre>void vTaskStartScheduler( void );</pre>
N *
N * Starts the real time kernel tick processing.  After calling the kernel
N * has control over which tasks are executed and when.
N *
N * See the demo application file main.c for an example of creating
N * tasks and starting the kernel.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N	 // Create at least one task before starting the kernel.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, NULL );
N
N	 // Start the real time kernel with preemption.
N	 vTaskStartScheduler ();
N
N	 // Will not get here unless a task calls vTaskEndScheduler ()
N }
N   </pre>
N *
N * \defgroup vTaskStartScheduler vTaskStartScheduler
N * \ingroup SchedulerControl
N */
Nvoid vTaskStartScheduler( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskStartScheduler( void ) ;
N
N/**
N * task. h
N * <pre>void vTaskEndScheduler( void );</pre>
N *
N * NOTE:  At the time of writing only the x86 real mode port, which runs on a PC
N * in place of DOS, implements this function.
N *
N * Stops the real time kernel tick.  All created tasks will be automatically
N * deleted and multitasking (either preemptive or cooperative) will
N * stop.  Execution then resumes from the point where vTaskStartScheduler ()
N * was called, as if vTaskStartScheduler () had just returned.
N *
N * See the demo application file main. c in the demo/PC directory for an
N * example that uses vTaskEndScheduler ().
N *
N * vTaskEndScheduler () requires an exit function to be defined within the
N * portable layer (see vPortEndScheduler () in port. c for the PC port).  This
N * performs hardware specific operations such as stopping the kernel tick.
N *
N * vTaskEndScheduler () will cause all of the resources allocated by the
N * kernel to be freed - but will not free resources allocated by application
N * tasks.
N *
N * Example usage:
N   <pre>
N void vTaskCode( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N
N		 // At some point we want to end the real time kernel processing
N		 // so call ...
N		 vTaskEndScheduler ();
N	 }
N }
N
N void vAFunction( void )
N {
N	 // Create at least one task before starting the kernel.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, NULL );
N
N	 // Start the real time kernel with preemption.
N	 vTaskStartScheduler ();
N
N	 // Will only get here when the vTaskCode () task has called
N	 // vTaskEndScheduler ().  When we get here we are back to single task
N	 // execution.
N }
N   </pre>
N *
N * \defgroup vTaskEndScheduler vTaskEndScheduler
N * \ingroup SchedulerControl
N */
Nvoid vTaskEndScheduler( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskEndScheduler( void ) ;
N
N/**
N * task. h
N * <pre>void vTaskSuspendAll( void );</pre>
N *
N * Suspends the scheduler without disabling interrupts.  Context switches will
N * not occur while the scheduler is suspended.
N *
N * After calling vTaskSuspendAll () the calling task will continue to execute
N * without risk of being swapped out until a call to xTaskResumeAll () has been
N * made.
N *
N * API functions that have the potential to cause a context switch (for example,
N * vTaskDelayUntil(), xQueueSend(), etc.) must not be called while the scheduler
N * is suspended.
N *
N * Example usage:
N   <pre>
N void vTask1( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N
N		 // ...
N
N		 // At some point the task wants to perform a long operation during
N		 // which it does not want to get swapped out.  It cannot use
N		 // taskENTER_CRITICAL ()/taskEXIT_CRITICAL () as the length of the
N		 // operation may cause interrupts to be missed - including the
N		 // ticks.
N
N		 // Prevent the real time kernel swapping out the task.
N		 vTaskSuspendAll ();
N
N		 // Perform the operation here.  There is no need to use critical
N		 // sections as we have all the microcontroller processing time.
N		 // During this time interrupts will still operate and the kernel
N		 // tick count will be maintained.
N
N		 // ...
N
N		 // The operation is complete.  Restart the kernel.
N		 xTaskResumeAll ();
N	 }
N }
N   </pre>
N * \defgroup vTaskSuspendAll vTaskSuspendAll
N * \ingroup SchedulerControl
N */
Nvoid vTaskSuspendAll( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskSuspendAll( void ) ;
N
N/**
N * task. h
N * <pre>BaseType_t xTaskResumeAll( void );</pre>
N *
N * Resumes scheduler activity after it was suspended by a call to
N * vTaskSuspendAll().
N *
N * xTaskResumeAll() only resumes the scheduler.  It does not unsuspend tasks
N * that were previously suspended by a call to vTaskSuspend().
N *
N * @return If resuming the scheduler caused a context switch then pdTRUE is
N *		  returned, otherwise pdFALSE is returned.
N *
N * Example usage:
N   <pre>
N void vTask1( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N
N		 // ...
N
N		 // At some point the task wants to perform a long operation during
N		 // which it does not want to get swapped out.  It cannot use
N		 // taskENTER_CRITICAL ()/taskEXIT_CRITICAL () as the length of the
N		 // operation may cause interrupts to be missed - including the
N		 // ticks.
N
N		 // Prevent the real time kernel swapping out the task.
N		 vTaskSuspendAll ();
N
N		 // Perform the operation here.  There is no need to use critical
N		 // sections as we have all the microcontroller processing time.
N		 // During this time interrupts will still operate and the real
N		 // time kernel tick count will be maintained.
N
N		 // ...
N
N		 // The operation is complete.  Restart the kernel.  We want to force
N		 // a context switch - but there is no point if resuming the scheduler
N		 // caused a context switch already.
N		 if( !xTaskResumeAll () )
N		 {
N			  taskYIELD ();
N		 }
N	 }
N }
N   </pre>
N * \defgroup xTaskResumeAll xTaskResumeAll
N * \ingroup SchedulerControl
N */
NBaseType_t xTaskResumeAll( void ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskResumeAll( void ) ;
N
N/*-----------------------------------------------------------
N * TASK UTILITIES
N *----------------------------------------------------------*/
N
N/**
N * task. h
N * <PRE>TickType_t xTaskGetTickCount( void );</PRE>
N *
N * @return The count of ticks since vTaskStartScheduler was called.
N *
N * \defgroup xTaskGetTickCount xTaskGetTickCount
N * \ingroup TaskUtils
N */
NTickType_t xTaskGetTickCount( void ) PRIVILEGED_FUNCTION;
XTickType_t xTaskGetTickCount( void ) ;
N
N/**
N * task. h
N * <PRE>TickType_t xTaskGetTickCountFromISR( void );</PRE>
N *
N * @return The count of ticks since vTaskStartScheduler was called.
N *
N * This is a version of xTaskGetTickCount() that is safe to be called from an
N * ISR - provided that TickType_t is the natural word size of the
N * microcontroller being used or interrupt nesting is either not supported or
N * not being used.
N *
N * \defgroup xTaskGetTickCountFromISR xTaskGetTickCountFromISR
N * \ingroup TaskUtils
N */
NTickType_t xTaskGetTickCountFromISR( void ) PRIVILEGED_FUNCTION;
XTickType_t xTaskGetTickCountFromISR( void ) ;
N
N/**
N * task. h
N * <PRE>uint16_t uxTaskGetNumberOfTasks( void );</PRE>
N *
N * @return The number of tasks that the real time kernel is currently managing.
N * This includes all ready, blocked and suspended tasks.  A task that
N * has been deleted but not yet freed by the idle task will also be
N * included in the count.
N *
N * \defgroup uxTaskGetNumberOfTasks uxTaskGetNumberOfTasks
N * \ingroup TaskUtils
N */
NUBaseType_t uxTaskGetNumberOfTasks( void ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetNumberOfTasks( void ) ;
N
N/**
N * task. h
N * <PRE>char *pcTaskGetName( TaskHandle_t xTaskToQuery );</PRE>
N *
N * @return The text (human readable) name of the task referenced by the handle
N * xTaskToQuery.  A task can query its own name by either passing in its own
N * handle, or by setting xTaskToQuery to NULL.
N *
N * \defgroup pcTaskGetName pcTaskGetName
N * \ingroup TaskUtils
N */
Nchar *pcTaskGetName( TaskHandle_t xTaskToQuery ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
Xchar *pcTaskGetName( TaskHandle_t xTaskToQuery ) ;  
N
N/**
N * task. h
N * <PRE>TaskHandle_t xTaskGetHandle( const char *pcNameToQuery );</PRE>
N *
N * NOTE:  This function takes a relatively long time to complete and should be
N * used sparingly.
N *
N * @return The handle of the task that has the human readable name pcNameToQuery.
N * NULL is returned if no matching name is found.  INCLUDE_xTaskGetHandle
N * must be set to 1 in FreeRTOSConfig.h for pcTaskGetHandle() to be available.
N *
N * \defgroup pcTaskGetHandle pcTaskGetHandle
N * \ingroup TaskUtils
N */
NTaskHandle_t xTaskGetHandle( const char *pcNameToQuery ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
XTaskHandle_t xTaskGetHandle( const char *pcNameToQuery ) ;  
N
N/**
N * task.h
N * <PRE>UBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask );</PRE>
N *
N * INCLUDE_uxTaskGetStackHighWaterMark must be set to 1 in FreeRTOSConfig.h for
N * this function to be available.
N *
N * Returns the high water mark of the stack associated with xTask.  That is,
N * the minimum free stack space there has been (in words, so on a 32 bit machine
N * a value of 1 means 4 bytes) since the task started.  The smaller the returned
N * number the closer the task has come to overflowing its stack.
N *
N * @param xTask Handle of the task associated with the stack to be checked.
N * Set xTask to NULL to check the stack of the calling task.
N *
N * @return The smallest amount of free stack space there has been (in words, so
N * actual spaces on the stack rather than bytes) since the task referenced by
N * xTask was created.
N */
NUBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask ) ;
N
N/* When using trace macros it is sometimes necessary to include task.h before
NFreeRTOS.h.  When this is done TaskHookFunction_t will not yet have been defined,
Nso the following two prototypes will cause a compilation error.  This can be
Nfixed by simply guarding against the inclusion of these two prototypes unless
Nthey are explicitly required by the configUSE_APPLICATION_TASK_TAG configuration
Nconstant. */
N#ifdef configUSE_APPLICATION_TASK_TAG
N	#if configUSE_APPLICATION_TASK_TAG == 1
X	#if 0 == 1
S		/**
S		 * task.h
S		 * <pre>void vTaskSetApplicationTaskTag( TaskHandle_t xTask, TaskHookFunction_t pxHookFunction );</pre>
S		 *
S		 * Sets pxHookFunction to be the task hook function used by the task xTask.
S		 * Passing xTask as NULL has the effect of setting the calling tasks hook
S		 * function.
S		 */
S		void vTaskSetApplicationTaskTag( TaskHandle_t xTask, TaskHookFunction_t pxHookFunction ) PRIVILEGED_FUNCTION;
S
S		/**
S		 * task.h
S		 * <pre>void xTaskGetApplicationTaskTag( TaskHandle_t xTask );</pre>
S		 *
S		 * Returns the pxHookFunction value assigned to the task xTask.
S		 */
S		TaskHookFunction_t xTaskGetApplicationTaskTag( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
N	#endif /* configUSE_APPLICATION_TASK_TAG ==1 */
N#endif /* ifdef configUSE_APPLICATION_TASK_TAG */
N
N#if( configNUM_THREAD_LOCAL_STORAGE_POINTERS > 0 )
X#if( 0 > 0 )
S
S	/* Each task contains an array of pointers that is dimensioned by the
S	configNUM_THREAD_LOCAL_STORAGE_POINTERS setting in FreeRTOSConfig.h.  The
S	kernel does not use the pointers itself, so the application writer can use
S	the pointers for any purpose they wish.  The following two functions are
S	used to set and query a pointer respectively. */
S	void vTaskSetThreadLocalStoragePointer( TaskHandle_t xTaskToSet, BaseType_t xIndex, void *pvValue ) PRIVILEGED_FUNCTION;
S	void *pvTaskGetThreadLocalStoragePointer( TaskHandle_t xTaskToQuery, BaseType_t xIndex ) PRIVILEGED_FUNCTION;
S
N#endif
N
N/**
N * task.h
N * <pre>BaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask, void *pvParameter );</pre>
N *
N * Calls the hook function associated with xTask.  Passing xTask as NULL has
N * the effect of calling the Running tasks (the calling task) hook function.
N *
N * pvParameter is passed to the hook function for the task to interpret as it
N * wants.  The return value is the value returned by the task hook function
N * registered by the user.
N */
NBaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask, void *pvParameter ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask, void *pvParameter ) ;
N
N/**
N * xTaskGetIdleTaskHandle() is only available if
N * INCLUDE_xTaskGetIdleTaskHandle is set to 1 in FreeRTOSConfig.h.
N *
N * Simply returns the handle of the idle task.  It is not valid to call
N * xTaskGetIdleTaskHandle() before the scheduler has been started.
N */
NTaskHandle_t xTaskGetIdleTaskHandle( void ) PRIVILEGED_FUNCTION;
XTaskHandle_t xTaskGetIdleTaskHandle( void ) ;
N
N/**
N * configUSE_TRACE_FACILITY must be defined as 1 in FreeRTOSConfig.h for
N * uxTaskGetSystemState() to be available.
N *
N * uxTaskGetSystemState() populates an TaskStatus_t structure for each task in
N * the system.  TaskStatus_t structures contain, among other things, members
N * for the task handle, task name, task priority, task state, and total amount
N * of run time consumed by the task.  See the TaskStatus_t structure
N * definition in this file for the full member list.
N *
N * NOTE:  This function is intended for debugging use only as its use results in
N * the scheduler remaining suspended for an extended period.
N *
N * @param pxTaskStatusArray A pointer to an array of TaskStatus_t structures.
N * The array must contain at least one TaskStatus_t structure for each task
N * that is under the control of the RTOS.  The number of tasks under the control
N * of the RTOS can be determined using the uxTaskGetNumberOfTasks() API function.
N *
N * @param uxArraySize The size of the array pointed to by the pxTaskStatusArray
N * parameter.  The size is specified as the number of indexes in the array, or
N * the number of TaskStatus_t structures contained in the array, not by the
N * number of bytes in the array.
N *
N * @param pulTotalRunTime If configGENERATE_RUN_TIME_STATS is set to 1 in
N * FreeRTOSConfig.h then *pulTotalRunTime is set by uxTaskGetSystemState() to the
N * total run time (as defined by the run time stats clock, see
N * http://www.freertos.org/rtos-run-time-stats.html) since the target booted.
N * pulTotalRunTime can be set to NULL to omit the total run time information.
N *
N * @return The number of TaskStatus_t structures that were populated by
N * uxTaskGetSystemState().  This should equal the number returned by the
N * uxTaskGetNumberOfTasks() API function, but will be zero if the value passed
N * in the uxArraySize parameter was too small.
N *
N * Example usage:
N   <pre>
N    // This example demonstrates how a human readable table of run time stats
N	// information is generated from raw data provided by uxTaskGetSystemState().
N	// The human readable table is written to pcWriteBuffer
N	void vTaskGetRunTimeStats( char *pcWriteBuffer )
N	{
N	TaskStatus_t *pxTaskStatusArray;
N	volatile UBaseType_t uxArraySize, x;
N	uint32_t ulTotalRunTime, ulStatsAsPercentage;
N
N		// Make sure the write buffer does not contain a string.
N		*pcWriteBuffer = 0x00;
N
N		// Take a snapshot of the number of tasks in case it changes while this
N		// function is executing.
N		uxArraySize = uxTaskGetNumberOfTasks();
N
N		// Allocate a TaskStatus_t structure for each task.  An array could be
N		// allocated statically at compile time.
N		pxTaskStatusArray = pvPortMalloc( uxArraySize * sizeof( TaskStatus_t ) );
N
N		if( pxTaskStatusArray != NULL )
N		{
N			// Generate raw status information about each task.
N			uxArraySize = uxTaskGetSystemState( pxTaskStatusArray, uxArraySize, &ulTotalRunTime );
N
N			// For percentage calculations.
N			ulTotalRunTime /= 100UL;
N
N			// Avoid divide by zero errors.
N			if( ulTotalRunTime > 0 )
N			{
N				// For each populated position in the pxTaskStatusArray array,
N				// format the raw data as human readable ASCII data
N				for( x = 0; x < uxArraySize; x++ )
N				{
N					// What percentage of the total run time has the task used?
N					// This will always be rounded down to the nearest integer.
N					// ulTotalRunTimeDiv100 has already been divided by 100.
N					ulStatsAsPercentage = pxTaskStatusArray[ x ].ulRunTimeCounter / ulTotalRunTime;
N
N					if( ulStatsAsPercentage > 0UL )
N					{
N						sprintf( pcWriteBuffer, "%s\t\t%lu\t\t%lu%%\r\n", pxTaskStatusArray[ x ].pcTaskName, pxTaskStatusArray[ x ].ulRunTimeCounter, ulStatsAsPercentage );
N					}
N					else
N					{
N						// If the percentage is zero here then the task has
N						// consumed less than 1% of the total run time.
N						sprintf( pcWriteBuffer, "%s\t\t%lu\t\t<1%%\r\n", pxTaskStatusArray[ x ].pcTaskName, pxTaskStatusArray[ x ].ulRunTimeCounter );
N					}
N
N					pcWriteBuffer += strlen( ( char * ) pcWriteBuffer );
N				}
N			}
N
N			// The array is no longer needed, free the memory it consumes.
N			vPortFree( pxTaskStatusArray );
N		}
N	}
N	</pre>
N */
NUBaseType_t uxTaskGetSystemState( TaskStatus_t * const pxTaskStatusArray, const UBaseType_t uxArraySize, uint32_t * const pulTotalRunTime ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetSystemState( TaskStatus_t * const pxTaskStatusArray, const UBaseType_t uxArraySize, uint32_t * const pulTotalRunTime ) ;
N
N/**
N * task. h
N * <PRE>void vTaskList( char *pcWriteBuffer );</PRE>
N *
N * configUSE_TRACE_FACILITY and configUSE_STATS_FORMATTING_FUNCTIONS must
N * both be defined as 1 for this function to be available.  See the
N * configuration section of the FreeRTOS.org website for more information.
N *
N * NOTE 1: This function will disable interrupts for its duration.  It is
N * not intended for normal application runtime use but as a debug aid.
N *
N * Lists all the current tasks, along with their current state and stack
N * usage high water mark.
N *
N * Tasks are reported as blocked ('B'), ready ('R'), deleted ('D') or
N * suspended ('S').
N *
N * PLEASE NOTE:
N *
N * This function is provided for convenience only, and is used by many of the
N * demo applications.  Do not consider it to be part of the scheduler.
N *
N * vTaskList() calls uxTaskGetSystemState(), then formats part of the
N * uxTaskGetSystemState() output into a human readable table that displays task
N * names, states and stack usage.
N *
N * vTaskList() has a dependency on the sprintf() C library function that might
N * bloat the code size, use a lot of stack, and provide different results on
N * different platforms.  An alternative, tiny, third party, and limited
N * functionality implementation of sprintf() is provided in many of the
N * FreeRTOS/Demo sub-directories in a file called printf-stdarg.c (note
N * printf-stdarg.c does not provide a full snprintf() implementation!).
N *
N * It is recommended that production systems call uxTaskGetSystemState()
N * directly to get access to raw stats data, rather than indirectly through a
N * call to vTaskList().
N *
N * @param pcWriteBuffer A buffer into which the above mentioned details
N * will be written, in ASCII form.  This buffer is assumed to be large
N * enough to contain the generated report.  Approximately 40 bytes per
N * task should be sufficient.
N *
N * \defgroup vTaskList vTaskList
N * \ingroup TaskUtils
N */
Nvoid vTaskList( char * pcWriteBuffer ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
Xvoid vTaskList( char * pcWriteBuffer ) ;  
N
N/**
N * task. h
N * <PRE>void vTaskGetRunTimeStats( char *pcWriteBuffer );</PRE>
N *
N * configGENERATE_RUN_TIME_STATS and configUSE_STATS_FORMATTING_FUNCTIONS
N * must both be defined as 1 for this function to be available.  The application
N * must also then provide definitions for
N * portCONFIGURE_TIMER_FOR_RUN_TIME_STATS() and portGET_RUN_TIME_COUNTER_VALUE()
N * to configure a peripheral timer/counter and return the timers current count
N * value respectively.  The counter should be at least 10 times the frequency of
N * the tick count.
N *
N * NOTE 1: This function will disable interrupts for its duration.  It is
N * not intended for normal application runtime use but as a debug aid.
N *
N * Setting configGENERATE_RUN_TIME_STATS to 1 will result in a total
N * accumulated execution time being stored for each task.  The resolution
N * of the accumulated time value depends on the frequency of the timer
N * configured by the portCONFIGURE_TIMER_FOR_RUN_TIME_STATS() macro.
N * Calling vTaskGetRunTimeStats() writes the total execution time of each
N * task into a buffer, both as an absolute count value and as a percentage
N * of the total system execution time.
N *
N * NOTE 2:
N *
N * This function is provided for convenience only, and is used by many of the
N * demo applications.  Do not consider it to be part of the scheduler.
N *
N * vTaskGetRunTimeStats() calls uxTaskGetSystemState(), then formats part of the
N * uxTaskGetSystemState() output into a human readable table that displays the
N * amount of time each task has spent in the Running state in both absolute and
N * percentage terms.
N *
N * vTaskGetRunTimeStats() has a dependency on the sprintf() C library function
N * that might bloat the code size, use a lot of stack, and provide different
N * results on different platforms.  An alternative, tiny, third party, and
N * limited functionality implementation of sprintf() is provided in many of the
N * FreeRTOS/Demo sub-directories in a file called printf-stdarg.c (note
N * printf-stdarg.c does not provide a full snprintf() implementation!).
N *
N * It is recommended that production systems call uxTaskGetSystemState() directly
N * to get access to raw stats data, rather than indirectly through a call to
N * vTaskGetRunTimeStats().
N *
N * @param pcWriteBuffer A buffer into which the execution times will be
N * written, in ASCII form.  This buffer is assumed to be large enough to
N * contain the generated report.  Approximately 40 bytes per task should
N * be sufficient.
N *
N * \defgroup vTaskGetRunTimeStats vTaskGetRunTimeStats
N * \ingroup TaskUtils
N */
Nvoid vTaskGetRunTimeStats( char *pcWriteBuffer ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
Xvoid vTaskGetRunTimeStats( char *pcWriteBuffer ) ;  
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction );</PRE>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * A notification sent to a task will remain pending until it is cleared by the
N * task calling xTaskNotifyWait() or ulTaskNotifyTake().  If the task was
N * already in the Blocked state to wait for a notification when the notification
N * arrives then the task will automatically be removed from the Blocked state
N * (unblocked) and the notification cleared.
N *
N * A task can use xTaskNotifyWait() to [optionally] block to wait for a
N * notification to be pending, or ulTaskNotifyTake() to [optionally] block
N * to wait for its notification value to have a non-zero value.  The task does
N * not consume any CPU time while it is in the Blocked state.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @param ulValue Data that can be sent with the notification.  How the data is
N * used depends on the value of the eAction parameter.
N *
N * @param eAction Specifies how the notification updates the task's notification
N * value, if at all.  Valid values for eAction are as follows:
N *
N * eSetBits -
N * The task's notification value is bitwise ORed with ulValue.  xTaskNofify()
N * always returns pdPASS in this case.
N *
N * eIncrement -
N * The task's notification value is incremented.  ulValue is not used and
N * xTaskNotify() always returns pdPASS in this case.
N *
N * eSetValueWithOverwrite -
N * The task's notification value is set to the value of ulValue, even if the
N * task being notified had not yet processed the previous notification (the
N * task already had a notification pending).  xTaskNotify() always returns
N * pdPASS in this case.
N *
N * eSetValueWithoutOverwrite -
N * If the task being notified did not already have a notification pending then
N * the task's notification value is set to ulValue and xTaskNotify() will
N * return pdPASS.  If the task being notified already had a notification
N * pending then no action is performed and pdFAIL is returned.
N *
N * eNoAction -
N * The task receives a notification without its notification value being
N * updated.  ulValue is not used and xTaskNotify() always returns pdPASS in
N * this case.
N *
N *  pulPreviousNotificationValue -
N *  Can be used to pass out the subject task's notification value before any
N *  bits are modified by the notify function.
N *
N * @return Dependent on the value of eAction.  See the description of the
N * eAction parameter.
N *
N * \defgroup xTaskNotify xTaskNotify
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue ) ;
N#define xTaskNotify( xTaskToNotify, ulValue, eAction ) xTaskGenericNotify( ( xTaskToNotify ), ( ulValue ), ( eAction ), NULL )
N#define xTaskNotifyAndQuery( xTaskToNotify, ulValue, eAction, pulPreviousNotifyValue ) xTaskGenericNotify( ( xTaskToNotify ), ( ulValue ), ( eAction ), ( pulPreviousNotifyValue ) )
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, BaseType_t *pxHigherPriorityTaskWoken );</PRE>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * A version of xTaskNotify() that can be used from an interrupt service routine
N * (ISR).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * A notification sent to a task will remain pending until it is cleared by the
N * task calling xTaskNotifyWait() or ulTaskNotifyTake().  If the task was
N * already in the Blocked state to wait for a notification when the notification
N * arrives then the task will automatically be removed from the Blocked state
N * (unblocked) and the notification cleared.
N *
N * A task can use xTaskNotifyWait() to [optionally] block to wait for a
N * notification to be pending, or ulTaskNotifyTake() to [optionally] block
N * to wait for its notification value to have a non-zero value.  The task does
N * not consume any CPU time while it is in the Blocked state.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @param ulValue Data that can be sent with the notification.  How the data is
N * used depends on the value of the eAction parameter.
N *
N * @param eAction Specifies how the notification updates the task's notification
N * value, if at all.  Valid values for eAction are as follows:
N *
N * eSetBits -
N * The task's notification value is bitwise ORed with ulValue.  xTaskNofify()
N * always returns pdPASS in this case.
N *
N * eIncrement -
N * The task's notification value is incremented.  ulValue is not used and
N * xTaskNotify() always returns pdPASS in this case.
N *
N * eSetValueWithOverwrite -
N * The task's notification value is set to the value of ulValue, even if the
N * task being notified had not yet processed the previous notification (the
N * task already had a notification pending).  xTaskNotify() always returns
N * pdPASS in this case.
N *
N * eSetValueWithoutOverwrite -
N * If the task being notified did not already have a notification pending then
N * the task's notification value is set to ulValue and xTaskNotify() will
N * return pdPASS.  If the task being notified already had a notification
N * pending then no action is performed and pdFAIL is returned.
N *
N * eNoAction -
N * The task receives a notification without its notification value being
N * updated.  ulValue is not used and xTaskNotify() always returns pdPASS in
N * this case.
N *
N * @param pxHigherPriorityTaskWoken  xTaskNotifyFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending the notification caused the
N * task to which the notification was sent to leave the Blocked state, and the
N * unblocked task has a priority higher than the currently running task.  If
N * xTaskNotifyFromISR() sets this value to pdTRUE then a context switch should
N * be requested before the interrupt is exited.  How a context switch is
N * requested from an ISR is dependent on the port - see the documentation page
N * for the port in use.
N *
N * @return Dependent on the value of eAction.  See the description of the
N * eAction parameter.
N *
N * \defgroup xTaskNotify xTaskNotify
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken ) ;
N#define xTaskNotifyFromISR( xTaskToNotify, ulValue, eAction, pxHigherPriorityTaskWoken ) xTaskGenericNotifyFromISR( ( xTaskToNotify ), ( ulValue ), ( eAction ), NULL, ( pxHigherPriorityTaskWoken ) )
N#define xTaskNotifyAndQueryFromISR( xTaskToNotify, ulValue, eAction, pulPreviousNotificationValue, pxHigherPriorityTaskWoken ) xTaskGenericNotifyFromISR( ( xTaskToNotify ), ( ulValue ), ( eAction ), ( pulPreviousNotificationValue ), ( pxHigherPriorityTaskWoken ) )
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait );</pre>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * A notification sent to a task will remain pending until it is cleared by the
N * task calling xTaskNotifyWait() or ulTaskNotifyTake().  If the task was
N * already in the Blocked state to wait for a notification when the notification
N * arrives then the task will automatically be removed from the Blocked state
N * (unblocked) and the notification cleared.
N *
N * A task can use xTaskNotifyWait() to [optionally] block to wait for a
N * notification to be pending, or ulTaskNotifyTake() to [optionally] block
N * to wait for its notification value to have a non-zero value.  The task does
N * not consume any CPU time while it is in the Blocked state.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param ulBitsToClearOnEntry Bits that are set in ulBitsToClearOnEntry value
N * will be cleared in the calling task's notification value before the task
N * checks to see if any notifications are pending, and optionally blocks if no
N * notifications are pending.  Setting ulBitsToClearOnEntry to ULONG_MAX (if
N * limits.h is included) or 0xffffffffUL (if limits.h is not included) will have
N * the effect of resetting the task's notification value to 0.  Setting
N * ulBitsToClearOnEntry to 0 will leave the task's notification value unchanged.
N *
N * @param ulBitsToClearOnExit If a notification is pending or received before
N * the calling task exits the xTaskNotifyWait() function then the task's
N * notification value (see the xTaskNotify() API function) is passed out using
N * the pulNotificationValue parameter.  Then any bits that are set in
N * ulBitsToClearOnExit will be cleared in the task's notification value (note
N * *pulNotificationValue is set before any bits are cleared).  Setting
N * ulBitsToClearOnExit to ULONG_MAX (if limits.h is included) or 0xffffffffUL
N * (if limits.h is not included) will have the effect of resetting the task's
N * notification value to 0 before the function exits.  Setting
N * ulBitsToClearOnExit to 0 will leave the task's notification value unchanged
N * when the function exits (in which case the value passed out in
N * pulNotificationValue will match the task's notification value).
N *
N * @param pulNotificationValue Used to pass the task's notification value out
N * of the function.  Note the value passed out will not be effected by the
N * clearing of any bits caused by ulBitsToClearOnExit being non-zero.
N *
N * @param xTicksToWait The maximum amount of time that the task should wait in
N * the Blocked state for a notification to be received, should a notification
N * not already be pending when xTaskNotifyWait() was called.  The task
N * will not consume any processing time while it is in the Blocked state.  This
N * is specified in kernel ticks, the macro pdMS_TO_TICSK( value_in_ms ) can be
N * used to convert a time specified in milliseconds to a time specified in
N * ticks.
N *
N * @return If a notification was received (including notifications that were
N * already pending when xTaskNotifyWait was called) then pdPASS is
N * returned.  Otherwise pdFAIL is returned.
N *
N * \defgroup xTaskNotifyWait xTaskNotifyWait
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait ) ;
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyGive( TaskHandle_t xTaskToNotify );</PRE>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this macro
N * to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * xTaskNotifyGive() is a helper macro intended for use when task notifications
N * are used as light weight and faster binary or counting semaphore equivalents.
N * Actual FreeRTOS semaphores are given using the xSemaphoreGive() API function,
N * the equivalent action that instead uses a task notification is
N * xTaskNotifyGive().
N *
N * When task notifications are being used as a binary or counting semaphore
N * equivalent then the task being notified should wait for the notification
N * using the ulTaskNotificationTake() API function rather than the
N * xTaskNotifyWait() API function.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for more details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @return xTaskNotifyGive() is a macro that calls xTaskNotify() with the
N * eAction parameter set to eIncrement - so pdPASS is always returned.
N *
N * \defgroup xTaskNotifyGive xTaskNotifyGive
N * \ingroup TaskNotifications
N */
N#define xTaskNotifyGive( xTaskToNotify ) xTaskGenericNotify( ( xTaskToNotify ), ( 0 ), eIncrement, NULL )
N
N/**
N * task. h
N * <PRE>void vTaskNotifyGiveFromISR( TaskHandle_t xTaskHandle, BaseType_t *pxHigherPriorityTaskWoken );
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this macro
N * to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * A version of xTaskNotifyGive() that can be called from an interrupt service
N * routine (ISR).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * vTaskNotifyGiveFromISR() is intended for use when task notifications are
N * used as light weight and faster binary or counting semaphore equivalents.
N * Actual FreeRTOS semaphores are given from an ISR using the
N * xSemaphoreGiveFromISR() API function, the equivalent action that instead uses
N * a task notification is vTaskNotifyGiveFromISR().
N *
N * When task notifications are being used as a binary or counting semaphore
N * equivalent then the task being notified should wait for the notification
N * using the ulTaskNotificationTake() API function rather than the
N * xTaskNotifyWait() API function.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for more details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @param pxHigherPriorityTaskWoken  vTaskNotifyGiveFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending the notification caused the
N * task to which the notification was sent to leave the Blocked state, and the
N * unblocked task has a priority higher than the currently running task.  If
N * vTaskNotifyGiveFromISR() sets this value to pdTRUE then a context switch
N * should be requested before the interrupt is exited.  How a context switch is
N * requested from an ISR is dependent on the port - see the documentation page
N * for the port in use.
N *
N * \defgroup xTaskNotifyWait xTaskNotifyWait
N * \ingroup TaskNotifications
N */
Nvoid vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
Xvoid vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken ) ;
N
N/**
N * task. h
N * <PRE>uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait );</pre>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * ulTaskNotifyTake() is intended for use when a task notification is used as a
N * faster and lighter weight binary or counting semaphore alternative.  Actual
N * FreeRTOS semaphores are taken using the xSemaphoreTake() API function, the
N * equivalent action that instead uses a task notification is
N * ulTaskNotifyTake().
N *
N * When a task is using its notification value as a binary or counting semaphore
N * other tasks should send notifications to it using the xTaskNotifyGive()
N * macro, or xTaskNotify() function with the eAction parameter set to
N * eIncrement.
N *
N * ulTaskNotifyTake() can either clear the task's notification value to
N * zero on exit, in which case the notification value acts like a binary
N * semaphore, or decrement the task's notification value on exit, in which case
N * the notification value acts like a counting semaphore.
N *
N * A task can use ulTaskNotifyTake() to [optionally] block to wait for a
N * the task's notification value to be non-zero.  The task does not consume any
N * CPU time while it is in the Blocked state.
N *
N * Where as xTaskNotifyWait() will return when a notification is pending,
N * ulTaskNotifyTake() will return when the task's notification value is
N * not zero.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param xClearCountOnExit if xClearCountOnExit is pdFALSE then the task's
N * notification value is decremented when the function exits.  In this way the
N * notification value acts like a counting semaphore.  If xClearCountOnExit is
N * not pdFALSE then the task's notification value is cleared to zero when the
N * function exits.  In this way the notification value acts like a binary
N * semaphore.
N *
N * @param xTicksToWait The maximum amount of time that the task should wait in
N * the Blocked state for the task's notification value to be greater than zero,
N * should the count not already be greater than zero when
N * ulTaskNotifyTake() was called.  The task will not consume any processing
N * time while it is in the Blocked state.  This is specified in kernel ticks,
N * the macro pdMS_TO_TICSK( value_in_ms ) can be used to convert a time
N * specified in milliseconds to a time specified in ticks.
N *
N * @return The task's notification count before it is either cleared to zero or
N * decremented (see the xClearCountOnExit parameter).
N *
N * \defgroup ulTaskNotifyTake ulTaskNotifyTake
N * \ingroup TaskNotifications
N */
Nuint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
Xuint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait ) ;
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyStateClear( TaskHandle_t xTask );</pre>
N *
N * If the notification state of the task referenced by the handle xTask is
N * eNotified, then set the task's notification state to eNotWaitingNotification.
N * The task's notification value is not altered.  Set xTask to NULL to clear the
N * notification state of the calling task.
N *
N * @return pdTRUE if the task's notification state was set to
N * eNotWaitingNotification, otherwise pdFALSE.
N * \defgroup xTaskNotifyStateClear xTaskNotifyStateClear
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskNotifyStateClear( TaskHandle_t xTask );
N
N/*-----------------------------------------------------------
N * SCHEDULER INTERNALS AVAILABLE FOR PORTING PURPOSES
N *----------------------------------------------------------*/
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS ONLY
N * INTENDED FOR USE WHEN IMPLEMENTING A PORT OF THE SCHEDULER AND IS
N * AN INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * Called from the real time kernel tick (either preemptive or cooperative),
N * this increments the tick count and checks if any tasks that are blocked
N * for a finite period required removing from a blocked list and placing on
N * a ready list.  If a non-zero value is returned then a context switch is
N * required because either:
N *   + A task was removed from a blocked list because its timeout had expired,
N *     or
N *   + Time slicing is in use and there is a task of equal priority to the
N *     currently running task.
N */
NBaseType_t xTaskIncrementTick( void ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskIncrementTick( void ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS AN
N * INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * THIS FUNCTION MUST BE CALLED WITH INTERRUPTS DISABLED.
N *
N * Removes the calling task from the ready list and places it both
N * on the list of tasks waiting for a particular event, and the
N * list of delayed tasks.  The task will be removed from both lists
N * and replaced on the ready list should either the event occur (and
N * there be no higher priority tasks waiting on the same event) or
N * the delay period expires.
N *
N * The 'unordered' version replaces the event list item value with the
N * xItemValue value, and inserts the list item at the end of the list.
N *
N * The 'ordered' version uses the existing event list item value (which is the
N * owning tasks priority) to insert the list item into the event list is task
N * priority order.
N *
N * @param pxEventList The list containing tasks that are blocked waiting
N * for the event to occur.
N *
N * @param xItemValue The item value to use for the event list item when the
N * event list is not ordered by task priority.
N *
N * @param xTicksToWait The maximum amount of time that the task should wait
N * for the event to occur.  This is specified in kernel ticks,the constant
N * portTICK_PERIOD_MS can be used to convert kernel ticks into a real time
N * period.
N */
Nvoid vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
Xvoid vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait ) ;
Nvoid vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
Xvoid vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS AN
N * INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * THIS FUNCTION MUST BE CALLED WITH INTERRUPTS DISABLED.
N *
N * This function performs nearly the same function as vTaskPlaceOnEventList().
N * The difference being that this function does not permit tasks to block
N * indefinitely, whereas vTaskPlaceOnEventList() does.
N *
N */
Nvoid vTaskPlaceOnEventListRestricted( List_t * const pxEventList, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) PRIVILEGED_FUNCTION;
Xvoid vTaskPlaceOnEventListRestricted( List_t * const pxEventList, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS AN
N * INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * THIS FUNCTION MUST BE CALLED WITH INTERRUPTS DISABLED.
N *
N * Removes a task from both the specified event list and the list of blocked
N * tasks, and places it on a ready queue.
N *
N * xTaskRemoveFromEventList()/vTaskRemoveFromUnorderedEventList() will be called
N * if either an event occurs to unblock a task, or the block timeout period
N * expires.
N *
N * xTaskRemoveFromEventList() is used when the event list is in task priority
N * order.  It removes the list item from the head of the event list as that will
N * have the highest priority owning task of all the tasks on the event list.
N * vTaskRemoveFromUnorderedEventList() is used when the event list is not
N * ordered and the event list items hold something other than the owning tasks
N * priority.  In this case the event list item value is updated to the value
N * passed in the xItemValue parameter.
N *
N * @return pdTRUE if the task being removed has a higher priority than the task
N * making the call, otherwise pdFALSE.
N */
NBaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList ) ;
Nvoid vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue ) PRIVILEGED_FUNCTION;
Xvoid vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS ONLY
N * INTENDED FOR USE WHEN IMPLEMENTING A PORT OF THE SCHEDULER AND IS
N * AN INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * Sets the pointer to the current TCB to the TCB of the highest priority task
N * that is ready to run.
N */
Nvoid vTaskSwitchContext( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskSwitchContext( void ) ;
N
N/*
N * THESE FUNCTIONS MUST NOT BE USED FROM APPLICATION CODE.  THEY ARE USED BY
N * THE EVENT BITS MODULE.
N */
NTickType_t uxTaskResetEventItemValue( void ) PRIVILEGED_FUNCTION;
XTickType_t uxTaskResetEventItemValue( void ) ;
N
N/*
N * Return the handle of the calling task.
N */
NTaskHandle_t xTaskGetCurrentTaskHandle( void ) PRIVILEGED_FUNCTION;
XTaskHandle_t xTaskGetCurrentTaskHandle( void ) ;
N
N/*
N * Capture the current time status for future reference.
N */
Nvoid vTaskSetTimeOutState( TimeOut_t * const pxTimeOut ) PRIVILEGED_FUNCTION;
Xvoid vTaskSetTimeOutState( TimeOut_t * const pxTimeOut ) ;
N
N/*
N * Compare the time status now with that previously captured to see if the
N * timeout has expired.
N */
NBaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait ) ;
N
N/*
N * Shortcut used by the queue implementation to prevent unnecessary call to
N * taskYIELD();
N */
Nvoid vTaskMissedYield( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskMissedYield( void ) ;
N
N/*
N * Returns the scheduler state as taskSCHEDULER_RUNNING,
N * taskSCHEDULER_NOT_STARTED or taskSCHEDULER_SUSPENDED.
N */
NBaseType_t xTaskGetSchedulerState( void ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskGetSchedulerState( void ) ;
N
N/*
N * Raises the priority of the mutex holder to that of the calling task should
N * the mutex holder have a priority less than the calling task.
N */
Nvoid vTaskPriorityInherit( TaskHandle_t const pxMutexHolder ) PRIVILEGED_FUNCTION;
Xvoid vTaskPriorityInherit( TaskHandle_t const pxMutexHolder ) ;
N
N/*
N * Set the priority of a task back to its proper priority in the case that it
N * inherited a higher priority while it was holding a semaphore.
N */
NBaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder ) ;
N
N/*
N * Get the uxTCBNumber assigned to the task referenced by the xTask parameter.
N */
NUBaseType_t uxTaskGetTaskNumber( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetTaskNumber( TaskHandle_t xTask ) ;
N
N/*
N * Set the uxTaskNumber of the task referenced by the xTask parameter to
N * uxHandle.
N */
Nvoid vTaskSetTaskNumber( TaskHandle_t xTask, const UBaseType_t uxHandle ) PRIVILEGED_FUNCTION;
Xvoid vTaskSetTaskNumber( TaskHandle_t xTask, const UBaseType_t uxHandle ) ;
N
N/*
N * Only available when configUSE_TICKLESS_IDLE is set to 1.
N * If tickless mode is being used, or a low power mode is implemented, then
N * the tick interrupt will not execute during idle periods.  When this is the
N * case, the tick count value maintained by the scheduler needs to be kept up
N * to date with the actual execution time by being skipped forward by a time
N * equal to the idle period.
N */
Nvoid vTaskStepTick( const TickType_t xTicksToJump ) PRIVILEGED_FUNCTION;
Xvoid vTaskStepTick( const TickType_t xTicksToJump ) ;
N
N/*
N * Only avilable when configUSE_TICKLESS_IDLE is set to 1.
N * Provided for use within portSUPPRESS_TICKS_AND_SLEEP() to allow the port
N * specific sleep function to determine if it is ok to proceed with the sleep,
N * and if it is ok to proceed, if it is ok to sleep indefinitely.
N *
N * This function is necessary because portSUPPRESS_TICKS_AND_SLEEP() is only
N * called with the scheduler suspended, not from within a critical section.  It
N * is therefore possible for an interrupt to request a context switch between
N * portSUPPRESS_TICKS_AND_SLEEP() and the low power mode actually being
N * entered.  eTaskConfirmSleepModeStatus() should be called from a short
N * critical section between the timer being stopped and the sleep mode being
N * entered to ensure it is ok to proceed into the sleep mode.
N */
NeSleepModeStatus eTaskConfirmSleepModeStatus( void ) PRIVILEGED_FUNCTION;
XeSleepModeStatus eTaskConfirmSleepModeStatus( void ) ;
N
N/*
N * For internal use only.  Increment the mutex held count when a mutex is
N * taken and return the handle of the task that has taken the mutex.
N */
Nvoid *pvTaskIncrementMutexHeldCount( void ) PRIVILEGED_FUNCTION;
Xvoid *pvTaskIncrementMutexHeldCount( void ) ;
N
N#ifdef __cplusplus
S}
N#endif
N#endif /* INC_TASK_H */
N
N
N
L 7 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N#include "queue.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\queue.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N
N#ifndef QUEUE_H
N#define QUEUE_H
N
N#ifndef INC_FREERTOS_H
S	#error "include FreeRTOS.h" must appear in source files before "include queue.h"
N#endif
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N
N/**
N * Type by which queues are referenced.  For example, a call to xQueueCreate()
N * returns an QueueHandle_t variable that can then be used as a parameter to
N * xQueueSend(), xQueueReceive(), etc.
N */
Ntypedef void * QueueHandle_t;
N
N/**
N * Type by which queue sets are referenced.  For example, a call to
N * xQueueCreateSet() returns an xQueueSet variable that can then be used as a
N * parameter to xQueueSelectFromSet(), xQueueAddToSet(), etc.
N */
Ntypedef void * QueueSetHandle_t;
N
N/**
N * Queue sets can contain both queues and semaphores, so the
N * QueueSetMemberHandle_t is defined as a type to be used where a parameter or
N * return value can be either an QueueHandle_t or an SemaphoreHandle_t.
N */
Ntypedef void * QueueSetMemberHandle_t;
N
N/* For internal use only. */
N#define	queueSEND_TO_BACK		( ( BaseType_t ) 0 )
N#define	queueSEND_TO_FRONT		( ( BaseType_t ) 1 )
N#define queueOVERWRITE			( ( BaseType_t ) 2 )
N
N/* For internal use only.  These definitions *must* match those in queue.c. */
N#define queueQUEUE_TYPE_BASE				( ( uint8_t ) 0U )
N#define queueQUEUE_TYPE_SET					( ( uint8_t ) 0U )
N#define queueQUEUE_TYPE_MUTEX 				( ( uint8_t ) 1U )
N#define queueQUEUE_TYPE_COUNTING_SEMAPHORE	( ( uint8_t ) 2U )
N#define queueQUEUE_TYPE_BINARY_SEMAPHORE	( ( uint8_t ) 3U )
N#define queueQUEUE_TYPE_RECURSIVE_MUTEX		( ( uint8_t ) 4U )
N
N/**
N * queue. h
N * <pre>
N QueueHandle_t xQueueCreate(
N							  UBaseType_t uxQueueLength,
N							  UBaseType_t uxItemSize
N						  );
N * </pre>
N *
N * Creates a new queue instance, and returns a handle by which the new queue
N * can be referenced.
N *
N * Internally, within the FreeRTOS implementation, queues use two blocks of
N * memory.  The first block is used to hold the queue's data structures.  The
N * second block is used to hold items placed into the queue.  If a queue is
N * created using xQueueCreate() then both blocks of memory are automatically
N * dynamically allocated inside the xQueueCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a queue is created using
N * xQueueCreateStatic() then the application writer must provide the memory that
N * will get used by the queue.  xQueueCreateStatic() therefore allows a queue to
N * be created without using any dynamic memory allocation.
N *
N * http://www.FreeRTOS.org/Embedded-RTOS-Queues.html
N *
N * @param uxQueueLength The maximum number of items that the queue can contain.
N *
N * @param uxItemSize The number of bytes each item in the queue will require.
N * Items are queued by copy, not by reference, so this is the number of bytes
N * that will be copied for each posted item.  Each item on the queue must be
N * the same size.
N *
N * @return If the queue is successfully create then a handle to the newly
N * created queue is returned.  If the queue cannot be created then 0 is
N * returned.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N };
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N	if( xQueue1 == 0 )
N	{
N		// Queue was not created and must not be used.
N	}
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue2 == 0 )
N	{
N		// Queue was not created and must not be used.
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueCreate xQueueCreate
N * \ingroup QueueManagement
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xQueueCreate( uxQueueLength, uxItemSize ) xQueueGenericCreate( ( uxQueueLength ), ( uxItemSize ), ( queueQUEUE_TYPE_BASE ) )
N#endif
N
N/**
N * queue. h
N * <pre>
N QueueHandle_t xQueueCreateStatic(
N							  UBaseType_t uxQueueLength,
N							  UBaseType_t uxItemSize,
N							  uint8_t *pucQueueStorageBuffer,
N							  StaticQueue_t *pxQueueBuffer
N						  );
N * </pre>
N *
N * Creates a new queue instance, and returns a handle by which the new queue
N * can be referenced.
N *
N * Internally, within the FreeRTOS implementation, queues use two blocks of
N * memory.  The first block is used to hold the queue's data structures.  The
N * second block is used to hold items placed into the queue.  If a queue is
N * created using xQueueCreate() then both blocks of memory are automatically
N * dynamically allocated inside the xQueueCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a queue is created using
N * xQueueCreateStatic() then the application writer must provide the memory that
N * will get used by the queue.  xQueueCreateStatic() therefore allows a queue to
N * be created without using any dynamic memory allocation.
N *
N * http://www.FreeRTOS.org/Embedded-RTOS-Queues.html
N *
N * @param uxQueueLength The maximum number of items that the queue can contain.
N *
N * @param uxItemSize The number of bytes each item in the queue will require.
N * Items are queued by copy, not by reference, so this is the number of bytes
N * that will be copied for each posted item.  Each item on the queue must be
N * the same size.
N *
N * @param pucQueueStorageBuffer If uxItemSize is not zero then
N * pucQueueStorageBuffer must point to a uint8_t array that is at least large
N * enough to hold the maximum number of items that can be in the queue at any
N * one time - which is ( uxQueueLength * uxItemsSize ) bytes.  If uxItemSize is
N * zero then pucQueueStorageBuffer can be NULL.
N *
N * @param pxQueueBuffer Must point to a variable of type StaticQueue_t, which
N * will be used to hold the queue's data structure.
N *
N * @return If the queue is created then a handle to the created queue is
N * returned.  If pxQueueBuffer is NULL then NULL is returned.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N };
N
N #define QUEUE_LENGTH 10
N #define ITEM_SIZE sizeof( uint32_t )
N
N // xQueueBuffer will hold the queue structure.
N StaticQueue_t xQueueBuffer;
N
N // ucQueueStorage will hold the items posted to the queue.  Must be at least
N // [(queue length) * ( queue item size)] bytes long.
N uint8_t ucQueueStorage[ QUEUE_LENGTH * ITEM_SIZE ];
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( QUEUE_LENGTH, // The number of items the queue can hold.
N							ITEM_SIZE	  // The size of each item in the queue
N							&( ucQueueStorage[ 0 ] ), // The buffer that will hold the items in the queue.
N							&xQueueBuffer ); // The buffer that will hold the queue structure.
N
N	// The queue is guaranteed to be created successfully as no dynamic memory
N	// allocation is used.  Therefore xQueue1 is now a handle to a valid queue.
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueCreateStatic xQueueCreateStatic
N * \ingroup QueueManagement
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	#define xQueueCreateStatic( uxQueueLength, uxItemSize, pucQueueStorage, pxQueueBuffer ) xQueueGenericCreateStatic( ( uxQueueLength ), ( uxItemSize ), ( pucQueueStorage ), ( pxQueueBuffer ), ( queueQUEUE_TYPE_BASE ) )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToToFront(
N								   QueueHandle_t	xQueue,
N								   const void		*pvItemToQueue,
N								   TickType_t		xTicksToWait
N							   );
N * </pre>
N *
N * This is a macro that calls xQueueGenericSend().
N *
N * Post an item to the front of a queue.  The item is queued by copy, not by
N * reference.  This function must not be called from an interrupt service
N * routine.  See xQueueSendFromISR () for an alternative which may be used
N * in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the
N * queue is full.  The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueSendToFront( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10 ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueSendToFront( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0 );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
N#define xQueueSendToFront( xQueue, pvItemToQueue, xTicksToWait ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), ( xTicksToWait ), queueSEND_TO_FRONT )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToBack(
N								   QueueHandle_t	xQueue,
N								   const void		*pvItemToQueue,
N								   TickType_t		xTicksToWait
N							   );
N * </pre>
N *
N * This is a macro that calls xQueueGenericSend().
N *
N * Post an item to the back of a queue.  The item is queued by copy, not by
N * reference.  This function must not be called from an interrupt service
N * routine.  See xQueueSendFromISR () for an alternative which may be used
N * in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the queue
N * is full.  The  time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueSendToBack( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10 ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueSendToBack( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0 );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
N#define xQueueSendToBack( xQueue, pvItemToQueue, xTicksToWait ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), ( xTicksToWait ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSend(
N							  QueueHandle_t xQueue,
N							  const void * pvItemToQueue,
N							  TickType_t xTicksToWait
N						 );
N * </pre>
N *
N * This is a macro that calls xQueueGenericSend().  It is included for
N * backward compatibility with versions of FreeRTOS.org that did not
N * include the xQueueSendToFront() and xQueueSendToBack() macros.  It is
N * equivalent to xQueueSendToBack().
N *
N * Post an item on a queue.  The item is queued by copy, not by reference.
N * This function must not be called from an interrupt service routine.
N * See xQueueSendFromISR () for an alternative which may be used in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the
N * queue is full.  The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueSend( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10 ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueSend( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0 );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
N#define xQueueSend( xQueue, pvItemToQueue, xTicksToWait ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), ( xTicksToWait ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueOverwrite(
N							  QueueHandle_t xQueue,
N							  const void * pvItemToQueue
N						 );
N * </pre>
N *
N * Only for use with queues that have a length of one - so the queue is either
N * empty or full.
N *
N * Post an item on a queue.  If the queue is already full then overwrite the
N * value held in the queue.  The item is queued by copy, not by reference.
N *
N * This function must not be called from an interrupt service routine.
N * See xQueueOverwriteFromISR () for an alternative which may be used in an ISR.
N *
N * @param xQueue The handle of the queue to which the data is being sent.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @return xQueueOverwrite() is a macro that calls xQueueGenericSend(), and
N * therefore has the same return values as xQueueSendToFront().  However, pdPASS
N * is the only value that can be returned because xQueueOverwrite() will write
N * to the queue even when the queue is already full.
N *
N * Example usage:
N   <pre>
N
N void vFunction( void *pvParameters )
N {
N QueueHandle_t xQueue;
N uint32_t ulVarToSend, ulValReceived;
N
N	// Create a queue to hold one uint32_t value.  It is strongly
N	// recommended *not* to use xQueueOverwrite() on queues that can
N	// contain more than one value, and doing so will trigger an assertion
N	// if configASSERT() is defined.
N	xQueue = xQueueCreate( 1, sizeof( uint32_t ) );
N
N	// Write the value 10 to the queue using xQueueOverwrite().
N	ulVarToSend = 10;
N	xQueueOverwrite( xQueue, &ulVarToSend );
N
N	// Peeking the queue should now return 10, but leave the value 10 in
N	// the queue.  A block time of zero is used as it is known that the
N	// queue holds a value.
N	ulValReceived = 0;
N	xQueuePeek( xQueue, &ulValReceived, 0 );
N
N	if( ulValReceived != 10 )
N	{
N		// Error unless the item was removed by a different task.
N	}
N
N	// The queue is still full.  Use xQueueOverwrite() to overwrite the
N	// value held in the queue with 100.
N	ulVarToSend = 100;
N	xQueueOverwrite( xQueue, &ulVarToSend );
N
N	// This time read from the queue, leaving the queue empty once more.
N	// A block time of 0 is used again.
N	xQueueReceive( xQueue, &ulValReceived, 0 );
N
N	// The value read should be the last value written, even though the
N	// queue was already full when the value was written.
N	if( ulValReceived != 100 )
N	{
N		// Error!
N	}
N
N	// ...
N}
N </pre>
N * \defgroup xQueueOverwrite xQueueOverwrite
N * \ingroup QueueManagement
N */
N#define xQueueOverwrite( xQueue, pvItemToQueue ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), 0, queueOVERWRITE )
N
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueGenericSend(
N									QueueHandle_t xQueue,
N									const void * pvItemToQueue,
N									TickType_t xTicksToWait
N									BaseType_t xCopyPosition
N								);
N * </pre>
N *
N * It is preferred that the macros xQueueSend(), xQueueSendToFront() and
N * xQueueSendToBack() are used in place of calling this function directly.
N *
N * Post an item on a queue.  The item is queued by copy, not by reference.
N * This function must not be called from an interrupt service routine.
N * See xQueueSendFromISR () for an alternative which may be used in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the
N * queue is full.  The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @param xCopyPosition Can take the value queueSEND_TO_BACK to place the
N * item at the back of the queue, or queueSEND_TO_FRONT to place the item
N * at the front of the queue (for high priority messages).
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueGenericSend( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10, queueSEND_TO_BACK ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueGenericSend( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0, queueSEND_TO_BACK );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
NBaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueuePeek(
N							 QueueHandle_t xQueue,
N							 void *pvBuffer,
N							 TickType_t xTicksToWait
N						 );</pre>
N *
N * This is a macro that calls the xQueueGenericReceive() function.
N *
N * Receive an item from a queue without removing the item from the queue.
N * The item is received by copy so a buffer of adequate size must be
N * provided.  The number of bytes copied into the buffer was defined when
N * the queue was created.
N *
N * Successfully received items remain on the queue so will be returned again
N * by the next call, or a call to xQueueReceive().
N *
N * This macro must not be used in an interrupt service routine.  See
N * xQueuePeekFromISR() for an alternative that can be called from an interrupt
N * service routine.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for an item to receive should the queue be empty at the time
N * of the call.	 The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N * xQueuePeek() will return immediately if xTicksToWait is 0 and the queue
N * is empty.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N QueueHandle_t xQueue;
N
N // Task to create a queue and post a value.
N void vATask( void *pvParameters )
N {
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Send a pointer to a struct AMessage object.  Don't block if the
N	// queue is already full.
N	pxMessage = & xMessage;
N	xQueueSend( xQueue, ( void * ) &pxMessage, ( TickType_t ) 0 );
N
N	// ... Rest of task code.
N }
N
N // Task to peek the data from the queue.
N void vADifferentTask( void *pvParameters )
N {
N struct AMessage *pxRxedMessage;
N
N	if( xQueue != 0 )
N	{
N		// Peek a message on the created queue.  Block for 10 ticks if a
N		// message is not immediately available.
N		if( xQueuePeek( xQueue, &( pxRxedMessage ), ( TickType_t ) 10 ) )
N		{
N			// pcRxedMessage now points to the struct AMessage variable posted
N			// by vATask, but the item still remains on the queue.
N		}
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueReceive xQueueReceive
N * \ingroup QueueManagement
N */
N#define xQueuePeek( xQueue, pvBuffer, xTicksToWait ) xQueueGenericReceive( ( xQueue ), ( pvBuffer ), ( xTicksToWait ), pdTRUE )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueuePeekFromISR(
N									QueueHandle_t xQueue,
N									void *pvBuffer,
N								);</pre>
N *
N * A version of xQueuePeek() that can be called from an interrupt service
N * routine (ISR).
N *
N * Receive an item from a queue without removing the item from the queue.
N * The item is received by copy so a buffer of adequate size must be
N * provided.  The number of bytes copied into the buffer was defined when
N * the queue was created.
N *
N * Successfully received items remain on the queue so will be returned again
N * by the next call, or a call to xQueueReceive().
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * \defgroup xQueuePeekFromISR xQueuePeekFromISR
N * \ingroup QueueManagement
N */
NBaseType_t xQueuePeekFromISR( QueueHandle_t xQueue, void * const pvBuffer ) PRIVILEGED_FUNCTION;
XBaseType_t xQueuePeekFromISR( QueueHandle_t xQueue, void * const pvBuffer ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueReceive(
N								 QueueHandle_t xQueue,
N								 void *pvBuffer,
N								 TickType_t xTicksToWait
N							);</pre>
N *
N * This is a macro that calls the xQueueGenericReceive() function.
N *
N * Receive an item from a queue.  The item is received by copy so a buffer of
N * adequate size must be provided.  The number of bytes copied into the buffer
N * was defined when the queue was created.
N *
N * Successfully received items are removed from the queue.
N *
N * This function must not be used in an interrupt service routine.  See
N * xQueueReceiveFromISR for an alternative that can.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for an item to receive should the queue be empty at the time
N * of the call.	 xQueueReceive() will return immediately if xTicksToWait
N * is zero and the queue is empty.  The time is defined in tick periods so the
N * constant portTICK_PERIOD_MS should be used to convert to real time if this is
N * required.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N QueueHandle_t xQueue;
N
N // Task to create a queue and post a value.
N void vATask( void *pvParameters )
N {
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Send a pointer to a struct AMessage object.  Don't block if the
N	// queue is already full.
N	pxMessage = & xMessage;
N	xQueueSend( xQueue, ( void * ) &pxMessage, ( TickType_t ) 0 );
N
N	// ... Rest of task code.
N }
N
N // Task to receive from the queue.
N void vADifferentTask( void *pvParameters )
N {
N struct AMessage *pxRxedMessage;
N
N	if( xQueue != 0 )
N	{
N		// Receive a message on the created queue.  Block for 10 ticks if a
N		// message is not immediately available.
N		if( xQueueReceive( xQueue, &( pxRxedMessage ), ( TickType_t ) 10 ) )
N		{
N			// pcRxedMessage now points to the struct AMessage variable posted
N			// by vATask.
N		}
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueReceive xQueueReceive
N * \ingroup QueueManagement
N */
N#define xQueueReceive( xQueue, pvBuffer, xTicksToWait ) xQueueGenericReceive( ( xQueue ), ( pvBuffer ), ( xTicksToWait ), pdFALSE )
N
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueGenericReceive(
N									   QueueHandle_t	xQueue,
N									   void	*pvBuffer,
N									   TickType_t	xTicksToWait
N									   BaseType_t	xJustPeek
N									);</pre>
N *
N * It is preferred that the macro xQueueReceive() be used rather than calling
N * this function directly.
N *
N * Receive an item from a queue.  The item is received by copy so a buffer of
N * adequate size must be provided.  The number of bytes copied into the buffer
N * was defined when the queue was created.
N *
N * This function must not be used in an interrupt service routine.  See
N * xQueueReceiveFromISR for an alternative that can.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for an item to receive should the queue be empty at the time
N * of the call.	 The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N * xQueueGenericReceive() will return immediately if the queue is empty and
N * xTicksToWait is 0.
N *
N * @param xJustPeek When set to true, the item received from the queue is not
N * actually removed from the queue - meaning a subsequent call to
N * xQueueReceive() will return the same item.  When set to false, the item
N * being received from the queue is also removed from the queue.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N QueueHandle_t xQueue;
N
N // Task to create a queue and post a value.
N void vATask( void *pvParameters )
N {
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Send a pointer to a struct AMessage object.  Don't block if the
N	// queue is already full.
N	pxMessage = & xMessage;
N	xQueueSend( xQueue, ( void * ) &pxMessage, ( TickType_t ) 0 );
N
N	// ... Rest of task code.
N }
N
N // Task to receive from the queue.
N void vADifferentTask( void *pvParameters )
N {
N struct AMessage *pxRxedMessage;
N
N	if( xQueue != 0 )
N	{
N		// Receive a message on the created queue.  Block for 10 ticks if a
N		// message is not immediately available.
N		if( xQueueGenericReceive( xQueue, &( pxRxedMessage ), ( TickType_t ) 10 ) )
N		{
N			// pcRxedMessage now points to the struct AMessage variable posted
N			// by vATask.
N		}
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueReceive xQueueReceive
N * \ingroup QueueManagement
N */
NBaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeek ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeek ) ;
N
N/**
N * queue. h
N * <pre>UBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue );</pre>
N *
N * Return the number of messages stored in a queue.
N *
N * @param xQueue A handle to the queue being queried.
N *
N * @return The number of messages available in the queue.
N *
N * \defgroup uxQueueMessagesWaiting uxQueueMessagesWaiting
N * \ingroup QueueManagement
N */
NUBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue ) ;
N
N/**
N * queue. h
N * <pre>UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue );</pre>
N *
N * Return the number of free spaces available in a queue.  This is equal to the
N * number of items that can be sent to the queue before the queue becomes full
N * if no items are removed.
N *
N * @param xQueue A handle to the queue being queried.
N *
N * @return The number of spaces available in the queue.
N *
N * \defgroup uxQueueMessagesWaiting uxQueueMessagesWaiting
N * \ingroup QueueManagement
N */
NUBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue ) ;
N
N/**
N * queue. h
N * <pre>void vQueueDelete( QueueHandle_t xQueue );</pre>
N *
N * Delete a queue - freeing all the memory allocated for storing of items
N * placed on the queue.
N *
N * @param xQueue A handle to the queue to be deleted.
N *
N * \defgroup vQueueDelete vQueueDelete
N * \ingroup QueueManagement
N */
Nvoid vQueueDelete( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
Xvoid vQueueDelete( QueueHandle_t xQueue ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToFrontFromISR(
N										 QueueHandle_t xQueue,
N										 const void *pvItemToQueue,
N										 BaseType_t *pxHigherPriorityTaskWoken
N									  );
N </pre>
N *
N * This is a macro that calls xQueueGenericSendFromISR().
N *
N * Post an item to the front of a queue.  It is safe to use this macro from
N * within an interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueSendToFrontFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueSendToFromFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPrioritTaskWoken;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWoken = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post the byte.
N		xQueueSendToFrontFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWoken );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.
N	if( xHigherPriorityTaskWoken )
N	{
N		taskYIELD ();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
N#define xQueueSendToFrontFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueSEND_TO_FRONT )
N
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToBackFromISR(
N										 QueueHandle_t xQueue,
N										 const void *pvItemToQueue,
N										 BaseType_t *pxHigherPriorityTaskWoken
N									  );
N </pre>
N *
N * This is a macro that calls xQueueGenericSendFromISR().
N *
N * Post an item to the back of a queue.  It is safe to use this macro from
N * within an interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueSendToBackFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueSendToBackFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPriorityTaskWoken;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWoken = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post the byte.
N		xQueueSendToBackFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWoken );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.
N	if( xHigherPriorityTaskWoken )
N	{
N		taskYIELD ();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
N#define xQueueSendToBackFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueOverwriteFromISR(
N							  QueueHandle_t xQueue,
N							  const void * pvItemToQueue,
N							  BaseType_t *pxHigherPriorityTaskWoken
N						 );
N * </pre>
N *
N * A version of xQueueOverwrite() that can be used in an interrupt service
N * routine (ISR).
N *
N * Only for use with queues that can hold a single item - so the queue is either
N * empty or full.
N *
N * Post an item on a queue.  If the queue is already full then overwrite the
N * value held in the queue.  The item is queued by copy, not by reference.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueOverwriteFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueOverwriteFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return xQueueOverwriteFromISR() is a macro that calls
N * xQueueGenericSendFromISR(), and therefore has the same return values as
N * xQueueSendToFrontFromISR().  However, pdPASS is the only value that can be
N * returned because xQueueOverwriteFromISR() will write to the queue even when
N * the queue is already full.
N *
N * Example usage:
N   <pre>
N
N QueueHandle_t xQueue;
N
N void vFunction( void *pvParameters )
N {
N 	// Create a queue to hold one uint32_t value.  It is strongly
N	// recommended *not* to use xQueueOverwriteFromISR() on queues that can
N	// contain more than one value, and doing so will trigger an assertion
N	// if configASSERT() is defined.
N	xQueue = xQueueCreate( 1, sizeof( uint32_t ) );
N}
N
Nvoid vAnInterruptHandler( void )
N{
N// xHigherPriorityTaskWoken must be set to pdFALSE before it is used.
NBaseType_t xHigherPriorityTaskWoken = pdFALSE;
Nuint32_t ulVarToSend, ulValReceived;
N
N	// Write the value 10 to the queue using xQueueOverwriteFromISR().
N	ulVarToSend = 10;
N	xQueueOverwriteFromISR( xQueue, &ulVarToSend, &xHigherPriorityTaskWoken );
N
N	// The queue is full, but calling xQueueOverwriteFromISR() again will still
N	// pass because the value held in the queue will be overwritten with the
N	// new value.
N	ulVarToSend = 100;
N	xQueueOverwriteFromISR( xQueue, &ulVarToSend, &xHigherPriorityTaskWoken );
N
N	// Reading from the queue will now return 100.
N
N	// ...
N
N	if( xHigherPrioritytaskWoken == pdTRUE )
N	{
N		// Writing to the queue caused a task to unblock and the unblocked task
N		// has a priority higher than or equal to the priority of the currently
N		// executing task (the task this interrupt interrupted).  Perform a context
N		// switch so this interrupt returns directly to the unblocked task.
N		portYIELD_FROM_ISR(); // or portEND_SWITCHING_ISR() depending on the port.
N	}
N}
N </pre>
N * \defgroup xQueueOverwriteFromISR xQueueOverwriteFromISR
N * \ingroup QueueManagement
N */
N#define xQueueOverwriteFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueOVERWRITE )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendFromISR(
N									 QueueHandle_t xQueue,
N									 const void *pvItemToQueue,
N									 BaseType_t *pxHigherPriorityTaskWoken
N								);
N </pre>
N *
N * This is a macro that calls xQueueGenericSendFromISR().  It is included
N * for backward compatibility with versions of FreeRTOS.org that did not
N * include the xQueueSendToBackFromISR() and xQueueSendToFrontFromISR()
N * macros.
N *
N * Post an item to the back of a queue.  It is safe to use this function from
N * within an interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueSendFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueSendFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPriorityTaskWoken;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWoken = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post the byte.
N		xQueueSendFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWoken );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.
N	if( xHigherPriorityTaskWoken )
N	{
N		// Actual macro used here is port specific.
N		portYIELD_FROM_ISR ();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
N#define xQueueSendFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueGenericSendFromISR(
N										   QueueHandle_t		xQueue,
N										   const	void	*pvItemToQueue,
N										   BaseType_t	*pxHigherPriorityTaskWoken,
N										   BaseType_t	xCopyPosition
N									   );
N </pre>
N *
N * It is preferred that the macros xQueueSendFromISR(),
N * xQueueSendToFrontFromISR() and xQueueSendToBackFromISR() be used in place
N * of calling this function directly.  xQueueGiveFromISR() is an
N * equivalent for use by semaphores that don't actually copy any data.
N *
N * Post an item on a queue.  It is safe to use this function from within an
N * interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueGenericSendFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueGenericSendFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @param xCopyPosition Can take the value queueSEND_TO_BACK to place the
N * item at the back of the queue, or queueSEND_TO_FRONT to place the item
N * at the front of the queue (for high priority messages).
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPriorityTaskWokenByPost;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWokenByPost = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post each byte.
N		xQueueGenericSendFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWokenByPost, queueSEND_TO_BACK );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.  Note that the
N	// name of the yield function required is port specific.
N	if( xHigherPriorityTaskWokenByPost )
N	{
N		taskYIELD_YIELD_FROM_ISR();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
NBaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition ) ;
NBaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueReceiveFromISR(
N									   QueueHandle_t	xQueue,
N									   void	*pvBuffer,
N									   BaseType_t *pxTaskWoken
N								   );
N * </pre>
N *
N * Receive an item from a queue.  It is safe to use this function from within an
N * interrupt service routine.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param pxTaskWoken A task may be blocked waiting for space to become
N * available on the queue.  If xQueueReceiveFromISR causes such a task to
N * unblock *pxTaskWoken will get set to pdTRUE, otherwise *pxTaskWoken will
N * remain unchanged.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N
N QueueHandle_t xQueue;
N
N // Function to create a queue and post some values.
N void vAFunction( void *pvParameters )
N {
N char cValueToPost;
N const TickType_t xTicksToWait = ( TickType_t )0xff;
N
N	// Create a queue capable of containing 10 characters.
N	xQueue = xQueueCreate( 10, sizeof( char ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Post some characters that will be used within an ISR.  If the queue
N	// is full then this task will block for xTicksToWait ticks.
N	cValueToPost = 'a';
N	xQueueSend( xQueue, ( void * ) &cValueToPost, xTicksToWait );
N	cValueToPost = 'b';
N	xQueueSend( xQueue, ( void * ) &cValueToPost, xTicksToWait );
N
N	// ... keep posting characters ... this task may block when the queue
N	// becomes full.
N
N	cValueToPost = 'c';
N	xQueueSend( xQueue, ( void * ) &cValueToPost, xTicksToWait );
N }
N
N // ISR that outputs all the characters received on the queue.
N void vISR_Routine( void )
N {
N BaseType_t xTaskWokenByReceive = pdFALSE;
N char cRxedChar;
N
N	while( xQueueReceiveFromISR( xQueue, ( void * ) &cRxedChar, &xTaskWokenByReceive) )
N	{
N		// A character was received.  Output the character now.
N		vOutputCharacter( cRxedChar );
N
N		// If removing the character from the queue woke the task that was
N		// posting onto the queue cTaskWokenByReceive will have been set to
N		// pdTRUE.  No matter how many times this loop iterates only one
N		// task will be woken.
N	}
N
N	if( cTaskWokenByPost != ( char ) pdFALSE;
N	{
N		taskYIELD ();
N	}
N }
N </pre>
N * \defgroup xQueueReceiveFromISR xQueueReceiveFromISR
N * \ingroup QueueManagement
N */
NBaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken ) ;
N
N/*
N * Utilities to query queues that are safe to use from an ISR.  These utilities
N * should be used only from witin an ISR, or within a critical section.
N */
NBaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue ) ;
NBaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue ) ;
NUBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue ) ;
N
N/*
N * The functions defined above are for passing data to and from tasks.  The
N * functions below are the equivalents for passing data to and from
N * co-routines.
N *
N * These functions are called from the co-routine macro implementation and
N * should not be called directly from application code.  Instead use the macro
N * wrappers defined within croutine.h.
N */
NBaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken );
NBaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue, void *pvBuffer, BaseType_t *pxTaskWoken );
NBaseType_t xQueueCRSend( QueueHandle_t xQueue, const void *pvItemToQueue, TickType_t xTicksToWait );
NBaseType_t xQueueCRReceive( QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait );
N
N/*
N * For internal use only.  Use xSemaphoreCreateMutex(),
N * xSemaphoreCreateCounting() or xSemaphoreGetMutexHolder() instead of calling
N * these functions directly.
N */
NQueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType ) ;
NQueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType, StaticQueue_t *pxStaticQueue ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType, StaticQueue_t *pxStaticQueue ) ;
NQueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount ) ;
NQueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount, StaticQueue_t *pxStaticQueue ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount, StaticQueue_t *pxStaticQueue ) ;
Nvoid* xQueueGetMutexHolder( QueueHandle_t xSemaphore ) PRIVILEGED_FUNCTION;
Xvoid* xQueueGetMutexHolder( QueueHandle_t xSemaphore ) ;
Nvoid* xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore ) PRIVILEGED_FUNCTION;
Xvoid* xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore ) ;
N
N/*
N * For internal use only.  Use xSemaphoreTakeMutexRecursive() or
N * xSemaphoreGiveMutexRecursive() instead of calling these functions directly.
N */
NBaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex, TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex, TickType_t xTicksToWait ) ;
NBaseType_t xQueueGiveMutexRecursive( QueueHandle_t pxMutex ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGiveMutexRecursive( QueueHandle_t pxMutex ) ;
N
N/*
N * Reset a queue back to its original empty state.  The return value is now
N * obsolete and is always set to pdPASS.
N */
N#define xQueueReset( xQueue ) xQueueGenericReset( xQueue, pdFALSE )
N
N/*
N * The registry is provided as a means for kernel aware debuggers to
N * locate queues, semaphores and mutexes.  Call vQueueAddToRegistry() add
N * a queue, semaphore or mutex handle to the registry if you want the handle
N * to be available to a kernel aware debugger.  If you are not using a kernel
N * aware debugger then this function can be ignored.
N *
N * configQUEUE_REGISTRY_SIZE defines the maximum number of handles the
N * registry can hold.  configQUEUE_REGISTRY_SIZE must be greater than 0
N * within FreeRTOSConfig.h for the registry to be available.  Its value
N * does not effect the number of queues, semaphores and mutexes that can be
N * created - just the number that the registry can hold.
N *
N * @param xQueue The handle of the queue being added to the registry.  This
N * is the handle returned by a call to xQueueCreate().  Semaphore and mutex
N * handles can also be passed in here.
N *
N * @param pcName The name to be associated with the handle.  This is the
N * name that the kernel aware debugger will display.  The queue registry only
N * stores a pointer to the string - so the string must be persistent (global or
N * preferably in ROM/Flash), not on the stack.
N */
N#if( configQUEUE_REGISTRY_SIZE > 0 )
X#if( 0U > 0 )
S	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcName ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N#endif
N
N/*
N * The registry is provided as a means for kernel aware debuggers to
N * locate queues, semaphores and mutexes.  Call vQueueAddToRegistry() add
N * a queue, semaphore or mutex handle to the registry if you want the handle
N * to be available to a kernel aware debugger, and vQueueUnregisterQueue() to
N * remove the queue, semaphore or mutex from the register.  If you are not using
N * a kernel aware debugger then this function can be ignored.
N *
N * @param xQueue The handle of the queue being removed from the registry.
N */
N#if( configQUEUE_REGISTRY_SIZE > 0 )
X#if( 0U > 0 )
S	void vQueueUnregisterQueue( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
N#endif
N
N/*
N * The queue registry is provided as a means for kernel aware debuggers to
N * locate queues, semaphores and mutexes.  Call pcQueueGetName() to look
N * up and return the name of a queue in the queue registry from the queue's
N * handle.
N *
N * @param xQueue The handle of the queue the name of which will be returned.
N * @return If the queue is in the registry then a pointer to the name of the
N * queue is returned.  If the queue is not in the registry then NULL is
N * returned.
N */
N#if( configQUEUE_REGISTRY_SIZE > 0 )
X#if( 0U > 0 )
S	const char *pcQueueGetName( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N#endif
N
N/*
N * Generic version of the function used to creaet a queue using dynamic memory
N * allocation.  This is called by other functions and macros that create other
N * RTOS objects that use the queue structure as their base.
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType ) PRIVILEGED_FUNCTION;
X	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType ) ;
N#endif
N
N/*
N * Generic version of the function used to creaet a queue using dynamic memory
N * allocation.  This is called by other functions and macros that create other
N * RTOS objects that use the queue structure as their base.
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	QueueHandle_t xQueueGenericCreateStatic( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, StaticQueue_t *pxStaticQueue, const uint8_t ucQueueType ) PRIVILEGED_FUNCTION;
N#endif
N
N/*
N * Queue sets provide a mechanism to allow a task to block (pend) on a read
N * operation from multiple queues or semaphores simultaneously.
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * A queue set must be explicitly created using a call to xQueueCreateSet()
N * before it can be used.  Once created, standard FreeRTOS queues and semaphores
N * can be added to the set using calls to xQueueAddToSet().
N * xQueueSelectFromSet() is then used to determine which, if any, of the queues
N * or semaphores contained in the set is in a state where a queue read or
N * semaphore take operation would be successful.
N *
N * Note 1:  See the documentation on http://wwwFreeRTOS.org/RTOS-queue-sets.html
N * for reasons why queue sets are very rarely needed in practice as there are
N * simpler methods of blocking on multiple objects.
N *
N * Note 2:  Blocking on a queue set that contains a mutex will not cause the
N * mutex holder to inherit the priority of the blocked task.
N *
N * Note 3:  An additional 4 bytes of RAM is required for each space in a every
N * queue added to a queue set.  Therefore counting semaphores that have a high
N * maximum count value should not be added to a queue set.
N *
N * Note 4:  A receive (in the case of a queue) or take (in the case of a
N * semaphore) operation must not be performed on a member of a queue set unless
N * a call to xQueueSelectFromSet() has first returned a handle to that set member.
N *
N * @param uxEventQueueLength Queue sets store events that occur on
N * the queues and semaphores contained in the set.  uxEventQueueLength specifies
N * the maximum number of events that can be queued at once.  To be absolutely
N * certain that events are not lost uxEventQueueLength should be set to the
N * total sum of the length of the queues added to the set, where binary
N * semaphores and mutexes have a length of 1, and counting semaphores have a
N * length set by their maximum count value.  Examples:
N *  + If a queue set is to hold a queue of length 5, another queue of length 12,
N *    and a binary semaphore, then uxEventQueueLength should be set to
N *    (5 + 12 + 1), or 18.
N *  + If a queue set is to hold three binary semaphores then uxEventQueueLength
N *    should be set to (1 + 1 + 1 ), or 3.
N *  + If a queue set is to hold a counting semaphore that has a maximum count of
N *    5, and a counting semaphore that has a maximum count of 3, then
N *    uxEventQueueLength should be set to (5 + 3), or 8.
N *
N * @return If the queue set is created successfully then a handle to the created
N * queue set is returned.  Otherwise NULL is returned.
N */
NQueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength ) PRIVILEGED_FUNCTION;
XQueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength ) ;
N
N/*
N * Adds a queue or semaphore to a queue set that was previously created by a
N * call to xQueueCreateSet().
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * Note 1:  A receive (in the case of a queue) or take (in the case of a
N * semaphore) operation must not be performed on a member of a queue set unless
N * a call to xQueueSelectFromSet() has first returned a handle to that set member.
N *
N * @param xQueueOrSemaphore The handle of the queue or semaphore being added to
N * the queue set (cast to an QueueSetMemberHandle_t type).
N *
N * @param xQueueSet The handle of the queue set to which the queue or semaphore
N * is being added.
N *
N * @return If the queue or semaphore was successfully added to the queue set
N * then pdPASS is returned.  If the queue could not be successfully added to the
N * queue set because it is already a member of a different queue set then pdFAIL
N * is returned.
N */
NBaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) ;
N
N/*
N * Removes a queue or semaphore from a queue set.  A queue or semaphore can only
N * be removed from a set if the queue or semaphore is empty.
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * @param xQueueOrSemaphore The handle of the queue or semaphore being removed
N * from the queue set (cast to an QueueSetMemberHandle_t type).
N *
N * @param xQueueSet The handle of the queue set in which the queue or semaphore
N * is included.
N *
N * @return If the queue or semaphore was successfully removed from the queue set
N * then pdPASS is returned.  If the queue was not in the queue set, or the
N * queue (or semaphore) was not empty, then pdFAIL is returned.
N */
NBaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) ;
N
N/*
N * xQueueSelectFromSet() selects from the members of a queue set a queue or
N * semaphore that either contains data (in the case of a queue) or is available
N * to take (in the case of a semaphore).  xQueueSelectFromSet() effectively
N * allows a task to block (pend) on a read operation on all the queues and
N * semaphores in a queue set simultaneously.
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * Note 1:  See the documentation on http://wwwFreeRTOS.org/RTOS-queue-sets.html
N * for reasons why queue sets are very rarely needed in practice as there are
N * simpler methods of blocking on multiple objects.
N *
N * Note 2:  Blocking on a queue set that contains a mutex will not cause the
N * mutex holder to inherit the priority of the blocked task.
N *
N * Note 3:  A receive (in the case of a queue) or take (in the case of a
N * semaphore) operation must not be performed on a member of a queue set unless
N * a call to xQueueSelectFromSet() has first returned a handle to that set member.
N *
N * @param xQueueSet The queue set on which the task will (potentially) block.
N *
N * @param xTicksToWait The maximum time, in ticks, that the calling task will
N * remain in the Blocked state (with other tasks executing) to wait for a member
N * of the queue set to be ready for a successful queue read or semaphore take
N * operation.
N *
N * @return xQueueSelectFromSet() will return the handle of a queue (cast to
N * a QueueSetMemberHandle_t type) contained in the queue set that contains data,
N * or the handle of a semaphore (cast to a QueueSetMemberHandle_t type) contained
N * in the queue set that is available, or NULL if no such queue or semaphore
N * exists before before the specified block time expires.
N */
NQueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet, const TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
XQueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet, const TickType_t xTicksToWait ) ;
N
N/*
N * A version of xQueueSelectFromSet() that can be used from an ISR.
N */
NQueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet ) PRIVILEGED_FUNCTION;
XQueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet ) ;
N
N/* Not public API functions. */
Nvoid vQueueWaitForMessageRestricted( QueueHandle_t xQueue, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) PRIVILEGED_FUNCTION;
Xvoid vQueueWaitForMessageRestricted( QueueHandle_t xQueue, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) ;
NBaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue ) ;
Nvoid vQueueSetQueueNumber( QueueHandle_t xQueue, UBaseType_t uxQueueNumber ) PRIVILEGED_FUNCTION;
Xvoid vQueueSetQueueNumber( QueueHandle_t xQueue, UBaseType_t uxQueueNumber ) ;
NUBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue ) ;
Nuint8_t ucQueueGetQueueType( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
Xuint8_t ucQueueGetQueueType( QueueHandle_t xQueue ) ;
N
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* QUEUE_H */
N
L 8 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N#include "semphr.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\semphr.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef SEMAPHORE_H
N#define SEMAPHORE_H
N
N#ifndef INC_FREERTOS_H
S	#error "include FreeRTOS.h" must appear in source files before "include semphr.h"
N#endif
N
N#include "queue.h"
N
Ntypedef QueueHandle_t SemaphoreHandle_t;
N
N#define semBINARY_SEMAPHORE_QUEUE_LENGTH	( ( uint8_t ) 1U )
N#define semSEMAPHORE_QUEUE_ITEM_LENGTH		( ( uint8_t ) 0U )
N#define semGIVE_BLOCK_TIME					( ( TickType_t ) 0U )
N
N
N/**
N * semphr. h
N * <pre>vSemaphoreCreateBinary( SemaphoreHandle_t xSemaphore )</pre>
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a binary semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * This old vSemaphoreCreateBinary() macro is now deprecated in favour of the
N * xSemaphoreCreateBinary() function.  Note that binary semaphores created using
N * the vSemaphoreCreateBinary() macro are created in a state such that the
N * first call to 'take' the semaphore would pass, whereas binary semaphores
N * created using xSemaphoreCreateBinary() are created in a state such that the
N * the semaphore must first be 'given' before it can be 'taken'.
N *
N * <i>Macro</i> that implements a semaphore by using the existing queue mechanism.
N * The queue length is 1 as this is a binary semaphore.  The data size is 0
N * as we don't want to actually store any data - we just want to know if the
N * queue is empty or full.
N *
N * This type of semaphore can be used for pure synchronisation between tasks or
N * between an interrupt and a task.  The semaphore need not be given back once
N * obtained, so one task/interrupt can continuously 'give' the semaphore while
N * another continuously 'takes' the semaphore.  For this reason this type of
N * semaphore does not use a priority inheritance mechanism.  For an alternative
N * that does use priority inheritance see xSemaphoreCreateMutex().
N *
N * @param xSemaphore Handle to the created semaphore.  Should be of type SemaphoreHandle_t.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to vSemaphoreCreateBinary ().
N    // This is a macro so pass the variable in directly.
N    vSemaphoreCreateBinary( xSemaphore );
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup vSemaphoreCreateBinary vSemaphoreCreateBinary
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define vSemaphoreCreateBinary( xSemaphore )																							\
N		{																																	\
N			( xSemaphore ) = xQueueGenericCreate( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_BINARY_SEMAPHORE );	\
N			if( ( xSemaphore ) != NULL )																									\
N			{																																\
N				( void ) xSemaphoreGive( ( xSemaphore ) );																					\
N			}																																\
N		}
X	#define vSemaphoreCreateBinary( xSemaphore )																									{																																				( xSemaphore ) = xQueueGenericCreate( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_BINARY_SEMAPHORE );				if( ( xSemaphore ) != NULL )																												{																																				( void ) xSemaphoreGive( ( xSemaphore ) );																								}																																		}
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateBinary( void )</pre>
N *
N * Creates a new binary semaphore instance, and returns a handle by which the
N * new semaphore can be referenced.
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a binary semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, binary semaphores use a block
N * of memory, in which the semaphore structure is stored.  If a binary semaphore
N * is created using xSemaphoreCreateBinary() then the required memory is
N * automatically dynamically allocated inside the xSemaphoreCreateBinary()
N * function.  (see http://www.freertos.org/a00111.html).  If a binary semaphore
N * is created using xSemaphoreCreateBinaryStatic() then the application writer
N * must provide the memory.  xSemaphoreCreateBinaryStatic() therefore allows a
N * binary semaphore to be created without using any dynamic memory allocation.
N *
N * The old vSemaphoreCreateBinary() macro is now deprecated in favour of this
N * xSemaphoreCreateBinary() function.  Note that binary semaphores created using
N * the vSemaphoreCreateBinary() macro are created in a state such that the
N * first call to 'take' the semaphore would pass, whereas binary semaphores
N * created using xSemaphoreCreateBinary() are created in a state such that the
N * the semaphore must first be 'given' before it can be 'taken'.
N *
N * This type of semaphore can be used for pure synchronisation between tasks or
N * between an interrupt and a task.  The semaphore need not be given back once
N * obtained, so one task/interrupt can continuously 'give' the semaphore while
N * another continuously 'takes' the semaphore.  For this reason this type of
N * semaphore does not use a priority inheritance mechanism.  For an alternative
N * that does use priority inheritance see xSemaphoreCreateMutex().
N *
N * @return Handle to the created semaphore, or NULL if the memory required to
N * hold the semaphore's data structures could not be allocated.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateBinary().
N    // This is a macro so pass the variable in directly.
N    xSemaphore = xSemaphoreCreateBinary();
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateBinary xSemaphoreCreateBinary
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xSemaphoreCreateBinary() xQueueGenericCreate( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_BINARY_SEMAPHORE )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateBinaryStatic( StaticSemaphore_t *pxSemaphoreBuffer )</pre>
N *
N * Creates a new binary semaphore instance, and returns a handle by which the
N * new semaphore can be referenced.
N *
N * NOTE: In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a binary semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, binary semaphores use a block
N * of memory, in which the semaphore structure is stored.  If a binary semaphore
N * is created using xSemaphoreCreateBinary() then the required memory is
N * automatically dynamically allocated inside the xSemaphoreCreateBinary()
N * function.  (see http://www.freertos.org/a00111.html).  If a binary semaphore
N * is created using xSemaphoreCreateBinaryStatic() then the application writer
N * must provide the memory.  xSemaphoreCreateBinaryStatic() therefore allows a
N * binary semaphore to be created without using any dynamic memory allocation.
N *
N * This type of semaphore can be used for pure synchronisation between tasks or
N * between an interrupt and a task.  The semaphore need not be given back once
N * obtained, so one task/interrupt can continuously 'give' the semaphore while
N * another continuously 'takes' the semaphore.  For this reason this type of
N * semaphore does not use a priority inheritance mechanism.  For an alternative
N * that does use priority inheritance see xSemaphoreCreateMutex().
N *
N * @param pxSemaphoreBuffer Must point to a variable of type StaticSemaphore_t,
N * which will then be used to hold the semaphore's data structure, removing the
N * need for the memory to be allocated dynamically.
N *
N * @return If the semaphore is created then a handle to the created semaphore is
N * returned.  If pxSemaphoreBuffer is NULL then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N StaticSemaphore_t xSemaphoreBuffer;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateBinary().
N    // The semaphore's data structures will be placed in the xSemaphoreBuffer
N    // variable, the address of which is passed into the function.  The
N    // function's parameter is not NULL, so the function will not attempt any
N    // dynamic memory allocation, and therefore the function will not return
N    // return NULL.
N    xSemaphore = xSemaphoreCreateBinary( &xSemaphoreBuffer );
N
N    // Rest of task code goes here.
N }
N </pre>
N * \defgroup xSemaphoreCreateBinaryStatic xSemaphoreCreateBinaryStatic
N * \ingroup Semaphores
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreCreateBinaryStatic( pxStaticSemaphore ) xQueueGenericCreateStatic( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, NULL, pxStaticSemaphore, queueQUEUE_TYPE_BINARY_SEMAPHORE )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * semphr. h
N * <pre>xSemaphoreTake(
N *                   SemaphoreHandle_t xSemaphore,
N *                   TickType_t xBlockTime
N *               )</pre>
N *
N * <i>Macro</i> to obtain a semaphore.  The semaphore must have previously been
N * created with a call to xSemaphoreCreateBinary(), xSemaphoreCreateMutex() or
N * xSemaphoreCreateCounting().
N *
N * @param xSemaphore A handle to the semaphore being taken - obtained when
N * the semaphore was created.
N *
N * @param xBlockTime The time in ticks to wait for the semaphore to become
N * available.  The macro portTICK_PERIOD_MS can be used to convert this to a
N * real time.  A block time of zero can be used to poll the semaphore.  A block
N * time of portMAX_DELAY can be used to block indefinitely (provided
N * INCLUDE_vTaskSuspend is set to 1 in FreeRTOSConfig.h).
N *
N * @return pdTRUE if the semaphore was obtained.  pdFALSE
N * if xBlockTime expired without the semaphore becoming available.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N // A task that creates a semaphore.
N void vATask( void * pvParameters )
N {
N    // Create the semaphore to guard a shared resource.
N    xSemaphore = xSemaphoreCreateBinary();
N }
N
N // A task that uses the semaphore.
N void vAnotherTask( void * pvParameters )
N {
N    // ... Do other things.
N
N    if( xSemaphore != NULL )
N    {
N        // See if we can obtain the semaphore.  If the semaphore is not available
N        // wait 10 ticks to see if it becomes free.
N        if( xSemaphoreTake( xSemaphore, ( TickType_t ) 10 ) == pdTRUE )
N        {
N            // We were able to obtain the semaphore and can now access the
N            // shared resource.
N
N            // ...
N
N            // We have finished accessing the shared resource.  Release the
N            // semaphore.
N            xSemaphoreGive( xSemaphore );
N        }
N        else
N        {
N            // We could not obtain the semaphore and can therefore not access
N            // the shared resource safely.
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreTake xSemaphoreTake
N * \ingroup Semaphores
N */
N#define xSemaphoreTake( xSemaphore, xBlockTime )		xQueueGenericReceive( ( QueueHandle_t ) ( xSemaphore ), NULL, ( xBlockTime ), pdFALSE )
N
N/**
N * semphr. h
N * xSemaphoreTakeRecursive(
N *                          SemaphoreHandle_t xMutex,
N *                          TickType_t xBlockTime
N *                        )
N *
N * <i>Macro</i> to recursively obtain, or 'take', a mutex type semaphore.
N * The mutex must have previously been created using a call to
N * xSemaphoreCreateRecursiveMutex();
N *
N * configUSE_RECURSIVE_MUTEXES must be set to 1 in FreeRTOSConfig.h for this
N * macro to be available.
N *
N * This macro must not be used on mutexes created using xSemaphoreCreateMutex().
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * @param xMutex A handle to the mutex being obtained.  This is the
N * handle returned by xSemaphoreCreateRecursiveMutex();
N *
N * @param xBlockTime The time in ticks to wait for the semaphore to become
N * available.  The macro portTICK_PERIOD_MS can be used to convert this to a
N * real time.  A block time of zero can be used to poll the semaphore.  If
N * the task already owns the semaphore then xSemaphoreTakeRecursive() will
N * return immediately no matter what the value of xBlockTime.
N *
N * @return pdTRUE if the semaphore was obtained.  pdFALSE if xBlockTime
N * expired without the semaphore becoming available.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xMutex = NULL;
N
N // A task that creates a mutex.
N void vATask( void * pvParameters )
N {
N    // Create the mutex to guard a shared resource.
N    xMutex = xSemaphoreCreateRecursiveMutex();
N }
N
N // A task that uses the mutex.
N void vAnotherTask( void * pvParameters )
N {
N    // ... Do other things.
N
N    if( xMutex != NULL )
N    {
N        // See if we can obtain the mutex.  If the mutex is not available
N        // wait 10 ticks to see if it becomes free.
N        if( xSemaphoreTakeRecursive( xSemaphore, ( TickType_t ) 10 ) == pdTRUE )
N        {
N            // We were able to obtain the mutex and can now access the
N            // shared resource.
N
N            // ...
N            // For some reason due to the nature of the code further calls to
N			// xSemaphoreTakeRecursive() are made on the same mutex.  In real
N			// code these would not be just sequential calls as this would make
N			// no sense.  Instead the calls are likely to be buried inside
N			// a more complex call structure.
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N
N            // The mutex has now been 'taken' three times, so will not be
N			// available to another task until it has also been given back
N			// three times.  Again it is unlikely that real code would have
N			// these calls sequentially, but instead buried in a more complex
N			// call structure.  This is just for illustrative purposes.
N            xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N
N			// Now the mutex can be taken by other tasks.
N        }
N        else
N        {
N            // We could not obtain the mutex and can therefore not access
N            // the shared resource safely.
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreTakeRecursive xSemaphoreTakeRecursive
N * \ingroup Semaphores
N */
N#if( configUSE_RECURSIVE_MUTEXES == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreTakeRecursive( xMutex, xBlockTime )	xQueueTakeMutexRecursive( ( xMutex ), ( xBlockTime ) )
N#endif
N
N/**
N * semphr. h
N * <pre>xSemaphoreGive( SemaphoreHandle_t xSemaphore )</pre>
N *
N * <i>Macro</i> to release a semaphore.  The semaphore must have previously been
N * created with a call to xSemaphoreCreateBinary(), xSemaphoreCreateMutex() or
N * xSemaphoreCreateCounting(). and obtained using sSemaphoreTake().
N *
N * This macro must not be used from an ISR.  See xSemaphoreGiveFromISR () for
N * an alternative which can be used from an ISR.
N *
N * This macro must also not be used on semaphores created using
N * xSemaphoreCreateRecursiveMutex().
N *
N * @param xSemaphore A handle to the semaphore being released.  This is the
N * handle returned when the semaphore was created.
N *
N * @return pdTRUE if the semaphore was released.  pdFALSE if an error occurred.
N * Semaphores are implemented using queues.  An error can occur if there is
N * no space on the queue to post a message - indicating that the
N * semaphore was not first obtained correctly.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N void vATask( void * pvParameters )
N {
N    // Create the semaphore to guard a shared resource.
N    xSemaphore = vSemaphoreCreateBinary();
N
N    if( xSemaphore != NULL )
N    {
N        if( xSemaphoreGive( xSemaphore ) != pdTRUE )
N        {
N            // We would expect this call to fail because we cannot give
N            // a semaphore without first "taking" it!
N        }
N
N        // Obtain the semaphore - don't block if the semaphore is not
N        // immediately available.
N        if( xSemaphoreTake( xSemaphore, ( TickType_t ) 0 ) )
N        {
N            // We now have the semaphore and can access the shared resource.
N
N            // ...
N
N            // We have finished accessing the shared resource so can free the
N            // semaphore.
N            if( xSemaphoreGive( xSemaphore ) != pdTRUE )
N            {
N                // We would not expect this call to fail because we must have
N                // obtained the semaphore to get here.
N            }
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreGive xSemaphoreGive
N * \ingroup Semaphores
N */
N#define xSemaphoreGive( xSemaphore )		xQueueGenericSend( ( QueueHandle_t ) ( xSemaphore ), NULL, semGIVE_BLOCK_TIME, queueSEND_TO_BACK )
N
N/**
N * semphr. h
N * <pre>xSemaphoreGiveRecursive( SemaphoreHandle_t xMutex )</pre>
N *
N * <i>Macro</i> to recursively release, or 'give', a mutex type semaphore.
N * The mutex must have previously been created using a call to
N * xSemaphoreCreateRecursiveMutex();
N *
N * configUSE_RECURSIVE_MUTEXES must be set to 1 in FreeRTOSConfig.h for this
N * macro to be available.
N *
N * This macro must not be used on mutexes created using xSemaphoreCreateMutex().
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * @param xMutex A handle to the mutex being released, or 'given'.  This is the
N * handle returned by xSemaphoreCreateMutex();
N *
N * @return pdTRUE if the semaphore was given.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xMutex = NULL;
N
N // A task that creates a mutex.
N void vATask( void * pvParameters )
N {
N    // Create the mutex to guard a shared resource.
N    xMutex = xSemaphoreCreateRecursiveMutex();
N }
N
N // A task that uses the mutex.
N void vAnotherTask( void * pvParameters )
N {
N    // ... Do other things.
N
N    if( xMutex != NULL )
N    {
N        // See if we can obtain the mutex.  If the mutex is not available
N        // wait 10 ticks to see if it becomes free.
N        if( xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 ) == pdTRUE )
N        {
N            // We were able to obtain the mutex and can now access the
N            // shared resource.
N
N            // ...
N            // For some reason due to the nature of the code further calls to
N			// xSemaphoreTakeRecursive() are made on the same mutex.  In real
N			// code these would not be just sequential calls as this would make
N			// no sense.  Instead the calls are likely to be buried inside
N			// a more complex call structure.
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N
N            // The mutex has now been 'taken' three times, so will not be
N			// available to another task until it has also been given back
N			// three times.  Again it is unlikely that real code would have
N			// these calls sequentially, it would be more likely that the calls
N			// to xSemaphoreGiveRecursive() would be called as a call stack
N			// unwound.  This is just for demonstrative purposes.
N            xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N
N			// Now the mutex can be taken by other tasks.
N        }
N        else
N        {
N            // We could not obtain the mutex and can therefore not access
N            // the shared resource safely.
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreGiveRecursive xSemaphoreGiveRecursive
N * \ingroup Semaphores
N */
N#if( configUSE_RECURSIVE_MUTEXES == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreGiveRecursive( xMutex )	xQueueGiveMutexRecursive( ( xMutex ) )
N#endif
N
N/**
N * semphr. h
N * <pre>
N xSemaphoreGiveFromISR(
N                          SemaphoreHandle_t xSemaphore,
N                          BaseType_t *pxHigherPriorityTaskWoken
N                      )</pre>
N *
N * <i>Macro</i> to  release a semaphore.  The semaphore must have previously been
N * created with a call to xSemaphoreCreateBinary() or xSemaphoreCreateCounting().
N *
N * Mutex type semaphores (those created using a call to xSemaphoreCreateMutex())
N * must not be used with this macro.
N *
N * This macro can be used from an ISR.
N *
N * @param xSemaphore A handle to the semaphore being released.  This is the
N * handle returned when the semaphore was created.
N *
N * @param pxHigherPriorityTaskWoken xSemaphoreGiveFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if giving the semaphore caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xSemaphoreGiveFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the semaphore was successfully given, otherwise errQUEUE_FULL.
N *
N * Example usage:
N <pre>
N \#define LONG_TIME 0xffff
N \#define TICKS_TO_WAIT	10
N SemaphoreHandle_t xSemaphore = NULL;
N
N // Repetitive task.
N void vATask( void * pvParameters )
N {
N    for( ;; )
N    {
N        // We want this task to run every 10 ticks of a timer.  The semaphore
N        // was created before this task was started.
N
N        // Block waiting for the semaphore to become available.
N        if( xSemaphoreTake( xSemaphore, LONG_TIME ) == pdTRUE )
N        {
N            // It is time to execute.
N
N            // ...
N
N            // We have finished our task.  Return to the top of the loop where
N            // we will block on the semaphore until it is time to execute
N            // again.  Note when using the semaphore for synchronisation with an
N			// ISR in this manner there is no need to 'give' the semaphore back.
N        }
N    }
N }
N
N // Timer ISR
N void vTimerISR( void * pvParameters )
N {
N static uint8_t ucLocalTickCount = 0;
N static BaseType_t xHigherPriorityTaskWoken;
N
N    // A timer tick has occurred.
N
N    // ... Do other time functions.
N
N    // Is it time for vATask () to run?
N	xHigherPriorityTaskWoken = pdFALSE;
N    ucLocalTickCount++;
N    if( ucLocalTickCount >= TICKS_TO_WAIT )
N    {
N        // Unblock the task by releasing the semaphore.
N        xSemaphoreGiveFromISR( xSemaphore, &xHigherPriorityTaskWoken );
N
N        // Reset the count so we release the semaphore again in 10 ticks time.
N        ucLocalTickCount = 0;
N    }
N
N    if( xHigherPriorityTaskWoken != pdFALSE )
N    {
N        // We can force a context switch here.  Context switching from an
N        // ISR uses port specific syntax.  Check the demo task for your port
N        // to find the syntax required.
N    }
N }
N </pre>
N * \defgroup xSemaphoreGiveFromISR xSemaphoreGiveFromISR
N * \ingroup Semaphores
N */
N#define xSemaphoreGiveFromISR( xSemaphore, pxHigherPriorityTaskWoken )	xQueueGiveFromISR( ( QueueHandle_t ) ( xSemaphore ), ( pxHigherPriorityTaskWoken ) )
N
N/**
N * semphr. h
N * <pre>
N xSemaphoreTakeFromISR(
N                          SemaphoreHandle_t xSemaphore,
N                          BaseType_t *pxHigherPriorityTaskWoken
N                      )</pre>
N *
N * <i>Macro</i> to  take a semaphore from an ISR.  The semaphore must have
N * previously been created with a call to xSemaphoreCreateBinary() or
N * xSemaphoreCreateCounting().
N *
N * Mutex type semaphores (those created using a call to xSemaphoreCreateMutex())
N * must not be used with this macro.
N *
N * This macro can be used from an ISR, however taking a semaphore from an ISR
N * is not a common operation.  It is likely to only be useful when taking a
N * counting semaphore when an interrupt is obtaining an object from a resource
N * pool (when the semaphore count indicates the number of resources available).
N *
N * @param xSemaphore A handle to the semaphore being taken.  This is the
N * handle returned when the semaphore was created.
N *
N * @param pxHigherPriorityTaskWoken xSemaphoreTakeFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if taking the semaphore caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xSemaphoreTakeFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the semaphore was successfully taken, otherwise
N * pdFALSE
N */
N#define xSemaphoreTakeFromISR( xSemaphore, pxHigherPriorityTaskWoken )	xQueueReceiveFromISR( ( QueueHandle_t ) ( xSemaphore ), NULL, ( pxHigherPriorityTaskWoken ) )
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateMutex( void )</pre>
N *
N * Creates a new mutex type semaphore instance, and returns a handle by which
N * the new mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, mutex semaphores use a block
N * of memory, in which the mutex structure is stored.  If a mutex is created
N * using xSemaphoreCreateMutex() then the required memory is automatically
N * dynamically allocated inside the xSemaphoreCreateMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a mutex is created using
N * xSemaphoreCreateMutexStatic() then the application writer must provided the
N * memory.  xSemaphoreCreateMutexStatic() therefore allows a mutex to be created
N * without using any dynamic memory allocation.
N *
N * Mutexes created using this function can be accessed using the xSemaphoreTake()
N * and xSemaphoreGive() macros.  The xSemaphoreTakeRecursive() and
N * xSemaphoreGiveRecursive() macros must not be used.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @return If the mutex was successfully created then a handle to the created
N * semaphore is returned.  If there was not enough heap to allocate the mutex
N * data structures then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateMutex().
N    // This is a macro so pass the variable in directly.
N    xSemaphore = xSemaphoreCreateMutex();
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateMutex xSemaphoreCreateMutex
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xSemaphoreCreateMutex() xQueueCreateMutex( queueQUEUE_TYPE_MUTEX )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateMutexStatic( StaticSemaphore_t *pxMutexBuffer )</pre>
N *
N * Creates a new mutex type semaphore instance, and returns a handle by which
N * the new mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, mutex semaphores use a block
N * of memory, in which the mutex structure is stored.  If a mutex is created
N * using xSemaphoreCreateMutex() then the required memory is automatically
N * dynamically allocated inside the xSemaphoreCreateMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a mutex is created using
N * xSemaphoreCreateMutexStatic() then the application writer must provided the
N * memory.  xSemaphoreCreateMutexStatic() therefore allows a mutex to be created
N * without using any dynamic memory allocation.
N *
N * Mutexes created using this function can be accessed using the xSemaphoreTake()
N * and xSemaphoreGive() macros.  The xSemaphoreTakeRecursive() and
N * xSemaphoreGiveRecursive() macros must not be used.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @param pxMutexBuffer Must point to a variable of type StaticSemaphore_t,
N * which will be used to hold the mutex's data structure, removing the need for
N * the memory to be allocated dynamically.
N *
N * @return If the mutex was successfully created then a handle to the created
N * mutex is returned.  If pxMutexBuffer was NULL then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N StaticSemaphore_t xMutexBuffer;
N
N void vATask( void * pvParameters )
N {
N    // A mutex cannot be used before it has been created.  xMutexBuffer is
N    // into xSemaphoreCreateMutexStatic() so no dynamic memory allocation is
N    // attempted.
N    xSemaphore = xSemaphoreCreateMutexStatic( &xMutexBuffer );
N
N    // As no dynamic memory allocation was performed, xSemaphore cannot be NULL,
N    // so there is no need to check it.
N }
N </pre>
N * \defgroup xSemaphoreCreateMutexStatic xSemaphoreCreateMutexStatic
N * \ingroup Semaphores
N */
N #if( configSUPPORT_STATIC_ALLOCATION == 1 )
X #if( 0 == 1 )
S	#define xSemaphoreCreateMutexStatic( pxMutexBuffer ) xQueueCreateMutexStatic( queueQUEUE_TYPE_MUTEX, ( pxMutexBuffer ) )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateRecursiveMutex( void )</pre>
N *
N * Creates a new recursive mutex type semaphore instance, and returns a handle
N * by which the new recursive mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, recursive mutexs use a block
N * of memory, in which the mutex structure is stored.  If a recursive mutex is
N * created using xSemaphoreCreateRecursiveMutex() then the required memory is
N * automatically dynamically allocated inside the
N * xSemaphoreCreateRecursiveMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a recursive mutex is created using
N * xSemaphoreCreateRecursiveMutexStatic() then the application writer must
N * provide the memory that will get used by the mutex.
N * xSemaphoreCreateRecursiveMutexStatic() therefore allows a recursive mutex to
N * be created without using any dynamic memory allocation.
N *
N * Mutexes created using this macro can be accessed using the
N * xSemaphoreTakeRecursive() and xSemaphoreGiveRecursive() macros.  The
N * xSemaphoreTake() and xSemaphoreGive() macros must not be used.
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @return xSemaphore Handle to the created mutex semaphore.  Should be of type
N * SemaphoreHandle_t.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateMutex().
N    // This is a macro so pass the variable in directly.
N    xSemaphore = xSemaphoreCreateRecursiveMutex();
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateRecursiveMutex xSemaphoreCreateRecursiveMutex
N * \ingroup Semaphores
N */
N#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configUSE_RECURSIVE_MUTEXES == 1 ) )
X#if( ( 1 == 1 ) && ( 0 == 1 ) )
S	#define xSemaphoreCreateRecursiveMutex() xQueueCreateMutex( queueQUEUE_TYPE_RECURSIVE_MUTEX )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateRecursiveMutexStatic( StaticSemaphore_t *pxMutexBuffer )</pre>
N *
N * Creates a new recursive mutex type semaphore instance, and returns a handle
N * by which the new recursive mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, recursive mutexs use a block
N * of memory, in which the mutex structure is stored.  If a recursive mutex is
N * created using xSemaphoreCreateRecursiveMutex() then the required memory is
N * automatically dynamically allocated inside the
N * xSemaphoreCreateRecursiveMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a recursive mutex is created using
N * xSemaphoreCreateRecursiveMutexStatic() then the application writer must
N * provide the memory that will get used by the mutex.
N * xSemaphoreCreateRecursiveMutexStatic() therefore allows a recursive mutex to
N * be created without using any dynamic memory allocation.
N *
N * Mutexes created using this macro can be accessed using the
N * xSemaphoreTakeRecursive() and xSemaphoreGiveRecursive() macros.  The
N * xSemaphoreTake() and xSemaphoreGive() macros must not be used.
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @param pxMutexBuffer Must point to a variable of type StaticSemaphore_t,
N * which will then be used to hold the recursive mutex's data structure,
N * removing the need for the memory to be allocated dynamically.
N *
N * @return If the recursive mutex was successfully created then a handle to the
N * created recursive mutex is returned.  If pxMutexBuffer was NULL then NULL is
N * returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N StaticSemaphore_t xMutexBuffer;
N
N void vATask( void * pvParameters )
N {
N    // A recursive semaphore cannot be used before it is created.  Here a
N    // recursive mutex is created using xSemaphoreCreateRecursiveMutexStatic().
N    // The address of xMutexBuffer is passed into the function, and will hold
N    // the mutexes data structures - so no dynamic memory allocation will be
N    // attempted.
N    xSemaphore = xSemaphoreCreateRecursiveMutexStatic( &xMutexBuffer );
N
N    // As no dynamic memory allocation was performed, xSemaphore cannot be NULL,
N    // so there is no need to check it.
N }
N </pre>
N * \defgroup xSemaphoreCreateRecursiveMutexStatic xSemaphoreCreateRecursiveMutexStatic
N * \ingroup Semaphores
N */
N#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configUSE_RECURSIVE_MUTEXES == 1 ) )
X#if( ( 0 == 1 ) && ( 0 == 1 ) )
S	#define xSemaphoreCreateRecursiveMutexStatic( pxStaticSemaphore ) xQueueCreateMutexStatic( queueQUEUE_TYPE_RECURSIVE_MUTEX, pxStaticSemaphore )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateCounting( UBaseType_t uxMaxCount, UBaseType_t uxInitialCount )</pre>
N *
N * Creates a new counting semaphore instance, and returns a handle by which the
N * new counting semaphore can be referenced.
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a counting semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, counting semaphores use a
N * block of memory, in which the counting semaphore structure is stored.  If a
N * counting semaphore is created using xSemaphoreCreateCounting() then the
N * required memory is automatically dynamically allocated inside the
N * xSemaphoreCreateCounting() function.  (see
N * http://www.freertos.org/a00111.html).  If a counting semaphore is created
N * using xSemaphoreCreateCountingStatic() then the application writer can
N * instead optionally provide the memory that will get used by the counting
N * semaphore.  xSemaphoreCreateCountingStatic() therefore allows a counting
N * semaphore to be created without using any dynamic memory allocation.
N *
N * Counting semaphores are typically used for two things:
N *
N * 1) Counting events.
N *
N *    In this usage scenario an event handler will 'give' a semaphore each time
N *    an event occurs (incrementing the semaphore count value), and a handler
N *    task will 'take' a semaphore each time it processes an event
N *    (decrementing the semaphore count value).  The count value is therefore
N *    the difference between the number of events that have occurred and the
N *    number that have been processed.  In this case it is desirable for the
N *    initial count value to be zero.
N *
N * 2) Resource management.
N *
N *    In this usage scenario the count value indicates the number of resources
N *    available.  To obtain control of a resource a task must first obtain a
N *    semaphore - decrementing the semaphore count value.  When the count value
N *    reaches zero there are no free resources.  When a task finishes with the
N *    resource it 'gives' the semaphore back - incrementing the semaphore count
N *    value.  In this case it is desirable for the initial count value to be
N *    equal to the maximum count value, indicating that all resources are free.
N *
N * @param uxMaxCount The maximum count value that can be reached.  When the
N *        semaphore reaches this value it can no longer be 'given'.
N *
N * @param uxInitialCount The count value assigned to the semaphore when it is
N *        created.
N *
N * @return Handle to the created semaphore.  Null if the semaphore could not be
N *         created.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N
N void vATask( void * pvParameters )
N {
N SemaphoreHandle_t xSemaphore = NULL;
N
N    // Semaphore cannot be used before a call to xSemaphoreCreateCounting().
N    // The max value to which the semaphore can count should be 10, and the
N    // initial value assigned to the count should be 0.
N    xSemaphore = xSemaphoreCreateCounting( 10, 0 );
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateCounting xSemaphoreCreateCounting
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xSemaphoreCreateCounting( uxMaxCount, uxInitialCount ) xQueueCreateCountingSemaphore( ( uxMaxCount ), ( uxInitialCount ) )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateCountingStatic( UBaseType_t uxMaxCount, UBaseType_t uxInitialCount, StaticSemaphore_t *pxSemaphoreBuffer )</pre>
N *
N * Creates a new counting semaphore instance, and returns a handle by which the
N * new counting semaphore can be referenced.
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a counting semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, counting semaphores use a
N * block of memory, in which the counting semaphore structure is stored.  If a
N * counting semaphore is created using xSemaphoreCreateCounting() then the
N * required memory is automatically dynamically allocated inside the
N * xSemaphoreCreateCounting() function.  (see
N * http://www.freertos.org/a00111.html).  If a counting semaphore is created
N * using xSemaphoreCreateCountingStatic() then the application writer must
N * provide the memory.  xSemaphoreCreateCountingStatic() therefore allows a
N * counting semaphore to be created without using any dynamic memory allocation.
N *
N * Counting semaphores are typically used for two things:
N *
N * 1) Counting events.
N *
N *    In this usage scenario an event handler will 'give' a semaphore each time
N *    an event occurs (incrementing the semaphore count value), and a handler
N *    task will 'take' a semaphore each time it processes an event
N *    (decrementing the semaphore count value).  The count value is therefore
N *    the difference between the number of events that have occurred and the
N *    number that have been processed.  In this case it is desirable for the
N *    initial count value to be zero.
N *
N * 2) Resource management.
N *
N *    In this usage scenario the count value indicates the number of resources
N *    available.  To obtain control of a resource a task must first obtain a
N *    semaphore - decrementing the semaphore count value.  When the count value
N *    reaches zero there are no free resources.  When a task finishes with the
N *    resource it 'gives' the semaphore back - incrementing the semaphore count
N *    value.  In this case it is desirable for the initial count value to be
N *    equal to the maximum count value, indicating that all resources are free.
N *
N * @param uxMaxCount The maximum count value that can be reached.  When the
N *        semaphore reaches this value it can no longer be 'given'.
N *
N * @param uxInitialCount The count value assigned to the semaphore when it is
N *        created.
N *
N * @param pxSemaphoreBuffer Must point to a variable of type StaticSemaphore_t,
N * which will then be used to hold the semaphore's data structure, removing the
N * need for the memory to be allocated dynamically.
N *
N * @return If the counting semaphore was successfully created then a handle to
N * the created counting semaphore is returned.  If pxSemaphoreBuffer was NULL
N * then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N StaticSemaphore_t xSemaphoreBuffer;
N
N void vATask( void * pvParameters )
N {
N SemaphoreHandle_t xSemaphore = NULL;
N
N    // Counting semaphore cannot be used before they have been created.  Create
N    // a counting semaphore using xSemaphoreCreateCountingStatic().  The max
N    // value to which the semaphore can count is 10, and the initial value
N    // assigned to the count will be 0.  The address of xSemaphoreBuffer is
N    // passed in and will be used to hold the semaphore structure, so no dynamic
N    // memory allocation will be used.
N    xSemaphore = xSemaphoreCreateCounting( 10, 0, &xSemaphoreBuffer );
N
N    // No memory allocation was attempted so xSemaphore cannot be NULL, so there
N    // is no need to check its value.
N }
N </pre>
N * \defgroup xSemaphoreCreateCountingStatic xSemaphoreCreateCountingStatic
N * \ingroup Semaphores
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreCreateCountingStatic( uxMaxCount, uxInitialCount, pxSemaphoreBuffer ) xQueueCreateCountingSemaphoreStatic( ( uxMaxCount ), ( uxInitialCount ), ( pxSemaphoreBuffer ) )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * semphr. h
N * <pre>void vSemaphoreDelete( SemaphoreHandle_t xSemaphore );</pre>
N *
N * Delete a semaphore.  This function must be used with care.  For example,
N * do not delete a mutex type semaphore if the mutex is held by a task.
N *
N * @param xSemaphore A handle to the semaphore to be deleted.
N *
N * \defgroup vSemaphoreDelete vSemaphoreDelete
N * \ingroup Semaphores
N */
N#define vSemaphoreDelete( xSemaphore ) vQueueDelete( ( QueueHandle_t ) ( xSemaphore ) )
N
N/**
N * semphr.h
N * <pre>TaskHandle_t xSemaphoreGetMutexHolder( SemaphoreHandle_t xMutex );</pre>
N *
N * If xMutex is indeed a mutex type semaphore, return the current mutex holder.
N * If xMutex is not a mutex type semaphore, or the mutex is available (not held
N * by a task), return NULL.
N *
N * Note: This is a good way of determining if the calling task is the mutex
N * holder, but not a good way of determining the identity of the mutex holder as
N * the holder may change between the function exiting and the returned value
N * being tested.
N */
N#define xSemaphoreGetMutexHolder( xSemaphore ) xQueueGetMutexHolder( ( xSemaphore ) )
N
N/**
N * semphr.h
N * <pre>TaskHandle_t xSemaphoreGetMutexHolderFromISR( SemaphoreHandle_t xMutex );</pre>
N *
N * If xMutex is indeed a mutex type semaphore, return the current mutex holder.
N * If xMutex is not a mutex type semaphore, or the mutex is available (not held
N * by a task), return NULL.
N *
N */
N#define xSemaphoreGetMutexHolderFromISR( xSemaphore ) xQueueGetMutexHolderFromISR( ( xSemaphore ) )
N
N/**
N * semphr.h
N * <pre>UBaseType_t uxSemaphoreGetCount( SemaphoreHandle_t xSemaphore );</pre>
N *
N * If the semaphore is a counting semaphore then uxSemaphoreGetCount() returns
N * its current count value.  If the semaphore is a binary semaphore then
N * uxSemaphoreGetCount() returns 1 if the semaphore is available, and 0 if the
N * semaphore is not available.
N *
N */
N#define uxSemaphoreGetCount( xSemaphore ) uxQueueMessagesWaiting( ( QueueHandle_t ) ( xSemaphore ) )
N
N#endif /* SEMAPHORE_H */
N
N
L 9 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N
N#define ndelay(x)	udelay(1)
N
Nextern void sysprintf(char *pcStr,...);
N#define printk	sysprintf
N
N#define KERN_EMERG
N#define KERN_ALERT
N#define KERN_CRIT
N#define KERN_ERR
N#define KERN_WARNING
N#define KERN_NOTICE
N#define KERN_INFO
N#define KERN_DEBUG
N
N#define kmalloc(size, flags)	pvPortMalloc(size)//malloc(size)
N//#define kzalloc(size, flags)	calloc(size, 1)
N#define vmalloc(size)		pvPortMalloc(size)//malloc(size)
N#define kfree(ptr)		vPortFree(ptr)//free(ptr)
N#define vfree(ptr)		vPortFree(ptr)//free(ptr)
N
N#define DECLARE_WAITQUEUE(...)	do { } while (0)
N#define add_wait_queue(...)	do { } while (0)
N#define remove_wait_queue(...)	do { } while (0)
N
N#define KERNEL_VERSION(a,b,c)	(((a) << 16) + ((b) << 8) + (c))
N
N/*
N * ..and if you can't take the strict
N * types, you can specify one yourself.
N *
N * Or not use min/max at all, of course.
N */
N
N#define min_t(type,x,y) ((type)x < (type)y ? (type) x: (type)y)
N#define max_t(type,x,y) ((type)x > (type)y ? (type) x: (type)y)
N
N#if 0
S#define min_t(type,x,y) \
S	({ type __x = (x); type __y = (y); __x < __y ? __x: __y; })
X#define min_t(type,x,y) 	({ type __x = (x); type __y = (y); __x < __y ? __x: __y; })
S#define max_t(type,x,y) \
S	({ type __x = (x); type __y = (y); __x > __y ? __x: __y; })
X#define max_t(type,x,y) 	({ type __x = (x); type __y = (y); __x > __y ? __x: __y; })
N#endif
N    
N#ifndef BUG
N#define BUG() do { \
N	sysprintf("U-Boot BUG at %s:%d!\n", __FILE__, __LINE__); \
N} while (0)
X#define BUG() do { 	sysprintf("U-Boot BUG at %s:%d!\n", __FILE__, __LINE__); } while (0)
N
N#define BUG_ON(condition) do { if (condition) BUG(); } while(0)
N#endif /* BUG */
N
N#define WARN_ON(x) if (x) {sysprintf("WARNING in %s line %d\n" \
N				  , __FILE__, __LINE__); }
X#define WARN_ON(x) if (x) {sysprintf("WARNING in %s line %d\n" 				  , __FILE__, __LINE__); }
N
N#define PAGE_SIZE	4096
N#endif
L 42 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "linux\mtd.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd.h" 1
N/*
N * Copyright (C) 1999-2003 David Woodhouse <dwmw2@infradead.org> et al.
N *
N * Released under GPL
N */
N
N#ifndef __MTD_MTD_H__
N#define __MTD_MTD_H__
N
N#include "linux\types.h"
N#include "div64.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\div64.h" 1
N#ifndef _ASM_GENERIC_DIV64_H
N#define _ASM_GENERIC_DIV64_H
N/*
N * Copyright (C) 2003 Bernardo Innocenti <bernie@develer.com>
N * Based on former asm-ppc/div64.h and asm-m68knommu/div64.h
N *
N * The semantics of do_div() are:
N *
N * uint32_t do_div(uint64_t *n, uint32_t base)
N * {
N *	uint32_t remainder = *n % base;
N *	*n = *n / base;
N *	return remainder;
N * }
N *
N * NOTE: macro parameter n is evaluated multiple times,
N *       beware of side effects!
N */
N#include <stdint.h>
N#include "linux\types.h"
N
Nextern uint32_t __div64_32(uint64_t *dividend, uint32_t divisor);
N
N/* The unnecessary pointer compare is there
N * to check for type safety (n must be 64bit)
N */
N#define do_div(n,base) (n = n/base)
N
N#if 0
S#define do_div(n,base) ({   \
S	uint32_t __base = (base);   \
S	uint32_t __rem; \
S	(void)(((typeof((n)) *)0) == ((uint64_t *)0));  \
S	if (((n) >> 32) == 0) { \
S		__rem = (uint32_t)(n) % __base; \
S		(n) = (uint32_t)(n) / __base;   \
S	} else  \
S		__rem = __div64_32(&(n), __base);   \
S	__rem;  \
S})
X#define do_div(n,base) ({   	uint32_t __base = (base);   	uint32_t __rem; 	(void)(((typeof((n)) *)0) == ((uint64_t *)0));  	if (((n) >> 32) == 0) { 		__rem = (uint32_t)(n) % __base; 		(n) = (uint32_t)(n) / __base;   	} else  		__rem = __div64_32(&(n), __base);   	__rem;  })
S
S/* Wrapper for do_div(). Doesn't modify dividend and returns
S * the result, not reminder.
S */
Sstatic __inline uint64_t lldiv(uint64_t dividend, uint32_t divisor)
S{
S	uint64_t __res = dividend;
S	do_div(__res, divisor);
S	return(__res);
S}
N#endif
N#endif /* _ASM_GENERIC_DIV64_H */
L 12 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd.h" 2
N#include "linux\mtd-abi.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd-abi.h" 1
N/*
N * $Id: mtd-abi.h,v 1.13 2005/11/07 11:14:56 gleixner Exp $
N *
N * Portions of MTD ABI definition which are shared by kernel and user space
N */
N
N#ifndef __MTD_ABI_H__
N#define __MTD_ABI_H__
N
N#include <stdint.h>
N
N#include <linux/compiler.h>
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/compiler.h" 1
N#ifndef __LINUX_COMPILER_H
N#define __LINUX_COMPILER_H
N
N#ifndef __ASSEMBLY__
N
N#ifdef __CHECKER__
S# define __user		__attribute__((noderef, address_space(1)))
S# define __kernel	/* default address space */
S# define __safe		__attribute__((safe))
S# define __force	__attribute__((force))
S# define __nocast	__attribute__((nocast))
S# define __iomem	__attribute__((noderef, address_space(2)))
S# define __acquires(x)	__attribute__((context(x,0,1)))
S# define __releases(x)	__attribute__((context(x,1,0)))
S# define __acquire(x)	__context__(x,1)
S# define __release(x)	__context__(x,-1)
S# define __cond_lock(x,c)	((c) ? ({ __acquire(x); 1; }) : 0)
Sextern void __chk_user_ptr(const volatile void __user *);
Sextern void __chk_io_ptr(const volatile void __iomem *);
N#else
N# define __user
N# define __kernel
N# define __safe
N# define __force
N# define __nocast
N# define __iomem
N# define __chk_user_ptr(x) (void)0
N# define __chk_io_ptr(x) (void)0
N# define __builtin_warning(x, y...) (1)
N# define __acquires(x)
N# define __releases(x)
N# define __acquire(x) (void)0
N# define __release(x) (void)0
N# define __cond_lock(x,c) (c)
N#endif
N
N#ifdef __KERNEL__
S
S#ifdef __GNUC__
S#include <linux/compiler-gcc.h>
S#endif
S
S#define notrace __attribute__((no_instrument_function))
S
S/* Intel compiler defines __GNUC__. So we will overwrite implementations
S * coming from above header files here
S */
S#ifdef __INTEL_COMPILER
S# include <linux/compiler-intel.h>
S#endif
S
S/*
S * Generic compiler-dependent macros required for kernel
S * build go below this comment. Actual compiler/compiler version
S * specific implementations come from the above header files
S */
S
Sstruct ftrace_branch_data {
S	const char *func;
S	const char *file;
S	unsigned line;
S	union {
S		struct {
S			unsigned long correct;
S			unsigned long incorrect;
S		};
S		struct {
S			unsigned long miss;
S			unsigned long hit;
S		};
S		unsigned long miss_hit[2];
S	};
S};
S
S/*
S * Note: DISABLE_BRANCH_PROFILING can be used by special lowlevel code
S * to disable branch tracing on a per file basis.
S */
S#if defined(CONFIG_TRACE_BRANCH_PROFILING) \
S    && !defined(DISABLE_BRANCH_PROFILING) && !defined(__CHECKER__)
X#if defined(CONFIG_TRACE_BRANCH_PROFILING)     && !defined(DISABLE_BRANCH_PROFILING) && !defined(__CHECKER__)
Svoid ftrace_likely_update(struct ftrace_branch_data *f, int val, int expect);
S
S#define likely_notrace(x)	__builtin_expect(!!(x), 1)
S#define unlikely_notrace(x)	__builtin_expect(!!(x), 0)
S
S#define __branch_check__(x, expect) ({					\
S			int ______r;					\
S			static struct ftrace_branch_data		\
S				__attribute__((__aligned__(4)))		\
S				__attribute__((section("_ftrace_annotated_branch"))) \
S				______f = {				\
S				.func = __func__,			\
S				.file = __FILE__,			\
S				.line = __LINE__,			\
S			};						\
S			______r = likely_notrace(x);			\
S			ftrace_likely_update(&______f, ______r, expect); \
S			______r;					\
S		})
X#define __branch_check__(x, expect) ({								int ______r;								static struct ftrace_branch_data						__attribute__((__aligned__(4)))						__attribute__((section("_ftrace_annotated_branch"))) 				______f = {								.func = __func__,							.file = __FILE__,							.line = __LINE__,						};									______r = likely_notrace(x);						ftrace_likely_update(&______f, ______r, expect); 			______r;							})
S
S/*
S * Using __builtin_constant_p(x) to ignore cases where the return
S * value is always the same.  This idea is taken from a similar patch
S * written by Daniel Walker.
S */
S# ifndef likely
S#  define likely(x)	(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 1))
S# endif
S# ifndef unlikely
S#  define unlikely(x)	(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 0))
S# endif
S
S#ifdef CONFIG_PROFILE_ALL_BRANCHES
S/*
S * "Define 'is'", Bill Clinton
S * "Define 'if'", Steven Rostedt
S */
S#define if(cond, ...) __trace_if( (cond , ## __VA_ARGS__) )
S#define __trace_if(cond) \
S	if (__builtin_constant_p((cond)) ? !!(cond) :			\
S	({								\
S		int ______r;						\
S		static struct ftrace_branch_data			\
S			__attribute__((__aligned__(4)))			\
S			__attribute__((section("_ftrace_branch")))	\
S			______f = {					\
S				.func = __func__,			\
S				.file = __FILE__,			\
S				.line = __LINE__,			\
S			};						\
S		______r = !!(cond);					\
S		______f.miss_hit[______r]++;					\
S		______r;						\
S	}))
X#define __trace_if(cond) 	if (__builtin_constant_p((cond)) ? !!(cond) :				({										int ______r;								static struct ftrace_branch_data						__attribute__((__aligned__(4)))						__attribute__((section("_ftrace_branch")))				______f = {									.func = __func__,							.file = __FILE__,							.line = __LINE__,						};								______r = !!(cond);							______f.miss_hit[______r]++;							______r;							}))
S#endif /* CONFIG_PROFILE_ALL_BRANCHES */
S
S#else
S# define likely(x)	__builtin_expect(!!(x), 1)
S# define unlikely(x)	__builtin_expect(!!(x), 0)
S#endif
S
S/* Optimization barrier */
S#ifndef barrier
S# define barrier() __memory_barrier()
S#endif
S
S/* Unreachable code */
S#ifndef unreachable
S# define unreachable() do { } while (1)
S#endif
S
S#ifndef RELOC_HIDE
S# define RELOC_HIDE(ptr, off)					\
S  ({ unsigned long __ptr;					\
S     __ptr = (unsigned long) (ptr);				\
S    (typeof(ptr)) (__ptr + (off)); })
X# define RELOC_HIDE(ptr, off)					  ({ unsigned long __ptr;					     __ptr = (unsigned long) (ptr);				    (typeof(ptr)) (__ptr + (off)); })
S#endif
S
N#endif /* __KERNEL__ */
N
N#endif /* __ASSEMBLY__ */
N
N#ifdef __KERNEL__
S/*
S * Allow us to mark functions as 'deprecated' and have gcc emit a nice
S * warning for each use, in hopes of speeding the functions removal.
S * Usage is:
S * 		int __deprecated foo(void)
S */
S#ifndef __deprecated
S# define __deprecated		/* unimplemented */
S#endif
S
S#ifdef MODULE
S#define __deprecated_for_modules __deprecated
S#else
S#define __deprecated_for_modules
S#endif
S
S#ifndef __must_check
S#define __must_check
S#endif
S
S#ifndef CONFIG_ENABLE_MUST_CHECK
S#undef __must_check
S#define __must_check
S#endif
S#ifndef CONFIG_ENABLE_WARN_DEPRECATED
S#undef __deprecated
S#undef __deprecated_for_modules
S#define __deprecated
S#define __deprecated_for_modules
S#endif
S
S/*
S * Allow us to avoid 'defined but not used' warnings on functions and data,
S * as well as force them to be emitted to the assembly file.
S *
S * As of gcc 3.4, static functions that are not marked with attribute((used))
S * may be elided from the assembly file.  As of gcc 3.4, static data not so
S * marked will not be elided, but this may change in a future gcc version.
S *
S * NOTE: Because distributions shipped with a backported unit-at-a-time
S * compiler in gcc 3.3, we must define __used to be __attribute__((used))
S * for gcc >=3.3 instead of 3.4.
S *
S * In prior versions of gcc, such functions and data would be emitted, but
S * would be warned about except with attribute((unused)).
S *
S * Mark functions that are referenced only in inline assembly as __used so
S * the code is emitted even though it appears to be unreferenced.
S */
S#ifndef __used
S# define __used			/* unimplemented */
S#endif
S
S#ifndef __maybe_unused
S# define __maybe_unused		/* unimplemented */
S#endif
S
S#ifndef __always_unused
S# define __always_unused	/* unimplemented */
S#endif
S
S#ifndef noinline
S#define noinline
S#endif
S
S/*
S * Rather then using noinline to prevent stack consumption, use
S * noinline_for_stack instead.  For documentaiton reasons.
S */
S#define noinline_for_stack noinline
S
S#ifndef __always_inline
S#define __always_inline inline
S#endif
S
N#endif /* __KERNEL__ */
N
N/*
N * From the GCC manual:
N *
N * Many functions do not examine any values except their arguments,
N * and have no effects except the return value.  Basically this is
N * just slightly more strict class than the `pure' attribute above,
N * since function is not allowed to read global memory.
N *
N * Note that a function that has pointer arguments and examines the
N * data pointed to must _not_ be declared `const'.  Likewise, a
N * function that calls a non-`const' function usually must not be
N * `const'.  It does not make sense for a `const' function to return
N * `void'.
N */
N#ifndef __attribute_const__
N# define __attribute_const__	/* unimplemented */
N#endif
N
N/*
N * Tell gcc if a function is cold. The compiler will assume any path
N * directly leading to the call is unlikely.
N */
N
N#ifndef __cold
N#define __cold
N#endif
N
N/* Simple shorthand for a section definition */
N#ifndef __section
N# define __section(S) __attribute__ ((__section__(#S)))
N#endif
N
N/* Are two types/vars the same type (ignoring qualifiers)? */
N#ifndef __same_type
N# define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
N#endif
N
N/* Compile time object size, -1 for unknown */
N#ifndef __compiletime_object_size
N# define __compiletime_object_size(obj) -1
N#endif
N#ifndef __compiletime_warning
N# define __compiletime_warning(message)
N#endif
N#ifndef __compiletime_error
N# define __compiletime_error(message)
N#endif
N
N/*
N * Prevent the compiler from merging or refetching accesses.  The compiler
N * is also forbidden from reordering successive instances of ACCESS_ONCE(),
N * but only when the compiler is aware of some particular ordering.  One way
N * to make the compiler aware of ordering is to put the two invocations of
N * ACCESS_ONCE() in different C statements.
N *
N * This macro does absolutely -nothing- to prevent the CPU from reordering,
N * merging, or refetching absolutely anything at any time.  Its main intended
N * use is to mediate communication between process-level code and irq/NMI
N * handlers, all running on the same CPU.
N */
N#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
N
N#endif /* __LINUX_COMPILER_H */
L 13 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd-abi.h" 2
N
Nstruct erase_info_user {
N	uint32_t start;
N	uint32_t length;
N};
N
Nstruct mtd_oob_buf {
N	uint32_t start;
N	uint32_t length;
N	unsigned char __user *ptr;
X	unsigned char  *ptr;
N};
N
N#define MTD_ABSENT		0
N#define MTD_RAM			1
N#define MTD_ROM			2
N#define MTD_NORFLASH		3
N#define MTD_NANDFLASH		4
N#define MTD_DATAFLASH		6
N#define MTD_UBIVOLUME		7
N
N#define MTD_WRITEABLE		0x400	/* Device is writeable */
N#define MTD_BIT_WRITEABLE	0x800	/* Single bits can be flipped */
N#define MTD_NO_ERASE		0x1000	/* No erase necessary */
N#define MTD_STUPID_LOCK		0x2000	/* Always locked after reset */
N
N/* Some common devices / combinations of capabilities */
N#define MTD_CAP_ROM		0
N#define MTD_CAP_RAM		(MTD_WRITEABLE | MTD_BIT_WRITEABLE | MTD_NO_ERASE)
N#define MTD_CAP_NORFLASH	(MTD_WRITEABLE | MTD_BIT_WRITEABLE)
N#define MTD_CAP_NANDFLASH	(MTD_WRITEABLE)
N
N/* ECC byte placement */
N#define MTD_NANDECC_OFF		0	/* Switch off ECC (Not recommended) */
N#define MTD_NANDECC_PLACE	1	/* Use the given placement in the structure (YAFFS1 legacy mode) */
N#define MTD_NANDECC_AUTOPLACE	2	/* Use the default placement scheme */
N#define MTD_NANDECC_PLACEONLY	3	/* Use the given placement in the structure (Do not store ecc result on read) */
N#define MTD_NANDECC_AUTOPL_USR	4	/* Use the given autoplacement scheme rather than using the default */
N
N/* OTP mode selection */
N#define MTD_OTP_OFF		0
N#define MTD_OTP_FACTORY		1
N#define MTD_OTP_USER		2
N
Nstruct mtd_info_user {
N	uint8_t type;
N	uint32_t flags;
N	uint32_t size;			/* Total size of the MTD */
N	uint32_t erasesize;
N	uint32_t writesize;
N	uint32_t oobsize;		/* Amount of OOB data per block (e.g. 16) */
N	/* The below two fields are obsolete and broken, do not use them
N	 * (TODO: remove at some point) */
N	uint32_t ecctype;
N	uint32_t eccsize;
N};
N
Nstruct region_info_user {
N	uint32_t offset;		/* At which this region starts,
N					 * from the beginning of the MTD */
N	uint32_t erasesize;		/* For this region */
N	uint32_t numblocks;		/* Number of blocks in this region */
N	uint32_t regionindex;
N};
N
Nstruct otp_info {
N	uint32_t start;
N	uint32_t length;
N	uint32_t locked;
N};
N
N#define MEMGETINFO		_IOR('M', 1, struct mtd_info_user)
N#define MEMERASE		_IOW('M', 2, struct erase_info_user)
N#define MEMWRITEOOB		_IOWR('M', 3, struct mtd_oob_buf)
N#define MEMREADOOB		_IOWR('M', 4, struct mtd_oob_buf)
N#define MEMLOCK			_IOW('M', 5, struct erase_info_user)
N#define MEMUNLOCK		_IOW('M', 6, struct erase_info_user)
N#define MEMGETREGIONCOUNT	_IOR('M', 7, int)
N#define MEMGETREGIONINFO	_IOWR('M', 8, struct region_info_user)
N#define MEMSETOOBSEL		_IOW('M', 9, struct nand_oobinfo)
N#define MEMGETOOBSEL		_IOR('M', 10, struct nand_oobinfo)
N#define MEMGETBADBLOCK		_IOW('M', 11, loff_t)
N#define MEMSETBADBLOCK		_IOW('M', 12, loff_t)
N#define OTPSELECT		_IOR('M', 13, int)
N#define OTPGETREGIONCOUNT	_IOW('M', 14, int)
N#define OTPGETREGIONINFO	_IOW('M', 15, struct otp_info)
N#define OTPLOCK			_IOR('M', 16, struct otp_info)
N#define ECCGETLAYOUT		_IOR('M', 17, struct nand_ecclayout)
N#define ECCGETSTATS		_IOR('M', 18, struct mtd_ecc_stats)
N#define MTDFILEMODE		_IO('M', 19)
N
N/*
N * Obsolete legacy interface. Keep it in order not to break userspace
N * interfaces
N */
Nstruct nand_oobinfo {
N	uint32_t useecc;
N	uint32_t eccbytes;
N	uint32_t oobfree[8][2];
N	uint32_t eccpos[48];
N};
N
Nstruct nand_oobfree {
N	uint32_t offset;
N	uint32_t length;
N};
N
N#define MTD_MAX_OOBFREE_ENTRIES	8
N/*
N * ECC layout control structure. Exported to userspace for
N * diagnosis and to allow creation of raw images
N */
Nstruct nand_ecclayout {
N	uint32_t eccbytes;
N	uint32_t eccpos[128];
N	uint32_t oobavail;
N	struct nand_oobfree oobfree[MTD_MAX_OOBFREE_ENTRIES];
X	struct nand_oobfree oobfree[8];
N};
N
N/**
N * struct mtd_ecc_stats - error correction stats
N *
N * @corrected:	number of corrected bits
N * @failed:	number of uncorrectable errors
N * @badblocks:	number of bad blocks in this partition
N * @bbtblocks:	number of blocks reserved for bad block tables
N */
Nstruct mtd_ecc_stats {
N	uint32_t corrected;
N	uint32_t failed;
N	uint32_t badblocks;
N	uint32_t bbtblocks;
N};
N
N/*
N * Read/write file modes for access to MTD
N */
Nenum mtd_file_modes {
N	MTD_MODE_NORMAL = MTD_OTP_OFF,
X	MTD_MODE_NORMAL = 0,
N	MTD_MODE_OTP_FACTORY = MTD_OTP_FACTORY,
X	MTD_MODE_OTP_FACTORY = 1,
N	MTD_MODE_OTP_USER = MTD_OTP_USER,
X	MTD_MODE_OTP_USER = 2,
N	MTD_MODE_RAW,
N};
N
N#endif /* __MTD_ABI_H__ */
L 13 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd.h" 2
N
N#define MTD_CHAR_MAJOR 90
N#define MTD_BLOCK_MAJOR 31
N#define MAX_MTD_DEVICES 32
N
N#define MTD_ERASE_PENDING	0x01
N#define MTD_ERASING		0x02
N#define MTD_ERASE_SUSPEND	0x04
N#define MTD_ERASE_DONE          0x08
N#define MTD_ERASE_FAILED        0x10
N
N#define MTD_FAIL_ADDR_UNKNOWN	-1LL
N
N/*
N * Enumeration for NAND/OneNAND flash chip state
N */
Nenum {
N	FL_READY,
N	FL_READING,
N	FL_WRITING,
N	FL_ERASING,
N	FL_SYNCING,
N	FL_CACHEDPRG,
N	FL_RESETING,
N	FL_UNLOCKING,
N	FL_LOCKING,
N	FL_PM_SUSPENDED,
N};
N
N/* If the erase fails, fail_addr might indicate exactly which block failed.  If
N   fail_addr = MTD_FAIL_ADDR_UNKNOWN, the failure was not at the device level or was not
N   specific to any particular block. */
Nstruct erase_info {
N	struct mtd_info *mtd;
N	uint64_t addr;
N	uint64_t len;
N	uint64_t fail_addr;
N	u_long time;
N	u_long retries;
N	u_int dev;
N	u_int cell;
N	void (*callback) (struct erase_info *self);
N	u_long priv;
N	u_char state;
N	struct erase_info *next;
N	int scrub;
N};
N
Nstruct mtd_erase_region_info {
N	uint64_t offset;			/* At which this region starts, from the beginning of the MTD */
N	u_int32_t erasesize;		/* For this region */
N	u_int32_t numblocks;		/* Number of blocks of erasesize in this region */
N	unsigned long *lockmap;		/* If keeping bitmap of locks */
N};
N
N/*
N * oob operation modes
N *
N * MTD_OOB_PLACE:	oob data are placed at the given offset
N * MTD_OOB_AUTO:	oob data are automatically placed at the free areas
N *			which are defined by the ecclayout
N * MTD_OOB_RAW:		mode to read raw data+oob in one chunk. The oob data
N *			is inserted into the data. Thats a raw image of the
N *			flash contents.
N */
Ntypedef enum {
N	MTD_OOB_PLACE,
N	MTD_OOB_AUTO,
N	MTD_OOB_RAW,
N} mtd_oob_mode_t;
N
N/**
N * struct mtd_oob_ops - oob operation operands
N * @mode:	operation mode
N *
N * @len:	number of data bytes to write/read
N *
N * @retlen:	number of data bytes written/read
N *
N * @ooblen:	number of oob bytes to write/read
N * @oobretlen:	number of oob bytes written/read
N * @ooboffs:	offset of oob data in the oob area (only relevant when
N *		mode = MTD_OOB_PLACE)
N * @datbuf:	data buffer - if NULL only oob data are read/written
N * @oobbuf:	oob data buffer
N *
N * Note, it is allowed to read more then one OOB area at one go, but not write.
N * The interface assumes that the OOB write requests program only one page's
N * OOB area.
N */
Nstruct mtd_oob_ops {
N	mtd_oob_mode_t	mode;
N	size_t		len;
N	size_t		retlen;
N	size_t		ooblen;
N	size_t		oobretlen;
N	uint32_t	ooboffs;
N	uint8_t		*datbuf;
N	uint8_t		*oobbuf;
N};
N
Nstruct mtd_info {
N	u_char type;
N	u_int32_t flags;
N	uint64_t size;	 /* Total size of the MTD */
N
N	/* "Major" erase size for the device. Naïve users may take this
N	 * to be the only erase size available, or may use the more detailed
N	 * information below if they desire
N	 */
N	u_int32_t erasesize;
N	/* Minimal writable flash unit size. In case of NOR flash it is 1 (even
N	 * though individual bits can be cleared), in case of NAND flash it is
N	 * one NAND page (or half, or one-fourths of it), in case of ECC-ed NOR
N	 * it is of ECC block size, etc. It is illegal to have writesize = 0.
N	 * Any driver registering a struct mtd_info must ensure a writesize of
N	 * 1 or larger.
N	 */
N	u_int32_t writesize;
N
N	u_int32_t oobsize;   /* Amount of OOB data per block (e.g. 16) */
N	u_int32_t oobavail;  /* Available OOB bytes per block */
N
N	/* Kernel-only stuff starts here. */
N	const char *name;
N	int index;
N
N	/* ecc layout structure pointer - read only ! */
N	struct nand_ecclayout *ecclayout;
N
N	/* Data for variable erase regions. If numeraseregions is zero,
N	 * it means that the whole device has erasesize as given above.
N	 */
N	int numeraseregions;
N	struct mtd_erase_region_info *eraseregions;
N
N	/*
N	 * Erase is an asynchronous operation.  Device drivers are supposed
N	 * to call instr->callback() whenever the operation completes, even
N	 * if it completes with a failure.
N	 * Callers are supposed to pass a callback function and wait for it
N	 * to be called before writing to the block.
N	 */
N	int (*erase) (struct mtd_info *mtd, struct erase_info *instr);
N
N	/* This stuff for eXecute-In-Place */
N	/* phys is optional and may be set to NULL */
N	int (*point) (struct mtd_info *mtd, loff_t from, size_t len,
N			size_t *retlen, void **virt, phys_addr_t *phys);
N
N	/* We probably shouldn't allow XIP if the unpoint isn't a NULL */
N	void (*unpoint) (struct mtd_info *mtd, loff_t from, size_t len);
N
N
N	int (*read) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*write) (struct mtd_info *mtd, loff_t to, size_t len, size_t *retlen, const u_char *buf);
N
N	/* In blackbox flight recorder like scenarios we want to make successful
N	   writes in interrupt context. panic_write() is only intended to be
N	   called when its known the kernel is about to panic and we need the
N	   write to succeed. Since the kernel is not going to be running for much
N	   longer, this function can break locks and delay to ensure the write
N	   succeeds (but not sleep). */
N
N	int (*panic_write) (struct mtd_info *mtd, loff_t to, size_t len, size_t *retlen, const u_char *buf);
N
N	int (*read_oob) (struct mtd_info *mtd, loff_t from,
N			 struct mtd_oob_ops *ops);
N	int (*write_oob) (struct mtd_info *mtd, loff_t to,
N			 struct mtd_oob_ops *ops);
N
N	/*
N	 * Methods to access the protection register area, present in some
N	 * flash devices. The user data is one time programmable but the
N	 * factory data is read only.
N	 */
N	int (*get_fact_prot_info) (struct mtd_info *mtd, struct otp_info *buf, size_t len);
N	int (*read_fact_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*get_user_prot_info) (struct mtd_info *mtd, struct otp_info *buf, size_t len);
N	int (*read_user_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*write_user_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*lock_user_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len);
N
N	/* Sync */
N	void (*sync) (struct mtd_info *mtd);
N
N	/* Chip-supported device locking */
N	int (*lock) (struct mtd_info *mtd, loff_t ofs, uint64_t len);
N	int (*unlock) (struct mtd_info *mtd, loff_t ofs, uint64_t len);
N
N	/* Bad block management functions */
N	int (*block_isbad) (struct mtd_info *mtd, loff_t ofs);
N	int (*block_markbad) (struct mtd_info *mtd, loff_t ofs);
N
N	/* ECC status information */
N	struct mtd_ecc_stats ecc_stats;
N	/* Subpage shift (NAND) */
N	int subpage_sft;
N
N	void *priv;
N
N	struct module *owner;
N	int usecount;
N
N	/* If the driver is something smart, like UBI, it may need to maintain
N	 * its own reference counting. The below functions are only for driver.
N	 * The driver may register its callbacks. These callbacks are not
N	 * supposed to be called by MTD users */
N	int (*get_device) (struct mtd_info *mtd);
N	void (*put_device) (struct mtd_info *mtd);
N	u_char rw_oob;
N	u_char skipfirstblk;
N};
N
Nstatic __inline uint32_t mtd_div_by_eb(uint64_t sz, struct mtd_info *mtd)
N{
N	do_div(sz, mtd->erasesize);
X	(sz = sz/mtd->erasesize);
N	return sz;
N}
N
Nstatic __inline uint32_t mtd_mod_by_eb(uint64_t sz, struct mtd_info *mtd)
N{
N	return do_div(sz, mtd->erasesize);
X	return (sz = sz/mtd->erasesize);
N}
N
N	/* Kernel-side ioctl definitions */
N
Nextern int add_mtd_device(struct mtd_info *mtd);
Nextern int del_mtd_device (struct mtd_info *mtd);
N
Nextern struct mtd_info *get_mtd_device(struct mtd_info *mtd, int num);
Nextern struct mtd_info *get_mtd_device_nm(const char *name);
N
Nextern void put_mtd_device(struct mtd_info *mtd);
Nextern void mtd_get_len_incl_bad(struct mtd_info *mtd, uint64_t offset,
N				 const uint64_t length, uint64_t *len_incl_bad,
N				 int *truncated);
N
Nvoid mtd_erase_callback(struct erase_info *instr);
N
N/*
N * Debugging macro and defines
N */
N#define MTD_DEBUG_LEVEL0	(0)	/* Quiet   */
N#define MTD_DEBUG_LEVEL1	(1)	/* Audible */
N#define MTD_DEBUG_LEVEL2	(2)	/* Loud    */
N#define MTD_DEBUG_LEVEL3	(3)	/* Noisy   */
N
N#ifdef CONFIG_MTD_DEBUG
S#define MTDDEBUG(n, args...)				\
S	do {						\
S		if (n <= CONFIG_MTD_DEBUG_VERBOSE)	\
S			sysprintf(KERN_INFO args);		\
S	} while(0)
X#define MTDDEBUG(n, args...)					do {								if (n <= CONFIG_MTD_DEBUG_VERBOSE)				sysprintf(KERN_INFO args);			} while(0)
N#else /* CONFIG_MTD_DEBUG */
N#define MTDDEBUG(n, args...)				\
N	do {						\
N		if (0)					\
N			sysprintf(args);		\
N	} while(0)
X#define MTDDEBUG(n, args...)					do {								if (0)								sysprintf(args);			} while(0)
N#endif /* CONFIG_MTD_DEBUG */
N
N#endif /* __MTD_MTD_H__ */
L 43 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "linux\nand.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\nand.h" 1
N/*
N *  linux/include/linux/mtd/nand.h
N *
N *  Copyright © 2000-2010 David Woodhouse <dwmw2@infradead.org>
N *                        Steven J. Hill <sjhill@realitydiluted.com>
N *		          Thomas Gleixner <tglx@linutronix.de>
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License version 2 as
N * published by the Free Software Foundation.
N *
N * Info:
N *	Contains standard defines and IDs for NAND flash devices
N *
N * Changelog:
N *	See git changelog.
N */
N#ifndef __LINUX_MTD_NAND_H
N#define __LINUX_MTD_NAND_H
N
N#include "config.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\config.h" 1
N#ifndef _LINUX_CONFIG_H
N#define _LINUX_CONFIG_H
N
N/* #include <linux/autoconf.h> */
N
N#endif
L 22 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\nand.h" 2
N
N#include "linux\mtd.h"
N#include "linux\bbm.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\bbm.h" 1
N/*
N *  linux/include/linux/mtd/bbm.h
N *
N *  NAND family Bad Block Management (BBM) header file
N *    - Bad Block Table (BBT) implementation
N *
N *  Copyright (c) 2005-2007 Samsung Electronics
N *  Kyungmin Park <kyungmin.park@samsung.com>
N *
N *  Copyright (c) 2000-2005
N *  Thomas Gleixner <tglx@linuxtronix.de>
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License as published by
N * the Free Software Foundation; either version 2 of the License, or
N * (at your option) any later version.
N *
N * This program is distributed in the hope that it will be useful,
N * but WITHOUT ANY WARRANTY; without even the implied warranty of
N * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
N * GNU General Public License for more details.
N *
N * You should have received a copy of the GNU General Public License
N * along with this program; if not, write to the Free Software
N * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
N *
N */
N#ifndef __LINUX_MTD_BBM_H
N#define __LINUX_MTD_BBM_H
N
N/* The maximum number of NAND chips in an array */
N#ifndef CONFIG_SYS_NAND_MAX_CHIPS
N#define CONFIG_SYS_NAND_MAX_CHIPS	1
N#endif
N
N/**
N * struct nand_bbt_descr - bad block table descriptor
N * @param options	options for this descriptor
N * @param pages		the page(s) where we find the bbt, used with
N *			option BBT_ABSPAGE when bbt is searched,
N *			then we store the found bbts pages here.
N *			Its an array and supports up to 8 chips now
N * @param offs		offset of the pattern in the oob area of the page
N * @param veroffs	offset of the bbt version counter in the oob are of the page
N * @param version	version read from the bbt page during scan
N * @param len		length of the pattern, if 0 no pattern check is performed
N * @param maxblocks	maximum number of blocks to search for a bbt. This number of
N *			blocks is reserved at the end of the device
N *			where the tables are written.
N * @param reserved_block_code	if non-0, this pattern denotes a reserved
N *			(rather than bad) block in the stored bbt
N * @param pattern	pattern to identify bad block table or factory marked
N *			good / bad blocks, can be NULL, if len = 0
N *
N * Descriptor for the bad block table marker and the descriptor for the
N * pattern which identifies good and bad blocks. The assumption is made
N * that the pattern and the version count are always located in the oob area
N * of the first block.
N */
Nstruct nand_bbt_descr {
N	int options;
N	int pages[CONFIG_SYS_NAND_MAX_CHIPS];
X	int pages[1];
N	int offs;
N	int veroffs;
N	uint8_t version[CONFIG_SYS_NAND_MAX_CHIPS];
X	uint8_t version[1];
N	int len;
N	int maxblocks;
N	int reserved_block_code;
N	uint8_t *pattern;
N};
N
N/* Options for the bad block table descriptors */
N
N/* The number of bits used per block in the bbt on the device */
N#define NAND_BBT_NRBITS_MSK	0x0000000F
N#define NAND_BBT_1BIT		0x00000001
N#define NAND_BBT_2BIT		0x00000002
N#define NAND_BBT_4BIT		0x00000004
N#define NAND_BBT_8BIT		0x00000008
N/* The bad block table is in the last good block of the device */
N#define NAND_BBT_LASTBLOCK	0x00000010
N/* The bbt is at the given page, else we must scan for the bbt */
N#define NAND_BBT_ABSPAGE	0x00000020
N/* The bbt is at the given page, else we must scan for the bbt */
N#define NAND_BBT_SEARCH		0x00000040
N/* bbt is stored per chip on multichip devices */
N#define NAND_BBT_PERCHIP	0x00000080
N/* bbt has a version counter at offset veroffs */
N#define NAND_BBT_VERSION	0x00000100
N/* Create a bbt if none exists */
N#define NAND_BBT_CREATE		0x00000200
N/* Search good / bad pattern through all pages of a block */
N#define NAND_BBT_SCANALLPAGES	0x00000400
N/* Scan block empty during good / bad block scan */
N#define NAND_BBT_SCANEMPTY	0x00000800
N/* Write bbt if neccecary */
N#define NAND_BBT_WRITE		0x00001000
N/* Read and write back block contents when writing bbt */
N#define NAND_BBT_SAVECONTENT	0x00002000
N/* Search good / bad pattern on the first and the second page */
N#define NAND_BBT_SCAN2NDPAGE	0x00004000
N/* Search good / bad pattern on the last page of the eraseblock */
N#define NAND_BBT_SCANLASTPAGE	0x00008000
N/* Chip stores bad block marker on BOTH 1st and 6th bytes of OOB */
N#define NAND_BBT_SCANBYTE1AND6 0x00100000
N/* The nand_bbt_descr was created dynamicaly and must be freed */
N#define NAND_BBT_DYNAMICSTRUCT 0x00200000
N/* The bad block table does not OOB for marker */
N#define NAND_BBT_NO_OOB		0x00400000
N
N/* The maximum number of blocks to scan for a bbt */
N#define NAND_BBT_SCAN_MAXBLOCKS	4
N
N/*
N * Constants for oob configuration
N */
N#define ONENAND_BADBLOCK_POS	0
N
N/*
N * Bad block scanning errors
N */
N#define ONENAND_BBT_READ_ERROR          1
N#define ONENAND_BBT_READ_ECC_ERROR      2
N#define ONENAND_BBT_READ_FATAL_ERROR    4
N
N/**
N * struct bbt_info - [GENERIC] Bad Block Table data structure
N * @param bbt_erase_shift	[INTERN] number of address bits in a bbt entry
N * @param badblockpos		[INTERN] position of the bad block marker in the oob area
N * @param bbt			[INTERN] bad block table pointer
N * @param badblock_pattern	[REPLACEABLE] bad block scan pattern used for initial bad block scan
N * @param priv			[OPTIONAL] pointer to private bbm date
N */
Nstruct bbm_info {
N	int bbt_erase_shift;
N	int badblockpos;
N	int options;
N
N	uint8_t *bbt;
N
N	int (*isbad_bbt) (struct mtd_info * mtd, loff_t ofs, int allowbbt);
N
N	/* TODO Add more NAND specific fileds */
N	struct nand_bbt_descr *badblock_pattern;
N
N	void *priv;
N};
N
N/* OneNAND BBT interface */
Nextern int onenand_scan_bbt (struct mtd_info *mtd, struct nand_bbt_descr *bd);
Nextern int onenand_default_bbt (struct mtd_info *mtd);
N
N#endif				/* __LINUX_MTD_BBM_H */
L 25 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\nand.h" 2
N
N
Nstruct mtd_info;
Nstruct nand_flash_dev;
N/* Scan and identify a NAND device */
Nextern int nand_scan (struct mtd_info *mtd, int max_chips);
N/* Separate phases of nand_scan(), allowing board driver to intervene
N * and override command or ECC setup according to flash type */
Nextern int nand_scan_ident(struct mtd_info *mtd, int max_chips,
N			   const struct nand_flash_dev *table);
Nextern int nand_scan_tail(struct mtd_info *mtd);
N
N/* Free resources held by the NAND device */
Nextern void nand_release(struct mtd_info *mtd);
N
N/* Internal helper for board drivers which need to override command function */
Nextern void nand_wait_ready(struct mtd_info *mtd);
N
N/*
N * This constant declares the max. oobsize / page, which
N * is supported now. If you add a chip with bigger oobsize/page
N * adjust this accordingly.
N */
N#define NAND_MAX_OOBSIZE	576
N#define NAND_MAX_PAGESIZE	8192
N
N/*
N * Constants for hardware specific CLE/ALE/NCE function
N *
N * These are bits which can be or'ed to set/clear multiple
N * bits in one go.
N */
N/* Select the chip by setting nCE to low */
N#define NAND_NCE		0x01
N/* Select the command latch by setting CLE to high */
N#define NAND_CLE		0x02
N/* Select the address latch by setting ALE to high */
N#define NAND_ALE		0x04
N
N#define NAND_CTRL_CLE		(NAND_NCE | NAND_CLE)
N#define NAND_CTRL_ALE		(NAND_NCE | NAND_ALE)
N#define NAND_CTRL_CHANGE	0x80
N
N/*
N * Standard NAND flash commands
N */
N#define NAND_CMD_READ0		0
N#define NAND_CMD_READ1		1
N#define NAND_CMD_RNDOUT		5
N#define NAND_CMD_PAGEPROG	0x10
N#define NAND_CMD_READOOB	0x50
N#define NAND_CMD_ERASE1		0x60
N#define NAND_CMD_STATUS		0x70
N#define NAND_CMD_STATUS_MULTI	0x71
N#define NAND_CMD_SEQIN		0x80
N#define NAND_CMD_RNDIN		0x85
N#define NAND_CMD_READID		0x90
N#define NAND_CMD_ERASE2		0xd0
N#define NAND_CMD_PARAM		0xec
N#define NAND_CMD_RESET		0xff
N
N#define NAND_CMD_LOCK		0x2a
N#define NAND_CMD_LOCK_TIGHT	0x2c
N#define NAND_CMD_UNLOCK1	0x23
N#define NAND_CMD_UNLOCK2	0x24
N#define NAND_CMD_LOCK_STATUS	0x7a
N
N/* Extended commands for large page devices */
N#define NAND_CMD_READSTART	0x30
N#define NAND_CMD_RNDOUTSTART	0xE0
N#define NAND_CMD_CACHEDPROG	0x15
N
N/* Extended commands for AG-AND device */
N/*
N * Note: the command for NAND_CMD_DEPLETE1 is really 0x00 but
N *       there is no way to distinguish that from NAND_CMD_READ0
N *       until the remaining sequence of commands has been completed
N *       so add a high order bit and mask it off in the command.
N */
N#define NAND_CMD_DEPLETE1	0x100
N#define NAND_CMD_DEPLETE2	0x38
N#define NAND_CMD_STATUS_MULTI	0x71
N#define NAND_CMD_STATUS_ERROR	0x72
N/* multi-bank error status (banks 0-3) */
N#define NAND_CMD_STATUS_ERROR0	0x73
N#define NAND_CMD_STATUS_ERROR1	0x74
N#define NAND_CMD_STATUS_ERROR2	0x75
N#define NAND_CMD_STATUS_ERROR3	0x76
N#define NAND_CMD_STATUS_RESET	0x7f
N#define NAND_CMD_STATUS_CLEAR	0xff
N
N#define NAND_CMD_NONE		-1
N
N/* Status bits */
N#define NAND_STATUS_FAIL	0x01
N#define NAND_STATUS_FAIL_N1	0x02
N#define NAND_STATUS_TRUE_READY	0x20
N#define NAND_STATUS_READY	0x40
N#define NAND_STATUS_WP		0x80
N
N/*
N * Constants for ECC_MODES
N */
Ntypedef enum {
N	NAND_ECC_NONE,
N	NAND_ECC_SOFT,
N	NAND_ECC_HW,
N	NAND_ECC_HW_SYNDROME,
N	NAND_ECC_HW_OOB_FIRST,
N	NAND_ECC_SOFT_BCH,
N} nand_ecc_modes_t;
N
N/*
N * Constants for Hardware ECC
N */
N/* Reset Hardware ECC for read */
N#define NAND_ECC_READ		0
N/* Reset Hardware ECC for write */
N#define NAND_ECC_WRITE		1
N/* Enable Hardware ECC before syndrom is read back from flash */
N#define NAND_ECC_READSYN	2
N
N/* Bit mask for flags passed to do_nand_read_ecc */
N#define NAND_GET_DEVICE		0x80
N
N
N/*
N * Option constants for bizarre disfunctionality and real
N * features.
N */
N/* Chip can not auto increment pages */
N#define NAND_NO_AUTOINCR	0x00000001
N/* Buswitdh is 16 bit */
N#define NAND_BUSWIDTH_16	0x00000002
N/* Device supports partial programming without padding */
N#define NAND_NO_PADDING		0x00000004
N/* Chip has cache program function */
N#define NAND_CACHEPRG		0x00000008
N/* Chip has copy back function */
N#define NAND_COPYBACK		0x00000010
N/*
N * AND Chip which has 4 banks and a confusing page / block
N * assignment. See Renesas datasheet for further information.
N */
N#define NAND_IS_AND		0x00000020
N/*
N * Chip has a array of 4 pages which can be read without
N * additional ready /busy waits.
N */
N#define NAND_4PAGE_ARRAY	0x00000040
N/*
N * Chip requires that BBT is periodically rewritten to prevent
N * bits from adjacent blocks from 'leaking' in altering data.
N * This happens with the Renesas AG-AND chips, possibly others.
N */
N#define BBT_AUTO_REFRESH	0x00000080
N/*
N * Chip does not require ready check on read. true
N * for all large page devices, as they do not support
N * autoincrement.
N */
N#define NAND_NO_READRDY		0x00000100
N/* Chip does not allow subpage writes */
N#define NAND_NO_SUBPAGE_WRITE	0x00000200
N
N/* Device is one of 'new' xD cards that expose fake nand command set */
N#define NAND_BROKEN_XD		0x00000400
N
N/* Device behaves just like nand, but is readonly */
N#define NAND_ROM		0x00000800
N
N/* Device supports subpage reads */
N#define NAND_SUBPAGE_READ       0x00001000
N
N/* Options valid for Samsung large page devices */
N#define NAND_SAMSUNG_LP_OPTIONS \
N	(NAND_NO_PADDING | NAND_CACHEPRG | NAND_COPYBACK)
X#define NAND_SAMSUNG_LP_OPTIONS 	(NAND_NO_PADDING | NAND_CACHEPRG | NAND_COPYBACK)
N
N/* Macros to identify the above */
N#define NAND_CANAUTOINCR(chip) (!(chip->options & NAND_NO_AUTOINCR))
N#define NAND_MUST_PAD(chip) (!(chip->options & NAND_NO_PADDING))
N#define NAND_HAS_CACHEPROG(chip) ((chip->options & NAND_CACHEPRG))
N#define NAND_HAS_COPYBACK(chip) ((chip->options & NAND_COPYBACK))
N#define NAND_HAS_SUBPAGE_READ(chip) ((chip->options & NAND_SUBPAGE_READ))
N
N/* Non chip related options */
N/*
N * Use a flash based bad block table. OOB identifier is saved in OOB area.
N * This option is passed to the default bad block table function.
N */
N#define NAND_USE_FLASH_BBT	0x00010000
N/* This option skips the bbt scan during initialization. */
N#define NAND_SKIP_BBTSCAN	0x00020000
N/*
N * This option is defined if the board driver allocates its own buffers
N * (e.g. because it needs them DMA-coherent).
N */
N#define NAND_OWN_BUFFERS	0x00040000
N/* Chip may not exist, so silence any errors in scan */
N#define NAND_SCAN_SILENT_NODEV	0x00080000
N/*
N * If passed additionally to NAND_USE_FLASH_BBT then BBT code will not touch
N * the OOB area.
N */
N#define NAND_USE_FLASH_BBT_NO_OOB	0x00800000
N/* Create an empty BBT with no vendor information if the BBT is available */
N#define NAND_CREATE_EMPTY_BBT		0x01000000
N
N/* Options set by nand scan */
N/* bbt has already been read */
N#define NAND_BBT_SCANNED	0x40000000
N/* Nand scan has allocated controller struct */
N#define NAND_CONTROLLER_ALLOC	0x80000000
N
N/* Cell info constants */
N#define NAND_CI_CHIPNR_MSK	0x03
N#define NAND_CI_CELLTYPE_MSK	0x0C
N
N/* Keep gcc happy */
Nstruct nand_chip;
N
Nstruct nand_onfi_params {
N	/* rev info and features block */
N	/* 'O' 'N' 'F' 'I'  */
N	u8 sig[4];
N	__le16 revision;
N	__le16 features;
N	__le16 opt_cmd;
N	u8 reserved[22];
N
N	/* manufacturer information block */
N	char manufacturer[12];
N	char model[20];
N	u8 jedec_id;
N	__le16 date_code;
N	u8 reserved2[13];
N
N	/* memory organization block */
N	__le32 byte_per_page;
N	__le16 spare_bytes_per_page;
N	__le32 data_bytes_per_ppage;
N	__le16 spare_bytes_per_ppage;
N	__le32 pages_per_block;
N	__le32 blocks_per_lun;
N	u8 lun_count;
N	u8 addr_cycles;
N	u8 bits_per_cell;
N	__le16 bb_per_lun;
N	__le16 block_endurance;
N	u8 guaranteed_good_blocks;
N	__le16 guaranteed_block_endurance;
N	u8 programs_per_page;
N	u8 ppage_attr;
N	u8 ecc_bits;
N	u8 interleaved_bits;
N	u8 interleaved_ops;
N	u8 reserved3[13];
N
N	/* electrical parameter block */
N	u8 io_pin_capacitance_max;
N	__le16 async_timing_mode;
N	__le16 program_cache_timing_mode;
N	__le16 t_prog;
N	__le16 t_bers;
N	__le16 t_r;
N	__le16 t_ccs;
N	__le16 src_sync_timing_mode;
N	__le16 src_ssync_features;
N	__le16 clk_pin_capacitance_typ;
N	__le16 io_pin_capacitance_typ;
N	__le16 input_pin_capacitance_typ;
N	u8 input_pin_capacitance_max;
N	u8 driver_strenght_support;
N	__le16 t_int_r;
N	__le16 t_ald;
N	u8 reserved4[7];
N
N	/* vendor */
N	u8 reserved5[90];
N
N	__le16 crc;
N} __attribute__((packed));
N
N#define ONFI_CRC_BASE	0x4F4E
N
N/**
N * struct nand_hw_control - Control structure for hardware controller (e.g ECC generator) shared among independent devices
N * @lock:               protection lock
N * @active:		the mtd device which holds the controller currently
N * @wq:			wait queue to sleep on if a NAND operation is in
N *			progress used instead of the per chip wait queue
N *			when a hw controller is available.
N */
Nstruct nand_hw_control {
N/* XXX U-BOOT XXX */
N#if 0
S	spinlock_t	 lock;
S	wait_queue_head_t wq;
N#endif
N	struct nand_chip *active;
N};
N
N/**
N * struct nand_ecc_ctrl - Control structure for ecc
N * @mode:	ecc mode
N * @steps:	number of ecc steps per page
N * @size:	data bytes per ecc step
N * @bytes:	ecc bytes per step
N * @total:	total number of ecc bytes per page
N * @prepad:	padding information for syndrome based ecc generators
N * @postpad:	padding information for syndrome based ecc generators
N * @layout:	ECC layout control struct pointer
N * @priv:	pointer to private ecc control data
N * @hwctl:	function to control hardware ecc generator. Must only
N *		be provided if an hardware ECC is available
N * @calculate:	function for ecc calculation or readback from ecc hardware
N * @correct:	function for ecc correction, matching to ecc generator (sw/hw)
N * @read_page_raw:	function to read a raw page without ECC
N * @write_page_raw:	function to write a raw page without ECC
N * @read_page:	function to read a page according to the ecc generator
N *		requirements.
N * @read_subpage:	function to read parts of the page covered by ECC.
N * @write_page:	function to write a page according to the ecc generator
N *		requirements.
N * @read_oob:	function to read chip OOB data
N * @write_oob:	function to write chip OOB data
N */
Nstruct nand_ecc_ctrl {
N	nand_ecc_modes_t mode;
N	int steps;
N	int size;
N	int bytes;
N	int total;
N	int prepad;
N	int postpad;
N	struct nand_ecclayout	*layout;
N	void *priv;
N	void (*hwctl)(struct mtd_info *mtd, int mode);
N	int (*calculate)(struct mtd_info *mtd, const uint8_t *dat,
N			uint8_t *ecc_code);
N	int (*correct)(struct mtd_info *mtd, uint8_t *dat, uint8_t *read_ecc,
N			uint8_t *calc_ecc);
N	int (*read_page_raw)(struct mtd_info *mtd, struct nand_chip *chip,
N			uint8_t *buf, int page);
N	void (*write_page_raw)(struct mtd_info *mtd, struct nand_chip *chip,
N			const uint8_t *buf);
N	int (*read_page)(struct mtd_info *mtd, struct nand_chip *chip,
N			uint8_t *buf, int page);
N	int (*read_subpage)(struct mtd_info *mtd, struct nand_chip *chip,
N			uint32_t offs, uint32_t len, uint8_t *buf);
N	void (*write_page)(struct mtd_info *mtd, struct nand_chip *chip,
N			const uint8_t *buf);
N	int (*read_oob)(struct mtd_info *mtd, struct nand_chip *chip, int page,
N			int sndcmd);
N	int (*write_oob)(struct mtd_info *mtd, struct nand_chip *chip,
N			int page);
N};
N
N/**
N * struct nand_buffers - buffer structure for read/write
N * @ecccalc:	buffer for calculated ecc
N * @ecccode:	buffer for ecc read from flash
N * @databuf:	buffer for data - dynamically sized
N *
N * Do not change the order of buffers. databuf and oobrbuf must be in
N * consecutive order.
N */
Nstruct nand_buffers {
Nuint8_t ecccalc[NAND_MAX_OOBSIZE];
Xuint8_t ecccalc[576];
Nuint8_t ecccode[NAND_MAX_OOBSIZE];
Xuint8_t ecccode[576];
Nuint8_t databuf[NAND_MAX_PAGESIZE + NAND_MAX_OOBSIZE];
Xuint8_t databuf[8192 + 576];
N};
N
N/**
N * struct nand_chip - NAND Private Flash Chip Data
N * @IO_ADDR_R:		[BOARDSPECIFIC] address to read the 8 I/O lines of the
N *			flash device
N * @IO_ADDR_W:		[BOARDSPECIFIC] address to write the 8 I/O lines of the
N *			flash device.
N * @read_byte:		[REPLACEABLE] read one byte from the chip
N * @read_word:		[REPLACEABLE] read one word from the chip
N * @write_buf:		[REPLACEABLE] write data from the buffer to the chip
N * @read_buf:		[REPLACEABLE] read data from the chip into the buffer
N * @verify_buf:		[REPLACEABLE] verify buffer contents against the chip
N *			data.
N * @select_chip:	[REPLACEABLE] select chip nr
N * @block_bad:		[REPLACEABLE] check, if the block is bad
N * @block_markbad:	[REPLACEABLE] mark the block bad
N * @cmd_ctrl:		[BOARDSPECIFIC] hardwarespecific function for controlling
N *			ALE/CLE/nCE. Also used to write command and address
N * @init_size:		[BOARDSPECIFIC] hardwarespecific function for setting
N *			mtd->oobsize, mtd->writesize and so on.
N *			@id_data contains the 8 bytes values of NAND_CMD_READID.
N *			Return with the bus width.
N * @dev_ready:		[BOARDSPECIFIC] hardwarespecific function for accesing
N *			device ready/busy line. If set to NULL no access to
N *			ready/busy is available and the ready/busy information
N *			is read from the chip status register.
N * @cmdfunc:		[REPLACEABLE] hardwarespecific function for writing
N *			commands to the chip.
N * @waitfunc:		[REPLACEABLE] hardwarespecific function for wait on
N *			ready.
N * @ecc:		[BOARDSPECIFIC] ecc control ctructure
N * @buffers:		buffer structure for read/write
N * @hwcontrol:		platform-specific hardware control structure
N * @ops:		oob operation operands
N * @erase_cmd:		[INTERN] erase command write function, selectable due
N *			to AND support.
N * @scan_bbt:		[REPLACEABLE] function to scan bad block table
N * @chip_delay:		[BOARDSPECIFIC] chip dependent delay for transferring
N *			data from array to read regs (tR).
N * @state:		[INTERN] the current state of the NAND device
N * @oob_poi:		poison value buffer
N * @page_shift:		[INTERN] number of address bits in a page (column
N *			address bits).
N * @phys_erase_shift:	[INTERN] number of address bits in a physical eraseblock
N * @bbt_erase_shift:	[INTERN] number of address bits in a bbt entry
N * @chip_shift:		[INTERN] number of address bits in one chip
N * @options:		[BOARDSPECIFIC] various chip options. They can partly
N *			be set to inform nand_scan about special functionality.
N *			See the defines for further explanation.
N * @badblockpos:	[INTERN] position of the bad block marker in the oob
N *			area.
N * @badblockbits:	[INTERN] number of bits to left-shift the bad block
N *			number
N * @cellinfo:		[INTERN] MLC/multichip data from chip ident
N * @numchips:		[INTERN] number of physical chips
N * @chipsize:		[INTERN] the size of one chip for multichip arrays
N * @pagemask:		[INTERN] page number mask = number of (pages / chip) - 1
N * @pagebuf:		[INTERN] holds the pagenumber which is currently in
N *			data_buf.
N * @subpagesize:	[INTERN] holds the subpagesize
N * @onfi_version:	[INTERN] holds the chip ONFI version (BCD encoded),
N *			non 0 if ONFI supported.
N * @onfi_params:	[INTERN] holds the ONFI page parameter when ONFI is
N *			supported, 0 otherwise.
N * @ecclayout:		[REPLACEABLE] the default ecc placement scheme
N * @bbt:		[INTERN] bad block table pointer
N * @bbt_td:		[REPLACEABLE] bad block table descriptor for flash
N *			lookup.
N * @bbt_md:		[REPLACEABLE] bad block table mirror descriptor
N * @badblock_pattern:	[REPLACEABLE] bad block scan pattern used for initial
N *			bad block scan.
N * @controller:		[REPLACEABLE] a pointer to a hardware controller
N *			structure which is shared among multiple independend
N *			devices.
N * @priv:		[OPTIONAL] pointer to private chip date
N * @errstat:		[OPTIONAL] hardware specific function to perform
N *			additional error status checks (determine if errors are
N *			correctable).
N * @write_page:		[REPLACEABLE] High-level page write function
N */
N
Nstruct nand_chip {
N	void __iomem *IO_ADDR_R;
X	void  *IO_ADDR_R;
N	void __iomem *IO_ADDR_W;
X	void  *IO_ADDR_W;
N
N	uint8_t (*read_byte)(struct mtd_info *mtd);
N	u16 (*read_word)(struct mtd_info *mtd);
N	void (*write_buf)(struct mtd_info *mtd, const uint8_t *buf, int len);
N	void (*read_buf)(struct mtd_info *mtd, uint8_t *buf, int len);
N	int (*verify_buf)(struct mtd_info *mtd, const uint8_t *buf, int len);
N	void (*select_chip)(struct mtd_info *mtd, int chip);
N	int (*block_bad)(struct mtd_info *mtd, loff_t ofs, int getchip);
N	int (*block_markbad)(struct mtd_info *mtd, loff_t ofs);
N	void (*cmd_ctrl)(struct mtd_info *mtd, int dat, unsigned int ctrl);
N	int (*init_size)(struct mtd_info *mtd, struct nand_chip *this,
N			u8 *id_data);
N	int (*dev_ready)(struct mtd_info *mtd);
N	void (*cmdfunc)(struct mtd_info *mtd, unsigned command, int column,
N			int page_addr);
N	int(*waitfunc)(struct mtd_info *mtd, struct nand_chip *this);
N	void (*erase_cmd)(struct mtd_info *mtd, int page);
N	int (*scan_bbt)(struct mtd_info *mtd);
N	int (*errstat)(struct mtd_info *mtd, struct nand_chip *this, int state,
N			int status, int page);
N	int (*write_page)(struct mtd_info *mtd, struct nand_chip *chip,
N			const uint8_t *buf, int page, int cached, int raw);
N
N	int chip_delay;
N	unsigned int options;
N
N	int page_shift;
N	int phys_erase_shift;
N	int bbt_erase_shift;
N	int chip_shift;
N	int numchips;
N	uint64_t chipsize;
N	int pagemask;
N	int pagebuf;
N	int subpagesize;
N	uint8_t cellinfo;
N	int badblockpos;
N	int badblockbits;
N
N	int onfi_version;
N#ifdef CONFIG_SYS_NAND_ONFI_DETECTION
S	struct nand_onfi_params onfi_params;
N#endif
N
N	int state;
N
N	uint8_t *oob_poi;
N	struct nand_hw_control *controller;
N	struct nand_ecclayout *ecclayout;
N
N	struct nand_ecc_ctrl ecc;
N	struct nand_buffers *buffers;
N	struct nand_hw_control hwcontrol;
N
N	struct mtd_oob_ops ops;
N
N	uint8_t *bbt;
N	struct nand_bbt_descr *bbt_td;
N	struct nand_bbt_descr *bbt_md;
N
N	struct nand_bbt_descr *badblock_pattern;
N
N	void *priv;
N};
N
N/*
N * NAND Flash Manufacturer ID Codes
N */
N#define NAND_MFR_TOSHIBA	0x98
N#define NAND_MFR_SAMSUNG	0xec
N#define NAND_MFR_FUJITSU	0x04
N#define NAND_MFR_NATIONAL	0x8f
N#define NAND_MFR_RENESAS	0x07
N#define NAND_MFR_STMICRO	0x20
N#define NAND_MFR_HYNIX		0xad
N#define NAND_MFR_MICRON		0x2c
N#define NAND_MFR_AMD		0x01
N
N/**
N * struct nand_flash_dev - NAND Flash Device ID Structure
N * @name:	Identify the device type
N * @id:		device ID code
N * @pagesize:	Pagesize in bytes. Either 256 or 512 or 0
N *		If the pagesize is 0, then the real pagesize
N *		and the eraseize are determined from the
N *		extended id bytes in the chip
N * @erasesize:	Size of an erase block in the flash device.
N * @chipsize:	Total chipsize in Mega Bytes
N * @options:	Bitfield to store chip relevant options
N */
Nstruct nand_flash_dev {
N	char *name;
N	int id;
N	unsigned long pagesize;
N	unsigned long chipsize;
N	unsigned long erasesize;
N	unsigned long options;
N};
N
N/**
N * struct nand_manufacturers - NAND Flash Manufacturer ID Structure
N * @name:	Manufacturer name
N * @id:		manufacturer ID code of device.
N*/
Nstruct nand_manufacturers {
N	int id;
N	char *name;
N};
N
Nextern const struct nand_flash_dev nand_flash_ids[];
Nextern const struct nand_manufacturers nand_manuf_ids[];
N
Nextern int nand_scan_bbt(struct mtd_info *mtd, struct nand_bbt_descr *bd);
Nextern int nand_update_bbt(struct mtd_info *mtd, loff_t offs);
Nextern int nand_default_bbt(struct mtd_info *mtd);
Nextern int nand_isbad_bbt(struct mtd_info *mtd, loff_t offs, int allowbbt);
Nextern int nand_erase_nand(struct mtd_info *mtd, struct erase_info *instr,
N			   int allowbbt);
Nextern int nand_do_read(struct mtd_info *mtd, loff_t from, size_t len,
N			size_t *retlen, uint8_t *buf);
N
N/*
N* Constants for oob configuration
N*/
N#define NAND_SMALL_BADBLOCK_POS		5
N#define NAND_LARGE_BADBLOCK_POS		0
N
N/**
N * struct platform_nand_chip - chip level device structure
N * @nr_chips:		max. number of chips to scan for
N * @chip_offset:	chip number offset
N * @nr_partitions:	number of partitions pointed to by partitions (or zero)
N * @partitions:		mtd partition list
N * @chip_delay:		R/B delay value in us
N * @options:		Option flags, e.g. 16bit buswidth
N * @ecclayout:		ecc layout info structure
N * @part_probe_types:	NULL-terminated array of probe types
N * @priv:		hardware controller specific settings
N */
Nstruct platform_nand_chip {
N	int nr_chips;
N	int chip_offset;
N	int nr_partitions;
N	struct mtd_partition *partitions;
N	struct nand_ecclayout *ecclayout;
N	int chip_delay;
N	unsigned int options;
N	const char **part_probe_types;
N	void *priv;
N};
N
N/* Keep gcc happy */
Nstruct platform_device;
N
N/**
N * struct platform_nand_ctrl - controller level device structure
N * @hwcontrol:		platform specific hardware control structure
N * @dev_ready:		platform specific function to read ready/busy pin
N * @select_chip:	platform specific chip select function
N * @cmd_ctrl:		platform specific function for controlling
N *			ALE/CLE/nCE. Also used to write command and address
N * @priv:		private data to transport driver specific settings
N *
N * All fields are optional and depend on the hardware driver requirements
N */
Nstruct platform_nand_ctrl {
N	void (*hwcontrol)(struct mtd_info *mtd, int cmd);
N	int (*dev_ready)(struct mtd_info *mtd);
N	void (*select_chip)(struct mtd_info *mtd, int chip);
N	void (*cmd_ctrl)(struct mtd_info *mtd, int dat, unsigned int ctrl);
N	void *priv;
N};
N
N/**
N * struct platform_nand_data - container structure for platform-specific data
N * @chip:		chip level chip structure
N * @ctrl:		controller level device structure
N */
Nstruct platform_nand_data {
N	struct platform_nand_chip chip;
N	struct platform_nand_ctrl ctrl;
N};
N
N/* Some helpers to access the data structures */
Nstatic __inline
Nstruct platform_nand_chip *get_platform_nandchip(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N
N	return chip->priv;
N}
N
N/* Standard NAND functions from nand_base.c */
Nvoid nand_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len);
Nvoid nand_write_buf16(struct mtd_info *mtd, const uint8_t *buf, int len);
Nvoid nand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len);
Nvoid nand_read_buf16(struct mtd_info *mtd, uint8_t *buf, int len);
Nuint8_t nand_read_byte(struct mtd_info *mtd);
N
N#endif /* __LINUX_MTD_NAND_H */
L 44 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "linux\nand_ecc.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\nand_ecc.h" 1
N/*
N *  drivers/mtd/nand_ecc.h
N *
N *  Copyright (C) 2000 Steven J. Hill (sjhill@realitydiluted.com)
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License version 2 as
N * published by the Free Software Foundation.
N *
N * This file is the header for the ECC algorithm.
N */
N
N#ifndef __MTD_NAND_ECC_H__
N#define __MTD_NAND_ECC_H__
N
Nstruct mtd_info;
N
N/*
N * Calculate 3 byte ECC code for 256 byte block
N */
Nint nand_calculate_ecc(struct mtd_info *mtd, const u_char *dat, u_char *ecc_code);
N
N/*
N * Detect and correct a 1 bit error for 256 byte block
N */
Nint nand_correct_data(struct mtd_info *mtd, u_char *dat, u_char *read_ecc, u_char *calc_ecc);
N
N#endif /* __MTD_NAND_ECC_H__ */
L 45 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "linux\nand_bch.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\nand_bch.h" 1
N/*
N * Copyright © 2011 Ivan Djelic <ivan.djelic@parrot.com>
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License version 2 as
N * published by the Free Software Foundation.
N *
N * This file is the header for the NAND BCH ECC implementation.
N */
N
N#ifndef __MTD_NAND_BCH_H__
N#define __MTD_NAND_BCH_H__
N
Nstruct mtd_info;
Nstruct nand_bch_control;
N
N#if defined(CONFIG_NAND_ECC_BCH)
X#if 0L
S
Sstatic __inline int mtd_nand_has_bch(void) { return 1; }
S
S/*
S * Calculate BCH ecc code
S */
Sint nand_bch_calculate_ecc(struct mtd_info *mtd, const u_char *dat,
S			   u_char *ecc_code);
S
S/*
S * Detect and correct bit errors
S */
Sint nand_bch_correct_data(struct mtd_info *mtd, u_char *dat, u_char *read_ecc,
S			  u_char *calc_ecc);
S/*
S * Initialize BCH encoder/decoder
S */
Sstruct nand_bch_control *
Snand_bch_init(struct mtd_info *mtd, unsigned int eccsize,
S	      unsigned int eccbytes, struct nand_ecclayout **ecclayout);
S/*
S * Release BCH encoder/decoder resources
S */
Svoid nand_bch_free(struct nand_bch_control *nbc);
S
N#else /* !CONFIG_NAND_ECC_BCH */
N
Nstatic __inline int mtd_nand_has_bch(void) { return 0; }
N
Nstatic __inline int
Nnand_bch_calculate_ecc(struct mtd_info *mtd, const u_char *dat,
N		       u_char *ecc_code)
N{
N	return -1;
N}
N
Nstatic __inline int
Nnand_bch_correct_data(struct mtd_info *mtd, unsigned char *buf,
N		      unsigned char *read_ecc, unsigned char *calc_ecc)
N{
N	return -1;
N}
N
Nstatic __inline struct nand_bch_control *
Nnand_bch_init(struct mtd_info *mtd, unsigned int eccsize,
N	      unsigned int eccbytes, struct nand_ecclayout **ecclayout)
N{
N	return NULL;
X	return 0;
N}
N
Nstatic __inline void nand_bch_free(struct nand_bch_control *nbc) {}
N
N#endif /* CONFIG_NAND_ECC_BCH */
N
N#endif /* __MTD_NAND_BCH_H__ */
L 46 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N
N#include "linux\partitions.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\partitions.h" 1
N/*
N * MTD partitioning layer definitions
N *
N * (C) 2000 Nicolas Pitre <nico@cam.org>
N *
N * This code is GPL
N *
N * $Id: partitions.h,v 1.17 2005/11/07 11:14:55 gleixner Exp $
N */
N
N#ifndef MTD_PARTITIONS_H
N#define MTD_PARTITIONS_H
N
N#include "linux\types.h"
N
N
N/*
N * Partition definition structure:
N *
N * An array of struct partition is passed along with a MTD object to
N * add_mtd_partitions() to create them.
N *
N * For each partition, these fields are available:
N * name: string that will be used to label the partition's MTD device.
N * size: the partition size; if defined as MTDPART_SIZ_FULL, the partition
N * 	will extend to the end of the master MTD device.
N * offset: absolute starting position within the master MTD device; if
N * 	defined as MTDPART_OFS_APPEND, the partition will start where the
N * 	previous one ended; if MTDPART_OFS_NXTBLK, at the next erase block.
N * mask_flags: contains flags that have to be masked (removed) from the
N * 	master MTD flag set for the corresponding MTD partition.
N * 	For example, to force a read-only partition, simply adding
N * 	MTD_WRITEABLE to the mask_flags will do the trick.
N *
N * Note: writeable partitions require their size and offset be
N * erasesize aligned (e.g. use MTDPART_OFS_NEXTBLK).
N */
N
Nstruct mtd_partition {
N	char *name;			/* identifier string */
N	uint64_t size;			/* partition size */
N	uint64_t offset;		/* offset within the master MTD space */
N	u_int32_t mask_flags;		/* master MTD flags to mask out for this partition */
N	struct nand_ecclayout *ecclayout;	/* out of band layout for this partition (NAND only)*/
N	struct mtd_info **mtdp;		/* pointer to store the MTD object */
N};
N
N#define MTDPART_OFS_NXTBLK	(-2)
N#define MTDPART_OFS_APPEND	(-1)
N#define MTDPART_SIZ_FULL	(0)
N
N
Nint add_mtd_partitions(struct mtd_info *, const struct mtd_partition *, int);
Nint del_mtd_partitions(struct mtd_info *);
N
N#if 0
S/*
S * Functions dealing with the various ways of partitioning the space
S */
S
Sstruct mtd_part_parser {
S	struct list_head list;
S	struct module *owner;
S	const char *name;
S	int (*parse_fn)(struct mtd_info *, struct mtd_partition **, unsigned long);
S};
S
Sextern int register_mtd_parser(struct mtd_part_parser *parser);
Sextern int deregister_mtd_parser(struct mtd_part_parser *parser);
Sextern int parse_mtd_partitions(struct mtd_info *master, const char **types,
S				struct mtd_partition **pparts, unsigned long origin);
S
S#define put_partition_parser(p) do { module_put((p)->owner); } while(0)
S
Sstruct device;
Sstruct device_node;
S
Sint __devinit of_mtd_parse_partitions(struct device *dev,
S				      struct mtd_info *mtd,
S				      struct device_node *node,
S				      struct mtd_partition **pparts);
N#endif
N
N#endif
L 48 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N
N#include "asm\io.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm\io.h" 1
N/*
N *  linux/include/asm-arm/io.h
N *
N *  Copyright (C) 1996-2000 Russell King
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License version 2 as
N * published by the Free Software Foundation.
N *
N * Modifications:
N *  16-Sep-1996	RMK	Inlined the inx/outx functions & optimised for both
N *			constant addresses and variable addresses.
N *  04-Dec-1997	RMK	Moved a lot of this stuff to the new architecture
N *			specific IO header files.
N *  27-Mar-1999	PJB	Second parameter of memcpy_toio is const..
N *  04-Apr-1999	PJB	Added check_signature.
N *  12-Dec-1999	RMK	More cleanups
N *  18-Jun-2000 RMK	Removed virt_to_* and friends definitions
N */
N#ifndef __ASM_ARM_IO_H
N#define __ASM_ARM_IO_H
N
N#ifdef __KERNEL__
S
S#include <linux/types.h>
S#include <asm/byteorder.h>
S#include <asm/memory.h>
S#if 0	/* XXX###XXX */
S#include <asm/arch/hardware.h>
S#endif	/* XXX###XXX */
S
Sstatic inline void sync(void)
S{
S}
S
S/*
S * Given a physical address and a length, return a virtual address
S * that can be used to access the memory range with the caching
S * properties specified by "flags".
S */
S#define MAP_NOCACHE	(0)
S#define MAP_WRCOMBINE	(0)
S#define MAP_WRBACK	(0)
S#define MAP_WRTHROUGH	(0)
S
Sstatic inline void *
Smap_physmem(phys_addr_t paddr, unsigned long len, unsigned long flags)
S{
S	return (void *)paddr;
S}
S
S/*
S * Take down a mapping set up by map_physmem().
S */
Sstatic inline void unmap_physmem(void *vaddr, unsigned long flags)
S{
S
S}
S
Sstatic inline phys_addr_t virt_to_phys(void * vaddr)
S{
S	return (phys_addr_t)(vaddr);
S}
S
S/*
S * Generic virtual read/write.  Note that we don't support half-word
S * read/writes.  We define __arch_*[bl] here, and leave __arch_*w
S * to the architecture specific code.
S */
S#define __arch_getb(a)			(*(volatile unsigned char *)(a))
S#define __arch_getw(a)			(*(volatile unsigned short *)(a))
S#define __arch_getl(a)			(*(volatile unsigned int *)(a))
S
S#define __arch_putb(v,a)		(*(volatile unsigned char *)(a) = (v))
S#define __arch_putw(v,a)		(*(volatile unsigned short *)(a) = (v))
S#define __arch_putl(v,a)		(*(volatile unsigned int *)(a) = (v))
S
Sextern inline void __raw_writesb(unsigned int addr, const void *data, int bytelen)
S{
S	uint8_t *buf = (uint8_t *)data;
S	while(bytelen--)
S		__arch_putb(*buf++, addr);
S}
S
Sextern inline void __raw_writesw(unsigned int addr, const void *data, int wordlen)
S{
S	uint16_t *buf = (uint16_t *)data;
S	while(wordlen--)
S		__arch_putw(*buf++, addr);
S}
S
Sextern inline void __raw_writesl(unsigned int addr, const void *data, int longlen)
S{
S	uint32_t *buf = (uint32_t *)data;
S	while(longlen--)
S		__arch_putl(*buf++, addr);
S}
S
Sextern inline void __raw_readsb(unsigned int addr, void *data, int bytelen)
S{
S	uint8_t *buf = (uint8_t *)data;
S	while(bytelen--)
S		*buf++ = __arch_getb(addr);
S}
S
Sextern inline void __raw_readsw(unsigned int addr, void *data, int wordlen)
S{
S	uint16_t *buf = (uint16_t *)data;
S	while(wordlen--)
S		*buf++ = __arch_getw(addr);
S}
S
Sextern inline void __raw_readsl(unsigned int addr, void *data, int longlen)
S{
S	uint32_t *buf = (uint32_t *)data;
S	while(longlen--)
S		*buf++ = __arch_getl(addr);
S}
S
S#define __raw_writeb(v,a)	__arch_putb(v,a)
S#define __raw_writew(v,a)	__arch_putw(v,a)
S#define __raw_writel(v,a)	__arch_putl(v,a)
S
S#define __raw_readb(a)		__arch_getb(a)
S#define __raw_readw(a)		__arch_getw(a)
S#define __raw_readl(a)		__arch_getl(a)
S
S/*
S * TODO: The kernel offers some more advanced versions of barriers, it might
S * have some advantages to use them instead of the simple one here.
S */
S#define dmb()		__asm__ __volatile__ ("" : : : "memory")
S#define __iormb()	dmb()
S#define __iowmb()	dmb()
S
S#define writeb(v,c)	({ u8  __v = v; __iowmb(); __arch_putb(__v,c); __v; })
S#define writew(v,c)	({ u16 __v = v; __iowmb(); __arch_putw(__v,c); __v; })
S#define writel(v,c)	({ u32 __v = v; __iowmb(); __arch_putl(__v,c); __v; })
S
S#define readb(c)	({ u8  __v = __arch_getb(c); __iormb(); __v; })
S#define readw(c)	({ u16 __v = __arch_getw(c); __iormb(); __v; })
S#define readl(c)	({ u32 __v = __arch_getl(c); __iormb(); __v; })
S
S/*
S * The compiler seems to be incapable of optimising constants
S * properly.  Spell it out to the compiler in some cases.
S * These are only valid for small values of "off" (< 1<<12)
S */
S#define __raw_base_writeb(val,base,off)	__arch_base_putb(val,base,off)
S#define __raw_base_writew(val,base,off)	__arch_base_putw(val,base,off)
S#define __raw_base_writel(val,base,off)	__arch_base_putl(val,base,off)
S
S#define __raw_base_readb(base,off)	__arch_base_getb(base,off)
S#define __raw_base_readw(base,off)	__arch_base_getw(base,off)
S#define __raw_base_readl(base,off)	__arch_base_getl(base,off)
S
S/*
S * Clear and set bits in one shot. These macros can be used to clear and
S * set multiple bits in a register using a single call. These macros can
S * also be used to set a multiple-bit bit pattern using a mask, by
S * specifying the mask in the 'clear' parameter and the new bit pattern
S * in the 'set' parameter.
S */
S
S#define out_arch(type,endian,a,v)	__raw_write##type(cpu_to_##endian(v),a)
S#define in_arch(type,endian,a)		endian##_to_cpu(__raw_read##type(a))
S
S#define out_le32(a,v)	out_arch(l,le32,a,v)
S#define out_le16(a,v)	out_arch(w,le16,a,v)
S
S#define in_le32(a)	in_arch(l,le32,a)
S#define in_le16(a)	in_arch(w,le16,a)
S
S#define out_be32(a,v)	out_arch(l,be32,a,v)
S#define out_be16(a,v)	out_arch(w,be16,a,v)
S
S#define in_be32(a)	in_arch(l,be32,a)
S#define in_be16(a)	in_arch(w,be16,a)
S
S#define out_8(a,v)	__raw_writeb(v,a)
S#define in_8(a)		__raw_readb(a)
S
S#define clrbits(type, addr, clear) \
S	out_##type((addr), in_##type(addr) & ~(clear))
X#define clrbits(type, addr, clear) 	out_##type((addr), in_##type(addr) & ~(clear))
S
S#define setbits(type, addr, set) \
S	out_##type((addr), in_##type(addr) | (set))
X#define setbits(type, addr, set) 	out_##type((addr), in_##type(addr) | (set))
S
S#define clrsetbits(type, addr, clear, set) \
S	out_##type((addr), (in_##type(addr) & ~(clear)) | (set))
X#define clrsetbits(type, addr, clear, set) 	out_##type((addr), (in_##type(addr) & ~(clear)) | (set))
S
S#define clrbits_be32(addr, clear) clrbits(be32, addr, clear)
S#define setbits_be32(addr, set) setbits(be32, addr, set)
S#define clrsetbits_be32(addr, clear, set) clrsetbits(be32, addr, clear, set)
S
S#define clrbits_le32(addr, clear) clrbits(le32, addr, clear)
S#define setbits_le32(addr, set) setbits(le32, addr, set)
S#define clrsetbits_le32(addr, clear, set) clrsetbits(le32, addr, clear, set)
S
S#define clrbits_be16(addr, clear) clrbits(be16, addr, clear)
S#define setbits_be16(addr, set) setbits(be16, addr, set)
S#define clrsetbits_be16(addr, clear, set) clrsetbits(be16, addr, clear, set)
S
S#define clrbits_le16(addr, clear) clrbits(le16, addr, clear)
S#define setbits_le16(addr, set) setbits(le16, addr, set)
S#define clrsetbits_le16(addr, clear, set) clrsetbits(le16, addr, clear, set)
S
S#define clrbits_8(addr, clear) clrbits(8, addr, clear)
S#define setbits_8(addr, set) setbits(8, addr, set)
S#define clrsetbits_8(addr, clear, set) clrsetbits(8, addr, clear, set)
S
S/*
S * Now, pick up the machine-defined IO definitions
S */
S#if 0	/* XXX###XXX */
S#include <asm/arch/io.h>
S#endif	/* XXX###XXX */
S
S/*
S *  IO port access primitives
S *  -------------------------
S *
S * The ARM doesn't have special IO access instructions; all IO is memory
S * mapped.  Note that these are defined to perform little endian accesses
S * only.  Their primary purpose is to access PCI and ISA peripherals.
S *
S * Note that for a big endian machine, this implies that the following
S * big endian mode connectivity is in place, as described by numerous
S * ARM documents:
S *
S *    PCI:  D0-D7   D8-D15 D16-D23 D24-D31
S *    ARM: D24-D31 D16-D23  D8-D15  D0-D7
S *
S * The machine specific io.h include defines __io to translate an "IO"
S * address to a memory address.
S *
S * Note that we prevent GCC re-ordering or caching values in expressions
S * by introducing sequence points into the in*() definitions.  Note that
S * __raw_* do not guarantee this behaviour.
S *
S * The {in,out}[bwl] macros are for emulating x86-style PCI/ISA IO space.
S */
S#ifdef __io
S#define outb(v,p)			__raw_writeb(v,__io(p))
S#define outw(v,p)			__raw_writew(cpu_to_le16(v),__io(p))
S#define outl(v,p)			__raw_writel(cpu_to_le32(v),__io(p))
S
S#define inb(p)	({ unsigned int __v = __raw_readb(__io(p)); __v; })
S#define inw(p)	({ unsigned int __v = le16_to_cpu(__raw_readw(__io(p))); __v; })
S#define inl(p)	({ unsigned int __v = le32_to_cpu(__raw_readl(__io(p))); __v; })
S
S#define outsb(p,d,l)			__raw_writesb(__io(p),d,l)
S#define outsw(p,d,l)			__raw_writesw(__io(p),d,l)
S#define outsl(p,d,l)			__raw_writesl(__io(p),d,l)
S
S#define insb(p,d,l)			__raw_readsb(__io(p),d,l)
S#define insw(p,d,l)			__raw_readsw(__io(p),d,l)
S#define insl(p,d,l)			__raw_readsl(__io(p),d,l)
S#endif
S
S#define outb_p(val,port)		outb((val),(port))
S#define outw_p(val,port)		outw((val),(port))
S#define outl_p(val,port)		outl((val),(port))
S#define inb_p(port)			inb((port))
S#define inw_p(port)			inw((port))
S#define inl_p(port)			inl((port))
S
S#define outsb_p(port,from,len)		outsb(port,from,len)
S#define outsw_p(port,from,len)		outsw(port,from,len)
S#define outsl_p(port,from,len)		outsl(port,from,len)
S#define insb_p(port,to,len)		insb(port,to,len)
S#define insw_p(port,to,len)		insw(port,to,len)
S#define insl_p(port,to,len)		insl(port,to,len)
S
S/*
S * ioremap and friends.
S *
S * ioremap takes a PCI memory address, as specified in
S * linux/Documentation/IO-mapping.txt.  If you want a
S * physical address, use __ioremap instead.
S */
Sextern void * __ioremap(unsigned long offset, size_t size, unsigned long flags);
Sextern void __iounmap(void *addr);
S
S/*
S * Generic ioremap support.
S *
S * Define:
S *  iomem_valid_addr(off,size)
S *  iomem_to_phys(off)
S */
S#ifdef iomem_valid_addr
S#define __arch_ioremap(off,sz,nocache)					\
S ({									\
S	unsigned long _off = (off), _size = (sz);			\
S	void *_ret = (void *)0;						\
S	if (iomem_valid_addr(_off, _size))				\
S		_ret = __ioremap(iomem_to_phys(_off),_size,nocache);	\
S	_ret;								\
S })
X#define __arch_ioremap(off,sz,nocache)					 ({										unsigned long _off = (off), _size = (sz);				void *_ret = (void *)0;							if (iomem_valid_addr(_off, _size))						_ret = __ioremap(iomem_to_phys(_off),_size,nocache);		_ret;								 })
S
S#define __arch_iounmap __iounmap
S#endif
S
S#define ioremap(off,sz)			__arch_ioremap((off),(sz),0)
S#define ioremap_nocache(off,sz)		__arch_ioremap((off),(sz),1)
S#define iounmap(_addr)			__arch_iounmap(_addr)
S
S/*
S * DMA-consistent mapping functions.  These allocate/free a region of
S * uncached, unwrite-buffered mapped memory space for use with DMA
S * devices.  This is the "generic" version.  The PCI specific version
S * is in pci.h
S */
Sextern void *consistent_alloc(int gfp, size_t size, dma_addr_t *handle);
Sextern void consistent_free(void *vaddr, size_t size, dma_addr_t handle);
Sextern void consistent_sync(void *vaddr, size_t size, int rw);
S
S/*
S * String version of IO memory access ops:
S */
Sextern void _memcpy_fromio(void *, unsigned long, size_t);
Sextern void _memcpy_toio(unsigned long, const void *, size_t);
Sextern void _memset_io(unsigned long, int, size_t);
S
Sextern void __readwrite_bug(const char *fn);
S
S/*
S * If this architecture has PCI memory IO, then define the read/write
S * macros.  These should only be used with the cookie passed from
S * ioremap.
S */
S#ifdef __mem_pci
S
S#define readb(c) ({ unsigned int __v = __raw_readb(__mem_pci(c)); __v; })
S#define readw(c) ({ unsigned int __v = le16_to_cpu(__raw_readw(__mem_pci(c))); __v; })
S#define readl(c) ({ unsigned int __v = le32_to_cpu(__raw_readl(__mem_pci(c))); __v; })
S
S#define writeb(v,c)		__raw_writeb(v,__mem_pci(c))
S#define writew(v,c)		__raw_writew(cpu_to_le16(v),__mem_pci(c))
S#define writel(v,c)		__raw_writel(cpu_to_le32(v),__mem_pci(c))
S
S#define memset_io(c,v,l)		_memset_io(__mem_pci(c),(v),(l))
S#define memcpy_fromio(a,c,l)		_memcpy_fromio((a),__mem_pci(c),(l))
S#define memcpy_toio(c,a,l)		_memcpy_toio(__mem_pci(c),(a),(l))
S
S#define eth_io_copy_and_sum(s,c,l,b) \
S				eth_copy_and_sum((s),__mem_pci(c),(l),(b))
X#define eth_io_copy_and_sum(s,c,l,b) 				eth_copy_and_sum((s),__mem_pci(c),(l),(b))
S
Sstatic inline int
Scheck_signature(unsigned long io_addr, const unsigned char *signature,
S		int length)
S{
S	int retval = 0;
S	do {
S		if (readb(io_addr) != *signature)
S			goto out;
S		io_addr++;
S		signature++;
S		length--;
S	} while (length);
S	retval = 1;
Sout:
S	return retval;
S}
S
S#elif !defined(readb)
S
S#define readb(addr)			(__readwrite_bug("readb"),0)
S#define readw(addr)			(__readwrite_bug("readw"),0)
S#define readl(addr)			(__readwrite_bug("readl"),0)
S#define writeb(v,addr)			__readwrite_bug("writeb")
S#define writew(v,addr)			__readwrite_bug("writew")
S#define writel(v,addr)			__readwrite_bug("writel")
S
S#define eth_io_copy_and_sum(a,b,c,d)	__readwrite_bug("eth_io_copy_and_sum")
S
S#define check_signature(io,sig,len)	(0)
S
S#endif	/* __mem_pci */
S
S/*
S * If this architecture has ISA IO, then define the isa_read/isa_write
S * macros.
S */
S#ifdef __mem_isa
S
S#define isa_readb(addr)			__raw_readb(__mem_isa(addr))
S#define isa_readw(addr)			__raw_readw(__mem_isa(addr))
S#define isa_readl(addr)			__raw_readl(__mem_isa(addr))
S#define isa_writeb(val,addr)		__raw_writeb(val,__mem_isa(addr))
S#define isa_writew(val,addr)		__raw_writew(val,__mem_isa(addr))
S#define isa_writel(val,addr)		__raw_writel(val,__mem_isa(addr))
S#define isa_memset_io(a,b,c)		_memset_io(__mem_isa(a),(b),(c))
S#define isa_memcpy_fromio(a,b,c)	_memcpy_fromio((a),__mem_isa(b),(c))
S#define isa_memcpy_toio(a,b,c)		_memcpy_toio(__mem_isa((a)),(b),(c))
S
S#define isa_eth_io_copy_and_sum(a,b,c,d) \
S				eth_copy_and_sum((a),__mem_isa(b),(c),(d))
X#define isa_eth_io_copy_and_sum(a,b,c,d) 				eth_copy_and_sum((a),__mem_isa(b),(c),(d))
S
Sstatic inline int
Sisa_check_signature(unsigned long io_addr, const unsigned char *signature,
S		    int length)
S{
S	int retval = 0;
S	do {
S		if (isa_readb(io_addr) != *signature)
S			goto out;
S		io_addr++;
S		signature++;
S		length--;
S	} while (length);
S	retval = 1;
Sout:
S	return retval;
S}
S
S#else	/* __mem_isa */
S
S#define isa_readb(addr)			(__readwrite_bug("isa_readb"),0)
S#define isa_readw(addr)			(__readwrite_bug("isa_readw"),0)
S#define isa_readl(addr)			(__readwrite_bug("isa_readl"),0)
S#define isa_writeb(val,addr)		__readwrite_bug("isa_writeb")
S#define isa_writew(val,addr)		__readwrite_bug("isa_writew")
S#define isa_writel(val,addr)		__readwrite_bug("isa_writel")
S#define isa_memset_io(a,b,c)		__readwrite_bug("isa_memset_io")
S#define isa_memcpy_fromio(a,b,c)	__readwrite_bug("isa_memcpy_fromio")
S#define isa_memcpy_toio(a,b,c)		__readwrite_bug("isa_memcpy_toio")
S
S#define isa_eth_io_copy_and_sum(a,b,c,d) \
S				__readwrite_bug("isa_eth_io_copy_and_sum")
X#define isa_eth_io_copy_and_sum(a,b,c,d) 				__readwrite_bug("isa_eth_io_copy_and_sum")
S
S#define isa_check_signature(io,sig,len)	(0)
S
S#endif	/* __mem_isa */
N#endif	/* __KERNEL__ */
N#endif	/* __ASM_ARM_IO_H */
L 50 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "asm\errno.h"
N#include "asm\bitops.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm\bitops.h" 1
N/*
N * Copyright 1995, Russell King.
N * Various bits and pieces copyrights include:
N *  Linus Torvalds (test_bit).
N *
N * bit 0 is the LSB of addr; bit 32 is the LSB of (addr+1).
N *
N * Please note that the code in this file should never be included
N * from user space.  Many of these are not implemented in assembler
N * since they would be too costly.  Also, they require priviledged
N * instructions (which are not available from user mode) to ensure
N * that they are atomic.
N */
N
N#ifndef __ASM_ARM_BITOPS_H
N#define __ASM_ARM_BITOPS_H
N
N
N/*
N * hweightN: returns the hamming weight (i.e. the number
N * of bits set) of a N-bit word
N */
N
N#define hweight32(x) generic_hweight32(x)
N#define hweight16(x) generic_hweight16(x)
N#define hweight8(x) generic_hweight8(x)
N
N
N#ifdef __KERNEL__
S
S#include <asm/proc/system.h>
S
S#define smp_mb__before_clear_bit()	do { } while (0)
S#define smp_mb__after_clear_bit()	do { } while (0)
S
S/*
S * Function prototypes to keep gcc -Wall happy.
S */
Sextern void set_bit(int nr, volatile void * addr);
S
Sextern void clear_bit(int nr, volatile void * addr);
S
Sextern void change_bit(int nr, volatile void * addr);
S
Sstatic __inline void __change_bit(int nr, volatile void *addr)
S{
S	unsigned long mask = BIT_MASK(nr);
S	unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr);
S
S	*p ^= mask;
S}
S
Sstatic __inline int __test_and_set_bit(int nr, volatile void *addr)
S{
S	unsigned long mask = BIT_MASK(nr);
S	unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr);
S	unsigned long old = *p;
S
S	*p = old | mask;
S	return (old & mask) != 0;
S}
S
Sstatic inline int test_and_set_bit(int nr, volatile void * addr)
S{
S	unsigned long flags;
S	int out;
S
S	local_irq_save(flags);
S	out = __test_and_set_bit(nr, addr);
S	local_irq_restore(flags);
S
S	return out;
S}
S
Sstatic inline int __test_and_clear_bit(int nr, volatile void *addr)
S{
S	unsigned long mask = BIT_MASK(nr);
S	unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr);
S	unsigned long old = *p;
S
S	*p = old & ~mask;
S	return (old & mask) != 0;
S}
S
Sstatic inline int test_and_clear_bit(int nr, volatile void * addr)
S{
S	unsigned long flags;
S	int out;
S
S	local_irq_save(flags);
S	out = __test_and_clear_bit(nr, addr);
S	local_irq_restore(flags);
S
S	return out;
S}
S
Sextern int test_and_change_bit(int nr, volatile void * addr);
S
Sstatic inline int __test_and_change_bit(int nr, volatile void *addr)
S{
S	unsigned long mask = BIT_MASK(nr);
S	unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr);
S	unsigned long old = *p;
S
S	*p = old ^ mask;
S	return (old & mask) != 0;
S}
S
Sextern int find_first_zero_bit(void * addr, unsigned size);
Sextern int find_next_zero_bit(void * addr, int size, int offset);
S
S/*
S * This routine doesn't need to be atomic.
S */
Sstatic inline int test_bit(int nr, const void * addr)
S{
S    return ((unsigned char *) addr)[nr >> 3] & (1U << (nr & 7));
S}
S
Sstatic inline int __ilog2(unsigned int x)
S{
S	return generic_fls(x) - 1;
S}
S
S/*
S * ffz = Find First Zero in word. Undefined if no zero exists,
S * so code should check against ~0UL first..
S */
Sstatic inline unsigned long ffz(unsigned long word)
S{
S	int k;
S
S	word = ~word;
S	k = 31;
S	if (word & 0x0000ffff) { k -= 16; word <<= 16; }
S	if (word & 0x00ff0000) { k -= 8;  word <<= 8;  }
S	if (word & 0x0f000000) { k -= 4;  word <<= 4;  }
S	if (word & 0x30000000) { k -= 2;  word <<= 2;  }
S	if (word & 0x40000000) { k -= 1; }
S	return k;
S}
S
S/*
S * hweightN: returns the hamming weight (i.e. the number
S * of bits set) of a N-bit word
S */
S
S#define hweight32(x) generic_hweight32(x)
S#define hweight16(x) generic_hweight16(x)
S#define hweight8(x) generic_hweight8(x)
S
S#define ext2_set_bit			test_and_set_bit
S#define ext2_clear_bit			test_and_clear_bit
S#define ext2_test_bit			test_bit
S#define ext2_find_first_zero_bit	find_first_zero_bit
S#define ext2_find_next_zero_bit		find_next_zero_bit
S
S/* Bitmap functions for the minix filesystem. */
S#define minix_test_and_set_bit(nr,addr)	test_and_set_bit(nr,addr)
S#define minix_set_bit(nr,addr)		set_bit(nr,addr)
S#define minix_test_and_clear_bit(nr,addr)	test_and_clear_bit(nr,addr)
S#define minix_test_bit(nr,addr)		test_bit(nr,addr)
S#define minix_find_first_zero_bit(addr,size)	find_first_zero_bit(addr,size)
S
N#endif /* __KERNEL__ */
N
N#endif /* _ARM_BITOPS_H */
L 52 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "linux\bitops.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\bitops.h" 1
N#ifndef _LINUX_BITOPS_H
N#define _LINUX_BITOPS_H
N
N#include "asm/types.h"
N
N/*
N * ffs: find first bit set. This is defined the same way as
N * the libc and compiler builtin ffs routines, therefore
N * differs in spirit from the above ffz (man ffs).
N */
N
Nstatic __inline int generic_ffs(int x)
N{
N	int r = 1;
N
N	if (!x)
N		return 0;
N	if (!(x & 0xffff)) {
N		x >>= 16;
N		r += 16;
N	}
N	if (!(x & 0xff)) {
N		x >>= 8;
N		r += 8;
N	}
N	if (!(x & 0xf)) {
N		x >>= 4;
N		r += 4;
N	}
N	if (!(x & 3)) {
N		x >>= 2;
N		r += 2;
N	}
N	if (!(x & 1)) {
N		x >>= 1;
N		r += 1;
N	}
N	return r;
N}
N
N/**
N * fls - find last (most-significant) bit set
N * @x: the word to search
N *
N * This is defined the same way as ffs.
N * Note fls(0) = 0, fls(1) = 1, fls(0x80000000) = 32.
N */
Nstatic __inline int generic_fls(int x)
N{
N	int r = 32;
N
N	if (!x)
N		return 0;
N	if (!(x & 0xffff0000u)) {
N		x <<= 16;
N		r -= 16;
N	}
N	if (!(x & 0xff000000u)) {
N		x <<= 8;
N		r -= 8;
N	}
N	if (!(x & 0xf0000000u)) {
N		x <<= 4;
N		r -= 4;
N	}
N	if (!(x & 0xc0000000u)) {
N		x <<= 2;
N		r -= 2;
N	}
N	if (!(x & 0x80000000u)) {
N		x <<= 1;
N		r -= 1;
N	}
N	return r;
N}
N
N
N/*
N * hweightN: returns the hamming weight (i.e. the number
N * of bits set) of a N-bit word
N */
N
Nstatic __inline unsigned int generic_hweight32(unsigned int w)
N{
N	unsigned int res = (w & 0x55555555) + ((w >> 1) & 0x55555555);
N	res = (res & 0x33333333) + ((res >> 2) & 0x33333333);
N	res = (res & 0x0F0F0F0F) + ((res >> 4) & 0x0F0F0F0F);
N	res = (res & 0x00FF00FF) + ((res >> 8) & 0x00FF00FF);
N	return (res & 0x0000FFFF) + ((res >> 16) & 0x0000FFFF);
N}
N
Nstatic __inline unsigned int generic_hweight16(unsigned int w)
N{
N	unsigned int res = (w & 0x5555) + ((w >> 1) & 0x5555);
N	res = (res & 0x3333) + ((res >> 2) & 0x3333);
N	res = (res & 0x0F0F) + ((res >> 4) & 0x0F0F);
N	return (res & 0x00FF) + ((res >> 8) & 0x00FF);
N}
N
Nstatic __inline unsigned int generic_hweight8(unsigned int w)
N{
N	unsigned int res = (w & 0x55) + ((w >> 1) & 0x55);
N	res = (res & 0x33) + ((res >> 2) & 0x33);
N	return (res & 0x0F) + ((res >> 4) & 0x0F);
N}
N
N#define BITS_PER_LONG 32
N#define BIT_MASK(nr)		(1UL << ((nr) % BITS_PER_LONG))
N#define BIT_WORD(nr)		((nr) / BITS_PER_LONG)
N
N#include "asm/bitops.h"
N
N/* linux/include/asm-generic/bitops/non-atomic.h */
N
N#ifndef PLATFORM__SET_BIT
N# define __set_bit generic_set_bit
N#endif
N
N#ifndef PLATFORM__CLEAR_BIT
N# define __clear_bit generic_clear_bit
N#endif
N
N#ifndef PLATFORM_FFS
N# define ffs generic_ffs
N#endif
N
N#ifndef PLATFORM_FLS
N# define fls generic_fls
N#endif
N
N/**
N * __set_bit - Set a bit in memory
N * @nr: the bit to set
N * @addr: the address to start counting from
N *
N * Unlike set_bit(), this function is non-atomic and may be reordered.
N * If it's called on the same region of memory simultaneously, the effect
N * may be that only one operation succeeds.
N */
Nstatic __inline void generic_set_bit(int nr, volatile unsigned long *addr)
N{
N	unsigned long mask = BIT_MASK(nr);
X	unsigned long mask = (1UL << ((nr) % 32));
N	unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr);
X	unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
N
N	*p  |= mask;
N}
N
Nstatic __inline void generic_clear_bit(int nr, volatile unsigned long *addr)
N{
N	unsigned long mask = BIT_MASK(nr);
X	unsigned long mask = (1UL << ((nr) % 32));
N	unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr);
X	unsigned long *p = ((unsigned long *)addr) + ((nr) / 32);
N
N	*p &= ~mask;
N}
N
N#endif
L 53 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N#include "nuc970.h"
L 1 "..\..\common\src\BSP\Driver\Include\nuc970.h" 1
N/**************************************************************************//**
N * @file     nuc970.h
N * @version  V1.00
N * $Revision: 30 $
N * $Date: 15/06/12 2:51p $
N * @brief    NUC970 peripheral access layer header file.
N *           This file contains all the peripheral register's definitions
N *           and memory mapping for NuMicro NUC970 MCU.
N *
N * @note
N * Copyright (C) 2015 Nuvoton Technology Corp. All rights reserved.
N *****************************************************************************/
N/**
N   \mainpage NuMicro NUC970 Family Driver Reference Guide
N   *
N   * <b>Introduction</b>
N   *
N   * This user manual describes the usage of NUC970 family device driver
N   *
N   * <b>Disclaimer</b>
N   *
N   * The Software is furnished "AS IS", without warranty as to performance or results, and
N   * the entire risk as to performance or results is assumed by YOU. Nuvoton disclaims all
N   * warranties, express, implied or otherwise, with regard to the Software, its use, or
N   * operation, including without limitation any and all warranties of merchantability, fitness
N   * for a particular purpose, and non-infringement of intellectual property rights.
N   *
N   * <b>Important Notice</b>
N   *
N   * Nuvoton Products are neither intended nor warranted for usage in systems or equipment,
N   * any malfunction or failure of which may cause loss of human life, bodily injury or severe
N   * property damage. Such applications are deemed, "Insecure Usage".
N   *
N   * Insecure usage includes, but is not limited to: equipment for surgical implementation,
N   * atomic energy control instruments, airplane or spaceship instruments, the control or
N   * operation of dynamic, brake or safety systems designed for vehicular use, traffic signal
N   * instruments, all types of safety devices, and other applications intended to support or
N   * sustain life.
N   *
N   * All Insecure Usage shall be made at customer's risk, and in the event that third parties
N   * lay claims to Nuvoton as a result of customer's Insecure Usage, customer shall indemnify
N   * the damages and liabilities thus incurred by Nuvoton.
N   *
N   * Please note that all data and specifications are subject to change without notice. All the
N   * trademarks of products and companies mentioned in this document belong to their respective
N   * owners.
N   *
N   * <b>Copyright Notice</b>
N   *
N   * Copyright (C) 2015 Nuvoton Technology Corp. All rights reserved.
N   */
N/**
N  * \page pg1 Revision History
N  *
N  * <b>Revision 1.00.000</b>
N  * \li Added 2D, CAN, CAP, JPEG, KPI, LCD, NAND, RTC, SC, SCUART drivers and sample codes
N  * \li Added USBH UAC class support
N  * \li Fixed compilation warnings
N  *
N  * <b>Revision 0.09.000</b>
N  * \li Preliminary release.
N*/
N#ifndef __NUC970_H__
N#define __NUC970_H__
N
N#include <stdint.h>
N
N/** @addtogroup NUC970_PERIPHERAL_MEM_MAP NUC970 Peripheral Memory Base
N  Memory Mapped Structure for NUC970 Peripheral
N  @{
N */
N
N/*!< AHB peripherals */
N#define    SYS_BA    0xB0000000  /*!< System Global Control */
N#define    CLK_BA    0xB0000200  /*!< Clock Control */
N#define    EBI_BA    0xB0001000  /*!< EBI Control */
N#define    SDIC_BA   0xB0001800  /*!< SDRAM (SDR/DDR/DDR2) Control */
N#define    EMC0_BA   0xB0002000  /*!< Ethernet MAC 0 Control */
N#define    EMC1_BA   0xB0003000  /*!< Ethernet MAC 1 Control */
N#define    GDMA_BA   0xB0004000  /*!< GDMA control */
N#define    USBH_BA   0xB0005000  /*!< USB Host EHCI Control */
N#define    USBD_BA   0xB0006000  /*!< USB Device Control */
N#define    USBO_BA   0xB0007000  /*!< OHCI USB Host Control */
N#define    LCM_BA    0xB0008000  /*!< Display, LCM Interface */
N#define    ACTL_BA   0xB0009000  /*!< Audio Control */
N#define    JPEG_BA   0xB000A000  /*!< JPEG Engine Control */
N#define    GE_BA     0xB000B000  /*!< 2-D Graphic Engine */
N#define    SDH_BA    0xB000C000  /*!< SD/SDIO Host Controller */
N#define    FMI_BA    0xB000D000  /*!< Flash Memory Card Interface */
N#define    CAP_BA    0xB000E000  /*!< Sensor (Capture) Interface Control */
N#define    CRPT_BA   0xB000F000  /*!< Crypto Engine Control */
N
N/*!< APB peripherals */
N#define    UART0_BA  0xB8000000  /*!< UART0 Control */
N#define    UART1_BA  0xB8000100  /*!< UART1 Control (High-Speed UART) */
N#define    UART2_BA  0xB8000200  /*!< UART2 Control (High-Speed UART) */
N#define    UART3_BA  0xB8000300  /*!< UART3 Control  */
N#define    UART4_BA  0xB8000400  /*!< UART4 Control (High-Speed UART) */
N#define    UART5_BA  0xB8000500  /*!< UART5 Control */
N#define    UART6_BA  0xB8000600  /*!< UART6 Control (High-Speed UART) */
N#define    UART7_BA  0xB8000700  /*!< UART7 Control */
N#define    UART8_BA  0xB8000800  /*!< UART8 Control (High-Speed UART) */
N#define    UART9_BA  0xB8000900  /*!< UART9 Control */
N#define    UARTA_BA  0xB8000A00  /*!< UARTA Control (High-Speed UART) */
N#define    TMR0_BA   0xB8001000  /*!< Timer 0 */
N#define    TMR1_BA   0xB8001010  /*!< Timer 1 */
N#define    TMR2_BA   0xB8001020  /*!< Timer 2 */
N#define    TMR3_BA   0xB8001030  /*!< Timer 3 */
N#define    TMR4_BA   0xB8001040  /*!< Timer 4 */
N#define    ETMR0_BA  0xB8001400  /*!< Enhanced Timer 0 */
N#define    ETMR1_BA  0xB8001500  /*!< Enhanced Timer 1 */
N#define    ETMR2_BA  0xB8001600  /*!< Enhanced Timer 2 */
N#define    ETMR3_BA  0xB8001700  /*!< Enhanced Timer 3 */
N#define    WDT_BA    0xB8001800  /*!< Watch Dog Timer */
N#define    WWDT_BA   0xB8001900  /*!< Window Watch Dog Timer */
N#define    AIC_BA    0xB8002000  /*!< Interrupt Controller */
N#define    GPIO_BA   0xB8003000  /*!< GPIO Control */
N#define    RTC_BA    0xB8004000  /*!< Real Time Clock Control */
N#define    SC0_BA    0xB8005000  /*!< Smart Card 0 Control */
N#define    SC1_BA    0xB8005400  /*!< Smart Card 1 Control */
N#define    I2C0_BA   0xB8006000  /*!< I2C 0 Control */
N#define    I2C1_BA   0xB8006100  /*!< I2C 1 Control */
N#define    SPI0_BA   0xB8006200  /*!< Serial Peripheral Interface 0 */
N#define    SPI1_BA   0xB8006300  /*!< Serial Peripheral Interface 1 */
N#define    PWM_BA    0xB8007000  /*!< Pulse Width Modulation (PWM) Control */
N#define    KPI_BA    0xB8008000  /*!< Keypad Interface Control */
N#define    ADC_BA    0xB800A000  /*!< ADC Control */
N#define    CAN0_BA   0xB800B000  /*!< CAN 0 Control */
N#define    CAN1_BA   0xB800B400  /*!< CAN 1 Control */
N#define    MTP_BA    0xB800C000  /*!< MTP Control */
N
N/*@}*/ /* end of group NUC970_PERIPHERAL_MEM_MAP */
N
N/******************************************************************************/
N/*                Device Specific Peripheral registers structures             */
N/******************************************************************************/
N/** @addtogroup NUC970_Peripherals NUC970 Control Register
N  NUC970 Device Specific Peripheral registers structures
N  @{
N*/
N
N/*---------------------- System Manger Controller -------------------------*/
N/**
N    @addtogroup SYS System Manger Controller(SYS)
N    Memory Mapped Structure for SYS Controller
N@{ */
N
N#define    REG_SYS_PDID         (SYS_BA+0x000)  /*!< Product Identifier Register */
N#define    REG_SYS_PWRON        (SYS_BA+0x004)  /*!< Power-On Setting Register */
N#define    REG_SYS_ARBCON       (SYS_BA+0x008)  /*!< Arbitration Control Register */
N#define    REG_SYS_LVRDCR       (SYS_BA+0x020)  /*!< Low Voltage Reset & Detect Control Register */
N#define    REG_SYS_MISCFCR      (SYS_BA+0x030)  /*!< Miscellaneous Function Control Register */
N#define    REG_SYS_MISCIER      (SYS_BA+0x040)  /*!< Miscellaneous Interrupt Enable Register */
N#define    REG_SYS_MISCISR      (SYS_BA+0x044)  /*!< Miscellaneous Interrupt Status Register */
N#define    REG_SYS_WKUPSER      (SYS_BA+0x058)  /*!< System Wakeup Source Enable Register */
N#define    REG_SYS_WKUPSSR      (SYS_BA+0x05C)  /*!< System Wakeup Source Status Register */
N#define    REG_SYS_AHBIPRST     (SYS_BA+0x060)  /*!< AHB IP Reset Control Register */
N#define    REG_SYS_APBIPRST0    (SYS_BA+0x064)  /*!< APB IP Reset Control Register 0 */
N#define    REG_SYS_APBIPRST1    (SYS_BA+0x068)  /*!< APB IP Reset Control Register 1 */
N#define    REG_SYS_RSTSTS       (SYS_BA+0x06C)  /*!< Reset Source Active Status Register */
N#define    REG_SYS_GPA_MFPL     (SYS_BA+0x070)  /*!< GPIOA Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPA_MFPH     (SYS_BA+0x074)  /*!< GPIOA High Byte Multiple Function Control Register */
N#define    REG_SYS_GPB_MFPL     (SYS_BA+0x078)  /*!< GPIOB Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPB_MFPH     (SYS_BA+0x07C)  /*!< GPIOB High Byte Multiple Function Control Register */
N#define    REG_SYS_GPC_MFPL     (SYS_BA+0x080)  /*!< GPIOC Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPC_MFPH     (SYS_BA+0x084)  /*!< GPIOC High Byte Multiple Function Control Register */
N#define    REG_SYS_GPD_MFPL     (SYS_BA+0x088)  /*!< GPIOD Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPD_MFPH     (SYS_BA+0x08C)  /*!< GPIOD High Byte Multiple Function Control Register */
N#define    REG_SYS_GPE_MFPL     (SYS_BA+0x090)  /*!< GPIOE Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPE_MFPH     (SYS_BA+0x094)  /*!< GPIOE High Byte Multiple Function Control Register */
N#define    REG_SYS_GPF_MFPL     (SYS_BA+0x098)  /*!< GPIOF Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPF_MFPH     (SYS_BA+0x09C)  /*!< GPIOF High Byte Multiple Function Control Register */
N#define    REG_SYS_GPG_MFPL     (SYS_BA+0x0A0)  /*!< GPIOG Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPG_MFPH     (SYS_BA+0x0A4)  /*!< GPIOG High Byte Multiple Function Control Register */
N#define    REG_SYS_GPH_MFPL     (SYS_BA+0x0A8)  /*!< GPIOH Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPH_MFPH     (SYS_BA+0x0AC)  /*!< GPIOH High Byte Multiple Function Control Register */
N#define    REG_SYS_GPI_MFPL     (SYS_BA+0x0B0)  /*!< GPIOI Low Byte Multiple Function Control Register */
N#define    REG_SYS_GPI_MFPH     (SYS_BA+0x0B4)  /*!< GPIOI High Byte Multiple Function Control Register */
N#define    REG_SYS_GPJ_MFPL     (SYS_BA+0x0B8)  /*!< GPIOJ Low Byte Multiple Function Control Register */
N#define    REG_SYS_DDR_DSCTL    (SYS_BA+0x0F0)  /*!< DDR I/O Driving Strength Control Register */
N#define    REG_SYS_PORDISCR     (SYS_BA+0x100)  /*!< Power-On-Reset Disable Control Register */
N#define    REG_SYS_ICEDBGCR     (SYS_BA+0x104)  /*!< ICE Debug Interface Control Register */
N#define    REG_SYS_ERRADDCR     (SYS_BA+0x108)  /*!< Error Response Address Control Regsiter */
N#define    REG_SYS_REGWPCTL     (SYS_BA+0x1FC)  /*!< Register Write-Protection Control Register */
N
N/**@}*/ /* end of SYS register group */
N
N/*---------------------- System Clock Controller -------------------------*/
N/**
N    @addtogroup CLK System Clock Controller(CLK)
N    Memory Mapped Structure for CLK Controller
N@{ */
N
N#define    REG_CLK_PMCON        (CLK_BA+0x00) /*!< Power Management Control Register */
N#define    REG_CLK_HCLKEN       (CLK_BA+0x10) /*!< AHB IP Clock Enable Control Register */
N#define    REG_CLK_PCLKEN0      (CLK_BA+0x18) /*!< APB IP Clock Enable Control Register 0 */
N#define    REG_CLK_PCLKEN1      (CLK_BA+0x1C) /*!< APB IP Clock Enable Control Register 1 */
N#define    REG_CLK_DIVCTL0      (CLK_BA+0x20) /*!< Clock Divider Control Register 0 */
N#define    REG_CLK_DIVCTL1      (CLK_BA+0x24) /*!< Clock Divider Control Register 1 */
N#define    REG_CLK_DIVCTL2      (CLK_BA+0x28) /*!< Clock Divider Control Register 2 */
N#define    REG_CLK_DIVCTL3      (CLK_BA+0x2C) /*!< Clock Divider Control Register 3 */
N#define    REG_CLK_DIVCTL4      (CLK_BA+0x30) /*!< Clock Divider Control Register 4 */
N#define    REG_CLK_DIVCTL5      (CLK_BA+0x34) /*!< Clock Divider Control Register 5 */
N#define    REG_CLK_DIVCTL6      (CLK_BA+0x38) /*!< Clock Divider Control Register 6 */
N#define    REG_CLK_DIVCTL7      (CLK_BA+0x3C) /*!< Clock Divider Control Register 7 */
N#define    REG_CLK_DIVCTL8      (CLK_BA+0x40) /*!< Clock Divider Control Register 8 */
N#define    REG_CLK_DIVCTL9      (CLK_BA+0x44) /*!< Clock Divider Control Register 9 */
N#define    REG_CLK_APLLCON      (CLK_BA+0x60) /*!< APLL Control Register */
N#define    REG_CLK_UPLLCON      (CLK_BA+0x64) /*!< UPLL Control Register */
N#define    REG_CLK_PLLSTBCNTR   (CLK_BA+0x80) /*!< PLL Stable Counter and Test Clock Control Register */
N
N/**@}*/ /* end of CLK register group */
N
N
N/*---------------------- External Bus Interface Controller -------------------------*/
N/**
N    @addtogroup EBI External Bus Interface Controller(EBI)
N    Memory Mapped Structure for EBI Controller
N@{ */
N
N#define    REG_EBI_CTL          (EBI_BA+0x000)  /*!< EBI control register */
N#define    REG_EBI_BNKCTL0      (EBI_BA+0x018)  /*!< External I/O 0 control register */
N#define    REG_EBI_BNKCTL1      (EBI_BA+0x01C)  /*!< External I/O 1 control register */
N#define    REG_EBI_BNKCTL2      (EBI_BA+0x020)  /*!< External I/O 2 control register */
N#define    REG_EBI_BNKCTL3      (EBI_BA+0x024)  /*!< External I/O 3 control register */
N#define    REG_EBI_BNKCTL4      (EBI_BA+0x028)  /*!< External I/O 4 control register */
N
N/**@}*/ /* end of EBI register group */
N
N
N/*---------------------- Ethernet MAC Controller -------------------------*/
N/**
N    @addtogroup EMAC Ethernet MAC Controller(EMAC)
N    Memory Mapped Structure for EMAC Controller
N@{ */
N
N#define     REG_EMAC0_CAMCMR      (EMC0_BA+0x000) /*!< CAM Command Register */
N#define     REG_EMAC0_CAMEN       (EMC0_BA+0x004) /*!< CAM Enable Register */
N#define     REG_EMAC0_CAM0M       (EMC0_BA+0x008)  /*!< CAM0 Most Significant Word Register */
N#define     REG_EMAC0_CAM0L       (EMC0_BA+0x00c)  /*!< CAM0 Least Significant Word Register */
N#define     REG_EMAC0_CAMxM_Reg(x)(REG_EMAC0_CAM0M+(x)*0x8)  /*!< CAMx Most Significant Word Register */
N#define     REG_EMAC0_CAMxL_Reg(x)(REG_EMAC0_CAM0L+(x)*0x8)  /*!< CAMx Least Significant Word Register */
N#define     REG_EMAC0_TXDLSA      (EMC0_BA+0x088) /*!< Transmit Descriptor Link List Start Address Register */
N#define     REG_EMAC0_RXDLSA      (EMC0_BA+0x08C) /*!< Receive Descriptor Link List Start Address Register */
N#define     REG_EMAC0_MCMDR       (EMC0_BA+0x090) /*!< MAC Command Register */
N#define     REG_EMAC0_MIID        (EMC0_BA+0x094) /*!< MII Management Data Register */
N#define     REG_EMAC0_MIIDA       (EMC0_BA+0x098) /*!< MII Management Control and Address Register */
N#define     REG_EMAC0_FFTCR       (EMC0_BA+0x09C) /*!< FIFO Threshold Control Register */
N#define     REG_EMAC0_TSDR        (EMC0_BA+0x0a0) /*!< Transmit Start Demand Register */
N#define     REG_EMAC0_RSDR        (EMC0_BA+0x0a4) /*!< Receive Start Demand Register */
N#define     REG_EMAC0_DMARFC      (EMC0_BA+0x0a8) /*!< Maximum Receive Frame Control Register */
N#define     REG_EMAC0_MIEN        (EMC0_BA+0x0ac) /*!< MAC Interrupt Enable Register */
N#define     REG_EMAC0_MISTA       (EMC0_BA+0x0b0) /*!< MAC Interrupt Status Register */
N#define     REG_EMAC0_MGSTA       (EMC0_BA+0x0b4) /*!< MAC General Status Register */
N#define     REG_EMAC0_MPCNT       (EMC0_BA+0x0b8) /*!< Missed Packet Count Register */
N#define     REG_EMAC0_MRPC        (EMC0_BA+0x0bc) /*!< MAC Receive Pause Count Register */
N#define     REG_EMAC0_DMARFS      (EMC0_BA+0x0c8) /*!< DMA Receive Frame Status Register */
N#define     REG_EMAC0_CTXDSA      (EMC0_BA+0x0cc) /*!< Current Transmit Descriptor Start Address Register */
N#define     REG_EMAC0_CTXBSA      (EMC0_BA+0x0d0) /*!< Current Transmit Buffer Start Address Register */
N#define     REG_EMAC0_CRXDSA      (EMC0_BA+0x0d4) /*!< Current Receive Descriptor Start Address Register */
N#define     REG_EMAC0_CRXBSA      (EMC0_BA+0x0d8) /*!< Current Receive Buffer Start Address Register */
N#define     REG_EMAC0_TSCTL       (EMC0_BA+0x100) /*!< Time Stamp Control Register */
N#define     REG_EMAC0_TSSEC       (EMC0_BA+0x110) /*!< Time Stamp Counter Second Register */
N#define     REG_EMAC0_TSSUBSEC    (EMC0_BA+0x114) /*!< Time Stamp Counter Sub Second Register */
N#define     REG_EMAC0_TSINC       (EMC0_BA+0x118) /*!< Time Stamp Increment Register  */
N#define     REG_EMAC0_TSADDEN     (EMC0_BA+0x11c) /*!< Time Stamp Addend Register */
N#define     REG_EMAC0_TSUPDSEC    (EMC0_BA+0x120) /*!< Time Stamp Update Second Register */
N#define     REG_EMAC0_TSUPDSUBSEC (EMC0_BA+0x124) /*!< Time Stamp Update Sub Second Register */
N#define     REG_EMAC0_TSALMSEC    (EMC0_BA+0x128) /*!< Time Stamp Alarm Second Register */
N#define     REG_EMAC0_TSALMSUBSEC (EMC0_BA+0x12c) /*!< Time Stamp Alarm Sub Second Register */
N
N#define     REG_EMAC1_CAMCMR      (EMC1_BA+0x000) /*!< CAM Command Register */
N#define     REG_EMAC1_CAMEN       (EMC1_BA+0x004) /*!< CAM Enable Register */
N#define     REG_EMAC1_CAM0M       (EMC1_BA+0x008)  /*!< CAM0 Most Significant Word Register */
N#define     REG_EMAC1_CAM0L       (EMC1_BA+0x00c)  /*!< CAM0 Least Significant Word Register */
N#define     REG_EMAC1_CAMxM_Reg(x)(REG_EMAC1_CAM0M+(x)*0x8)  /*!< CAMx Most Significant Word Register */
N#define     REG_EMAC1_CAMxL_Reg(x)(REG_EMAC1_CAM0L+(x)*0x8)  /*!< CAMx Least Significant Word Register */
N#define     REG_EMAC1_TXDLSA      (EMC1_BA+0x088) /*!< Transmit Descriptor Link List Start Address Register */
N#define     REG_EMAC1_RXDLSA      (EMC1_BA+0x08C) /*!< Receive Descriptor Link List Start Address Register */
N#define     REG_EMAC1_MCMDR       (EMC1_BA+0x090) /*!< MAC Command Register */
N#define     REG_EMAC1_MIID        (EMC1_BA+0x094) /*!< MII Management Data Register */
N#define     REG_EMAC1_MIIDA       (EMC1_BA+0x098) /*!< MII Management Control and Address Register */
N#define     REG_EMAC1_FFTCR       (EMC1_BA+0x09C) /*!< FIFO Threshold Control Register */
N#define     REG_EMAC1_TSDR        (EMC1_BA+0x0a0) /*!< Transmit Start Demand Register */
N#define     REG_EMAC1_RSDR        (EMC1_BA+0x0a4) /*!< Receive Start Demand Register */
N#define     REG_EMAC1_DMARFC      (EMC1_BA+0x0a8) /*!< Maximum Receive Frame Control Register */
N#define     REG_EMAC1_MIEN        (EMC1_BA+0x0ac) /*!< MAC Interrupt Enable Register */
N#define     REG_EMAC1_MISTA       (EMC1_BA+0x0b0) /*!< MAC Interrupt Status Register */
N#define     REG_EMAC1_MGSTA       (EMC1_BA+0x0b4) /*!< MAC General Status Register */
N#define     REG_EMAC1_MPCNT       (EMC1_BA+0x0b8) /*!< Missed Packet Count Register */
N#define     REG_EMAC1_MRPC        (EMC1_BA+0x0bc) /*!< MAC Receive Pause Count Register */
N#define     REG_EMAC1_DMARFS      (EMC1_BA+0x0c8) /*!< DMA Receive Frame Status Register */
N#define     REG_EMAC1_CTXDSA      (EMC1_BA+0x0cc) /*!< Current Transmit Descriptor Start Address Register */
N#define     REG_EMAC1_CTXBSA      (EMC1_BA+0x0d0) /*!< Current Transmit Buffer Start Address Register */
N#define     REG_EMAC1_CRXDSA      (EMC1_BA+0x0d4) /*!< Current Receive Descriptor Start Address Register */
N#define     REG_EMAC1_CRXBSA      (EMC1_BA+0x0d8) /*!< Current Receive Buffer Start Address Register */
N#define     REG_EMAC1_TSCTL       (EMC1_BA+0x100) /*!< Time Stamp Control Register */
N#define     REG_EMAC1_TSSEC       (EMC1_BA+0x110) /*!< Time Stamp Counter Second Register */
N#define     REG_EMAC1_TSSUBSEC    (EMC1_BA+0x114) /*!< Time Stamp Counter Sub Second Register */
N#define     REG_EMAC1_TSINC       (EMC1_BA+0x118) /*!< Time Stamp Increment Register  */
N#define     REG_EMAC1_TSADDEN     (EMC1_BA+0x11c) /*!< Time Stamp Addend Register */
N#define     REG_EMAC1_TSUPDSEC    (EMC1_BA+0x120) /*!< Time Stamp Update Second Register */
N#define     REG_EMAC1_TSUPDSUBSEC (EMC1_BA+0x124) /*!< Time Stamp Update Sub Second Register */
N#define     REG_EMAC1_TSALMSEC    (EMC1_BA+0x128) /*!< Time Stamp Alarm Second Register */
N#define     REG_EMAC1_TSALMSUBSEC (EMC1_BA+0x12c) /*!< Time Stamp Alarm Sub Second Register */
N
N/**@}*/ /* end of EMAC register group */
N
N/*----------------------  General Direct Memory Access Controller -------------------------*/
N/**
N    @addtogroup GDMA  General Direct Memory Access Controller(GDMA)
N    Memory Mapped Structure for GDMA Controller
N@{ */
N
N#define     REG_GDMA_CTL0   (GDMA_BA+0x000)  /*!< Channel 0 Control Register */
N#define     REG_GDMA_SRCB0  (GDMA_BA+0x004)  /*!< Channel 0 Source Base Address Register */
N#define     REG_GDMA_DSTB0  (GDMA_BA+0x008)  /*!< Channel 0 Destination Base Address Register */
N#define     REG_GDMA_TCNT0  (GDMA_BA+0x00C)  /*!< Channel 0 Transfer Count Register */
N#define     REG_GDMA_CSRC0  (GDMA_BA+0x010)  /*!< Channel 0 Current Source Address Register */
N#define     REG_GDMA_CDST0  (GDMA_BA+0x014)  /*!< Channel 0 Current Destination Address Register */
N#define     REG_GDMA_CTCNT0 (GDMA_BA+0x018)  /*!< Channel 0 Current Transfer Count Register */
N#define     REG_GDMA_DADR0  (GDMA_BA+0x01C)  /*!< Channel 0 Descriptor Address Register */
N#define     REG_GDMA_CTL1   (GDMA_BA+0x020)  /*!< Channel 1 Control Register */
N#define     REG_GDMA_SRCB1  (GDMA_BA+0x024)  /*!< Channel 1 Source Base Address Register */
N#define     REG_GDMA_DSTB1  (GDMA_BA+0x028)  /*!< Channel 1 Destination Base Address Register */
N#define     REG_GDMA_TCNT1  (GDMA_BA+0x02C)  /*!< Channel 1 Transfer Count Register */
N#define     REG_GDMA_CSRC1  (GDMA_BA+0x030)  /*!< Channel 1 Current Source Address Register */
N#define     REG_GDMA_CDST1  (GDMA_BA+0x034)  /*!< Channel 1 Current Destination Address Register */
N#define     REG_GDMA_CTCNT1 (GDMA_BA+0x038)  /*!< Channel 1 Current Transfer Count Register */
N#define     REG_GDMA_DADR1  (GDMA_BA+0x03C)  /*!< Channel 1 Descriptor Address Register */
N#define     REG_GDMA_INTBUF0    (GDMA_BA+0x080)  /*!< GDMA Internal Buffer Word 0 */
N#define     REG_GDMA_INTBUF1    (GDMA_BA+0x084)  /*!< GDMA Internal Buffer Word 1 */
N#define     REG_GDMA_INTBUF2    (GDMA_BA+0x088)  /*!< GDMA Internal Buffer Word 2 */
N#define     REG_GDMA_INTBUF3    (GDMA_BA+0x08C)  /*!< GDMA Internal Buffer Word 3 */
N#define     REG_GDMA_INTBUF4    (GDMA_BA+0x090)  /*!< GDMA Internal Buffer Word 4 */
N#define     REG_GDMA_INTBUF5    (GDMA_BA+0x094)  /*!< GDMA Internal Buffer Word 5 */
N#define     REG_GDMA_INTBUF6    (GDMA_BA+0x098)  /*!< GDMA Internal Buffer Word 6 */
N#define     REG_GDMA_INTBUF7    (GDMA_BA+0x09C)  /*!< GDMA Internal Buffer Word 7 */
N#define     REG_GDMA_INTCS  (GDMA_BA+0x0A0)  /*!< Interrupt Control and Status Register */
N
N/**@}*/ /* end of GDMA register group */
N
N
N
N/*---------------------- USB Device Controller -------------------------*/
N/**
N    @addtogroup USBD USB Device Controller(USBD)
N    Memory Mapped Structure for USBD Controller
N@{ */
N#define     REG_USBD_GINTSTS        (USBD_BA+0x00)  /*!< Interrupt Status Low Register */
N#define     REG_USBD_GINTEN         (USBD_BA+0x08)  /*!< Interrupt Enable Low Register */
N#define     REG_USBD_BUSINTSTS      (USBD_BA+0x10)  /*!< USB Bus Interrupt Status Register */
N#define     REG_USBD_BUSINTEN       (USBD_BA+0x14)  /*!< USB Bus Interrupt Enable Register */
N#define     REG_USBD_OPER           (USBD_BA+0x18)  /*!< USB Operational Register */
N#define     REG_USBD_FRAMECNT       (USBD_BA+0x1C)  /*!< USB Frame Count Register */
N#define     REG_USBD_FADDR          (USBD_BA+0x20)  /*!< USB Function Address Register */
N#define     REG_USBD_TEST           (USBD_BA+0x24)  /*!< USB Test Mode Register */
N#define     REG_USBD_CEPDAT         (USBD_BA+0x28)  /*!< Control-ep data buffer register */
N#define     REG_USBD_CEPCTL         (USBD_BA+0x2C)  /*!< Control-ep control and status register */
N#define     REG_USBD_CEPINTEN       (USBD_BA+0x30)  /*!< Control-ep interrupt enable register */
N#define     REG_USBD_CEPINTSTS      (USBD_BA+0x34)  /*!< Control-ep interrupt status register */
N#define     REG_USBD_CEPTXCNT       (USBD_BA+0x38)  /*!< In-transfer data count register */
N#define     REG_USBD_CEPRXCNT       (USBD_BA+0x3C)  /*!< Out-transfer data count register */
N#define     REG_USBD_CEPDATCNT      (USBD_BA+0x40)  /*!< Control-ep data count register */
N#define     REG_USBD_SETUP1_0       (USBD_BA+0x44)  /*!< Setup byte1 & byte0 register */
N#define     REG_USBD_SETUP3_2       (USBD_BA+0x48)  /*!< Setup byte3 & byte2 register */
N#define     REG_USBD_SETUP5_4       (USBD_BA+0x4C)  /*!< Setup byte5 & byte4 register */
N#define     REG_USBD_SETUP7_6       (USBD_BA+0x50)  /*!< Setup byte7 & byte6 register */
N#define     REG_USBD_CEPBUFSTART    (USBD_BA+0x54)  /*!< Control-ep ram start address register */
N#define     REG_USBD_CEPBUFEND      (USBD_BA+0x58)  /*!< Control-ep ram end address register */
N#define     REG_USBD_DMACTL         (USBD_BA+0x5C)  /*!< Dma control and status register */
N#define     REG_USBD_DMACNT         (USBD_BA+0x60)  /*!< Dma count register */
N
N#define     REG_USBD_EPADAT         (USBD_BA+0x64)  /*!< Endpoint A data buffer register */
N#define     REG_USBD_EPAINTSTS      (USBD_BA+0x68)  /*!< Endpoint A interrupt status register */
N#define     REG_USBD_EPAINTEN       (USBD_BA+0x6C)  /*!< Endpoint A interrupt enable register */
N#define     REG_USBD_EPADATCNT      (USBD_BA+0x70)  /*!< Data count available in endpoint A buffer */
N#define     REG_USBD_EPARSPCTL      (USBD_BA+0x74)  /*!< Endpoint A response register set/clear */
N#define     REG_USBD_EPAMPS         (USBD_BA+0x78)  /*!< Endpoint A max packet size register */
N#define     REG_USBD_EPATXCNT       (USBD_BA+0x7C)  /*!< Endpoint A transfer count register */
N#define     REG_USBD_EPACFG         (USBD_BA+0x80)  /*!< Endpoint A configuration register */
N#define     REG_USBD_EPABUFSTART    (USBD_BA+0x84)  /*!< Endpoint A ram start address register */
N#define     REG_USBD_EPABUFEND      (USBD_BA+0x88)  /*!< Endpoint A ram end address register */
N
N#define     REG_USBD_EPBDAT         (USBD_BA+0x8C)  /*!< Endpoint B data buffer register */
N#define     REG_USBD_EPBINTSTS      (USBD_BA+0x90)  /*!< Endpoint B interrupt status register */
N#define     REG_USBD_EPBINTEN       (USBD_BA+0x94)  /*!< Endpoint B interrupt enable register */
N#define     REG_USBD_EPBDATCNT      (USBD_BA+0x98)  /*!< Data count available in endpoint B buffer */
N#define     REG_USBD_EPBRSPCTL      (USBD_BA+0x9C)  /*!< Endpoint B response register set/clear */
N#define     REG_USBD_EPBMPS         (USBD_BA+0xA0)  /*!< Endpoint B max packet size register */
N#define     REG_USBD_EPBTXCNT       (USBD_BA+0xA4)  /*!< Endpoint B transfer count register */
N#define     REG_USBD_EPBCFG         (USBD_BA+0xA8)  /*!< Endpoint B configuration register */
N#define     REG_USBD_EPBBUFSTART    (USBD_BA+0xAC)  /*!< Endpoint B ram start address register */
N#define     REG_USBD_EPBBUFEND      (USBD_BA+0xB0)  /*!< Endpoint B ram end address register */
N
N#define     REG_USBD_EPCDAT         (USBD_BA+0xB4)  /*!< Endpoint C data buffer register */
N#define     REG_USBD_EPCINTSTS      (USBD_BA+0xB8)  /*!< Endpoint C interrupt status register */
N#define     REG_USBD_EPCINTEN       (USBD_BA+0xBC)  /*!< Endpoint C interrupt enable register */
N#define     REG_USBD_EPCDATCNT      (USBD_BA+0xC0)  /*!< Data count available in endpoint C buffer */
N#define     REG_USBD_EPCRSPCTL      (USBD_BA+0xC4)  /*!< Endpoint C response register set/clear */
N#define     REG_USBD_EPCMPS         (USBD_BA+0xC8)  /*!< Endpoint C max packet size register */
N#define     REG_USBD_EPCTXCNT       (USBD_BA+0xCC)  /*!< Endpoint C transfer count register */
N#define     REG_USBD_EPCCFG         (USBD_BA+0xD0)  /*!< Endpoint C configuration register */
N#define     REG_USBD_EPCBUFSTART    (USBD_BA+0xD4)  /*!< Endpoint C ram start address register */
N#define     REG_USBD_EPCBUFEND      (USBD_BA+0xD8)  /*!< Endpoint C ram end address register */
N
N#define     REG_USBD_EPDDAT         (USBD_BA+0xDC)  /*!< Endpoint D data buffer register */
N#define     REG_USBD_EPDINTSTS      (USBD_BA+0xE0)  /*!< Endpoint D interrupt status register */
N#define     REG_USBD_EPDINTEN       (USBD_BA+0xE4)  /*!< Endpoint D interrupt enable register */
N#define     REG_USBD_EPDDATCNT      (USBD_BA+0xE8)  /*!< Data count available in endpoint D buffer */
N#define     REG_USBD_EPDRSPCTL      (USBD_BA+0xEC)  /*!< Endpoint D response register set/clear */
N#define     REG_USBD_EPDMPS         (USBD_BA+0xF0)  /*!< Endpoint D max packet size register */
N#define     REG_USBD_EPDTXCNT       (USBD_BA+0xF4)  /*!< Endpoint D transfer count register */
N#define     REG_USBD_EPDCFG         (USBD_BA+0xF8)  /*!< Endpoint D configuration register */
N#define     REG_USBD_EPDBUFSTART    (USBD_BA+0xFC)  /*!< Endpoint D ram start address register */
N#define     REG_USBD_EPDBUFEND      (USBD_BA+0x100) /*!< Endpoint D ram end address register */
N
N#define     REG_USBD_EPEDAT         (USBD_BA+0x104) /*!< Endpoint E data buffer register */
N#define     REG_USBD_EPEINTSTS      (USBD_BA+0x108) /*!< Endpoint E interrupt status register */
N#define     REG_USBD_EPEINTEN       (USBD_BA+0x10C) /*!< Endpoint E interrupt enable register */
N#define     REG_USBD_EPEDATCNT      (USBD_BA+0x110) /*!< Data count available in endpoint E buffer */
N#define     REG_USBD_EPERSPCTL      (USBD_BA+0x114) /*!< Endpoint E response register set/clear */
N#define     REG_USBD_EPEMPS         (USBD_BA+0x118) /*!< Endpoint E max packet size register */
N#define     REG_USBD_EPETXCNT       (USBD_BA+0x11C) /*!< Endpoint E transfer count register */
N#define     REG_USBD_EPECFG         (USBD_BA+0x120) /*!< Endpoint E configuration register */
N#define     REG_USBD_EPEBUFSTART    (USBD_BA+0x124) /*!< Endpoint E ram start address register */
N#define     REG_USBD_EPEBUFEND      (USBD_BA+0x128) /*!< Endpoint E ram end address register */
N
N#define     REG_USBD_EPFDAT         (USBD_BA+0x12C) /*!< Endpoint F data buffer register */
N#define     REG_USBD_EPFINTSTS      (USBD_BA+0x130) /*!< Endpoint F interrupt status register */
N#define     REG_USBD_EPFINTEN       (USBD_BA+0x134) /*!< Endpoint F interrupt enable register */
N#define     REG_USBD_EPFDATCNT      (USBD_BA+0x138) /*!< Data count available in endpoint F buffer */
N#define     REG_USBD_EPFRSPCTL      (USBD_BA+0x13C) /*!< Endpoint F response register set/clear */
N#define     REG_USBD_EPFMPS         (USBD_BA+0x140) /*!< Endpoint F max packet size register */
N#define     REG_USBD_EPFTXCNT       (USBD_BA+0x144) /*!< Endpoint F transfer count register */
N#define     REG_USBD_EPFCFG         (USBD_BA+0x148) /*!< Endpoint F configuration register */
N#define     REG_USBD_EPFBUFSTART    (USBD_BA+0x14C) /*!< Endpoint F ram start address register */
N#define     REG_USBD_EPFBUFEND      (USBD_BA+0x150) /*!< Endpoint F ram end address register */
N
N#define     REG_USBD_EPGDAT         (USBD_BA+0x154) /*!< Endpoint G data buffer register */
N#define     REG_USBD_EPGINTSTS      (USBD_BA+0x158) /*!< Endpoint G interrupt status register */
N#define     REG_USBD_EPGINTEN       (USBD_BA+0x15C) /*!< Endpoint G interrupt enable register */
N#define     REG_USBD_EPGDATCNT      (USBD_BA+0x160) /*!< Data count available in endpoint G buffer */
N#define     REG_USBD_EPGRSPCTL      (USBD_BA+0x164) /*!< Endpoint G response register set/clear */
N#define     REG_USBD_EPGMPS         (USBD_BA+0x168) /*!< Endpoint G max packet size register */
N#define     REG_USBD_EPGTXCNT       (USBD_BA+0x16C) /*!< Endpoint G transfer count register */
N#define     REG_USBD_EPGCFG         (USBD_BA+0x170) /*!< Endpoint G configuration register */
N#define     REG_USBD_EPGBUFSTART    (USBD_BA+0x174) /*!< Endpoint G ram start address register */
N#define     REG_USBD_EPGBUFEND      (USBD_BA+0x178) /*!< Endpoint G ram end address register */
N
N#define     REG_USBD_EPHDAT         (USBD_BA+0x17C) /*!< Endpoint H data buffer register */
N#define     REG_USBD_EPHINTSTS      (USBD_BA+0x180) /*!< Endpoint H interrupt status register */
N#define     REG_USBD_EPHINTEN       (USBD_BA+0x184) /*!< Endpoint H interrupt enable register */
N#define     REG_USBD_EPHDATCNT      (USBD_BA+0x188) /*!< Data count available in endpoint H buffer */
N#define     REG_USBD_EPHRSPCTL      (USBD_BA+0x18C) /*!< Endpoint H response register set/clear */
N#define     REG_USBD_EPHMPS         (USBD_BA+0x190) /*!< Endpoint H max packet size register */
N#define     REG_USBD_EPHTXCNT       (USBD_BA+0x194) /*!< Endpoint H transfer count register */
N#define     REG_USBD_EPHCFG         (USBD_BA+0x198) /*!< Endpoint H configuration register */
N#define     REG_USBD_EPHBUFSTART    (USBD_BA+0x19C) /*!< Endpoint H ram start address register */
N#define     REG_USBD_EPHBUFEND      (USBD_BA+0x1A0) /*!< Endpoint H ram end address register */
N
N#define     REG_USBD_EPIDAT         (USBD_BA+0x1A4) /*!< Endpoint I data buffer register */
N#define     REG_USBD_EPIINTSTS      (USBD_BA+0x1A8) /*!< Endpoint I interrupt status register */
N#define     REG_USBD_EPIINTEN       (USBD_BA+0x1AC) /*!< Endpoint I interrupt enable register */
N#define     REG_USBD_EPIDATCNT      (USBD_BA+0x1B0) /*!< Data count available in endpoint I buffer */
N#define     REG_USBD_EPIRSPCTL      (USBD_BA+0x1B4) /*!< Endpoint I response register set/clear */
N#define     REG_USBD_EPIMPS         (USBD_BA+0x1B8) /*!< Endpoint I max packet size register */
N#define     REG_USBD_EPITXCNT       (USBD_BA+0x1BC) /*!< Endpoint I transfer count register */
N#define     REG_USBD_EPICFG         (USBD_BA+0x1C0) /*!< Endpoint I configuration register */
N#define     REG_USBD_EPIBUFSTART    (USBD_BA+0x1C4) /*!< Endpoint I ram start address register */
N#define     REG_USBD_EPIBUFEND      (USBD_BA+0x1C8) /*!< Endpoint I ram end address register */
N
N#define     REG_USBD_EPJDAT         (USBD_BA+0x1CC) /*!< Endpoint J data buffer register */
N#define     REG_USBD_EPJINTSTS      (USBD_BA+0x1D0) /*!< Endpoint J interrupt status register */
N#define     REG_USBD_EPJINTEN       (USBD_BA+0x1D4) /*!< Endpoint J interrupt enable register */
N#define     REG_USBD_EPJDATCNT      (USBD_BA+0x1D8) /*!< Data count available in endpoint J buffer */
N#define     REG_USBD_EPJRSPCTL      (USBD_BA+0x1DC) /*!< Endpoint J response register set/clear */
N#define     REG_USBD_EPJMPS         (USBD_BA+0x1E0) /*!< Endpoint J max packet size register */
N#define     REG_USBD_EPJTXCNT       (USBD_BA+0x1E4) /*!< Endpoint J transfer count register */
N#define     REG_USBD_EPJCFG         (USBD_BA+0x1E8) /*!< Endpoint J configuration register */
N#define     REG_USBD_EPJBUFSTART    (USBD_BA+0x1EC) /*!< Endpoint J ram start address register */
N#define     REG_USBD_EPJBUFEND      (USBD_BA+0x1F0) /*!< Endpoint J ram end address register */
N
N#define     REG_USBD_EPKDAT         (USBD_BA+0x1F4) /*!< Endpoint K data buffer register */
N#define     REG_USBD_EPKINTSTS      (USBD_BA+0x1F8) /*!< Endpoint K interrupt status register */
N#define     REG_USBD_EPKINTEN       (USBD_BA+0x1FC) /*!< Endpoint K interrupt enable register */
N#define     REG_USBD_EPKDATCNT      (USBD_BA+0x200) /*!< Data count available in endpoint K buffer */
N#define     REG_USBD_EPKRSPCTL      (USBD_BA+0x204) /*!< Endpoint K response register set/clear */
N#define     REG_USBD_EPKMPS         (USBD_BA+0x208) /*!< Endpoint K max packet size register */
N#define     REG_USBD_EPKTXCNT       (USBD_BA+0x20C) /*!< Endpoint K transfer count register */
N#define     REG_USBD_EPKCFG         (USBD_BA+0x210) /*!< Endpoint K configuration register */
N#define     REG_USBD_EPKBUFSTART    (USBD_BA+0x214) /*!< Endpoint K ram start address register */
N#define     REG_USBD_EPKBUFEND      (USBD_BA+0x218) /*!< Endpoint K ram end address register */
N
N#define     REG_USBD_EPLDAT         (USBD_BA+0x21C) /*!< Endpoint L data buffer register */
N#define     REG_USBD_EPLINTSTS      (USBD_BA+0x220) /*!< Endpoint L interrupt status register */
N#define     REG_USBD_EPLINTEN       (USBD_BA+0x224) /*!< Endpoint L interrupt enable register */
N#define     REG_USBD_EPLDATCNT      (USBD_BA+0x228) /*!< Data count available in endpoint L buffer */
N#define     REG_USBD_EPLRSPCTL      (USBD_BA+0x22C) /*!< Endpoint L response register set/clear */
N#define     REG_USBD_EPLMPS         (USBD_BA+0x230) /*!< Endpoint L max packet size register */
N#define     REG_USBD_EPLTXCNT       (USBD_BA+0x234) /*!< Endpoint L transfer count register */
N#define     REG_USBD_EPLCFG         (USBD_BA+0x238) /*!< Endpoint L configuration register */
N#define     REG_USBD_EPLBUFSTART    (USBD_BA+0x23C) /*!< Endpoint L ram start address register */
N#define     REG_USBD_EPLBUFEND      (USBD_BA+0x240) /*!< Endpoint L ram end address register */
N#define     REG_USBD_DMAADDR        (USBD_BA+0x700) /*!< AHB_DMA address register */
N#define     REG_USBD_PHYCTL         (USBD_BA+0x704) /*!< USB PHY control register */
N
N/**@}*/ /* end of USBD register group */
N
N
N/*----------------------  LCD Display Interface Controller -------------------------*/
N/**
N    @addtogroup LCM  LCD Display Interface Controller(LCM)
N    Memory Mapped Structure for LCM Controller
N@{ */
N
N#define     REG_LCM_DCCS        (LCM_BA+0x00)  /*!< Display Controller Control/Status Register */
N#define     REG_LCM_DEV_CTRL    (LCM_BA+0x04)  /*!< Display Output Device Control Register */
N#define     REG_LCM_MPU_CMD     (LCM_BA+0x08)  /*!< MPU-Interface LCD Write Command */
N#define     REG_LCM_INT_CS      (LCM_BA+0x0c)  /*!< Interrupt Control/Status Register */
N#define     REG_LCM_CRTC_SIZE   (LCM_BA+0x10)  /*!< CRTC Display Size Control Register */
N#define     REG_LCM_CRTC_DEND   (LCM_BA+0x14)  /*!< CRTC Display Enable End */
N#define     REG_LCM_CRTC_HR     (LCM_BA+0x18)  /*!< CRTC Internal Horizontal Retrace Control Register */
N#define     REG_LCM_CRTC_HSYNC  (LCM_BA+0x1C)  /*!< CRTC Horizontal Sync Control Register */
N#define     REG_LCM_CRTC_VR     (LCM_BA+0x20)  /*!< CRTC Internal Vertical Retrace Control Register */
N#define     REG_LCM_VA_BADDR0   (LCM_BA+0x24)  /*!< Video Stream Frame Buffer-0 Starting Address */
N#define     REG_LCM_VA_BADDR1   (LCM_BA+0x28)  /*!< Video Stream Frame Buffer-1 Starting Address */
N#define     REG_LCM_VA_FBCTRL   (LCM_BA+0x2C)  /*!< Video Stream Frame Buffer Control Register */
N#define     REG_LCM_VA_SCALE    (LCM_BA+0x30)  /*!< Video Stream Scaling Control Register */
N#define     REG_LCM_VA_WIN      (LCM_BA+0x38)  /*!< Image Stream Active Window Coordinates */
N#define     REG_LCM_VA_STUFF    (LCM_BA+0x3C)  /*!< Image Stream Stuff Pixel */
N#define     REG_LCM_OSD_WINS    (LCM_BA+0x40)  /*!< OSD Window Starting Coordinates */
N#define     REG_LCM_OSD_WINE    (LCM_BA+0x44)  /*!< OSD Window Ending Coordinates */
N#define     REG_LCM_OSD_BADDR   (LCM_BA+0x48)  /*!< OSD Stream Frame Buffer Starting Address */
N#define     REG_LCM_OSD_FBCTRL  (LCM_BA+0x4c)  /*!< OSD Stream Frame Buffer Control Register */
N#define     REG_LCM_OSD_OVERLAY (LCM_BA+0x50)  /*!< OSD Overlay Control Register */
N#define     REG_LCM_OSD_CKEY    (LCM_BA+0x54)  /*!< OSD Overlay Color-Key Pattern Register */
N#define     REG_LCM_OSD_CMASK   (LCM_BA+0x58)  /*!< OSD Overlay Color-Key Mask Register */
N#define     REG_LCM_OSD_SKIP1   (LCM_BA+0x5C)  /*!< OSD Window Skip1 Register */
N#define     REG_LCM_OSD_SKIP2   (LCM_BA+0x60)  /*!< OSD Window Skip2 Register */
N#define     REG_LCM_OSD_SCALE   (LCM_BA+0x64)  /*!< OSD horizontal up scaling control register */
N#define     REG_LCM_MPU_VSYNC   (LCM_BA+0x68)  /*!< MPU Vsync control register */
N#define     REG_LCM_HC_CTRL     (LCM_BA+0x6C)  /*!< Hardware cursor control Register */
N#define     REG_LCM_HC_POS      (LCM_BA+0x70)  /*!< Hardware cursot tip point potison on va picture */
N#define     REG_LCM_HC_WBCTRL   (LCM_BA+0x74)  /*!< Hardware Cursor Window Buffer Control Register */
N#define     REG_LCM_HC_BADDR    (LCM_BA+0x78)  /*!< Hardware cursor memory base address register */
N#define     REG_LCM_HC_COLOR0   (LCM_BA+0x7C)  /*!< Hardware cursor color ram register mapped to bpp = 0 */
N#define     REG_LCM_HC_COLOR1   (LCM_BA+0x80)  /*!< Hardware cursor color ram register mapped to bpp = 1 */
N#define     REG_LCM_HC_COLOR2   (LCM_BA+0x84)  /*!< Hardware cursor color ram register mapped to bpp = 2 */
N#define     REG_LCM_HC_COLOR3   (LCM_BA+0x88)  /*!< Hardware cursor color ram register mapped to bpp = 3 */
N
N/**@}*/ /* end of LCM register group */
N
N
N/*---------------------- I2S Interface Controller -------------------------*/
N/**
N    @addtogroup I2S I2S Interface Controller(I2S)
N    Memory Mapped Structure for I2S Controller
N@{ */
N
N#define     REG_ACTL_CON            (ACTL_BA+0x00)      /*!< Audio controller control register */
N#define     REG_ACTL_RESET          (ACTL_BA+0x04)      /*!< Sub block reset control register */
N#define     REG_ACTL_RDESB          (ACTL_BA+0x08)      /*!< DMA destination base address register for record */
N#define     REG_ACTL_RDES_LENGTH    (ACTL_BA+0x0C)      /*!< DMA destination length register for record */
N#define     REG_ACTL_RDESC          (ACTL_BA+0x10)      /*!< DMA destination current address for record */
N#define     REG_ACTL_PDESB          (ACTL_BA+0x14)      /*!< DMA destination current address for play */
N#define     REG_ACTL_PDES_LENGTH    (ACTL_BA+0x18)      /*!< DMA destination length register for play */
N#define     REG_ACTL_PDESC          (ACTL_BA+0x1C)      /*!< DMA destination current address register for play */
N#define     REG_ACTL_RSR            (ACTL_BA+0x20)      /*!< Record status register */
N#define     REG_ACTL_PSR            (ACTL_BA+0x24)      /*!< Play status register */
N#define     REG_ACTL_I2SCON         (ACTL_BA+0x28)      /*!< I2S control register */
N#define     REG_ACTL_COUNTER        (ACTL_BA+0x2C)      /*!< DMA count down values */
N#define     REG_ACTL_PCMCON         (ACTL_BA+0x30)      /*!< PCM interface control register */
N#define     REG_ACTL_PCMS1ST        (ACTL_BA+0x34)      /*!< PCM interface slot1 start register */
N#define     REG_ACTL_PCMS2ST        (ACTL_BA+0x38)      /*!< PCM interface slot2 start register */
N#define     REG_ACTL_RDESB2         (ACTL_BA+0x40)      /*!< DMA destination base address register for record right channel */
N#define     REG_ACTL_PDESB2         (ACTL_BA+0x44)      /*!< DMA destination base address register for play right channel */
N
N/**@}*/ /* end of I2S register group */
N
N/*---------------------- 2D Graphic Engine -------------------------*/
N/**
N    @addtogroup GE2D 2D Graphic Engine(GE2D)
N    Memory Mapped Structure for GE2D Controller
N@{ */
N
N#define     REG_GE2D_TRG            (GE_BA+0x00)  /*!< Graphic Engine Trigger Control Register */
N#define     REG_GE2D_XYSORG         (GE_BA+0x04)  /*!< Graphic Engine XY Mode Source Origin Starting Register */
N#define     REG_GE2D_TCNTVHSF       (GE_BA+0x08)  /*!< Graphic Engine Tile Width/Height or V/H Scale Factor N/M */
N#define     REG_GE2D_XYRRP          (GE_BA+0x0C)  /*!< Graphic Engine Rotate Reference Point XY Address */
N#define     REG_GE2D_INTSTS         (GE_BA+0x10)  /*!< Graphic Engine Interrupt Status Register */
N#define     REG_GE2D_PATSA          (GE_BA+0x14)  /*!< Graphic Engine Pattern Location Starting Address Register */
N#define     REG_GE2D_BETSC          (GE_BA+0x18)  /*!< GE Bresenham Error Term Stepping Constant Register */
N#define     REG_GE2D_BIEPC          (GE_BA+0x1C)  /*!< GE Bresenham Initial Error, Pixel Count Major M Register */
N#define     REG_GE2D_CTL            (GE_BA+0x20)  /*!< Graphic Engine Control Register */
N#define     REG_GE2D_BGCOLR         (GE_BA+0x24)  /*!< Graphic Engine Background Color Register */
N#define     REG_GE2D_FGCOLR         (GE_BA+0x28)  /*!< Graphic Engine Foreground Color Register */
N#define     REG_GE2D_TRNSCOLR       (GE_BA+0x2C)  /*!< Graphic Engine Transparency Color Register */
N#define     REG_GE2D_TCMSK          (GE_BA+0x30)  /*!< Graphic Engine Transparency Color Mask Register */
N#define     REG_GE2D_XYDORG         (GE_BA+0x34)  /*!< Graphic Engine XY Mode Display Origin Starting Register */
N#define     REG_GE2D_SDPITCH        (GE_BA+0x38)  /*!< Graphic Engine Source/Destination Pitch Register */
N#define     REG_GE2D_SRCSPA         (GE_BA+0x3C)  /*!< Graphic Engine Source Start XY/Linear Address Register */
N#define     REG_GE2D_DSTSPA         (GE_BA+0x40)  /*!< Graphic Engine Destination Start XY/Linear Register */
N#define     REG_GE2D_RTGLSZ         (GE_BA+0x44)  /*!< Graphic Engine Dimension XY/Linear Register */
N#define     REG_GE2D_CLPBTL         (GE_BA+0x48)  /*!< Graphic Engine Clipping Boundary Top/Left Register */
N#define     REG_GE2D_CLPBBR         (GE_BA+0x4C)  /*!< Graphic Engine Clipping Boundary Bottom/Right Register */
N#define     REG_GE2D_PTNA           (GE_BA+0x50)  /*!< Graphic Engine Pattern A Register */
N#define     REG_GE2D_PTNB           (GE_BA+0x54)  /*!< Graphic Engine Pattern B Register */
N#define     REG_GE2D_WRPLNMSK       (GE_BA+0x58)  /*!< Graphic Engine Write Plane Mask Register */
N#define     REG_GE2D_MISCTL         (GE_BA+0x5C)  /*!< Graphic Engine Miscellaneous Control Register */
N#define     REG_GE2D_GEHBDW0        (GE_BA+0x60)  /*!< Graphic Engine HostBLT data Port 0 Register */
N#define     REG_GE2D_GEHBDW1        (GE_BA+0x64)  /*!< Graphic Engine HostBLT data Port 1 Register */
N#define     REG_GE2D_GEHBDW2        (GE_BA+0x68)  /*!< Graphic Engine HostBLT data Port 2 Register */
N#define     REG_GE2D_GEHBDW3        (GE_BA+0x6C)  /*!< Graphic Engine HostBLT data Port 3 Register */
N#define     REG_GE2D_GEHBDW4        (GE_BA+0x70)  /*!< Graphic Engine HostBLT data Port 4 Register */
N#define     REG_GE2D_GEHBDW5        (GE_BA+0x74)  /*!< Graphic Engine HostBLT data Port 5 Register */
N#define     REG_GE2D_GEHBDW6        (GE_BA+0x78)  /*!< Graphic Engine HostBLT data Port 6 Register */
N#define     REG_GE2D_GEHBDW7        (GE_BA+0x7C)  /*!< Graphic Engine HostBLT data Port 7 Register */
N
N/**@}*/ /* end of GE2D register group */
N
N/*---------------------- Flash Memory Interface -------------------------*/
N/**
N    @addtogroup FMI Flash Memory Interface(FMI)
N    Memory Mapped Structure for FMI Controller
N@{ */
N
N/* DMAC Control Registers*/
N#define     REG_FMI_BUFFER      (FMI_BA+0x000)   /*!< FMI Embedded Buffer Word */
N#define     REG_FMI_DMACTL      (FMI_BA+0x400)   /*!< FMI DMA Control Register */
N#define     REG_FMI_DMASA       (FMI_BA+0x408)   /*!< FMI DMA Transfer Starting Address Register */
N#define     REG_FMI_DMABCNT     (FMI_BA+0x40C)   /*!< FMI DMA Transfer Byte Count Register */
N#define     REG_FMI_DMAINTEN    (FMI_BA+0x410)   /*!< FMI DMA Interrupt Enable Register */
N#define     REG_FMI_DMAINTSTS   (FMI_BA+0x414)   /*!< FMI DMA Interrupt Status Register */
N
N#define     REG_FMI_CTL         (FMI_BA+0x800)   /*!< Global Control and Status Register */
N#define     REG_FMI_INTEN       (FMI_BA+0x804)   /*!< Global Interrupt Control Register */
N#define     REG_FMI_INTSTS      (FMI_BA+0x808)   /*!< Global Interrupt Status Register */
N
N/* eMMC Registers */
N#define     REG_FMI_EMMCCTL     (FMI_BA+0x820)   /*!< eMMC control and status register */
N#define     REG_FMI_EMMCCMD     (FMI_BA+0x824)   /*!< eMMC command argument register */
N#define     REG_FMI_EMMCINTEN   (FMI_BA+0x828)   /*!< eMMC interrupt enable register */
N#define     REG_FMI_EMMCINTSTS  (FMI_BA+0x82C)   /*!< eMMC interrupt status register */
N#define     REG_FMI_EMMCRESP0   (FMI_BA+0x830)   /*!< eMMC receive response token register 0 */
N#define     REG_FMI_EMMCRESP1   (FMI_BA+0x834)   /*!< eMMC receive response token register 1 */
N#define     REG_FMI_EMMCBLEN    (FMI_BA+0x838)   /*!< eMMC block length register */
N#define     REG_FMI_EMMCTOUT    (FMI_BA+0x83C)   /*!< eMMC block length register */
N
N/* NAND-type Flash Registers */
N#define     REG_NANDCTL         (FMI_BA+0x8A0)   /*!< NAND Flash Control and Status Register */
N#define     REG_NANDTMCTL       (FMI_BA+0x8A4)   /*!< NAND Flash Timing Control Register */
N#define     REG_NANDINTEN       (FMI_BA+0x8A8)   /*!< NAND Flash Interrupt Control Register */
N#define     REG_NANDINTSTS      (FMI_BA+0x8AC)   /*!< NAND Flash Interrupt Status Register */
N#define     REG_NANDCMD         (FMI_BA+0x8B0)   /*!< NAND Flash Command Port Register */
N#define     REG_NANDADDR        (FMI_BA+0x8B4)   /*!< NAND Flash Address Port Register */
N#define     REG_NANDDATA        (FMI_BA+0x8B8)   /*!< NAND Flash Data Port Register */
N#define     REG_NANDRACTL       (FMI_BA+0x8BC)   /*!< NAND Flash Redundant Area Control Register */
N#define     REG_NANDECTL        (FMI_BA+0x8C0)   /*!< NAND Flash Extend Control Regsiter */
N#define     REG_NANDECCES0      (FMI_BA+0x8D0)   /*!< NAND Flash ECC Error Status 0 */
N#define     REG_NANDECCES1      (FMI_BA+0x8D4)   /*!< NAND Flash ECC Error Status 1 */
N#define     REG_NANDECCES2      (FMI_BA+0x8D8)   /*!< NAND Flash ECC Error Status 2 */
N#define     REG_NANDECCES3      (FMI_BA+0x8DC)   /*!< NAND Flash ECC Error Status 3 */
N#define     REG_NANDPROTA0      (FMI_BA+0x8E0)   /*!< NAND Flash Protect Region End Address 0 */
N#define     REG_NANDPROTA1      (FMI_BA+0x8E4)   /*!< NAND Flash Protect Region End Address 1 */
N
N/* NAND-type Flash BCH Error Address Registers */
N#define     REG_NANDECCEA0      (FMI_BA+0x900)   /*!< NAND Flash ECC Error Byte Address 0 */
N#define     REG_NANDECCEA1      (FMI_BA+0x904)   /*!< NAND Flash ECC Error Byte Address 1 */
N#define     REG_NANDECCEA2      (FMI_BA+0x908)   /*!< NAND Flash ECC Error Byte Address 2 */
N#define     REG_NANDECCEA3      (FMI_BA+0x90C)   /*!< NAND Flash ECC Error Byte Address 3 */
N#define     REG_NANDECCEA4      (FMI_BA+0x910)   /*!< NAND Flash ECC Error Byte Address 4 */
N#define     REG_NANDECCEA5      (FMI_BA+0x914)   /*!< NAND Flash ECC Error Byte Address 5 */
N#define     REG_NANDECCEA6      (FMI_BA+0x918)   /*!< NAND Flash ECC Error Byte Address 6 */
N#define     REG_NANDECCEA7      (FMI_BA+0x91C)   /*!< NAND Flash ECC Error Byte Address 7 */
N#define     REG_NANDECCEA8      (FMI_BA+0x920)   /*!< NAND Flash ECC Error Byte Address 8 */
N#define     REG_NANDECCEA9      (FMI_BA+0x924)   /*!< NAND Flash ECC Error Byte Address 9 */
N#define     REG_NANDECCEA10     (FMI_BA+0x928)   /*!< NAND Flash ECC Error Byte Address 10 */
N#define     REG_NANDECCEA11     (FMI_BA+0x92C)   /*!< NAND Flash ECC Error Byte Address 11 */
N
N/* NAND-type Flash BCH Error Data Registers */
N#define     REG_NANDECCED0      (FMI_BA+0x960)   /*!< NAND Flash ECC Error Data Register 0 */
N#define     REG_NANDECCED1      (FMI_BA+0x964)   /*!< NAND Flash ECC Error Data Register 1 */
N#define     REG_NANDECCED2      (FMI_BA+0x968)   /*!< NAND Flash ECC Error Data Register 2 */
N#define     REG_NANDECCED3      (FMI_BA+0x96C)   /*!< NAND Flash ECC Error Data Register 3 */
N#define     REG_NANDECCED4      (FMI_BA+0x970)   /*!< NAND Flash ECC Error Data Register 4 */
N#define     REG_NANDECCED5      (FMI_BA+0x974)   /*!< NAND Flash ECC Error Data Register 5 */
N
N/* NAND-type Flash Redundant Area Registers */
N#define     REG_NANDRA0         (FMI_BA+0xA00)   /*!< NAND Flash Redundant Area Register */
N#define     REG_NANDRA1         (FMI_BA+0xA04)   /*!< NAND Flash Redundant Area Register */
N
N/**@}*/ /* end of FMI register group */
N
N
N/*---------------------- SD/SDIO Host Controller -------------------------*/
N/**
N    @addtogroup SDH SD/SDIO Host Controller(SDH)
N    Memory Mapped Structure for SDH Controller
N@{ */
N
N/* DMAC Control Registers*/
N#define     REG_SDH_FB0         (SDH_BA+0x000)   /*!< SD Host Embedded Buffer Word */
N#define     REG_SDH_DMACTL      (SDH_BA+0x400)   /*!< SD Host DMA Control and Status Register */
N#define     REG_SDH_DMASA       (SDH_BA+0x408)   /*!< SD Host DMA Transfer Starting Address Register */
N#define     REG_SDH_DMABCNT     (SDH_BA+0x40C)   /*!< SD Host DMA Transfer Byte Count Register */
N#define     REG_SDH_DMAINTEN    (SDH_BA+0x410)   /*!< SD Host DMA Interrupt Enable Register */
N#define     REG_SDH_DMAINTSTS   (SDH_BA+0x414)   /*!< SD Host DMA Interrupt Status Register */
N
N#define     REG_SDH_GCTL        (SDH_BA+0x800)   /*!< SD Host Global Control and Status Register */
N#define     REG_SDH_GINTEN      (SDH_BA+0x804)   /*!< SD Host Global Interrupt Control Register */
N#define     REG_SDH_GINTSTS     (SDH_BA+0x808)   /*!< SD Host Global Interrupt Status Register */
N
N/* Secure Digit Registers */
N#define     REG_SDH_CTL         (SDH_BA+0x820)   /*!< SD Host control and status register */
N#define     REG_SDH_CMD         (SDH_BA+0x824)   /*!< SD Host command argument register */
N#define     REG_SDH_INTEN       (SDH_BA+0x828)   /*!< SD Host interrupt enable register */
N#define     REG_SDH_INTSTS      (SDH_BA+0x82C)   /*!< SD Host interrupt status register */
N#define     REG_SDH_RESP0       (SDH_BA+0x830)   /*!< SD Host receive response token register 0 */
N#define     REG_SDH_RESP1       (SDH_BA+0x834)   /*!< SD Host receive response token register 1 */
N#define     REG_SDH_BLEN        (SDH_BA+0x838)   /*!< SD Host block length register */
N#define     REG_SDH_TMOUT       (SDH_BA+0x83C)   /*!< SD Host Response/Data-in Time-out register */
N#define     REG_SDH_ECTL        (SDH_BA+0x840)   /*!< SD Host Extend Control Register */
N
N/**@}*/ /* end of SDH register group */
N
N
N/*---------------------- Cryptographic Accelerator -------------------------*/
N/**
N    @addtogroup CRYPTO Cryptographic Accelerator(CRYPTO)
N    Memory Mapped Structure for Cryptographic Accelerator registers
N@{ */
N
N/* Crypto Control Registers */
N#define     CRPT_INTEN          (CRPT_BA+0x000)  /*!< Crypto Interrupt Enable Control Register      */
N#define     CRPT_INTSTS         (CRPT_BA+0x004)  /*!< Crypto Interrupt Flag                         */
N
N/* PRNG Registers */
N#define     CRPT_PRNG_CTL       (CRPT_BA+0x008)  /*!< PRNG Control Register                         */
N#define     CRPT_PRNG_SEED      (CRPT_BA+0x00C)  /*!< Seed for PRNG                                 */
N#define     CRPT_PRNG_KEY0      (CRPT_BA+0x010)  /*!< PRNG Generated Key 0                          */
N#define     CRPT_PRNG_KEY1      (CRPT_BA+0x014)  /*!< PRNG Generated Key 1                          */
N#define     CRPT_PRNG_KEY2      (CRPT_BA+0x018)  /*!< PRNG Generated Key 2                          */
N#define     CRPT_PRNG_KEY3      (CRPT_BA+0x01C)  /*!< PRNG Generated Key 3                          */
N#define     CRPT_PRNG_KEY4      (CRPT_BA+0x020)  /*!< PRNG Generated Key 4                          */
N#define     CRPT_PRNG_KEY5      (CRPT_BA+0x024)  /*!< PRNG Generated Key 5                          */
N#define     CRPT_PRNG_KEY6      (CRPT_BA+0x028)  /*!< PRNG Generated Key 6                          */
N#define     CRPT_PRNG_KEY7      (CRPT_BA+0x02C)  /*!< PRNG Generated Key 7                          */
N
N/* AES/TDES feedback Registers */
N#define     CRPT_AES_FDBCK0     (CRPT_BA+0x050)  /*!< AES Engine Output Feedback Data after Cryptographic Operation   */
N#define     CRPT_AES_FDBCK1     (CRPT_BA+0x054)  /*!< AES Engine Output Feedback Data after Cryptographic Operation   */
N#define     CRPT_AES_FDBCK2     (CRPT_BA+0x058)  /*!< AES Engine Output Feedback Data after Cryptographic Operation   */
N#define     CRPT_AES_FDBCK3     (CRPT_BA+0x05C)  /*!< AES Engine Output Feedback Data after Cryptographic Operation   */
N#define     CRPT_TDES_FDBCKH    (CRPT_BA+0x060)  /*!< TDES/DES Engine Output Feedback High Word Data after Cryptographic Operation  */
N#define     CRPT_TDES_FDBCKL    (CRPT_BA+0x064)  /*!< TDES/DES Engine Output Feedback Low Word Data after Cryptographic Operation   */
N
N/* AES Control Registers */
N#define     CRPT_AES_CTL        (CRPT_BA+0x100)   /*!< AES Control Register                               */
N#define     CRPT_AES_STS        (CRPT_BA+0x104)   /*!< AES Engine Flag                                    */
N#define     CRPT_AES_DATIN      (CRPT_BA+0x108)   /*!< AES Engine Data Input Port Register                */
N#define     CRPT_AES_DATOUT     (CRPT_BA+0x10C)   /*!< AES Engine Data Output Port Register               */
N#define     CRPT_AES0_KEY0      (CRPT_BA+0x110)   /*!< AES Key Word 0 Register for Channel 0              */
N#define     CRPT_AES0_KEY1      (CRPT_BA+0x114)   /*!< AES Key Word 1 Register for Channel 0              */
N#define     CRPT_AES0_KEY2      (CRPT_BA+0x118)   /*!< AES Key Word 2 Register for Channel 0              */
N#define     CRPT_AES0_KEY3      (CRPT_BA+0x11C)   /*!< AES Key Word 3 Register for Channel 0              */
N#define     CRPT_AES0_KEY4      (CRPT_BA+0x120)   /*!< AES Key Word 4 Register for Channel 0              */
N#define     CRPT_AES0_KEY5      (CRPT_BA+0x124)   /*!< AES Key Word 5 Register for Channel 0              */
N#define     CRPT_AES0_KEY6      (CRPT_BA+0x128)   /*!< AES Key Word 6 Register for Channel 0              */
N#define     CRPT_AES0_KEY7      (CRPT_BA+0x12C)   /*!< AES Key Word 7 Register for Channel 0              */
N#define     CRPT_AES0_IV0       (CRPT_BA+0x130)   /*!< AES Initial Vector Word 0 Register for Channel 0   */
N#define     CRPT_AES0_IV1       (CRPT_BA+0x134)   /*!< AES Initial Vector Word 1 Register for Channel 0   */
N#define     CRPT_AES0_IV2       (CRPT_BA+0x138)   /*!< AES Initial Vector Word 2 Register for Channel 0   */
N#define     CRPT_AES0_IV3       (CRPT_BA+0x13C)   /*!< AES Initial Vector Word 3 Register for Channel 0   */
N#define     CRPT_AES0_SADDR     (CRPT_BA+0x140)   /*!< AES DMA Source Address Register for Channel 0      */
N#define     CRPT_AES0_DADDR     (CRPT_BA+0x144)   /*!< AES DMA Destination Address Register for Channel 0 */
N#define     CRPT_AES0_CNT       (CRPT_BA+0x148)   /*!< AES Byte Count Register for Channel 0              */
N#define     CRPT_AES1_KEY0      (CRPT_BA+0x14C)   /*!< AES Key Word 0 Register for Channel 1              */
N#define     CRPT_AES1_KEY1      (CRPT_BA+0x150)   /*!< AES Key Word 1 Register for Channel 1              */
N#define     CRPT_AES1_KEY2      (CRPT_BA+0x154)   /*!< AES Key Word 2 Register for Channel 1              */
N#define     CRPT_AES1_KEY3      (CRPT_BA+0x158)   /*!< AES Key Word 3 Register for Channel 1              */
N#define     CRPT_AES1_KEY4      (CRPT_BA+0x15C)   /*!< AES Key Word 4 Register for Channel 1              */
N#define     CRPT_AES1_KEY5      (CRPT_BA+0x160)   /*!< AES Key Word 5 Register for Channel 1              */
N#define     CRPT_AES1_KEY6      (CRPT_BA+0x164)   /*!< AES Key Word 6 Register for Channel 1              */
N#define     CRPT_AES1_KEY7      (CRPT_BA+0x168)   /*!< AES Key Word 7 Register for Channel 1              */
N#define     CRPT_AES1_IV0       (CRPT_BA+0x16C)   /*!< AES Initial Vector Word 0 Register for Channel 1   */
N#define     CRPT_AES1_IV1       (CRPT_BA+0x170)   /*!< AES Initial Vector Word 1 Register for Channel 1   */
N#define     CRPT_AES1_IV2       (CRPT_BA+0x174)   /*!< AES Initial Vector Word 2 Register for Channel 1   */
N#define     CRPT_AES1_IV3       (CRPT_BA+0x178)   /*!< AES Initial Vector Word 3 Register for Channel 1   */
N#define     CRPT_AES1_SADDR     (CRPT_BA+0x17C)   /*!< AES DMA Source Address Register for Channel 1      */
N#define     CRPT_AES1_DADDR     (CRPT_BA+0x180)   /*!< AES DMA Destination Address Register for Channel 1 */
N#define     CRPT_AES1_CNT       (CRPT_BA+0x184)   /*!< AES Byte Count Register for Channel 1              */
N#define     CRPT_AES2_KEY0      (CRPT_BA+0x188)   /*!< AES Key Word 0 Register for Channel 2              */
N#define     CRPT_AES2_KEY1      (CRPT_BA+0x18C)   /*!< AES Key Word 1 Register for Channel 2              */
N#define     CRPT_AES2_KEY2      (CRPT_BA+0x190)   /*!< AES Key Word 2 Register for Channel 2              */
N#define     CRPT_AES2_KEY3      (CRPT_BA+0x194)   /*!< AES Key Word 3 Register for Channel 2              */
N#define     CRPT_AES2_KEY4      (CRPT_BA+0x198)   /*!< AES Key Word 4 Register for Channel 2              */
N#define     CRPT_AES2_KEY5      (CRPT_BA+0x19C)   /*!< AES Key Word 5 Register for Channel 2              */
N#define     CRPT_AES2_KEY6      (CRPT_BA+0x1A0)   /*!< AES Key Word 6 Register for Channel 2              */
N#define     CRPT_AES2_KEY7      (CRPT_BA+0x1A4)   /*!< AES Key Word 7 Register for Channel 2              */
N#define     CRPT_AES2_IV0       (CRPT_BA+0x1A8)   /*!< AES Initial Vector Word 0 Register for Channel 2   */
N#define     CRPT_AES2_IV1       (CRPT_BA+0x1AC)   /*!< AES Initial Vector Word 1 Register for Channel 2   */
N#define     CRPT_AES2_IV2       (CRPT_BA+0x1B0)   /*!< AES Initial Vector Word 2 Register for Channel 2   */
N#define     CRPT_AES2_IV3       (CRPT_BA+0x1B4)   /*!< AES Initial Vector Word 3 Register for Channel 2   */
N#define     CRPT_AES2_SADDR     (CRPT_BA+0x1B8)   /*!< AES DMA Source Address Register for Channel 2      */
N#define     CRPT_AES2_DADDR     (CRPT_BA+0x1BC)   /*!< AES DMA Destination Address Register for Channel 2 */
N#define     CRPT_AES2_CNT       (CRPT_BA+0x1C0)   /*!< AES Byte Count Register for Channel 2              */
N#define     CRPT_AES3_KEY0      (CRPT_BA+0x1C4)   /*!< AES Key Word 0 Register for Channel 3              */
N#define     CRPT_AES3_KEY1      (CRPT_BA+0x1C8)   /*!< AES Key Word 1 Register for Channel 3              */
N#define     CRPT_AES3_KEY2      (CRPT_BA+0x1CC)   /*!< AES Key Word 2 Register for Channel 3              */
N#define     CRPT_AES3_KEY3      (CRPT_BA+0x1D0)   /*!< AES Key Word 3 Register for Channel 3              */
N#define     CRPT_AES3_KEY4      (CRPT_BA+0x1D4)   /*!< AES Key Word 4 Register for Channel 3              */
N#define     CRPT_AES3_KEY5      (CRPT_BA+0x1D8)   /*!< AES Key Word 5 Register for Channel 3              */
N#define     CRPT_AES3_KEY6      (CRPT_BA+0x1DC)   /*!< AES Key Word 6 Register for Channel 3              */
N#define     CRPT_AES3_KEY7      (CRPT_BA+0x1E0)   /*!< AES Key Word 7 Register for Channel 3              */
N#define     CRPT_AES3_IV0       (CRPT_BA+0x1E4)   /*!< AES Initial Vector Word 0 Register for Channel 3   */
N#define     CRPT_AES3_IV1       (CRPT_BA+0x1E8)   /*!< AES Initial Vector Word 1 Register for Channel 3   */
N#define     CRPT_AES3_IV2       (CRPT_BA+0x1EC)   /*!< AES Initial Vector Word 2 Register for Channel 3   */
N#define     CRPT_AES3_IV3       (CRPT_BA+0x1F0)   /*!< AES Initial Vector Word 3 Register for Channel 3   */
N#define     CRPT_AES3_SADDR     (CRPT_BA+0x1F4)   /*!< AES DMA Source Address Register for Channel 3      */
N#define     CRPT_AES3_DADDR     (CRPT_BA+0x1F8)   /*!< AES DMA Destination Address Register for Channel 3 */
N#define     CRPT_AES3_CNT       (CRPT_BA+0x1FC)   /*!< AES Byte Count Register for Channel 3              */
N
N/* DES/TDES Control Registers */
N#define     CRPT_TDES_CTL       (CRPT_BA+0x200)   /*!< TDES/DES Control Register                          */
N#define     CRPT_TDES_STS       (CRPT_BA+0x204)   /*!< TDES/DES Engine Flag                               */
N#define     CRPT_TDES0_KEY1H    (CRPT_BA+0x208)   /*!< TDES/DES Key 1 High Word Register for Channel 0    */
N#define     CRPT_TDES0_KEY1L    (CRPT_BA+0x20C)   /*!< TDES/DES Key 1 Low Word Register for Channel 0     */
N#define     CRPT_TDES0_KEY2H    (CRPT_BA+0x210)   /*!< TDES/DES Key 2 High Word Register for Channel 0    */
N#define     CRPT_TDES0_KEY2L    (CRPT_BA+0x214)   /*!< TDES/DES Key 2 Low Word Register for Channel 0     */
N#define     CRPT_TDES0_KEY3H    (CRPT_BA+0x218)   /*!< TDES/DES Key 3 High Word Register for Channel 0    */
N#define     CRPT_TDES0_KEY3L    (CRPT_BA+0x21C)   /*!< TDES/DES Key 3 Low Word Register for Channel 0     */
N#define     CRPT_TDES0_IVH      (CRPT_BA+0x220)   /*!< TDES/DES Initial Vector High Word Register for Channel 0 */
N#define     CRPT_TDES0_IVL      (CRPT_BA+0x224)   /*!< TDES/DES Initial Vector Low Word Register for Channel 0  */
N#define     CRPT_TDES0_SADDR    (CRPT_BA+0x228)   /*!< TDES/DES DMA Source Address Register for Channel 0       */
N#define     CRPT_TDES0_DADDR    (CRPT_BA+0x22C)   /*!< TDES/DES DMA Destination Address Register for Channel 0  */
N#define     CRPT_TDES0_CNT      (CRPT_BA+0x230)   /*!< TDES/DES Byte Count Register for Channel 0         */
N#define     CRPT_TDES_DATIN     (CRPT_BA+0x234)   /*!< TDES/DES Engine Input data Word Register           */
N#define     CRPT_TDES_DATOUT    (CRPT_BA+0x238)   /*!< TDES/DES Engine Output data Word Register          */
N#define     CRPT_TDES1_KEY1H    (CRPT_BA+0x248)   /*!< TDES/DES Key 1 High Word Register for Channel 1    */
N#define     CRPT_TDES1_KEY1L    (CRPT_BA+0x24C)   /*!< TDES/DES Key 1 Low Word Register for Channel 1     */
N#define     CRPT_TDES1_KEY2H    (CRPT_BA+0x250)   /*!< TDES/DES Key 2 High Word Register for Channel 1    */
N#define     CRPT_TDES1_KEY2L    (CRPT_BA+0x254)   /*!< TDES/DES Key 2 Low Word Register for Channel 1     */
N#define     CRPT_TDES1_KEY3H    (CRPT_BA+0x258)   /*!< TDES/DES Key 3 High Word Register for Channel 1    */
N#define     CRPT_TDES1_KEY3L    (CRPT_BA+0x25C)   /*!< TDES/DES Key 3 Low Word Register for Channel 1     */
N#define     CRPT_TDES1_IVH      (CRPT_BA+0x260)   /*!< TDES/DES Initial Vector High Word Register for Channel 1 */
N#define     CRPT_TDES1_IVL      (CRPT_BA+0x264)   /*!< TDES/DES Initial Vector Low Word Register for Channel 1  */
N#define     CRPT_TDES1_SADDR    (CRPT_BA+0x268)   /*!< TDES/DES DMA Source Address Register for Channel 1       */
N#define     CRPT_TDES1_DADDR    (CRPT_BA+0x26C)   /*!< TDES/DES DMA Destination Address Register for Channel 1  */
N#define     CRPT_TDES1_CNT      (CRPT_BA+0x270)   /*!< TDES/DES Byte Count Register for Channel 1         */
N#define     CRPT_TDES2_KEY1H    (CRPT_BA+0x288)   /*!< TDES/DES Key 1 High Word Register for Channel 2    */
N#define     CRPT_TDES2_KEY1L    (CRPT_BA+0x28C)   /*!< TDES/DES Key 1 Low Word Register for Channel 2     */
N#define     CRPT_TDES2_KEY2H    (CRPT_BA+0x290)   /*!< TDES/DES Key 2 High Word Register for Channel 2    */
N#define     CRPT_TDES2_KEY2L    (CRPT_BA+0x294)   /*!< TDES/DES Key 2 Low Word Register for Channel 2     */
N#define     CRPT_TDES2_KEY3H    (CRPT_BA+0x298)   /*!< TDES/DES Key 3 High Word Register for Channel 2    */
N#define     CRPT_TDES2_KEY3L    (CRPT_BA+0x29C)   /*!< TDES/DES Key 3 Low Word Register for Channel 2     */
N#define     CRPT_TDES2_IVH      (CRPT_BA+0x2A0)   /*!< TDES/DES Initial Vector High Word Register for Channel 2 */
N#define     CRPT_TDES2_IVL      (CRPT_BA+0x2A4)   /*!< TDES/DES Initial Vector Low Word Register for Channel 2  */
N#define     CRPT_TDES2_SADDR    (CRPT_BA+0x2A8)   /*!< TDES/DES DMA Source Address Register for Channel 2       */
N#define     CRPT_TDES2_DADDR    (CRPT_BA+0x2AC)   /*!< TDES/DES DMA Destination Address Register for Channel 2  */
N#define     CRPT_TDES2_CNT      (CRPT_BA+0x2B0)   /*!< TDES/DES Byte Count Register for Channel 3         */
N#define     CRPT_TDES3_KEY1H    (CRPT_BA+0x2C8)   /*!< TDES/DES Key 1 High Word Register for Channel 3    */
N#define     CRPT_TDES3_KEY1L    (CRPT_BA+0x2CC)   /*!< TDES/DES Key 1 Low Word Register for Channel 3     */
N#define     CRPT_TDES3_KEY2H    (CRPT_BA+0x2D0)   /*!< TDES/DES Key 2 High Word Register for Channel 3    */
N#define     CRPT_TDES3_KEY2L    (CRPT_BA+0x2D4)   /*!< TDES/DES Key 2 Low Word Register for Channel 3     */
N#define     CRPT_TDES3_KEY3H    (CRPT_BA+0x2D8)   /*!< TDES/DES Key 3 High Word Register for Channel 3    */
N#define     CRPT_TDES3_KEY3L    (CRPT_BA+0x2DC)   /*!< TDES/DES Key 3 Low Word Register for Channel 3     */
N#define     CRPT_TDES3_IVH      (CRPT_BA+0x2E0)   /*!< TDES/DES Initial Vector High Word Register for Channel 3 */
N#define     CRPT_TDES3_IVL      (CRPT_BA+0x2E4)   /*!< TDES/DES Initial Vector Low Word Register for Channel 3  */
N#define     CRPT_TDES3_SADDR    (CRPT_BA+0x2E8)   /*!< TDES/DES DMA Source Address Register for Channel 3       */
N#define     CRPT_TDES3_DADDR    (CRPT_BA+0x2EC)   /*!< TDES/DES DMA Destination Address Register for Channel 3  */
N#define     CRPT_TDES3_CNT      (CRPT_BA+0x2F0)   /*!< TDES/DES Byte Count Register for Channel 3         */
N
N/* SHA/HMAC Control Registers */
N#define     CRPT_HMAC_CTL       (CRPT_BA+0x300)   /*!< SHA/HMAC Control Register                          */
N#define     CRPT_HMAC_STS       (CRPT_BA+0x304)   /*!< SHA/HMAC Status Flag                               */
N#define     CRPT_HMAC_DGST0     (CRPT_BA+0x308)   /*!< SHA/HMAC Digest Message 0                          */
N#define     CRPT_HMAC_DGST1     (CRPT_BA+0x30C)   /*!< SHA/HMAC Digest Message 1                          */
N#define     CRPT_HMAC_DGST2     (CRPT_BA+0x310)   /*!< SHA/HMAC Digest Message 2                          */
N#define     CRPT_HMAC_DGST3     (CRPT_BA+0x314)   /*!< SHA/HMAC Digest Message 3                          */
N#define     CRPT_HMAC_DGST4     (CRPT_BA+0x318)   /*!< SHA/HMAC Digest Message 4                          */
N#define     CRPT_HMAC_DGST5     (CRPT_BA+0x31C)   /*!< SHA/HMAC Digest Message 5                          */
N#define     CRPT_HMAC_DGST6     (CRPT_BA+0x320)   /*!< SHA/HMAC Digest Message 6                          */
N#define     CRPT_HMAC_DGST7     (CRPT_BA+0x324)   /*!< SHA/HMAC Digest Message 7                          */
N#define     CRPT_HMAC_DGST8     (CRPT_BA+0x328)   /*!< SHA/HMAC Digest Message 8                          */
N#define     CRPT_HMAC_DGST9     (CRPT_BA+0x32C)   /*!< SHA/HMAC Digest Message 8                          */
N#define     CRPT_HMAC_DGST10    (CRPT_BA+0x330)   /*!< SHA/HMAC Digest Message 10                         */
N#define     CRPT_HMAC_DGST11    (CRPT_BA+0x334)   /*!< SHA/HMAC Digest Message 11                         */
N#define     CRPT_HMAC_DGST12    (CRPT_BA+0x338)   /*!< SHA/HMAC Digest Message 12                         */
N#define     CRPT_HMAC_DGST13    (CRPT_BA+0x33C)   /*!< SHA/HMAC Digest Message 13                         */
N#define     CRPT_HMAC_DGST14    (CRPT_BA+0x340)   /*!< SHA/HMAC Digest Message 14                         */
N#define     CRPT_HMAC_DGST15    (CRPT_BA+0x344)   /*!< SHA/HMAC Digest Message 15                         */
N#define     CRPT_HMAC_KEYCNT    (CRPT_BA+0x348)   /*!< SHA/HMAC Key Byte Count                            */
N#define     CRPT_HMAC_SADDR     (CRPT_BA+0x34C)   /*!< SHA/HMAC Key Byte Count                            */
N#define     CRPT_HMAC_DMACNT    (CRPT_BA+0x350)   /*!< SHA/HMAC Byte Count Register                       */
N#define     CRPT_HMAC_DATIN     (CRPT_BA+0x354)   /*!< SHA/HMAC Engine Non-DMA Mode Data Input Port Register  */
N
N/**@}*/ /* end of Cryptographic Accelerator register group */
N
N
N
N
N/*---------------------- Universal Asynchronous Receiver/Transmitter Controller -------------------------*/
N/**
N    @addtogroup UART Universal Asynchronous Receiver/Transmitter Controller(UART)
N    Memory Mapped Structure for UART Controller
N@{ */
N
N#define     REG_UART0_RBR    (UART0_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART0_THR    (UART0_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART0_IER    (UART0_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART0_FCR    (UART0_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART0_LCR    (UART0_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART0_MCR   (UART0_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART0_MSR    (UART0_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART0_FSR    (UART0_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART0_ISR   (UART0_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART0_TOR       (UART0_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART0_BAUD      (UART0_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART0_IRCR   (UART0_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART0_ALT_CSR   (UART0_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART0_FUN_SEL   (UART0_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART0_LIN_CTL   (UART0_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART0_LIN_SR    (UART0_BA+0x38)  /*!< LIN Status Register */
N
N
N
N
N/*
N  UART1 Control Registers
N*/
N#define     REG_UART1_RBR   (UART1_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART1_THR   (UART1_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART1_IER   (UART1_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART1_FCR   (UART1_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART1_LCR   (UART1_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART1_MCR   (UART1_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART1_MSR   (UART1_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART1_FSR       (UART1_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART1_ISR   (UART1_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART1_TOR       (UART1_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART1_BAUD      (UART1_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART1_IRCR      (UART1_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART1_ALT_CSR   (UART1_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART1_FUN_SEL   (UART1_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART1_LIN_CTL   (UART1_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART1_LIN_SR    (UART1_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UART2 Control Registers
N*/
N#define     REG_UART2_RBR   (UART2_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART2_THR   (UART2_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART2_IER   (UART2_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART2_FCR   (UART2_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART2_LCR   (UART2_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART2_MCR   (UART2_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART2_MSR   (UART2_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART2_FSR   (UART2_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART2_ISR   (UART2_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART2_TOR   (UART2_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART2_BAUD  (UART2_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART2_IRCR  (UART2_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART2_ALT_CSR   (UART2_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART2_FUN_SEL   (UART2_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART2_LIN_CTL   (UART2_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART2_LIN_SR    (UART2_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UART3 Control Registers
N*/
N#define     REG_UART3_RBR   (UART3_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART3_THR   (UART3_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART3_IER   (UART3_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART3_FCR   (UART3_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART3_LCR   (UART3_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART3_MCR   (UART3_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART3_MSR   (UART3_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART3_FSR   (UART3_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART3_ISR   (UART3_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART3_TOR   (UART3_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART3_BAUD  (UART3_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART3_IRCR  (UART3_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART3_ALT_CSR   (UART3_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART3_FUN_SEL   (UART3_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART3_LIN_CTL   (UART3_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART3_LIN_SR    (UART3_BA+0x38)  /*!< LIN Status Register */
N
N
N/*
N  UART4 Control Registers
N*/
N#define     REG_UART4_RBR   (UART4_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART4_THR   (UART4_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART4_IER   (UART4_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART4_FCR   (UART4_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART4_LCR   (UART4_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART4_MCR   (UART4_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART4_MSR   (UART4_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART4_FSR   (UART4_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART4_ISR   (UART4_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART4_TOR   (UART4_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART4_BAUD  (UART4_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART4_IRCR  (UART4_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART4_ALT_CSR   (UART4_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART4_FUN_SEL   (UART4_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART4_LIN_CTL   (UART4_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART4_LIN_SR    (UART4_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UART5 Control Registers
N*/
N#define     REG_UART5_RBR   (UART5_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART5_THR   (UART5_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART5_IER   (UART5_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART5_FCR   (UART5_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART5_LCR   (UART5_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART5_MCR   (UART5_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART5_MSR   (UART5_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART5_FSR   (UART5_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART5_ISR   (UART5_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART5_TOR   (UART5_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART5_BAUD  (UART5_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART5_IRCR  (UART5_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART5_ALT_CSR   (UART5_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART5_FUN_SEL   (UART5_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART5_LIN_CTL   (UART5_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART5_LIN_SR    (UART5_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UART6 Control Registers
N*/
N#define     REG_UART6_RBR   (UART6_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART6_THR   (UART6_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART6_IER   (UART6_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART6_FCR   (UART6_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART6_LCR   (UART6_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART6_MCR   (UART6_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART6_MSR   (UART6_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART6_FSR   (UART6_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART6_ISR   (UART6_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART6_TOR   (UART6_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART6_BAUD  (UART6_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART6_IRCR  (UART6_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART6_ALT_CSR   (UART6_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART6_FUN_SEL   (UART6_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART6_LIN_CTL   (UART6_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART6_LIN_SR    (UART6_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UART7 Control Registers
N*/
N#define     REG_UART7_RBR   (UART7_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART7_THR   (UART7_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART7_IER   (UART7_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART7_FCR   (UART7_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART7_LCR   (UART7_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART7_MCR   (UART7_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART7_MSR   (UART7_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART7_FSR   (UART7_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART7_ISR   (UART7_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART7_TOR   (UART7_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART7_BAUD  (UART7_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART7_IRCR  (UART7_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART7_ALT_CSR   (UART7_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART7_FUN_SEL   (UART7_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART7_LIN_CTL   (UART7_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART7_LIN_SR    (UART7_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UART8 Control Registers
N*/
N#define     REG_UART8_RBR   (UART8_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART8_THR   (UART8_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART8_IER   (UART8_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART8_FCR   (UART8_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART8_LCR   (UART8_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART8_MCR   (UART8_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART8_MSR   (UART8_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART8_FSR   (UART8_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART8_ISR   (UART8_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART8_TOR   (UART8_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART8_BAUD  (UART8_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART8_IRCR  (UART8_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART8_ALT_CSR   (UART8_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART8_FUN_SEL   (UART8_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART8_LIN_CTL   (UART8_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART8_LIN_SR    (UART8_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UART9 Control Registers
N*/
N#define     REG_UART9_RBR   (UART9_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UART9_THR   (UART9_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UART9_IER   (UART9_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UART9_FCR   (UART9_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UART9_LCR   (UART9_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UART9_MCR   (UART9_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UART9_MSR   (UART9_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UART9_FSR   (UART9_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UART9_ISR   (UART9_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UART9_TOR   (UART9_BA+0x20)  /*!< Time-out Register */
N#define     REG_UART9_BAUD  (UART9_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UART9_IRCR  (UART9_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UART9_ALT_CSR   (UART9_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UART9_FUN_SEL   (UART9_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UART9_LIN_CTL   (UART9_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UART9_LIN_SR    (UART9_BA+0x38)  /*!< LIN Status Register */
N
N/*
N  UARTA Control Registers
N*/
N#define     REG_UARTA_RBR   (UARTA_BA+0x00)  /*!< Receive Buffer Register */
N#define     REG_UARTA_THR   (UARTA_BA+0x00)  /*!< Transmit Holding Register */
N#define     REG_UARTA_IER   (UARTA_BA+0x04)  /*!< Interrupt Enable Register */
N#define     REG_UARTA_FCR   (UARTA_BA+0x08)  /*!< FIFO Control Register */
N#define     REG_UARTA_LCR   (UARTA_BA+0x0C)  /*!< Line Control Register */
N#define     REG_UARTA_MCR   (UARTA_BA+0x10)  /*!< Modem Control Register */
N#define     REG_UARTA_MSR   (UARTA_BA+0x14)  /*!< MODEM Status Register */
N#define     REG_UARTA_FSR   (UARTA_BA+0x18)  /*!< FIFO Status Register */
N#define     REG_UARTA_ISR   (UARTA_BA+0x1C)  /*!< Interrupt Status Control Register */
N#define     REG_UARTA_TOR   (UARTA_BA+0x20)  /*!< Time-out Register */
N#define     REG_UARTA_BAUD  (UARTA_BA+0x24)  /*!< Baud Rate Divider Register */
N#define     REG_UARTA_IRCR  (UARTA_BA+0x28)  /*!< IrDA Control Register */
N#define     REG_UARTA_ALT_CSR   (UARTA_BA+0x2C)  /*!< Alternate Control Register */
N#define     REG_UARTA_FUN_SEL   (UARTA_BA+0x30)  /*!< UART Function Select REgister */
N#define     REG_UARTA_LIN_CTL   (UARTA_BA+0x34)  /*!< UART LIN Control Register */
N#define     REG_UARTA_LIN_SR    (UARTA_BA+0x38)  /*!< LIN Status Register */
N
N
N/**@}*/ /* end of UART register group */
N
N
N/*---------------------- Timer Controller -------------------------*/
N/**
N    @addtogroup TIMER Timer Controller(TIMER)
N    Memory Mapped Structure for TIMER Controller
N@{ */
N
N#define     REG_TMR0_TCSR   (TMR0_BA+0x00)  /*!< Timer Control and Status Register 0  */
N#define     REG_TMR0_TICR   (TMR0_BA+0x04)  /*!< Timer Compare Register 0             */
N#define     REG_TMR0_TDR    (TMR0_BA+0x08)  /*!< Timer Data Register 0                */
N
N#define     REG_TMR1_TCSR   (TMR1_BA+0x00)  /*!< Timer Control and Status Register 1  */
N#define     REG_TMR1_TICR   (TMR1_BA+0x04)  /*!< Timer Compare Register 1             */
N#define     REG_TMR1_TDR    (TMR1_BA+0x08)  /*!< Timer Data Register 1                */
N
N#define     REG_TMR2_TCSR   (TMR2_BA+0x00)  /*!< Timer Control and Status Register 2  */
N#define     REG_TMR2_TICR   (TMR2_BA+0x04)  /*!< Timer Compare Register 2             */
N#define     REG_TMR2_TDR    (TMR2_BA+0x08)  /*!< Timer Data Register 2                */
N
N#define     REG_TMR3_TCSR   (TMR3_BA+0x00)  /*!< Timer Control and Status Register 3  */
N#define     REG_TMR3_TICR   (TMR3_BA+0x04)  /*!< Timer Compare Register 3             */
N#define     REG_TMR3_TDR    (TMR3_BA+0x08)  /*!< Timer Data Register 3                */
N
N#define     REG_TMR4_TCSR   (TMR4_BA+0x00)  /*!< Timer Control and Status Register 4  */
N#define     REG_TMR4_TICR   (TMR4_BA+0x04)  /*!< Timer Compare Register 4             */
N#define     REG_TMR4_TDR    (TMR4_BA+0x08)  /*!< Timer Data Register 4                */
N
N#define     REG_TMR_TISR    (TMR0_BA+0x60)  /*!< Timer Interrupt Status Register      */
N
N/**@}*/ /* end of TIMER register group */
N
N/*---------------------- Enhance Timer Controller -------------------------*/
N/**
N    @addtogroup ETIMER Enhance Timer Controller(ETIMER)
N    Memory Mapped Structure for TIMER Controller
N@{ */
N
N#define     REG_ETMR0_CTL       (ETMR0_BA+0x00)  /*!< Enhance Timer 0 Control Register */
N#define     REG_ETMR0_PRECNT    (ETMR0_BA+0x04)  /*!< Enhance Timer 0 Pre-Scale Counter Register */
N#define     REG_ETMR0_CMPR      (ETMR0_BA+0x08)  /*!< Enhance Timer 0 Compare Register */
N#define     REG_ETMR0_IER       (ETMR0_BA+0x0C)  /*!< Enhance Timer 0 Interrupt Enable Register */
N#define     REG_ETMR0_ISR       (ETMR0_BA+0x10)  /*!< Enhance Timer 0 Interrupt Status Register  */
N#define     REG_ETMR0_DR        (ETMR0_BA+0x14)  /*!< Enhance Timer 0 Data Register */
N#define     REG_ETMR0_TCAP      (ETMR0_BA+0x18)  /*!< Enhance Timer 0 Capture Data Register  */
N
N#define     REG_ETMR1_CTL       (ETMR1_BA+0x00)  /*!< Enhance Timer 1 Control Register */
N#define     REG_ETMR1_PRECNT    (ETMR1_BA+0x04)  /*!< Enhance Timer 1 Pre-Scale Counter Register */
N#define     REG_ETMR1_CMPR      (ETMR1_BA+0x08)  /*!< Enhance Timer 1 Compare Register */
N#define     REG_ETMR1_IER       (ETMR1_BA+0x0C)  /*!< Enhance Timer 1 Interrupt Enable Register */
N#define     REG_ETMR1_ISR       (ETMR1_BA+0x10)  /*!< Enhance Timer 1 Interrupt Status Register  */
N#define     REG_ETMR1_DR        (ETMR1_BA+0x14)  /*!< Enhance Timer 1 Data Register */
N#define     REG_ETMR1_TCAP      (ETMR1_BA+0x18)  /*!< Enhance Timer 1 Capture Data Register  */
N
N#define     REG_ETMR2_CTL       (ETMR2_BA+0x00)  /*!< Enhance Timer 2 Control Register */
N#define     REG_ETMR2_PRECNT    (ETMR2_BA+0x04)  /*!< Enhance Timer 2 Pre-Scale Counter Register */
N#define     REG_ETMR2_CMPR      (ETMR2_BA+0x08)  /*!< Enhance Timer 2 Compare Register */
N#define     REG_ETMR2_IER       (ETMR2_BA+0x0C)  /*!< Enhance Timer 2 Interrupt Enable Register */
N#define     REG_ETMR2_ISR       (ETMR2_BA+0x10)  /*!< Enhance Timer 2 Interrupt Status Register  */
N#define     REG_ETMR2_DR        (ETMR2_BA+0x14)  /*!< Enhance Timer 2 Data Register */
N#define     REG_ETMR2_TCAP      (ETMR2_BA+0x18)  /*!< Enhance Timer 2 Capture Data Register  */
N
N#define     REG_ETMR3_CTL       (ETMR3_BA+0x00)  /*!< Enhance Timer 3 Control Register */
N#define     REG_ETMR3_PRECNT    (ETMR3_BA+0x04)  /*!< Enhance Timer 3 Pre-Scale Counter Register */
N#define     REG_ETMR3_CMPR      (ETMR3_BA+0x08)  /*!< Enhance Timer 3 Compare Register */
N#define     REG_ETMR3_IER       (ETMR3_BA+0x0C)  /*!< Enhance Timer 3 Interrupt Enable Register */
N#define     REG_ETMR3_ISR       (ETMR3_BA+0x10)  /*!< Enhance Timer 3 Interrupt Status Register  */
N#define     REG_ETMR3_DR        (ETMR3_BA+0x14)  /*!< Enhance Timer 3 Data Register */
N#define     REG_ETMR3_TCAP      (ETMR3_BA+0x18)  /*!< Enhance Timer 3 Capture Data Register  */
N/**@}*/ /* end of ETIMER register group */
N
N/*---------------------- WDT Controller -------------------------*/
N/**
N    @addtogroup WDT Watch Dog Timer Controller(WDT)
N    Memory Mapped Structure for WDT Controller
N@{ */
N
N#define     REG_WDT_CTL         (WDT_BA+0x00)  /*!< WDT Control Register              */
N#define     REG_WDT_ATLCTL      (WDT_BA+0x04)  /*!< WDT Alternative Control Register  */
N
N/**@}*/ /* end of WDT register group */
N
N/*---------------------- WWDT Controller -------------------------*/
N/**
N    @addtogroup WWDT Window Watch Dog Timer Controller(WWDT)
N    Memory Mapped Structure for WWDT Controller
N@{ */
N
N#define     REG_WWDT_RLDCNT     (WWDT_BA+0x00)  /*!< WWDT Reload Counter Register             */
N#define     REG_WWDT_CTL        (WWDT_BA+0x04)  /*!< WWDT Control Register                    */
N#define     REG_WWDT_STATUS     (WWDT_BA+0x08)  /*!< WWDT Status Register                     */
N#define     REG_WWDT_CNT        (WWDT_BA+0x0C)  /*!< WWDT Counter Value Register              */
N
N/**@}*/ /* end of WWDT register group */
N
N/*---------------------- SC Host Interface -------------------------*/
N/**
N    @addtogroup SC Smart Card Host Interface (SC)
N    Memory Mapped Structure for Smart Card Host Interface
N@{ */
N
N#define     REG_SC0_DAT     (SC0_BA+0x00)  /*!< SC0 Receiving/Transmit Holding Buffer Register */
N#define     REG_SC0_CTL     (SC0_BA+0x04)  /*!< SC0 Control Register */
N#define     REG_SC0_ALTCTL  (SC0_BA+0x08)  /*!< SC0 Alternate Control Register  */
N#define     REG_SC0_EGT     (SC0_BA+0x0C)  /*!< SC0 Extend Guard Time Register  */
N#define     REG_SC0_RXTOUT  (SC0_BA+0x10)  /*!< SC0 Receive Buffer Time-out Register */
N#define     REG_SC0_ETUCTL  (SC0_BA+0x14)  /*!< SC0 ETU Control Register */
N#define     REG_SC0_INTEN   (SC0_BA+0x18)  /*!< SC0 Interrupt Enable Control Register */
N#define     REG_SC0_INTSTS  (SC0_BA+0x1C)  /*!< SC0 Interrupt Status Register */
N#define     REG_SC0_STATUS  (SC0_BA+0x20)  /*!< SC0 Status Register */
N#define     REG_SC0_PINCTL  (SC0_BA+0x24)  /*!< SC0 Pin Control State Register */
N#define     REG_SC0_TMRCTL0 (SC0_BA+0x28)  /*!< SC0 Internal Timer Control Register 0 */
N#define     REG_SC0_TMRCTL1 (SC0_BA+0x2C)  /*!< SC0 Internal Timer Control Register 1 */
N#define     REG_SC0_TMRCTL2 (SC0_BA+0x30)  /*!< SC0 Internal Timer Control Register 2 */
N#define     REG_SC0_UARTCTL (SC0_BA+0x34)  /*!< SC0 UART Mode Control Register */
N#define     REG_SC0_TMRDAT0 (SC0_BA+0x38)  /*!< SC0 Timer Current Data Register 0 */
N#define     REG_SC0_TMRDAT1 (SC0_BA+0x3C)  /*!< SC0 Timer Current Data Register 1 */
N
N#define     REG_SC1_DAT     (SC1_BA+0x00)  /*!< SC1 Receiving/Transmit Holding Buffer Register */
N#define     REG_SC1_CTL     (SC1_BA+0x04)  /*!< SC1 Control Register */
N#define     REG_SC1_ALTCTL  (SC1_BA+0x08)  /*!< SC1 Alternate Control Register  */
N#define     REG_SC1_EGT     (SC1_BA+0x0C)  /*!< SC1 Extend Guard Time Register  */
N#define     REG_SC1_RXTOUT  (SC1_BA+0x10)  /*!< SC1 Receive Buffer Time-out Register */
N#define     REG_SC1_ETUCTL  (SC1_BA+0x14)  /*!< SC1 ETU Control Register */
N#define     REG_SC1_INTEN   (SC1_BA+0x18)  /*!< SC1 Interrupt Enable Control Register */
N#define     REG_SC1_INTSTS  (SC1_BA+0x1C)  /*!< SC1 Interrupt Status Register */
N#define     REG_SC1_STATUS  (SC1_BA+0x20)  /*!< SC1 Status Register */
N#define     REG_SC1_PINCTL  (SC1_BA+0x24)  /*!< SC1 Pin Control State Register */
N#define     REG_SC1_TMRCTL0 (SC1_BA+0x28)  /*!< SC1 Internal Timer Control Register 0 */
N#define     REG_SC1_TMRCTL1 (SC1_BA+0x2C)  /*!< SC1 Internal Timer Control Register 1 */
N#define     REG_SC1_TMRCTL2 (SC1_BA+0x30)  /*!< SC1 Internal Timer Control Register 2 */
N#define     REG_SC1_UARTCTL (SC1_BA+0x34)  /*!< SC1 UART Mode Control Register */
N#define     REG_SC1_TMRDAT0 (SC1_BA+0x38)  /*!< SC1 Timer Current Data Register 0 */
N#define     REG_SC1_TMRDAT1 (SC1_BA+0x3C)  /*!< SC1 Timer Current Data Register 1 */
N
N/**@}*/ /* end of SC register group */
N
N
N/*---------------------- Advance Interrupt Controller -------------------------*/
N/**
N    @addtogroup AIC Advance Interrupt Controller(AIC)
N    Memory Mapped Structure for AIC Controller
N@{ */
N
N#define     REG_AIC_SCR1    (AIC_BA+0x00)    /*!< Source control register 1 */
N#define     REG_AIC_SCR2    (AIC_BA+0x04)    /*!< Source control register 2 */
N#define     REG_AIC_SCR3    (AIC_BA+0x08)    /*!< Source control register 3 */
N#define     REG_AIC_SCR4    (AIC_BA+0x0C)    /*!< Source control register 4 */
N#define     REG_AIC_SCR5    (AIC_BA+0x10)    /*!< Source control register 5 */
N#define     REG_AIC_SCR6    (AIC_BA+0x14)    /*!< Source control register 6 */
N#define     REG_AIC_SCR7    (AIC_BA+0x18)    /*!< Source control register 7 */
N#define     REG_AIC_SCR8    (AIC_BA+0x1C)    /*!< Source control register 8 */
N#define     REG_AIC_SCR9    (AIC_BA+0x20)    /*!< Source control register 9 */
N#define     REG_AIC_SCR10   (AIC_BA+0x24)    /*!< Source control register 10 */
N#define     REG_AIC_SCR11   (AIC_BA+0x28)    /*!< Source control register 11 */
N#define     REG_AIC_SCR12   (AIC_BA+0x2C)    /*!< Source control register 12 */
N#define     REG_AIC_SCR13   (AIC_BA+0x30)    /*!< Source control register 13 */
N#define     REG_AIC_SCR14   (AIC_BA+0x34)    /*!< Source control register 14 */
N#define     REG_AIC_SCR15   (AIC_BA+0x38)    /*!< Source control register 15 */
N#define     REG_AIC_SCR16   (AIC_BA+0x3C)    /*!< Source control register 16 */
N#define     REG_AIC_IRSR    (AIC_BA+0x100)   /*!< Interrupt raw status register */
N#define     REG_AIC_IRSRH   (AIC_BA+0x104)   /*!< Interrupt raw status register (Hign) */
N#define     REG_AIC_IASR    (AIC_BA+0x108)   /*!< Interrupt active status register */
N#define     REG_AIC_IASRH   (AIC_BA+0x10C)   /*!< Interrupt active status register (Hign) */
N#define     REG_AIC_ISR     (AIC_BA+0x110)   /*!< Interrupt status register */
N#define     REG_AIC_ISRH    (AIC_BA+0x114)   /*!< Interrupt status register (High) */
N#define     REG_AIC_IPER    (AIC_BA+0x118)   /*!< Interrupt priority encoding register */
N#define     REG_AIC_ISNR    (AIC_BA+0x120)   /*!< Interrupt source number register */
N#define     REG_AIC_OISR    (AIC_BA+0x124)   /*!< Output interrupt status register */
N#define     REG_AIC_IMR     (AIC_BA+0x128)   /*!< Interrupt mask register */
N#define     REG_AIC_IMRH    (AIC_BA+0x12C)   /*!< Interrupt mask register (High) */
N#define     REG_AIC_MECR    (AIC_BA+0x130)   /*!< Mask enable command register */
N#define     REG_AIC_MECRH   (AIC_BA+0x134)   /*!< Mask enable command register (High) */
N#define     REG_AIC_MDCR    (AIC_BA+0x138)   /*!< Mask disable command register */
N#define     REG_AIC_MDCRH   (AIC_BA+0x13C)   /*!< Mask disable command register (High) */
N#define     REG_AIC_SSCR    (AIC_BA+0x140)   /*!< Source Set Command Register */
N#define     REG_AIC_SSCRH   (AIC_BA+0x144)   /*!< Source Set Command Register (High) */
N#define     REG_AIC_SCCR    (AIC_BA+0x148)   /*!< Source Clear Command Register */
N#define     REG_AIC_SCCRH   (AIC_BA+0x14C)   /*!< Source Clear Command Register (High) */
N#define     REG_AIC_EOSCR   (AIC_BA+0x150)   /*!< End of service command register */
N
N/**@}*/ /* end of AIC register group */
N
N
N/*---------------------- General Purpose Input/Output Controller -------------------------*/
N/**
N    @addtogroup GPIO General Purpose Input/Output Controller(GPIO)
N    Memory Mapped Structure for GPIO Controller
N@{ */
N
N#define     REG_GPIOA_DIR       (GPIO_BA+0x000)  /*!< GPIO portA direction control register */
N#define     REG_GPIOA_DATAOUT   (GPIO_BA+0x004)  /*!< GPIO portA data output register */
N#define     REG_GPIOA_DATAIN    (GPIO_BA+0x008)  /*!< GPIO portA data input register */
N#define     REG_GPIOA_IMD       (GPIO_BA+0x00C)  /*!< GPIO Port A Interrupt Mode Register */
N#define     REG_GPIOA_IREN      (GPIO_BA+0x010)  /*!< GPIO Port A Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOA_IFEN      (GPIO_BA+0x014)  /*!< GPIO Port A Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOA_ISR       (GPIO_BA+0x018)  /*!< GPIO Port A Interrupt Status Register */
N#define     REG_GPIOA_DBEN      (GPIO_BA+0x01C)  /*!< GPIO Port A De-bounce Enable Register */
N#define     REG_GPIOA_PUEN      (GPIO_BA+0x020)  /*!< GPIO Port A Pull-Up Enable Register */
N#define     REG_GPIOA_PDEN      (GPIO_BA+0x024)  /*!< GPIO Port A Pull-Down Enable Register */
N#define     REG_GPIOA_ICEN      (GPIO_BA+0x028)  /*!< GPIO Port A CMOS Input Enable Register */
N#define     REG_GPIOA_ISEN      (GPIO_BA+0x02C)  /*!< GPIO Port A Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOB_DIR       (GPIO_BA+0x040)  /*!< GPIO port B direction control register */
N#define     REG_GPIOB_DATAOUT   (GPIO_BA+0x044)  /*!< GPIO port B data output register */
N#define     REG_GPIOB_DATAIN    (GPIO_BA+0x048)  /*!< GPIO port B data input register */
N#define     REG_GPIOB_IMD       (GPIO_BA+0x04C)  /*!< GPIO Port B Interrupt Mode Register */
N#define     REG_GPIOB_IREN      (GPIO_BA+0x050)  /*!< GPIO Port B Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOB_IFEN      (GPIO_BA+0x054)  /*!< GPIO Port B Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOB_ISR       (GPIO_BA+0x058)  /*!< GPIO Port B Interrupt Status Register */
N#define     REG_GPIOB_DBEN      (GPIO_BA+0x05C)  /*!< GPIO Port B De-bounce Enable Register */
N#define     REG_GPIOB_PUEN      (GPIO_BA+0x060)  /*!< GPIO Port B Pull-Up Enable Register */
N#define     REG_GPIOB_PDEN      (GPIO_BA+0x064)  /*!< GPIO Port B Pull-Down Enable Register */
N#define     REG_GPIOB_ICEN      (GPIO_BA+0x068)  /*!< GPIO Port B CMOS Input Enable Register */
N#define     REG_GPIOB_ISEN      (GPIO_BA+0x06C)  /*!< GPIO Port B Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOC_DIR       (GPIO_BA+0x080)  /*!< GPIO port C direction control register */
N#define     REG_GPIOC_DATAOUT   (GPIO_BA+0x084)  /*!< GPIO port C data output register */
N#define     REG_GPIOC_DATAIN    (GPIO_BA+0x088)  /*!< GPIO port C data input register */
N#define     REG_GPIOC_IMD       (GPIO_BA+0x08C)  /*!< GPIO Port C Interrupt Mode Register */
N#define     REG_GPIOC_IREN      (GPIO_BA+0x090)  /*!< GPIO Port C Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOC_IFEN      (GPIO_BA+0x094)  /*!< GPIO Port C Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOC_ISR       (GPIO_BA+0x098)  /*!< GPIO Port C Interrupt Status Register */
N#define     REG_GPIOC_DBEN      (GPIO_BA+0x09C)  /*!< GPIO Port C De-bounce Enable Register */
N#define     REG_GPIOC_PUEN      (GPIO_BA+0x0A0)  /*!< GPIO Port C Pull-Up Enable Register */
N#define     REG_GPIOC_PDEN      (GPIO_BA+0x0A4)  /*!< GPIO Port C Pull-Down Enable Register */
N#define     REG_GPIOC_ICEN      (GPIO_BA+0x0A8)  /*!< GPIO Port C CMOS Input Enable Register */
N#define     REG_GPIOC_ISEN      (GPIO_BA+0x0AC)  /*!< GPIO Port C Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOD_DIR       (GPIO_BA+0x0C0)  /*!< GPIO port D direction control register */
N#define     REG_GPIOD_DATAOUT   (GPIO_BA+0x0C4)  /*!< GPIO port D data output register */
N#define     REG_GPIOD_DATAIN    (GPIO_BA+0x0C8)  /*!< GPIO port D data input register */
N#define     REG_GPIOD_IMD       (GPIO_BA+0x0CC)  /*!< GPIO Port D Interrupt Mode Register */
N#define     REG_GPIOD_IREN      (GPIO_BA+0x0D0)  /*!< GPIO Port D Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOD_IFEN      (GPIO_BA+0x0D4)  /*!< GPIO Port D Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOD_ISR       (GPIO_BA+0x0D8)  /*!< GPIO Port D Interrupt Status Register */
N#define     REG_GPIOD_DBEN      (GPIO_BA+0x0DC)  /*!< GPIO Port D De-bounce Enable Register */
N#define     REG_GPIOD_PUEN      (GPIO_BA+0x0E0)  /*!< GPIO Port D Pull-Up Enable Register */
N#define     REG_GPIOD_PDEN      (GPIO_BA+0x0E4)  /*!< GPIO Port D Pull-Down Enable Register */
N#define     REG_GPIOD_ICEN      (GPIO_BA+0x0E8)  /*!< GPIO Port D CMOS Input Enable Register */
N#define     REG_GPIOD_ISEN      (GPIO_BA+0x0EC)  /*!< GPIO Port D Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOE_DIR       (GPIO_BA+0x100)  /*!< GPIO port E direction control register */
N#define     REG_GPIOE_DATAOUT   (GPIO_BA+0x104)  /*!< GPIO port E data output register */
N#define     REG_GPIOE_DATAIN    (GPIO_BA+0x108)  /*!< GPIO port E data input register */
N#define     REG_GPIOE_IMD       (GPIO_BA+0x10C)  /*!< GPIO Port E Interrupt Mode Register */
N#define     REG_GPIOE_IREN      (GPIO_BA+0x110)  /*!< GPIO Port E Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOE_IFEN      (GPIO_BA+0x114)  /*!< GPIO Port E Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOE_ISR       (GPIO_BA+0x118)  /*!< GPIO Port E Interrupt Status Register */
N#define     REG_GPIOE_DBEN      (GPIO_BA+0x11C)  /*!< GPIO Port E De-bounce Enable Register */
N#define     REG_GPIOE_PUEN      (GPIO_BA+0x120)  /*!< GPIO Port E Pull-Up Enable Register */
N#define     REG_GPIOE_PDEN      (GPIO_BA+0x124)  /*!< GPIO Port E Pull-Down Enable Register */
N#define     REG_GPIOE_ICEN      (GPIO_BA+0x128)  /*!< GPIO Port E CMOS Input Enable Register */
N#define     REG_GPIOE_ISEN      (GPIO_BA+0x12C)  /*!< GPIO Port E Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOF_DIR       (GPIO_BA+0x140)  /*!< GPIO port F direction control register */
N#define     REG_GPIOF_DATAOUT   (GPIO_BA+0x144)  /*!< GPIO port F data output register */
N#define     REG_GPIOF_DATAIN    (GPIO_BA+0x148)  /*!< GPIO port F data input register */
N#define     REG_GPIOF_IMD       (GPIO_BA+0x14C)  /*!< GPIO Port F Interrupt Mode Register */
N#define     REG_GPIOF_IREN      (GPIO_BA+0x150)  /*!< GPIO Port F Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOF_IFEN      (GPIO_BA+0x154)  /*!< GPIO Port F Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOF_ISR       (GPIO_BA+0x158)  /*!< GPIO Port F Interrupt Status Register */
N#define     REG_GPIOF_DBEN      (GPIO_BA+0x15C)  /*!< GPIO Port F De-bounce Enable Register */
N#define     REG_GPIOF_PUEN      (GPIO_BA+0x160)  /*!< GPIO Port F Pull-Up Enable Register */
N#define     REG_GPIOF_PDEN      (GPIO_BA+0x164)  /*!< GPIO Port F Pull-Down Enable Register */
N#define     REG_GPIOF_ICEN      (GPIO_BA+0x168)  /*!< GPIO Port F CMOS Input Enable Register */
N#define     REG_GPIOF_ISEN      (GPIO_BA+0x16C)  /*!< GPIO Port F Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOG_DIR       (GPIO_BA+0x180)  /*!< GPIO port G direction control register */
N#define     REG_GPIOG_DATAOUT   (GPIO_BA+0x184)  /*!< GPIO port G data output register */
N#define     REG_GPIOG_DATAIN    (GPIO_BA+0x188)  /*!< GPIO port G data input register */
N#define     REG_GPIOG_IMD       (GPIO_BA+0x18C)  /*!< GPIO Port G Interrupt Mode Register */
N#define     REG_GPIOG_IREN      (GPIO_BA+0x190)  /*!< GPIO Port G Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOG_IFEN      (GPIO_BA+0x194)  /*!< GPIO Port G Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOG_ISR       (GPIO_BA+0x198)  /*!< GPIO Port G Interrupt Status Register */
N#define     REG_GPIOG_DBEN      (GPIO_BA+0x19C)  /*!< GPIO Port G De-bounce Enable Register */
N#define     REG_GPIOG_PUEN      (GPIO_BA+0x1A0)  /*!< GPIO Port G Pull-Up Enable Register */
N#define     REG_GPIOG_PDEN      (GPIO_BA+0x1A4)  /*!< GPIO Port G Pull-Down Enable Register */
N#define     REG_GPIOG_ICEN      (GPIO_BA+0x1A8)  /*!< GPIO Port G CMOS Input Enable Register */
N#define     REG_GPIOG_ISEN      (GPIO_BA+0x1AC)  /*!< GPIO Port G Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOH_DIR       (GPIO_BA+0x1C0)  /*!< GPIO port H direction control register */
N#define     REG_GPIOH_DATAOUT   (GPIO_BA+0x1C4)  /*!< GPIO port H data output register */
N#define     REG_GPIOH_DATAIN    (GPIO_BA+0x1C8)  /*!< GPIO port H data input register */
N#define     REG_GPIOH_IMD       (GPIO_BA+0x1CC)  /*!< GPIO Port H Interrupt Mode Register */
N#define     REG_GPIOH_IREN      (GPIO_BA+0x1D0)  /*!< GPIO Port H Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOH_IFEN      (GPIO_BA+0x1D4)  /*!< GPIO Port H Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOH_ISR       (GPIO_BA+0x1D8)  /*!< GPIO Port H Interrupt Status Register */
N#define     REG_GPIOH_DBEN      (GPIO_BA+0x1DC)  /*!< GPIO Port H De-bounce Enable Register */
N#define     REG_GPIOH_PUEN      (GPIO_BA+0x1E0)  /*!< GPIO Port H Pull-Up Enable Register */
N#define     REG_GPIOH_PDEN      (GPIO_BA+0x1E4)  /*!< GPIO Port H Pull-Down Enable Register */
N#define     REG_GPIOH_ICEN      (GPIO_BA+0x1E8)  /*!< GPIO Port H CMOS Input Enable Register */
N#define     REG_GPIOH_ISEN      (GPIO_BA+0x1EC)  /*!< GPIO Port H Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOI_DIR       (GPIO_BA+0x200)  /*!< GPIO port I direction control register */
N#define     REG_GPIOI_DATAOUT   (GPIO_BA+0x204)  /*!< GPIO port I data output register */
N#define     REG_GPIOI_DATAIN    (GPIO_BA+0x208)  /*!< GPIO port I data input register */
N#define     REG_GPIOI_IMD       (GPIO_BA+0x20C)  /*!< GPIO Port I Interrupt Mode Register */
N#define     REG_GPIOI_IREN      (GPIO_BA+0x210)  /*!< GPIO Port I Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOI_IFEN      (GPIO_BA+0x214)  /*!< GPIO Port I Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOI_ISR       (GPIO_BA+0x218)  /*!< GPIO Port I Interrupt Status Register */
N#define     REG_GPIOI_DBEN      (GPIO_BA+0x21C)  /*!< GPIO Port I De-bounce Enable Register */
N#define     REG_GPIOI_PUEN      (GPIO_BA+0x220)  /*!< GPIO Port I Pull-Up Enable Register */
N#define     REG_GPIOI_PDEN      (GPIO_BA+0x224)  /*!< GPIO Port I Pull-Down Enable Register */
N#define     REG_GPIOI_ICEN      (GPIO_BA+0x228)  /*!< GPIO Port I CMOS Input Enable Register */
N#define     REG_GPIOI_ISEN      (GPIO_BA+0x22C)  /*!< GPIO Port I Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIOJ_DIR       (GPIO_BA+0x240)  /*!< GPIO port J direction control register */
N#define     REG_GPIOJ_DATAOUT   (GPIO_BA+0x244)  /*!< GPIO port J data output register */
N#define     REG_GPIOJ_DATAIN    (GPIO_BA+0x248)  /*!< GPIO port J data input register */
N#define     REG_GPIOJ_IMD       (GPIO_BA+0x24C)  /*!< GPIO Port J Interrupt Mode Register */
N#define     REG_GPIOJ_IREN      (GPIO_BA+0x250)  /*!< GPIO Port J Interrupt Rising-Edge or Level-High Enable Register */
N#define     REG_GPIOJ_IFEN      (GPIO_BA+0x254)  /*!< GPIO Port J Interrupt Falling-Edge or Level-Low Enable Register */
N#define     REG_GPIOJ_ISR       (GPIO_BA+0x258)  /*!< GPIO Port J Interrupt Status Register */
N#define     REG_GPIOJ_DBEN      (GPIO_BA+0x25C)  /*!< GPIO Port J De-bounce Enable Register */
N#define     REG_GPIOJ_PUEN      (GPIO_BA+0x260)  /*!< GPIO Port J Pull-Up Enable Register */
N#define     REG_GPIOJ_PDEN      (GPIO_BA+0x264)  /*!< GPIO Port J Pull-Down Enable Register */
N#define     REG_GPIOJ_ICEN      (GPIO_BA+0x268)  /*!< GPIO Port J CMOS Input Enable Register */
N#define     REG_GPIOJ_ISEN      (GPIO_BA+0x26C)  /*!< GPIO Port J Schmitt-Trigger Input Enable Register */
N
N#define     REG_GPIO_DBNCECON   (GPIO_BA+0x3F0)  /*!< GPIO Debounce Control Register */
N#define     REG_GPIO_ISR        (GPIO_BA+0x3FC)  /*!< GPIO Port Interrupt Status Register */
N
N/**@}*/ /* end of GPIO register group */
N
N
N/*---------------------- Real Time Clock Controller -------------------------*/
N/**
N    @addtogroup RTC Real Time Clock Controller(RTC)
N    Memory Mapped Structure for RTC Controller
N@{ */
N
N#define     REG_RTC_INIT    (RTC_BA+0x00)   /*!< RTC Initiation Register */
N#define     REG_RTC_RWEN    (RTC_BA+0x04)   /*!< RTC Access Enable Register */
N#define     REG_RTC_FREQADJ (RTC_BA+0x08)   /*!< RTC Frequency Compensation Register */
N#define     REG_RTC_TIME    (RTC_BA+0x0C)   /*!< Time Loading Register */
N#define     REG_RTC_CAL     (RTC_BA+0x10)   /*!< Calendar Loading Register */
N#define     REG_RTC_TIMEFMT (RTC_BA+0x14)   /*!< Time Format Selection Register */
N#define     REG_RTC_WEEKDAY (RTC_BA+0x18)   /*!< Day of the Week Register */
N#define     REG_RTC_TALM    (RTC_BA+0x1C)   /*!< Time Alarm Register */
N#define     REG_RTC_CALM    (RTC_BA+0x20)   /*!< Calendar Alarm Register */
N#define     REG_RTC_LEAPYEAR    (RTC_BA+0x24)   /*!< Leap year Indicator Register */
N#define     REG_RTC_INTEN   (RTC_BA+0x28)   /*!< RTC Interrupt Enable Register */
N#define     REG_RTC_INTSTS  (RTC_BA+0x2C)   /*!< RTC Interrupt Indicator Register */
N#define     REG_RTC_TICK    (RTC_BA+0x30)   /*!< RTC Time Tick Register */
N#define     REG_RTC_PWRCTL      (RTC_BA+0x34)   /*!< Power Control Register */
N#define     REG_RTC_PWRCNT      (RTC_BA+0x38)   /*!< Power Control Counter Register */
N#define     REG_RTC_SPR0        (RTC_BA+0x40)   /*!< Spare REgistger 0 */
N#define     REG_RTC_SPR1        (RTC_BA+0x44)   /*!< Spare REgistger 1 */
N#define     REG_RTC_SPR2        (RTC_BA+0x48)   /*!< Spare REgistger 2 */
N#define     REG_RTC_SPR3        (RTC_BA+0x4C)   /*!< Spare REgistger 3 */
N#define     REG_RTC_SPR4        (RTC_BA+0x50)   /*!< Spare REgistger 4 */
N#define     REG_RTC_SPR5        (RTC_BA+0x54)   /*!< Spare REgistger 5 */
N#define     REG_RTC_SPR6        (RTC_BA+0x58)   /*!< Spare REgistger 6 */
N#define     REG_RTC_SPR7        (RTC_BA+0x5C)   /*!< Spare REgistger 7 */
N#define     REG_RTC_SPR8        (RTC_BA+0x60)   /*!< Spare REgistger 8 */
N#define     REG_RTC_SPR9        (RTC_BA+0x64)   /*!< Spare REgistger 9 */
N#define     REG_RTC_SPR10       (RTC_BA+0x68)   /*!< Spare REgistger 10 */
N#define     REG_RTC_SPR11       (RTC_BA+0x6C)   /*!< Spare REgistger 11 */
N#define     REG_RTC_SPR12       (RTC_BA+0x70)   /*!< Spare REgistger 12 */
N#define     REG_RTC_SPR13       (RTC_BA+0x74)   /*!< Spare REgistger 13 */
N#define     REG_RTC_SPR14       (RTC_BA+0x78)   /*!< Spare REgistger 14 */
N#define     REG_RTC_SPR15       (RTC_BA+0x7C)   /*!< Spare REgistger 15 */
N
N/**@}*/ /* end of RTC register group */
N
N/*---------------------- Inter-IC Bus Controller -------------------------*/
N/**
N    @addtogroup I2C Inter-IC Bus Controller(I2C)
N    Memory Mapped Structure for I2C Controller
N@{ */
N
N#define     REG_I2C0_CSR        (I2C0_BA+0x00)  /*!< Control and Status Register */
N#define     REG_I2C0_DIVIDER    (I2C0_BA+0x04)  /*!< Clock Prescale Register */
N#define     REG_I2C0_CMDR       (I2C0_BA+0x08)  /*!< Command Register */
N#define     REG_I2C0_SWR        (I2C0_BA+0x0C)  /*!< Software Mode Control Register */
N#define     REG_I2C0_RXR        (I2C0_BA+0x10)  /*!< Data Receive Register */
N#define     REG_I2C0_TXR        (I2C0_BA+0x14)  /*!< Data Transmit Register */
N
N#define     REG_I2C1_CSR        (I2C1_BA+0x00)  /*!< Control and Status Register */
N#define     REG_I2C1_DIVIDER    (I2C1_BA+0x04)  /*!< Clock Prescale Register */
N#define     REG_I2C1_CMDR       (I2C1_BA+0x08)  /*!< Command Register */
N#define     REG_I2C1_SWR        (I2C1_BA+0x0C)  /*!< Software Mode Control Register */
N#define     REG_I2C1_RXR        (I2C1_BA+0x10)  /*!< Data Receive Register */
N#define     REG_I2C1_TXR        (I2C1_BA+0x14)  /*!< Data Transmit Register */
N
N/**@}*/ /* end of I2C register group */
N
N
N/*---------------------- Serial Peripheral Interface Controller -------------------------*/
N/**
N    @addtogroup SPI Serial Peripheral Interface Controller(SPI)
N    Memory Mapped Structure for SPI Controller
N@{ */
N
N#define     REG_SPI0_CNTRL   (SPI0_BA+0x00)  /*!< Control and Status Register */
N#define     REG_SPI0_DIVIDER (SPI0_BA+0x04)  /*!< Clock Divider Register */
N#define     REG_SPI0_SSR     (SPI0_BA+0x08)  /*!< Slave Select Register */
N#define     REG_SPI0_RX0     (SPI0_BA+0x10)  /*!< Data Receive Register 0 */
N#define     REG_SPI0_RX1     (SPI0_BA+0x14)  /*!< Data Receive Register 1 */
N#define     REG_SPI0_RX2     (SPI0_BA+0x18)  /*!< Data Receive Register 2 */
N#define     REG_SPI0_RX3     (SPI0_BA+0x1C)  /*!< Data Receive Register 3 */
N#define     REG_SPI0_TX0     (SPI0_BA+0x10)  /*!< Data Transmit Register 0 */
N#define     REG_SPI0_TX1     (SPI0_BA+0x14)  /*!< Data Transmit Register 1 */
N#define     REG_SPI0_TX2     (SPI0_BA+0x18)  /*!< Data Transmit Register 2 */
N#define     REG_SPI0_TX3     (SPI0_BA+0x1C)  /*!< Data Transmit Register 3 */
N
N#define     REG_SPI1_CNTRL   (SPI1_BA+0x00)  /*!< Control and Status Register */
N#define     REG_SPI1_DIVIDER (SPI1_BA+0x04)  /*!< Clock Divider Register */
N#define     REG_SPI1_SSR     (SPI1_BA+0x08)  /*!< Slave Select Register */
N#define     REG_SPI1_RX0     (SPI1_BA+0x10)  /*!< Data Receive Register 0 */
N#define     REG_SPI1_RX1     (SPI1_BA+0x14)  /*!< Data Receive Register 1 */
N#define     REG_SPI1_RX2     (SPI1_BA+0x18)  /*!< Data Receive Register 2 */
N#define     REG_SPI1_RX3     (SPI1_BA+0x1C)  /*!< Data Receive Register 3 */
N#define     REG_SPI1_TX0     (SPI1_BA+0x10)  /*!< Data Transmit Register 0 */
N#define     REG_SPI1_TX1     (SPI1_BA+0x14)  /*!< Data Transmit Register 1 */
N#define     REG_SPI1_TX2     (SPI1_BA+0x18)  /*!< Data Transmit Register 2 */
N#define     REG_SPI1_TX3     (SPI1_BA+0x1C)  /*!< Data Transmit Register 3 */
N
N/**@}*/ /* end of SPI register group */
N
N
N/*---------------------- Pulse Width Modulation Controller -------------------------*/
N/**
N    @addtogroup PWM Pulse Width Modulation Controller(PWM)
N    Memory Mapped Structure for PWM Controller
N@{ */
N
N#define     REG_PWM_PPR     (PWM_BA+0x00)  /*!< PWM Pre-scale Register 0 */
N#define     REG_PWM_CSR     (PWM_BA+0x04)  /*!< PWM Clock Select Register */
N#define     REG_PWM_PCR     (PWM_BA+0x08)  /*!< PWM Control Register */
N#define     REG_PWM_CNR0    (PWM_BA+0x0C)  /*!< PWM Counter Register 0 */
N#define     REG_PWM_CMR0    (PWM_BA+0x10)  /*!< PWM Comparator Register 0 */
N#define     REG_PWM_PDR0    (PWM_BA+0x14)  /*!< PWM Data Register 0 */
N#define     REG_PWM_CNR1    (PWM_BA+0x18)  /*!< PWM Counter Register 1 */
N#define     REG_PWM_CMR1    (PWM_BA+0x1C)  /*!< PWM Comparator Register 1 */
N#define     REG_PWM_PDR1    (PWM_BA+0x20)  /*!< PWM Data Register 1 */
N#define     REG_PWM_CNR2    (PWM_BA+0x24)  /*!< PWM Counter Register 2 */
N#define     REG_PWM_CMR2    (PWM_BA+0x28)  /*!< PWM Comparator Register 2 */
N#define     REG_PWM_PDR2    (PWM_BA+0x2C)  /*!< PWM Data Register 2 */
N#define     REG_PWM_CNR3    (PWM_BA+0x30)  /*!< PWM Counter Register 3 */
N#define     REG_PWM_CMR3    (PWM_BA+0x34)  /*!< PWM Comparator Register 3 */
N#define     REG_PWM_PDR3    (PWM_BA+0x38)  /*!< PWM Data Register 3 */
N#define     REG_PWM_PIER    (PWM_BA+0x3C)  /*!< PWM Timer Interrupt Enable Register */
N#define     REG_PWM_PIIR    (PWM_BA+0x40)  /*!< PWM Timer Interrupt Identification Register */
N
N/**@}*/ /* end of PWM register group */
N
N
N/*---------------------- Keypad Interface -------------------------*/
N/**
N    @addtogroup KPI Keypad Interface(KPI)
N    Memory Mapped Structure for KPI Controller
N@{ */
N
N#define     REG_KPI_CONF    (KPI_BA+0x00)  /*!< Keypad controller configuration Register */
N#define     REG_KPI_3KCONF  (KPI_BA+0x04)  /*!< Keypad controller 3-keys configuration register */
N#define     REG_KPI_STATUS  (KPI_BA+0x08)  /*!< Keypad status register */
N#define     REG_KPI_RSTC    (KPI_BA+0x0C)  /*!< Keypad  Reset Period Controller register */
N#define     REG_KPI_KEST        (KPI_BA+0x10)  /*!< Keypad Key State Indicator */
N#define     REG_KPI_KPE         (KPI_BA+0x18)  /*!< Press Key Event Indicator */
N#define     REG_KPI_KRE         (KPI_BA+0x20)  /*!< Release Key Event Indicator */
N#define     REG_KPI_PRESCALDIV  (KPI_BA+0x28)  /*!< Pre-Scale Divider */
N
N/**@}*/ /* end of KPI register group */
N
N
N
N
N/*---------------------- Analog to Digital Converter -------------------------*/
N/**
N    @addtogroup ADC Analog to Digital Converter(ADC)
N    Memory Mapped Structure for ADC Controller
N@{ */
N
N#define REG_ADC_CTL       (ADC_BA+0x000) /*!< ADC Contrl */
N#define REG_ADC_CONF      (ADC_BA+0x004) /*!< ADC Configure */
N#define REG_ADC_IER       (ADC_BA+0x008) /*!< ADC Interrupt Enable Register */
N#define REG_ADC_ISR       (ADC_BA+0x00C) /*!< ADC Interrupt Status Register */
N#define REG_ADC_WKISR     (ADC_BA+0x010) /*!< ADC Wake Up Interrupt Status Register */
N#define REG_ADC_XYDATA    (ADC_BA+0x020) /*!< ADC Touch XY Pressure Data */
N#define REG_ADC_ZDATA     (ADC_BA+0x024) /*!< ADC Touch Z Pressure Data */
N#define REG_ADC_DATA      (ADC_BA+0x028) /*!< ADC Normal Conversion Data */
N#define REG_ADC_VBADATA   (ADC_BA+0x02C) /*!< ADC Battery Detection Data */
N#define REG_ADC_KPDATA    (ADC_BA+0x030) /*!< ADC Key Pad Data */
N#define REG_ADC_SELFDATA  (ADC_BA+0x034) /*!< ADC Self-Test Data */
N#define REG_ADC_XYSORT0   (ADC_BA+0x1F4) /*!< ADC Touch XY Position Mean Value Sort 0 */
N#define REG_ADC_XYSORT1   (ADC_BA+0x1F8) /*!< ADC Touch XY Position Mean Value Sort 1 */
N#define REG_ADC_XYSORT2   (ADC_BA+0x1FC) /*!< ADC Touch XY Position Mean Value Sort 2 */
N#define REG_ADC_XYSORT3   (ADC_BA+0x200) /*!< ADC Touch XY Position Mean Value Sort 3 */
N#define REG_ADC_ZSORT0    (ADC_BA+0x204) /*!< ADC Touch Z Pressure Mean Value Sort 0 */
N#define REG_ADC_ZSORT1    (ADC_BA+0x208) /*!< ADC Touch Z Pressure Mean Value Sort 1 */
N#define REG_ADC_ZSORT2    (ADC_BA+0x20C) /*!< ADC Touch Z Pressure Mean Value Sort 2 */
N#define REG_ADC_ZSORT3    (ADC_BA+0x210) /*!< ADC Touch Z Pressure Mean Value Sort 3 */
N#define REG_ADC_MTMULCK   (ADC_BA+0x220) /*!< ADC Manual Test Mode Unlock */
N#define REG_ADC_MTCONF    (ADC_BA+0x224) /*!< ADC Manual Test Mode Configure */
N#define REG_ADC_MTCON     (ADC_BA+0x228) /*!< ADC Manual Test Mode Control */
N#define REG_ADC_ADCAII    (ADC_BA+0x22C) /*!< ADC Analog Interface Information */
N#define REG_ADC_ADCAIIRLT (ADC_BA+0x230) /*!< ADC Analog Interface Information Result */
N
N/**@}*/ /* end of ADC register group */
N
N/*------------------ Capture Sensor Interface Controller ---------------------*/
N/**
N    @addtogroup CAP Capture Sensor Interface Controller(CAP)
N    Memory Mapped Structure for CAP Controller
N@{ */
N
N#define REG_CAP_CTL            (CAP_BA+0x000)  /*!< Image Capture Interface Control Register */
N#define REG_CAP_PAR            (CAP_BA+0x004)  /*!< Image Capture Interface Parameter Register */
N#define REG_CAP_INT            (CAP_BA+0x008)  /*!< Image Capture Interface Interrupt Registe */
N#define REG_CAP_POSTERIZE      (CAP_BA+0x00C)  /*!< YUV Component Posterizing Factor Register */
N#define REG_CAP_MD             (CAP_BA+0x010)  /*!< Motion Detection Register */
N#define REG_CAP_MDADDR         (CAP_BA+0x014)  /*!< Motion Detection Output Address Register */
N#define REG_CAP_MDYADDR        (CAP_BA+0x018)  /*!< Motion Detection Temp YOutput Address Register */
N#define REG_CAP_SEPIA          (CAP_BA+0x01C)  /*!< Sepia Effect Control Register */
N#define REG_CAP_CWSP           (CAP_BA+0x020)  /*!< Cropping Window Starting Address Register */
N#define REG_CAP_CWS            (CAP_BA+0x024)  /*!< Cropping Window Size Register */
N#define REG_CAP_PKTSL          (CAP_BA+0x028)  /*!< Packet Scaling Vertical/Horizontal Factor Register (LSB) */
N#define REG_CAP_PLNSL          (CAP_BA+0x02C)  /*!< Planar Scaling Vertical/Horizontal Factor Register (LSB) */
N#define REG_CAP_FRCTL          (CAP_BA+0x030)  /*!< Scaling Frame Rate Factor Register */
N#define REG_CAP_STRIDE         (CAP_BA+0x034)  /*!< Frame Output Pixel Stride Register */
N#define REG_CAP_FIFOTH         (CAP_BA+0x03C)  /*!< FIFO threshold Register */
N#define REG_CAP_CMPADDR        (CAP_BA+0x040)  /*!< Compare Packet Memory Base Address Register */
N#define REG_CAP_PKTSM          (CAP_BA+0x048)  /*!< Packet Scaling Vertical/Horizontal Factor Register (MSB) */
N#define REG_CAP_PLNSM          (CAP_BA+0x04C)  /*!< Planar Scaling Vertical/Horizontal Factor Register (MSB) */
N#define REG_CAP_CURADDRP       (CAP_BA+0x050)  /*!< Current Packet System Memory Address Register */
N#define REG_CAP_CURADDRY       (CAP_BA+0x054)  /*!< Current Planar Y System Memory Address Register */
N#define REG_CAP_CURADDRU       (CAP_BA+0x058)  /*!< Current Planar U System Memory Address Register */
N#define REG_CAP_CURADDRV       (CAP_BA+0x05C)  /*!< Current Planar V System Memory Address Register */
N#define REG_CAP_PKTBA0         (CAP_BA+0x060)  /*!< System Memory Packet Base Address Register */
N#define REG_CAP_PKTBA1         (CAP_BA+0x064)  /*!< System Memory Packet Base Address Register */
N#define REG_CAP_YBA            (CAP_BA+0x080)  /*!< System Memory Planar Y Base Address Register */
N#define REG_CAP_UBA            (CAP_BA+0x084)  /*!< System Memory Planar U Base Address Register */
N#define REG_CAP_VBA            (CAP_BA+0x088)  /*!< System Memory Planar V Base Address Register */
N
N/**@}*/ /* end of CAP register group */
N
N/*------------------ SDRAM Interface Controller ---------------------*/
N/**
N    @addtogroup SDIC SDRAM Interface Controller(SDIC)
N    Memory Mapped Structure for SDIC Controller
N@{ */
N
N#define REG_SDIC_OPMCTL     (SDIC_BA+0x000)    /*!< SDRAM Controller Operation Mode Control Register */
N#define REG_SDIC_CMD        (SDIC_BA+0x004)    /*!< SDRAM Command Register */
N#define REG_SDIC_REFCTL     (SDIC_BA+0x008)    /*!< SDRAM Controller Refresh Control Register */
N#define REG_SDIC_SIZE0      (SDIC_BA+0x010)    /*!< SDRAM 0 Size Register */
N#define REG_SDIC_SIZE1      (SDIC_BA+0x014)    /*!< SDRAM 1 Size Register */
N#define REG_SDIC_MR         (SDIC_BA+0x018)    /*!< SDRAM Mode Register */
N#define REG_SDIC_EMR        (SDIC_BA+0x01C)    /*!< SDRAM Extended Mode Register */
N#define REG_SDIC_EMR2       (SDIC_BA+0x020)    /*!< SDRAM Extended Mode Register 2 */
N#define REG_SDIC_EMR3       (SDIC_BA+0x024)    /*!< SDRAM Extended Mode Register 3 */
N#define REG_SDIC_TIME       (SDIC_BA+0x028)    /*!< SDRAM Timing Control Register */
N#define REG_SDIC_DQSODS     (SDIC_BA+0x030)    /*!< DQS Output Delay Selection Register */
N#define REG_SDIC_CKDQSDS    (SDIC_BA+0x034)    /*!< Clock and DQS Delay Selection Register */
N#define REG_SDIC_DAENSEL    (SDIC_BA+0x038)    /*!< Data Latch Enable Selection Register */
N
N/**@}*/ /* end of SDIC register group */
N
N/*---------------------- Controller Area Network -------------------------*/
N/**
N    @addtogroup CAN Controller Area Network(CAN)
N    Memory Mapped Structure for CAN Controller
N@{ */
N
N#define REG_CAN0_CON       (CAN0_BA+0x00) /*!< Control Register */
N#define REG_CAN0_STATUS    (CAN0_BA+0x04) /*!< Status Register */
N#define REG_CAN0_ERR       (CAN0_BA+0x08) /*!< Error Counter Register */
N#define REG_CAN0_BTIME     (CAN0_BA+0x0C) /*!< Bit Time Register */
N#define REG_CAN0_IIDR      (CAN0_BA+0x10) /*!< Interrupt Identifier Register */
N#define REG_CAN0_TEST      (CAN0_BA+0x14) /*!< Test Register */
N#define REG_CAN0_BRPE      (CAN0_BA+0x18) /*!< BRP Extension Register */
N#define REG_CAN0_IF1_CREQ  (CAN0_BA+0x20) /*!< IF1 Command Request Register */
N#define REG_CAN0_IF2_CREQ  (CAN0_BA+0x80) /*!< IF2 Command Request Register */
N#define REG_CAN0_IF1_CMASK (CAN0_BA+0x24) /*!< IF1 Command Mask Register */
N#define REG_CAN0_IF2_CMASK (CAN0_BA+0x84) /*!< IF2 Command Mask Register */
N#define REG_CAN0_IF1_MASK1 (CAN0_BA+0x28) /*!< IF1 Msak 1 Register */
N#define REG_CNA0_IF2_MASK1 (CAN0_BA+0x88) /*!< IF2 Mask 1 Register */
N#define REG_CAN0_IF1_MASK2 (CAN0_BA+0x2C) /*!< IF1 Mask 2 Register */
N#define REG_CAN0_IF2_MASK2 (CAN0_BA+0x8C) /*!< IF2 Mask 2 REgister */
N#define REG_CAN0_IF1_ARB1  (CAN0_BA+0x30) /*!< IF1 Arbitration 1 Register */
N#define REG_CAN0_IF2_ARB1  (CAN0_BA+0x90) /*!< IF2 Arbitration 1 Register */
N#define REG_CAN0_IF1_ARB2  (CAN0_BA+0x34) /*!< IF1 Arbitration 2 Register */
N#define REG_CAN0_IF2_ARB2  (CAN0_BA+0x94) /*!< IF2 Arbitration 2 Register */
N#define REG_CAN0_IF1_MCON  (CAN0_BA+0x38) /*!< IF1 Message Control Register */
N#define REG_CAN0_IF2_MCON  (CAN0_BA+0x98) /*!< IF2 Message Control Register */
N#define REG_CAN0_IF1_DAT_A1 (CAN0_BA+0x3C) /*!< IF1 Data A1 Register */
N#define REG_CAN0_IF1_DAT_A2 (CAN0_BA+0x40) /*!< IF1 Data A2 Register */
N#define REG_CAN0_IF1_DAT_B1 (CAN0_BA+0x44) /*!< IF1 Data B1 Register */
N#define REG_CAN0_IF1_DAT_B2 (CAN0_BA+0x48) /*!< IF1 Data B2 Register */
N#define REG_CAN0_IF2_DAT_A1 (CAN0_BA+0x9C) /*!< IF2 Data A1 Register */
N#define REG_CAN0_IF2_DAT_A2 (CAN0_BA+0xA0) /*!< IF2 Data A2 Register */
N#define REG_CAN0_IF2_DAT_B1 (CAN0_BA+0xA4) /*!< IF2 Data B1 Register */
N#define REG_CAN0_IF2_DAT_B2 (CAN0_BA+0xA8) /*!< IF2 Data B2 Register */
N#define REG_CAN0_TXREQ1     (CAN0_BA+0x100) /*!< Transmission Request Register 1 */
N#define REG_CAN0_TXREQ2     (CAN0_BA+0x104) /*!< Transmission Request Register 2 */
N#define REG_CAN0_NDAT1      (CAN0_BA+0x120) /*!< New Data Register 1 */
N#define REG_CAN0_NDAT2      (CAN0_BA+0x124) /*!< New Data Register 2 */
N#define REG_CAN0_IPND1      (CAN0_BA+0x140) /*!< Interrupt Pending Register 1 */
N#define REG_CAN0_IPND2      (CAN0_BA+0x142) /*!< Interrupt Pending Register 2 */
N#define REG_CAN0_MVLD1      (CAN0_BA+0x160) /*!< Message Valid Register 1 */
N#define REG_CAN0_MVLD2      (CAN0_BA+0x164) /*!< Message Valid Register 2 */
N#define REG_CAN0_WU_EN      (CAN0_BA+0x168) /*!< Wake-up Function Enable */
N#define REG_CAN0_WU_STATUS  (CAN0_BA+0x16C) /*!< Wake-up Function Status */
N
N#define REG_CAN1_CON       (CAN1_BA+0x00) /*!< Control Register */
N#define REG_CAN1_STATUS    (CAN1_BA+0x04) /*!< Status Register */
N#define REG_CAN1_ERR       (CAN1_BA+0x08) /*!< Error Counter Register */
N#define REG_CAN1_BTIME     (CAN1_BA+0x0C) /*!< Bit Time Register */
N#define REG_CAN1_IIDR      (CAN1_BA+0x10) /*!< Interrupt Identifier Register */
N#define REG_CAN1_TEST      (CAN1_BA+0x14) /*!< Test Register */
N#define REG_CAN1_BRPE      (CAN1_BA+0x18) /*!< BRP Extension Register */
N#define REG_CAN1_IF1_CREQ  (CAN1_BA+0x20) /*!< IF1 Command Request Register */
N#define REG_CAN1_IF2_CREQ  (CAN1_BA+0x80) /*!< IF2 Command Request Register */
N#define REG_CAN1_IF1_CMASK (CAN1_BA+0x24) /*!< IF1 Command Mask Register */
N#define REG_CAN1_IF2_CMASK (CAN1_BA+0x84) /*!< IF2 Command Mask Register */
N#define REG_CAN1_IF1_MASK1 (CAN1_BA+0x28) /*!< IF1 Msak 1 Register */
N#define REG_CNA1_IF2_MASK1 (CAN1_BA+0x88) /*!< IF2 Mask 1 Register */
N#define REG_CAN1_IF1_MASK2 (CAN1_BA+0x2C) /*!< IF1 Mask 2 Register */
N#define REG_CAN1_IF2_MASK2 (CAN1_BA+0x8C) /*!< IF2 Mask 2 REgister */
N#define REG_CAN1_IF1_ARB1  (CAN1_BA+0x30) /*!< IF1 Arbitration 1 Register */
N#define REG_CAN1_IF2_ARB1  (CAN1_BA+0x90) /*!< IF2 Arbitration 1 Register */
N#define REG_CAN1_IF1_ARB2  (CAN1_BA+0x34) /*!< IF1 Arbitration 2 Register */
N#define REG_CAN1_IF2_ARB2  (CAN1_BA+0x94) /*!< IF2 Arbitration 2 Register */
N#define REG_CAN1_IF1_MCON  (CAN1_BA+0x38) /*!< IF1 Message Control Register */
N#define REG_CAN1_IF2_MCON  (CAN1_BA+0x98) /*!< IF2 Message Control Register */
N#define REG_CAN1_IF1_DAT_A1 (CAN1_BA+0x3C) /*!< IF1 Data A1 Register */
N#define REG_CAN1_IF1_DAT_A2 (CAN1_BA+0x40) /*!< IF1 Data A2 Register */
N#define REG_CAN1_IF1_DAT_B1 (CAN1_BA+0x44) /*!< IF1 Data B1 Register */
N#define REG_CAN1_IF1_DAT_B2 (CAN1_BA+0x48) /*!< IF1 Data B2 Register */
N#define REG_CAN1_IF2_DAT_A1 (CAN1_BA+0x9C) /*!< IF2 Data A1 Register */
N#define REG_CAN1_IF2_DAT_A2 (CAN1_BA+0xA0) /*!< IF2 Data A2 Register */
N#define REG_CAN1_IF2_DAT_B1 (CAN1_BA+0xA4) /*!< IF2 Data B1 Register */
N#define REG_CAN1_IF2_DAT_B2 (CAN1_BA+0xA8) /*!< IF2 Data B2 Register */
N#define REG_CAN1_TXREQ1     (CAN1_BA+0x100) /*!< Transmission Request Register 1 */
N#define REG_CAN1_TXREQ2     (CAN1_BA+0x104) /*!< Transmission Request Register 2 */
N#define REG_CAN1_NDAT1      (CAN1_BA+0x120) /*!< New Data Register 1 */
N#define REG_CAN1_NDAT2      (CAN1_BA+0x124) /*!< New Data Register 2 */
N#define REG_CAN1_IPND1      (CAN1_BA+0x140) /*!< Interrupt Pending Register 1 */
N#define REG_CAN1_IPND2      (CAN1_BA+0x142) /*!< Interrupt Pending Register 2 */
N#define REG_CAN1_MVLD1      (CAN1_BA+0x160) /*!< Message Valid Register 1 */
N#define REG_CAN1_MVLD2      (CAN1_BA+0x164) /*!< Message Valid Register 2 */
N#define REG_CAN1_WU_EN      (CAN1_BA+0x168) /*!< Wake-up Function Enable */
N#define REG_CAN1_WU_STATUS  (CAN1_BA+0x16C) /*!< Wake-up Function Status */
N
N/**@}*/ /* end of CAN register group */
N
N
N/*------------------- Multi-Time Programmable Controller --------------------*/
N/**
N    @addtogroup MTP Multi-Time Programmable Controller (MTP)
N    Memory Mapped Structure for MTP Controller
N@{ */
N
N#define     MTP_KEYEN           (MTP_BA+0x000)   /*!< MTP Key Enable Register                       */
N#define     MTP_USERDATA        (MTP_BA+0x00C)   /*!< MTP User Defined Data Register                */
N#define     MTP_KEY0            (MTP_BA+0x010)   /*!< MTP KEY 0 Register                            */
N#define     MTP_KEY1            (MTP_BA+0x014)   /*!< MTP KEY 1 Register                            */
N#define     MTP_KEY2            (MTP_BA+0x018)   /*!< MTP KEY 2 Register                            */
N#define     MTP_KEY3            (MTP_BA+0x01C)   /*!< MTP KEY 3 Register                            */
N#define     MTP_KEY4            (MTP_BA+0x020)   /*!< MTP KEY 4 Register                            */
N#define     MTP_KEY5            (MTP_BA+0x024)   /*!< MTP KEY 5 Register                            */
N#define     MTP_KEY6            (MTP_BA+0x028)   /*!< MTP KEY 6 Register                            */
N#define     MTP_KEY7            (MTP_BA+0x02C)   /*!< MTP KEY 7 Register                            */
N#define     MTP_PCYCLE          (MTP_BA+0x030)   /*!< MTP Program Cycle Program Count Register      */
N#define     MTP_CTL             (MTP_BA+0x034)   /*!< MTP Control Register                          */
N#define     MTP_PSTART          (MTP_BA+0x038)   /*!< MTP Program Start Registe                     */
N#define     MTP_STATUS          (MTP_BA+0x040)   /*!< MTP Status Registe                            */
N#define     MTP_REGLCTL         (MTP_BA+0x050)   /*!< MTP Register Write-Protection Control Register*/
N
N/**@}*/ /* end of MTP register group */
N
N
N/*------------------- JPEG Controller --------------------*/
N/**
N    @addtogroup JPEG JPEG Controller (JPEG)
N    Memory Mapped Structure for JPEG Controller
N@{ */
N#define JMCR           (JPEG_BA+0x00)           /*!< JPEG Mode Control Register  */
N#define JHEADER        (JPEG_BA+0x04)           /*!< JPEG Encode Header Control Register  */
N#define JITCR          (JPEG_BA+0x08)           /*!< JPEG Image Type Control Register  */
N#define JPRIQC         (JPEG_BA+0x10)           /*!< JPEG Primary Q-Table Control Register  */
N#define JTHBQC         (JPEG_BA+0x14)           /*!< JPEG Thumbnail Q-Table Control Register  */
N#define JPRIWH         (JPEG_BA+0x18)           /*!< JPEG Encode Primary Width/Height Register  */
N#define JTHBWH         (JPEG_BA+0x1C)           /*!< JPEG Encode Thumbnail Width/Height Register  */
N#define JPRST          (JPEG_BA+0x20)           /*!< JPEG Encode Primary Restart Interval Register  */
N#define JTRST          (JPEG_BA+0x24)           /*!< JPEG Encode Thumbnail Restart Interval  */
N#define JDECWH         (JPEG_BA+0x28)           /*!< JPEG Decode Image Width/Height Register  */
N#define JINTCR         (JPEG_BA+0x2C)           /*!< JPEG Interrupt Control and Status Register  */
N#define JDOWFBS        (JPEG_BA+0x3c)           /*!< JPEG Decoding Output Wait Frame Buffer Size  */
N#define JPEG_BSBAD     (JPEG_BA+0x40)           /*!< JPEG Test Control Register  */
N#define JWINDEC0       (JPEG_BA+0x44)           /*!< JPEG Window Decode Mode Control Register 0  */
N#define JWINDEC1       (JPEG_BA+0x48)           /*!< JPEG Window Decode Mode Control Register 1  */
N#define JWINDEC2       (JPEG_BA+0x4C)           /*!< JPEG Window Decode Mode Control Register 2  */
N#define JMACR          (JPEG_BA+0x50)           /*!< JPEG Memory Address Mode Control Register  */
N#define JPSCALU        (JPEG_BA+0x54)           /*!< JPEG Primary Scaling-Up Control Register  */
N#define JPSCALD        (JPEG_BA+0x58)           /*!< JPEG Primary Scaling-Down Control Register  */
N#define JTSCALD        (JPEG_BA+0x5C)           /*!< JPEG Thumbnail  Scaling-Down Control Register  */
N#define JDBCR          (JPEG_BA+0x60)           /*!< JPEG Dual-Buffer Control Register  */
N#define JRESERVE       (JPEG_BA+0x70)           /*!< JPEG Encode Primary Bit-stream Reserved Size Register  */
N#define JOFFSET        (JPEG_BA+0x74)           /*!< JPEG Offset Between Primary & Thumbnail Register  */
N#define JFSTRIDE       (JPEG_BA+0x78)           /*!< JPEG Encode Bit-stream Frame Stride Register  */
N#define JYADDR0        (JPEG_BA+0x7C)           /*!< JPEG Y Component Frame Buffer-0 Starting Address Register  */
N#define JUADDR0        (JPEG_BA+0x80)           /*!< JPEG U Component Frame Buffer-0 Starting Address Register  */
N#define JVADDR0        (JPEG_BA+0x84)           /*!< JPEG V Component Frame Buffer-0 Starting Address Register  */
N#define JYADDR1        (JPEG_BA+0x88)           /*!< JPEG Y Component Frame Buffer-1 Starting Address Register  */
N#define JUADDR1        (JPEG_BA+0x8C)           /*!< JPEG U Component Frame Buffer-1 Starting Address Register  */
N#define JVADDR1        (JPEG_BA+0x90)           /*!< JPEG V Component Frame Buffer-1 Starting Address Register  */
N#define JYSTRIDE       (JPEG_BA+0x94)           /*!< JPEG Y Component Frame Buffer Stride Register  */
N#define JUSTRIDE       (JPEG_BA+0x98)           /*!< JPEG U Component Frame Buffer Stride Register  */
N#define JVSTRIDE       (JPEG_BA+0x9C)           /*!< JPEG V Component Frame Buffer Stride Register  */
N#define JIOADDR0       (JPEG_BA+0xA0)           /*!< JPEG Bit-stream Frame Buffer-0 Starting Address Register  */
N#define JIOADDR1       (JPEG_BA+0xA4)           /*!< JPEG Bit-stream Frame Buffer-1 Starting Address Register  */
N#define JPRI_SIZE      (JPEG_BA+0xA8)           /*!< JPEG Encode Primary Image Bit-stream Size Register  */
N#define JTHB_SIZE      (JPEG_BA+0xAC)           /*!< JPEG Encode Thumbnail Image Bit-stream Size Register  */
N#define JUPRAT         (JPEG_BA+0xB0)           /*!< JPEG Encode Up-Scale Ratio Register  */
N#define JBSFIFO        (JPEG_BA+0xB4)           /*!< JPEG Bit-stream FIFO Control Register  */
N#define JSRCH          (JPEG_BA+0xB8)           /*!< JPEG Encode Source Image Height  */
N#define JQTAB0         (JPEG_BA+0x100)          /*!< JPEG Quantization-Table 0 Register  */
N#define JQTAB1         (JPEG_BA+0x140)          /*!< JPEG Quantization-Table 1 Register  */
N#define JQTAB2         (JPEG_BA+0x180)          /*!< JPEG Quantization-Table 2 Register  */
N
N/**@}*/ /* end of JPEG register group */
N
N
N
N/*@}*/ /* end of group NUC970_Peripherals */
N
N
N/** @addtogroup NUC970_IO_ROUTINE NUC970 I/O Routines
N  The Declaration of NUC970 I/O Routines
N  @{
N */
N
Ntypedef volatile unsigned char  vu8;        ///< Define 8-bit unsigned volatile data type
Ntypedef volatile unsigned short vu16;       ///< Define 16-bit unsigned volatile data type
Ntypedef volatile unsigned long  vu32;       ///< Define 32-bit unsigned volatile data type
N
N/**
N  * @brief Get a 8-bit unsigned value from specified address
N  * @param[in] addr Address to get 8-bit data from
N  * @return  8-bit unsigned value stored in specified address
N  */
N#define M8(addr)  (*((vu8  *) (addr)))
N
N/**
N  * @brief Get a 16-bit unsigned value from specified address
N  * @param[in] addr Address to get 16-bit data from
N  * @return  16-bit unsigned value stored in specified address
N  * @note The input address must be 16-bit aligned
N  */
N#define M16(addr) (*((vu16 *) (addr)))
N
N/**
N  * @brief Get a 32-bit unsigned value from specified address
N  * @param[in] addr Address to get 32-bit data from
N  * @return  32-bit unsigned value stored in specified address
N  * @note The input address must be 32-bit aligned
N  */
N#define M32(addr) (*((vu32 *) (addr)))
N
N/**
N  * @brief Set a 32-bit unsigned value to specified I/O port
N  * @param[in] port Port address to set 32-bit data
N  * @param[in] value Value to write to I/O port
N  * @return  None
N  * @note The output port must be 32-bit aligned
N  */
N#define outpw(port,value)     *((volatile unsigned int *)(port)) = value
N
N/**
N  * @brief Get a 32-bit unsigned value from specified I/O port
N  * @param[in] port Port address to get 32-bit data from
N  * @return  32-bit unsigned value stored in specified I/O port
N  * @note The input port must be 32-bit aligned
N  */
N#define inpw(port)            (*((volatile unsigned int *)(port)))
N
N/**
N  * @brief Set a 16-bit unsigned value to specified I/O port
N  * @param[in] port Port address to set 16-bit data
N  * @param[in] value Value to write to I/O port
N  * @return  None
N  * @note The output port must be 16-bit aligned
N  */
N#define outps(port,value)     *((volatile unsigned short *)(port)) = value
N
N/**
N  * @brief Get a 16-bit unsigned value from specified I/O port
N  * @param[in] port Port address to get 16-bit data from
N  * @return  16-bit unsigned value stored in specified I/O port
N  * @note The input port must be 16-bit aligned
N  */
N#define inps(port)            (*((volatile unsigned short *)(port)))
N
N/**
N  * @brief Set a 8-bit unsigned value to specified I/O port
N  * @param[in] port Port address to set 8-bit data
N  * @param[in] value Value to write to I/O port
N  * @return  None
N  */
N#define outpb(port,value)     *((volatile unsigned char *)(port)) = value
N
N/**
N  * @brief Get a 8-bit unsigned value from specified I/O port
N  * @param[in] port Port address to get 8-bit data from
N  * @return  8-bit unsigned value stored in specified I/O port
N  */
N#define inpb(port)            (*((volatile unsigned char *)(port)))
N
N/**
N  * @brief Set a 32-bit unsigned value to specified I/O port
N  * @param[in] port Port address to set 32-bit data
N  * @param[in] value Value to write to I/O port
N  * @return  None
N  * @note The output port must be 32-bit aligned
N  */
N#define outp32(port,value)    *((volatile unsigned int *)(port)) = value
N
N/**
N  * @brief Get a 32-bit unsigned value from specified I/O port
N  * @param[in] port Port address to get 32-bit data from
N  * @return  32-bit unsigned value stored in specified I/O port
N  * @note The input port must be 32-bit aligned
N  */
N#define inp32(port)           (*((volatile unsigned int *)(port)))
N
N/**
N  * @brief Set a 16-bit unsigned value to specified I/O port
N  * @param[in] port Port address to set 16-bit data
N  * @param[in] value Value to write to I/O port
N  * @return  None
N  * @note The output port must be 16-bit aligned
N  */
N#define outp16(port,value)    *((volatile unsigned short *)(port)) = value
N
N/**
N  * @brief Get a 16-bit unsigned value from specified I/O port
N  * @param[in] port Port address to get 16-bit data from
N  * @return  16-bit unsigned value stored in specified I/O port
N  * @note The input port must be 16-bit aligned
N  */
N#define inp16(port)           (*((volatile unsigned short *)(port)))
N
N/**
N  * @brief Set a 8-bit unsigned value to specified I/O port
N  * @param[in] port Port address to set 8-bit data
N  * @param[in] value Value to write to I/O port
N  * @return  None
N  */
N#define outp8(port,value)     *((volatile unsigned char *)(port)) = value
N
N/**
N  * @brief Get a 8-bit unsigned value from specified I/O port
N  * @param[in] port Port address to get 8-bit data from
N  * @return  8-bit unsigned value stored in specified I/O port
N  */
N#define inp8(port)            (*((volatile unsigned char *)(port)))
N
N
N/*@}*/ /* end of group NUC970_IO_ROUTINE */
N
N/******************************************************************************/
N/*                Legacy Constants                                            */
N/******************************************************************************/
N/** @addtogroup NUC970_legacy_Constants NUC970 Legacy Constants
N  NUC970 Legacy Constants
N  @{
N*/
Ntypedef void *            PVOID;    ///< Define void pointer data type
Ntypedef void              VOID;     ///< Define void data type
Ntypedef char              BOOL;     ///< Define bool data type
Ntypedef char *            PBOOL;    ///< Define bool pointer data type
N
Ntypedef char              INT8;     ///< Define 8-bit singed data type
Ntypedef char              CHAR;     ///< Define char data type
Ntypedef char *            PINT8;    ///< Define 8-bit singed pointer data type
Ntypedef char *            PCHAR;    ///< Define char pointer data type
Ntypedef unsigned char     UINT8;    ///< Define 8-bit unsigned data type
Ntypedef unsigned char     UCHAR;    ///< Define char unsigned data type
Ntypedef unsigned char *   PUINT8;   ///< Define 8-bit unsigned pointer data type
Ntypedef unsigned char *   PUCHAR;   ///< Define char unsigned pointer data type
Ntypedef char *            PSTR;     ///< Define string pointer data type
Ntypedef const char *      PCSTR;    ///< Define constant string pointer data type
N
Ntypedef short             SHORT;    ///< Define short signed data type
Ntypedef short *           PSHORT;   ///< Define short signed pointer data type
Ntypedef unsigned short    USHORT;   ///< Define short unsigned data type
Ntypedef unsigned short *  PUSHORT;  ///< Define short unsigned pointer data type
N
Ntypedef short             INT16;    ///< Define 16-bit signed data type
Ntypedef short *           PINT16;   ///< Define 16-bit signed pointer data type
Ntypedef unsigned short    UINT16;   ///< Define 16-bit unsigned data type
Ntypedef unsigned short *  PUINT16;  ///< Define 16-bit unsigned pointer data type
N
Ntypedef int               INT;      ///< Define integer signed data type
Ntypedef int *             PINT;     ///< Define integer signed pointer data type
Ntypedef unsigned int      UINT;     ///< Define integer unsigned data type
Ntypedef unsigned int *    PUINT;    ///< Define integer unsigned pointer data type
N
Ntypedef int               INT32;    ///< Define 32-bit signed data type
Ntypedef int *             PINT32;   ///< Define 32-bit signed pointer data type
Ntypedef unsigned int      UINT32;   ///< Define 32-bit unsigned data type
Ntypedef unsigned int *    PUINT32;  ///< Define 32-bit unsigned pointer data type
N
Ntypedef __int64           INT64;    ///< Define 64-bit signed data type
Ntypedef unsigned __int64  UINT64;   ///< Define 64-bit unsigned data type
N
Ntypedef float             FLOAT;    ///< Define float data type
Ntypedef float *           PFLOAT;   ///< Define float pointer data type
N
Ntypedef double            DOUBLE;   ///< Define double data type
Ntypedef double *          PDOUBLE;  ///< Define double pointer data type
N
Ntypedef int               SIZE_T;   ///< Define size of data type
N
Ntypedef unsigned char     REG8;     ///< Define 8-bit register data type
Ntypedef unsigned short    REG16;    ///< Define 16-bit register data type
Ntypedef unsigned int      REG32;    ///< Define 32-bit register data type
N
N
N#ifndef NULL
S#define NULL           (0)      ///< NULL pointer
N#endif
N
N#define SPECIAL        (2)
N#define TRUE           (1)      ///< Boolean true, define to use in API parameters or return value
N#define FALSE          (0)      ///< Boolean false, define to use in API parameters or return value
N
N#define ENABLE         (1)      ///< Enable, define to use in API parameters
N#define DISABLE        (0)      ///< Disable, define to use in API parameters
N
N
N#define   Successful  0         ///< Function return value success
N#define   Fail        1         ///< Function return value failed
N
N/* Define one bit mask */
N#define BIT0     (0x00000001)       ///< Bit 0 mask of an 32 bit integer
N#define BIT1     (0x00000002)       ///< Bit 1 mask of an 32 bit integer
N#define BIT2     (0x00000004)       ///< Bit 2 mask of an 32 bit integer
N#define BIT3     (0x00000008)       ///< Bit 3 mask of an 32 bit integer
N#define BIT4     (0x00000010)       ///< Bit 4 mask of an 32 bit integer
N#define BIT5     (0x00000020)       ///< Bit 5 mask of an 32 bit integer
N#define BIT6     (0x00000040)       ///< Bit 6 mask of an 32 bit integer
N#define BIT7     (0x00000080)       ///< Bit 7 mask of an 32 bit integer
N#define BIT8     (0x00000100)       ///< Bit 8 mask of an 32 bit integer
N#define BIT9     (0x00000200)       ///< Bit 9 mask of an 32 bit integer
N#define BIT10    (0x00000400)       ///< Bit 10 mask of an 32 bit integer
N#define BIT11    (0x00000800)       ///< Bit 11 mask of an 32 bit integer
N#define BIT12    (0x00001000)       ///< Bit 12 mask of an 32 bit integer
N#define BIT13    (0x00002000)       ///< Bit 13 mask of an 32 bit integer
N#define BIT14    (0x00004000)       ///< Bit 14 mask of an 32 bit integer
N#define BIT15    (0x00008000)       ///< Bit 15 mask of an 32 bit integer
N#define BIT16    (0x00010000)       ///< Bit 16 mask of an 32 bit integer
N#define BIT17    (0x00020000)       ///< Bit 17 mask of an 32 bit integer
N#define BIT18    (0x00040000)       ///< Bit 18 mask of an 32 bit integer
N#define BIT19    (0x00080000)       ///< Bit 19 mask of an 32 bit integer
N#define BIT20    (0x00100000)       ///< Bit 20 mask of an 32 bit integer
N#define BIT21    (0x00200000)       ///< Bit 21 mask of an 32 bit integer
N#define BIT22    (0x00400000)       ///< Bit 22 mask of an 32 bit integer
N#define BIT23    (0x00800000)       ///< Bit 23 mask of an 32 bit integer
N#define BIT24    (0x01000000)       ///< Bit 24 mask of an 32 bit integer
N#define BIT25    (0x02000000)       ///< Bit 25 mask of an 32 bit integer
N#define BIT26    (0x04000000)       ///< Bit 26 mask of an 32 bit integer
N#define BIT27    (0x08000000)       ///< Bit 27 mask of an 32 bit integer
N#define BIT28    (0x10000000)       ///< Bit 28 mask of an 32 bit integer
N#define BIT29    (0x20000000)       ///< Bit 29 mask of an 32 bit integer
N#define BIT30    (0x40000000)       ///< Bit 30 mask of an 32 bit integer
N#define BIT31    (0x80000000)       ///< Bit 31 mask of an 32 bit integer
N
N/* Byte Mask Definitions */
N#define BYTE0_Msk              (0x000000FF)         ///< Mask to get bit0~bit7 from a 32 bit integer
N#define BYTE1_Msk              (0x0000FF00)         ///< Mask to get bit8~bit15 from a 32 bit integer
N#define BYTE2_Msk              (0x00FF0000)         ///< Mask to get bit16~bit23 from a 32 bit integer
N#define BYTE3_Msk              (0xFF000000)         ///< Mask to get bit24~bit31 from a 32 bit integer
N
N#define GET_BYTE0(u32Param)    ((u32Param & BYTE0_Msk)      )  /*!< Extract Byte 0 (Bit  0~ 7) from parameter u32Param */
N#define GET_BYTE1(u32Param)    ((u32Param & BYTE1_Msk) >>  8)  /*!< Extract Byte 1 (Bit  8~15) from parameter u32Param */
N#define GET_BYTE2(u32Param)    ((u32Param & BYTE2_Msk) >> 16)  /*!< Extract Byte 2 (Bit 16~23) from parameter u32Param */
N#define GET_BYTE3(u32Param)    ((u32Param & BYTE3_Msk) >> 24)  /*!< Extract Byte 3 (Bit 24~31) from parameter u32Param */
N
N
N#endif /* __NUC970_H__ */
N
N/*@}*/ /* end of group NUC970_legacy_Constants */
L 54 "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2
N
N#define CONFIG_SYS_HZ			1000
N
Nextern   void sysprintf(char* pcStr,...);
N#define min(a,b)	( ((a) > (b)) ? (b) : (a) )
N#define ARRAY_SIZE(a) (sizeof(a) / sizeof((a)[0]))
N
Nextern void udelay(unsigned int tick);
Nextern unsigned int get_timer(unsigned int tick);
N
N/*
N * CONFIG_SYS_NAND_RESET_CNT is used as a timeout mechanism when resetting
N * a flash.  NAND flash is initialized prior to interrupts so standard timers
N * can't be used.  CONFIG_SYS_NAND_RESET_CNT should be set to a value
N * which is greater than (max NAND reset time / NAND status read time).
N * A conservative default of 200000 (500 us / 25 ns) is used as a default.
N */
N#ifndef CONFIG_SYS_NAND_RESET_CNT
N#define CONFIG_SYS_NAND_RESET_CNT 200000
N#endif
N
N/* Define default oob placement schemes for large and small page devices */
Nstatic struct nand_ecclayout nand_oob_8;
Nstatic struct nand_ecclayout nand_oob_16;
Nstatic struct nand_ecclayout nand_oob_64;
Nstatic struct nand_ecclayout nand_oob_128;
N
Nstatic int nand_get_device(struct nand_chip *chip, struct mtd_info *mtd,
N			   int new_state);
N
Nstatic int nand_do_write_oob(struct mtd_info *mtd, loff_t to,
N			     struct mtd_oob_ops *ops);
N
Nstatic int nand_wait(struct mtd_info *mtd, struct nand_chip *this);
N
Nstatic int check_offs_len(struct mtd_info *mtd,
N					loff_t ofs, uint64_t len)
N{
N	struct nand_chip *chip = mtd->priv;
N	int ret = 0;
N
N	/* Start address must align on block boundary */
N	if (ofs & ((1 << chip->phys_erase_shift) - 1)) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Unaligned address\n", __func__);
X		do { if (0) sysprintf("%s: Unaligned address\n", __func__); } while(0);
N		ret = -EINVAL;
X		ret = -22;
N	}
N
N	/* Length must align on block boundary */
N	if (len & ((1 << chip->phys_erase_shift) - 1)) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Length not block aligned\n",
N					__func__);
X		do { if (0) sysprintf("%s: Length not block aligned\n", __func__); } while(0);
N		ret = -EINVAL;
X		ret = -22;
N	}
N
N	/* Do not allow past end of device */
N	if (ofs + len > mtd->size) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Past end of device\n",
N					__func__);
X		do { if (0) sysprintf("%s: Past end of device\n", __func__); } while(0);
N		ret = -EINVAL;
X		ret = -22;
N	}
N
N	return ret;
N}
N
N/**
N * nand_release_device - [GENERIC] release chip
N * @mtd:	MTD device structure
N *
N * Deselect, release chip lock and wake up anyone waiting on the device
N */
Nstatic void nand_release_device(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N
N	/* De-select the NAND device */
N	chip->select_chip(mtd, -1);
N}
N
N/**
N * nand_read_byte - [DEFAULT] read one byte from the chip
N * @mtd:	MTD device structure
N *
N * Default read function for 8bit buswith
N */
Nuint8_t nand_read_byte(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N	return inpb(chip->IO_ADDR_R);
X	return (*((volatile unsigned char *)(chip->IO_ADDR_R)));
N}
N
N/**
N * nand_read_byte16 - [DEFAULT] read one byte endianess aware from the chip
N * @mtd:	MTD device structure
N *
N * Default read function for 16bit buswith with
N * endianess conversion
N */
Nstatic uint8_t nand_read_byte16(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N	return (uint8_t) (inpw(chip->IO_ADDR_R));
X	return (uint8_t) ((*((volatile unsigned int *)(chip->IO_ADDR_R))));
N}
N
N/**
N * nand_read_word - [DEFAULT] read one word from the chip
N * @mtd:	MTD device structure
N *
N * Default read function for 16bit buswith without
N * endianess conversion
N */
Nstatic u16 nand_read_word(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N	return inpw(chip->IO_ADDR_R);
X	return (*((volatile unsigned int *)(chip->IO_ADDR_R)));
N}
N
N/**
N * nand_select_chip - [DEFAULT] control CE line
N * @mtd:	MTD device structure
N * @chipnr:	chipnumber to select, -1 for deselect
N *
N * Default select function for 1 chip devices.
N */
Nstatic void nand_select_chip(struct mtd_info *mtd, int chipnr)
N{
N	struct nand_chip *chip = mtd->priv;
N
N	switch (chipnr) {
N	case -1:
N		chip->cmd_ctrl(mtd, NAND_CMD_NONE, 0 | NAND_CTRL_CHANGE);
X		chip->cmd_ctrl(mtd, -1, 0 | 0x80);
N		break;
N	case 0:
N		break;
N
N	default:
N		BUG();
X		do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\nand_base.c", 189); } while (0);
N	}
N}
N
N/**
N * nand_write_buf - [DEFAULT] write buffer to chip
N * @mtd:	MTD device structure
N * @buf:	data buffer
N * @len:	number of bytes to write
N *
N * Default write function for 8bit buswith
N */
Nvoid nand_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
N{
N	int i;
N	struct nand_chip *chip = mtd->priv;
N
N	for (i = 0; i < len; i++)
N		outpb(chip->IO_ADDR_W, buf[i]);
X		*((volatile unsigned char *)(chip->IO_ADDR_W)) = buf[i];
N}
N
N/**
N * nand_read_buf - [DEFAULT] read chip data into buffer
N * @mtd:	MTD device structure
N * @buf:	buffer to store date
N * @len:	number of bytes to read
N *
N * Default read function for 8bit buswith
N */
Nvoid nand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
N{
N	int i;
N	struct nand_chip *chip = mtd->priv;
N
N	for (i = 0; i < len; i++)
N		buf[i] = inpb(chip->IO_ADDR_R);
X		buf[i] = (*((volatile unsigned char *)(chip->IO_ADDR_R)));
N}
N
N/**
N * nand_verify_buf - [DEFAULT] Verify chip data against buffer
N * @mtd:	MTD device structure
N * @buf:	buffer containing the data to compare
N * @len:	number of bytes to compare
N *
N * Default verify function for 8bit buswith
N */
Nstatic int nand_verify_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
N{
N	int i;
N	struct nand_chip *chip = mtd->priv;
N
N	for (i = 0; i < len; i++)
N		if (buf[i] != inpb(chip->IO_ADDR_R))
X		if (buf[i] != (*((volatile unsigned char *)(chip->IO_ADDR_R))))
N			return -EFAULT;
X			return -14;
N	return 0;
N}
N
N/**
N * nand_write_buf16 - [DEFAULT] write buffer to chip
N * @mtd:	MTD device structure
N * @buf:	data buffer
N * @len:	number of bytes to write
N *
N * Default write function for 16bit buswith
N */
Nvoid nand_write_buf16(struct mtd_info *mtd, const uint8_t *buf, int len)
N{
N	int i;
N	struct nand_chip *chip = mtd->priv;
N	u16 *p = (u16 *) buf;
N	len >>= 1;
N
N	for (i = 0; i < len; i++)
N		outpw(chip->IO_ADDR_W, p[i]);
X		*((volatile unsigned int *)(chip->IO_ADDR_W)) = p[i];
N
N}
N
N/**
N * nand_read_buf16 - [DEFAULT] read chip data into buffer
N * @mtd:	MTD device structure
N * @buf:	buffer to store date
N * @len:	number of bytes to read
N *
N * Default read function for 16bit buswith
N */
Nvoid nand_read_buf16(struct mtd_info *mtd, uint8_t *buf, int len)
N{
N	int i;
N	struct nand_chip *chip = mtd->priv;
N	u16 *p = (u16 *) buf;
N	len >>= 1;
N
N	for (i = 0; i < len; i++)
N		p[i] = inpw(chip->IO_ADDR_R);
X		p[i] = (*((volatile unsigned int *)(chip->IO_ADDR_R)));
N}
N
N/**
N * nand_verify_buf16 - [DEFAULT] Verify chip data against buffer
N * @mtd:	MTD device structure
N * @buf:	buffer containing the data to compare
N * @len:	number of bytes to compare
N *
N * Default verify function for 16bit buswith
N */
Nstatic int nand_verify_buf16(struct mtd_info *mtd, const uint8_t *buf, int len)
N{
N	int i;
N	struct nand_chip *chip = mtd->priv;
N	u16 *p = (u16 *) buf;
N	len >>= 1;
N
N	for (i = 0; i < len; i++)
N		if (p[i] != inpw(chip->IO_ADDR_R))
X		if (p[i] != (*((volatile unsigned int *)(chip->IO_ADDR_R))))
N			return -EFAULT;
X			return -14;
N
N	return 0;
N}
N
N/**
N * nand_block_bad - [DEFAULT] Read bad block marker from the chip
N * @mtd:	MTD device structure
N * @ofs:	offset from device start
N * @getchip:	0, if the chip is already selected
N *
N * Check, if the block is bad.
N */
Nstatic int nand_block_bad(struct mtd_info *mtd, loff_t ofs, int getchip)
N{
N	int page, chipnr, res = 0;
N	struct nand_chip *chip = mtd->priv;
N	u16 bad;
N
N	if (chip->options & NAND_BBT_SCANLASTPAGE)
X	if (chip->options & 0x00008000)
N		ofs += mtd->erasesize - mtd->writesize;
N
N	page = (int)(ofs >> chip->page_shift) & chip->pagemask;
N
N	if (getchip) {
N		chipnr = (int)(ofs >> chip->chip_shift);
N
N		nand_get_device(chip, mtd, FL_READING);
N
N		/* Select the NAND device */
N		chip->select_chip(mtd, chipnr);
N	}
N
N	if (chip->options & NAND_BUSWIDTH_16) {
X	if (chip->options & 0x00000002) {
N		chip->cmdfunc(mtd, NAND_CMD_READOOB, chip->badblockpos & 0xFE,
X		chip->cmdfunc(mtd, 0x50, chip->badblockpos & 0xFE,
N			      page);
N		bad = (chip->read_word(mtd));
N		if (chip->badblockpos & 0x1)
N			bad >>= 8;
N		else
N			bad &= 0xFF;
N	} else {
N		chip->cmdfunc(mtd, NAND_CMD_READOOB, chip->badblockpos, page);
X		chip->cmdfunc(mtd, 0x50, chip->badblockpos, page);
N		bad = chip->read_byte(mtd);
N	}
N
N	if (chip->badblockbits == 8)
N		res = bad != 0xFF;
N	else
N		res = hweight8(bad) < chip->badblockbits;
X		res = generic_hweight8(bad) < chip->badblockbits;
N
N	if (getchip)
N		nand_release_device(mtd);
N
N	return res;
N}
N
N/**
N * nand_default_block_markbad - [DEFAULT] mark a block bad
N * @mtd:	MTD device structure
N * @ofs:	offset from device start
N *
N * This is the default implementation, which can be overridden by
N * a hardware specific driver.
N*/
Nstatic int nand_default_block_markbad(struct mtd_info *mtd, loff_t ofs)
N{
N	struct nand_chip *chip = mtd->priv;
N	uint8_t buf[2] = { 0, 0 };
N	int block, ret, i = 0;
N
N	if (chip->options & NAND_BBT_SCANLASTPAGE)
X	if (chip->options & 0x00008000)
N		ofs += mtd->erasesize - mtd->writesize;
N
N	/* Get block number */
N	block = (int)(ofs >> chip->bbt_erase_shift);
N	if (chip->bbt)
N		chip->bbt[block >> 2] |= 0x01 << ((block & 0x03) << 1);
N
N	/* Do we have a flash based bad block table ? */
N	if (chip->options & NAND_USE_FLASH_BBT)
X	if (chip->options & 0x00010000)
N		ret = nand_update_bbt(mtd, ofs);
N	else {
N		nand_get_device(chip, mtd, FL_WRITING);
N
N		/* Write to first two pages and to byte 1 and 6 if necessary.
N		 * If we write to more than one location, the first error
N		 * encountered quits the procedure. We write two bytes per
N		 * location, so we dont have to mess with 16 bit access.
N		 */
N		do {
N			chip->ops.len = chip->ops.ooblen = 2;
N			chip->ops.datbuf = NULL;
X			chip->ops.datbuf = 0;
N			chip->ops.oobbuf = buf;
N			chip->ops.ooboffs = chip->badblockpos & ~0x01;
N
N			ret = nand_do_write_oob(mtd, ofs, &chip->ops);
N
N			if (!ret && (chip->options & NAND_BBT_SCANBYTE1AND6)) {
X			if (!ret && (chip->options & 0x00100000)) {
N				chip->ops.ooboffs = NAND_SMALL_BADBLOCK_POS
X				chip->ops.ooboffs = 5
N					& ~0x01;
N				ret = nand_do_write_oob(mtd, ofs, &chip->ops);
N			}
N			i++;
N			ofs += mtd->writesize;
N		} while (!ret && (chip->options & NAND_BBT_SCAN2NDPAGE) &&
X		} while (!ret && (chip->options & 0x00004000) &&
N				i < 2);
N
N		nand_release_device(mtd);
N	}
N	if (!ret)
N		mtd->ecc_stats.badblocks++;
N
N	return ret;
N}
N
N/**
N * nand_check_wp - [GENERIC] check if the chip is write protected
N * @mtd:	MTD device structure
N * Check, if the device is write protected
N *
N * The function expects, that the device is already selected
N */
Nstatic int nand_check_wp(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N
N	/* broken xD cards report WP despite being writable */
N	if (chip->options & NAND_BROKEN_XD)
X	if (chip->options & 0x00000400)
N		return 0;
N
N	/* Check the WP bit */
N	chip->cmdfunc(mtd, NAND_CMD_STATUS, -1, -1);
X	chip->cmdfunc(mtd, 0x70, -1, -1);
N	return (chip->read_byte(mtd) & NAND_STATUS_WP) ? 0 : 1;
X	return (chip->read_byte(mtd) & 0x80) ? 0 : 1;
N}
N
N/**
N * nand_block_checkbad - [GENERIC] Check if a block is marked bad
N * @mtd:	MTD device structure
N * @ofs:	offset from device start
N * @getchip:	0, if the chip is already selected
N * @allowbbt:	1, if its allowed to access the bbt area
N *
N * Check, if the block is bad. Either by reading the bad block table or
N * calling of the scan function.
N */
Nstatic int nand_block_checkbad(struct mtd_info *mtd, loff_t ofs, int getchip,
N			       int allowbbt)
N{
N	struct nand_chip *chip = mtd->priv;
N
N	if (!(chip->options & NAND_BBT_SCANNED)) {
X	if (!(chip->options & 0x40000000)) {
N		chip->options |= NAND_BBT_SCANNED;
X		chip->options |= 0x40000000;
N		chip->scan_bbt(mtd);
N	}
N
N	if (!chip->bbt)
N		return chip->block_bad(mtd, ofs, getchip);
N
N	/* Return info from the table */
N	return nand_isbad_bbt(mtd, ofs, allowbbt);
N}
N
N/*
N * Wait for the ready pin, after a command
N * The timeout is catched later.
N */
Nvoid nand_wait_ready(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N	u32 timeo = (CONFIG_SYS_HZ * 20) / 1000;
X	u32 timeo = (1000 * 20) / 1000;
N	u32 time_start;
N
N	time_start = get_timer(0);
N
N	/* wait until command is processed or timeout occures */
N	while (get_timer(time_start) < timeo) {
N		if (chip->dev_ready)
N			if (chip->dev_ready(mtd))
N				break;
N	}
N}
N
N/**
N * nand_command - [DEFAULT] Send command to NAND device
N * @mtd:	MTD device structure
N * @command:	the command to be sent
N * @column:	the column address for this command, -1 if none
N * @page_addr:	the page address for this command, -1 if none
N *
N * Send command to NAND device. This function is used for small page
N * devices (256/512 Bytes per page)
N */
Nstatic void nand_command(struct mtd_info *mtd, unsigned int command,
N			 int column, int page_addr)
N{
N	register struct nand_chip *chip = mtd->priv;
X	 struct nand_chip *chip = mtd->priv;
N	int ctrl = NAND_CTRL_CLE | NAND_CTRL_CHANGE;
X	int ctrl = (0x01 | 0x02) | 0x80;
N	uint32_t rst_sts_cnt = CONFIG_SYS_NAND_RESET_CNT;
X	uint32_t rst_sts_cnt = 200000;
N
N	/*
N	 * Write out the command to the device.
N	 */
N	if (command == NAND_CMD_SEQIN) {
X	if (command == 0x80) {
N		int readcmd;
N
N		if (column >= mtd->writesize) {
N			/* OOB area */
N			column -= mtd->writesize;
N			readcmd = NAND_CMD_READOOB;
X			readcmd = 0x50;
N		} else if (column < 256) {
N			/* First 256 bytes --> READ0 */
N			readcmd = NAND_CMD_READ0;
X			readcmd = 0;
N		} else {
N			column -= 256;
N			readcmd = NAND_CMD_READ1;
X			readcmd = 1;
N		}
N		chip->cmd_ctrl(mtd, readcmd, ctrl);
N		ctrl &= ~NAND_CTRL_CHANGE;
X		ctrl &= ~0x80;
N	}
N	chip->cmd_ctrl(mtd, command, ctrl);
N
N	/*
N	 * Address cycle, when necessary
N	 */
N	ctrl = NAND_CTRL_ALE | NAND_CTRL_CHANGE;
X	ctrl = (0x01 | 0x04) | 0x80;
N	/* Serially input address */
N	if (column != -1) {
N		/* Adjust columns for 16 bit buswidth */
N		if (chip->options & NAND_BUSWIDTH_16)
X		if (chip->options & 0x00000002)
N			column >>= 1;
N		chip->cmd_ctrl(mtd, column, ctrl);
N		ctrl &= ~NAND_CTRL_CHANGE;
X		ctrl &= ~0x80;
N	}
N	if (page_addr != -1) {
N		chip->cmd_ctrl(mtd, page_addr, ctrl);
N		ctrl &= ~NAND_CTRL_CHANGE;
X		ctrl &= ~0x80;
N		chip->cmd_ctrl(mtd, page_addr >> 8, ctrl);
N		/* One more address cycle for devices > 32MiB */
N		if (chip->chipsize > (32 << 20))
N			chip->cmd_ctrl(mtd, page_addr >> 16, ctrl);
N	}
N	chip->cmd_ctrl(mtd, NAND_CMD_NONE, NAND_NCE | NAND_CTRL_CHANGE);
X	chip->cmd_ctrl(mtd, -1, 0x01 | 0x80);
N
N	/*
N	 * program and erase have their own busy handlers
N	 * status and sequential in needs no delay
N	 */
N	switch (command) {
N
N	case NAND_CMD_PAGEPROG:
X	case 0x10:
N	case NAND_CMD_ERASE1:
X	case 0x60:
N	case NAND_CMD_ERASE2:
X	case 0xd0:
N	case NAND_CMD_SEQIN:
X	case 0x80:
N	case NAND_CMD_STATUS:
X	case 0x70:
N		return;
N
N	case NAND_CMD_RESET:
X	case 0xff:
N		if (chip->dev_ready)
N			break;
N		udelay(chip->chip_delay);
N		chip->cmd_ctrl(mtd, NAND_CMD_STATUS,
X		chip->cmd_ctrl(mtd, 0x70,
N			       NAND_CTRL_CLE | NAND_CTRL_CHANGE);
X			       (0x01 | 0x02) | 0x80);
N		chip->cmd_ctrl(mtd,
N			       NAND_CMD_NONE, NAND_NCE | NAND_CTRL_CHANGE);
X			       -1, 0x01 | 0x80);
N		while (!(chip->read_byte(mtd) & NAND_STATUS_READY) &&
X		while (!(chip->read_byte(mtd) & 0x40) &&
N			(rst_sts_cnt--));
N		return;
N
N		/* This applies to read commands */
N	default:
N		/*
N		 * If we don't have access to the busy pin, we apply the given
N		 * command delay
N		 */
N		if (!chip->dev_ready) {
N			udelay(chip->chip_delay);
N			return;
N		}
N	}
N	/* Apply this short delay always to ensure that we do wait tWB in
N	 * any case on any machine. */
N	ndelay(100);
X	udelay(1);
N
N	nand_wait_ready(mtd);
N}
N
N/**
N * nand_command_lp - [DEFAULT] Send command to NAND large page device
N * @mtd:	MTD device structure
N * @command:	the command to be sent
N * @column:	the column address for this command, -1 if none
N * @page_addr:	the page address for this command, -1 if none
N *
N * Send command to NAND device. This is the version for the new large page
N * devices We dont have the separate regions as we have in the small page
N * devices.  We must emulate NAND_CMD_READOOB to keep the code compatible.
N */
Nstatic void nand_command_lp(struct mtd_info *mtd, unsigned int command,
N			    int column, int page_addr)
N{
N	register struct nand_chip *chip = mtd->priv;
X	 struct nand_chip *chip = mtd->priv;
N	uint32_t rst_sts_cnt = CONFIG_SYS_NAND_RESET_CNT;
X	uint32_t rst_sts_cnt = 200000;
N
N	/* Emulate NAND_CMD_READOOB */
N	if (command == NAND_CMD_READOOB) {
X	if (command == 0x50) {
N		column += mtd->writesize;
N		command = NAND_CMD_READ0;
X		command = 0;
N	}
N
N	/* Command latch cycle */
N	chip->cmd_ctrl(mtd, command & 0xff,
N		       NAND_NCE | NAND_CLE | NAND_CTRL_CHANGE);
X		       0x01 | 0x02 | 0x80);
N
N	if (column != -1 || page_addr != -1) {
N		int ctrl = NAND_CTRL_CHANGE | NAND_NCE | NAND_ALE;
X		int ctrl = 0x80 | 0x01 | 0x04;
N
N		/* Serially input address */
N		if (column != -1) {
N			/* Adjust columns for 16 bit buswidth */
N			if (chip->options & NAND_BUSWIDTH_16)
X			if (chip->options & 0x00000002)
N				column >>= 1;
N			chip->cmd_ctrl(mtd, column, ctrl);
N			ctrl &= ~NAND_CTRL_CHANGE;
X			ctrl &= ~0x80;
N			chip->cmd_ctrl(mtd, column >> 8, ctrl);
N		}
N		if (page_addr != -1) {
N			chip->cmd_ctrl(mtd, page_addr, ctrl);
N			chip->cmd_ctrl(mtd, page_addr >> 8,
N				       NAND_NCE | NAND_ALE);
X				       0x01 | 0x04);
N			/* One more address cycle for devices > 128MiB */
N			if (chip->chipsize > (128 << 20))
N				chip->cmd_ctrl(mtd, page_addr >> 16,
N					       NAND_NCE | NAND_ALE);
X					       0x01 | 0x04);
N		}
N	}
N	chip->cmd_ctrl(mtd, NAND_CMD_NONE, NAND_NCE | NAND_CTRL_CHANGE);
X	chip->cmd_ctrl(mtd, -1, 0x01 | 0x80);
N
N	/*
N	 * program and erase have their own busy handlers
N	 * status, sequential in, and deplete1 need no delay
N	 */
N	switch (command) {
N
N	case NAND_CMD_CACHEDPROG:
X	case 0x15:
N	case NAND_CMD_PAGEPROG:
X	case 0x10:
N	case NAND_CMD_ERASE1:
X	case 0x60:
N	case NAND_CMD_ERASE2:
X	case 0xd0:
N	case NAND_CMD_SEQIN:
X	case 0x80:
N	case NAND_CMD_RNDIN:
X	case 0x85:
N	case NAND_CMD_STATUS:
X	case 0x70:
N	case NAND_CMD_DEPLETE1:
X	case 0x100:
N		return;
N
N		/*
N		 * read error status commands require only a short delay
N		 */
N	case NAND_CMD_STATUS_ERROR:
X	case 0x72:
N	case NAND_CMD_STATUS_ERROR0:
X	case 0x73:
N	case NAND_CMD_STATUS_ERROR1:
X	case 0x74:
N	case NAND_CMD_STATUS_ERROR2:
X	case 0x75:
N	case NAND_CMD_STATUS_ERROR3:
X	case 0x76:
N		udelay(chip->chip_delay);
N		return;
N
N	case NAND_CMD_RESET:
X	case 0xff:
N		if (chip->dev_ready)
N			break;
N		udelay(chip->chip_delay);
N		chip->cmd_ctrl(mtd, NAND_CMD_STATUS,
X		chip->cmd_ctrl(mtd, 0x70,
N			       NAND_NCE | NAND_CLE | NAND_CTRL_CHANGE);
X			       0x01 | 0x02 | 0x80);
N		chip->cmd_ctrl(mtd, NAND_CMD_NONE,
X		chip->cmd_ctrl(mtd, -1,
N			       NAND_NCE | NAND_CTRL_CHANGE);
X			       0x01 | 0x80);
N		while (!(chip->read_byte(mtd) & NAND_STATUS_READY) &&
X		while (!(chip->read_byte(mtd) & 0x40) &&
N			(rst_sts_cnt--));
N		return;
N
N	case NAND_CMD_RNDOUT:
X	case 5:
N		/* No ready / busy check necessary */
N		chip->cmd_ctrl(mtd, NAND_CMD_RNDOUTSTART,
X		chip->cmd_ctrl(mtd, 0xE0,
N			       NAND_NCE | NAND_CLE | NAND_CTRL_CHANGE);
X			       0x01 | 0x02 | 0x80);
N		chip->cmd_ctrl(mtd, NAND_CMD_NONE,
X		chip->cmd_ctrl(mtd, -1,
N			       NAND_NCE | NAND_CTRL_CHANGE);
X			       0x01 | 0x80);
N		return;
N
N	case NAND_CMD_READ0:
X	case 0:
N		chip->cmd_ctrl(mtd, NAND_CMD_READSTART,
X		chip->cmd_ctrl(mtd, 0x30,
N			       NAND_NCE | NAND_CLE | NAND_CTRL_CHANGE);
X			       0x01 | 0x02 | 0x80);
N		chip->cmd_ctrl(mtd, NAND_CMD_NONE,
X		chip->cmd_ctrl(mtd, -1,
N			       NAND_NCE | NAND_CTRL_CHANGE);
X			       0x01 | 0x80);
N
N		/* This applies to read commands */
N	default:
N		/*
N		 * If we don't have access to the busy pin, we apply the given
N		 * command delay
N		 */
N		if (!chip->dev_ready) {
N			udelay(chip->chip_delay);
N			return;
N		}
N	}
N
N	/* Apply this short delay always to ensure that we do wait tWB in
N	 * any case on any machine. */
N	ndelay(100);
X	udelay(1);
N
N	nand_wait_ready(mtd);
N}
N
N/**
N * nand_get_device - [GENERIC] Get chip for selected access
N * @chip:	the nand chip descriptor
N * @mtd:	MTD device structure
N * @new_state:	the state which is requested
N *
N * Get the device and lock it for exclusive access
N */
Nstatic int
Nnand_get_device(struct nand_chip *chip, struct mtd_info *mtd, int new_state)
N{
N	chip->state = new_state;
N	return 0;
N}
N
N/**
N * nand_wait - [DEFAULT]  wait until the command is done
N * @mtd:	MTD device structure
N * @chip:	NAND chip structure
N *
N * Wait for command done. This applies to erase and program only
N * Erase can take up to 400ms and program up to 20ms according to
N * general NAND and SmartMedia specs
N */
Nstatic int nand_wait(struct mtd_info *mtd, struct nand_chip *chip)
N{
N	unsigned long	timeo;
N	int state = chip->state;
N	u32 time_start;
N
N	if (state == FL_ERASING)
N		timeo = (CONFIG_SYS_HZ * 400) / 1000;
X		timeo = (1000 * 400) / 1000;
N	else
N		timeo = (CONFIG_SYS_HZ * 20) / 1000;
X		timeo = (1000 * 20) / 1000;
N
N	if ((state == FL_ERASING) && (chip->options & NAND_IS_AND))
X	if ((state == FL_ERASING) && (chip->options & 0x00000020))
N		chip->cmdfunc(mtd, NAND_CMD_STATUS_MULTI, -1, -1);
X		chip->cmdfunc(mtd, 0x71, -1, -1);
N	else
N		chip->cmdfunc(mtd, NAND_CMD_STATUS, -1, -1);
X		chip->cmdfunc(mtd, 0x70, -1, -1);
N
N	time_start = get_timer(0);
N
N	while (1) {
N		if (get_timer(time_start) > timeo) {
N			sysprintf("Timeout!");
N			return 0x01;
N		}
N
N		if (chip->dev_ready) {
N			if (chip->dev_ready(mtd))
N				break;
N		} else {
N			if (chip->read_byte(mtd) & NAND_STATUS_READY)
X			if (chip->read_byte(mtd) & 0x40)
N				break;
N		}
N	}
N#ifdef PPCHAMELON_NAND_TIMER_HACK
S	time_start = get_timer(0);
S	while (get_timer(time_start) < 10)
S		;
N#endif /*  PPCHAMELON_NAND_TIMER_HACK */
N
N	return (int)chip->read_byte(mtd);
N}
N
N/**
N * nand_read_page_raw - [Intern] read raw page data without ecc
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	buffer to store read data
N * @page:	page number to read
N *
N * Not for syndrome calculating ecc controllers, which use a special oob layout
N */
Nstatic int nand_read_page_raw(struct mtd_info *mtd, struct nand_chip *chip,
N			      uint8_t *buf, int page)
N{
N	chip->read_buf(mtd, buf, mtd->writesize);
N	chip->read_buf(mtd, chip->oob_poi, mtd->oobsize);
N	return 0;
N}
N
N/**
N * nand_read_page_raw_syndrome - [Intern] read raw page data without ecc
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	buffer to store read data
N * @page:	page number to read
N *
N * We need a special oob layout and handling even when OOB isn't used.
N */
Nstatic int nand_read_page_raw_syndrome(struct mtd_info *mtd,
N					struct nand_chip *chip,
N					uint8_t *buf, int page)
N{
N	int eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	uint8_t *oob = chip->oob_poi;
N	int steps, size;
N
N	for (steps = chip->ecc.steps; steps > 0; steps--) {
N		chip->read_buf(mtd, buf, eccsize);
N		buf += eccsize;
N
N		if (chip->ecc.prepad) {
N			chip->read_buf(mtd, oob, chip->ecc.prepad);
N			oob += chip->ecc.prepad;
N		}
N
N		chip->read_buf(mtd, oob, eccbytes);
N		oob += eccbytes;
N
N		if (chip->ecc.postpad) {
N			chip->read_buf(mtd, oob, chip->ecc.postpad);
N			oob += chip->ecc.postpad;
N		}
N	}
N
N	size = mtd->oobsize - (oob - chip->oob_poi);
N	if (size)
N		chip->read_buf(mtd, oob, size);
N
N	return 0;
N}
N
N/**
N * nand_read_page_swecc - [REPLACABLE] software ecc based page read function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	buffer to store read data
N * @page:	page number to read
N */
Nstatic int nand_read_page_swecc(struct mtd_info *mtd, struct nand_chip *chip,
N				uint8_t *buf, int page)
N{
N	int i, eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	int eccsteps = chip->ecc.steps;
N	uint8_t *p = buf;
N	uint8_t *ecc_calc = chip->buffers->ecccalc;
N	uint8_t *ecc_code = chip->buffers->ecccode;
N	uint32_t *eccpos = chip->ecc.layout->eccpos;
N
N	chip->ecc.read_page_raw(mtd, chip, buf, page);
N
N	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize)
N		chip->ecc.calculate(mtd, p, &ecc_calc[i]);
N
N	for (i = 0; i < chip->ecc.total; i++)
N		ecc_code[i] = chip->oob_poi[eccpos[i]];
N
N	eccsteps = chip->ecc.steps;
N	p = buf;
N
N	for (i = 0 ; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
N		int stat;
N
N		stat = chip->ecc.correct(mtd, p, &ecc_code[i], &ecc_calc[i]);
N		if (stat < 0)
N			mtd->ecc_stats.failed++;
N		else
N			mtd->ecc_stats.corrected += stat;
N	}
N	return 0;
N}
N
N/**
N * nand_read_subpage - [REPLACABLE] software ecc based sub-page read function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @data_offs:	offset of requested data within the page
N * @readlen:	data length
N * @bufpoi:	buffer to store read data
N */
Nstatic int nand_read_subpage(struct mtd_info *mtd, struct nand_chip *chip,
N			uint32_t data_offs, uint32_t readlen, uint8_t *bufpoi)
N{
N	int start_step, end_step, num_steps;
N	uint32_t *eccpos = chip->ecc.layout->eccpos;
N	uint8_t *p;
N	int data_col_addr, i, gaps = 0;
N	int datafrag_len, eccfrag_len, aligned_len, aligned_pos;
N	int busw = (chip->options & NAND_BUSWIDTH_16) ? 2 : 1;
X	int busw = (chip->options & 0x00000002) ? 2 : 1;
N	int index = 0;
N
N	/* Column address wihin the page aligned to ECC size (256bytes). */
N	start_step = data_offs / chip->ecc.size;
N	end_step = (data_offs + readlen - 1) / chip->ecc.size;
N	num_steps = end_step - start_step + 1;
N
N	/* Data size aligned to ECC ecc.size*/
N	datafrag_len = num_steps * chip->ecc.size;
N	eccfrag_len = num_steps * chip->ecc.bytes;
N
N	data_col_addr = start_step * chip->ecc.size;
N	/* If we read not a page aligned data */
N	if (data_col_addr != 0)
N		chip->cmdfunc(mtd, NAND_CMD_RNDOUT, data_col_addr, -1);
X		chip->cmdfunc(mtd, 5, data_col_addr, -1);
N
N	p = bufpoi + data_col_addr;
N	chip->read_buf(mtd, p, datafrag_len);
N
N	/* Calculate  ECC */
N	for (i = 0; i < eccfrag_len ; i += chip->ecc.bytes, p += chip->ecc.size)
N		chip->ecc.calculate(mtd, p, &chip->buffers->ecccalc[i]);
N
N	/* The performance is faster if to position offsets
N	   according to ecc.pos. Let make sure here that
N	   there are no gaps in ecc positions */
N	for (i = 0; i < eccfrag_len - 1; i++) {
N		if (eccpos[i + start_step * chip->ecc.bytes] + 1 !=
N			eccpos[i + start_step * chip->ecc.bytes + 1]) {
N			gaps = 1;
N			break;
N		}
N	}
N	if (gaps) {
N		chip->cmdfunc(mtd, NAND_CMD_RNDOUT, mtd->writesize, -1);
X		chip->cmdfunc(mtd, 5, mtd->writesize, -1);
N		chip->read_buf(mtd, chip->oob_poi, mtd->oobsize);
N	} else {
N		/* send the command to read the particular ecc bytes */
N		/* take care about buswidth alignment in read_buf */
N		index = start_step * chip->ecc.bytes;
N
N		aligned_pos = eccpos[index] & ~(busw - 1);
N		aligned_len = eccfrag_len;
N		if (eccpos[index] & (busw - 1))
N			aligned_len++;
N		if (eccpos[index + (num_steps * chip->ecc.bytes)] & (busw - 1))
N			aligned_len++;
N
N		chip->cmdfunc(mtd, NAND_CMD_RNDOUT,
X		chip->cmdfunc(mtd, 5,
N					mtd->writesize + aligned_pos, -1);
N		chip->read_buf(mtd, &chip->oob_poi[aligned_pos], aligned_len);
N	}
N
N	for (i = 0; i < eccfrag_len; i++)
N		chip->buffers->ecccode[i] = chip->oob_poi[eccpos[i + index]];
N
N	p = bufpoi + data_col_addr;
N	for (i = 0; i < eccfrag_len ; i += chip->ecc.bytes, p += chip->ecc.size) {
N		int stat;
N
N		stat = chip->ecc.correct(mtd, p,
N			&chip->buffers->ecccode[i], &chip->buffers->ecccalc[i]);
N		if (stat < 0)
N			mtd->ecc_stats.failed++;
N		else
N			mtd->ecc_stats.corrected += stat;
N	}
N	return 0;
N}
N
N/**
N * nand_read_page_hwecc - [REPLACABLE] hardware ecc based page read function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	buffer to store read data
N * @page:	page number to read
N *
N * Not for syndrome calculating ecc controllers which need a special oob layout
N */
Nstatic int nand_read_page_hwecc(struct mtd_info *mtd, struct nand_chip *chip,
N				uint8_t *buf, int page)
N{
N	int i, eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	int eccsteps = chip->ecc.steps;
N	uint8_t *p = buf;
N	uint8_t *ecc_calc = chip->buffers->ecccalc;
N	uint8_t *ecc_code = chip->buffers->ecccode;
N	uint32_t *eccpos = chip->ecc.layout->eccpos;
N
N	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
N		chip->ecc.hwctl(mtd, NAND_ECC_READ);
X		chip->ecc.hwctl(mtd, 0);
N		chip->read_buf(mtd, p, eccsize);
N		chip->ecc.calculate(mtd, p, &ecc_calc[i]);
N	}
N	chip->read_buf(mtd, chip->oob_poi, mtd->oobsize);
N
N	for (i = 0; i < chip->ecc.total; i++)
N		ecc_code[i] = chip->oob_poi[eccpos[i]];
N
N	eccsteps = chip->ecc.steps;
N	p = buf;
N
N	for (i = 0 ; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
N		int stat;
N
N		stat = chip->ecc.correct(mtd, p, &ecc_code[i], &ecc_calc[i]);
N		if (stat < 0)
N			mtd->ecc_stats.failed++;
N		else
N			mtd->ecc_stats.corrected += stat;
N	}
N	return 0;
N}
N
N/**
N * nand_read_page_hwecc_oob_first - [REPLACABLE] hw ecc, read oob first
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	buffer to store read data
N * @page:	page number to read
N *
N * Hardware ECC for large page chips, require OOB to be read first.
N * For this ECC mode, the write_page method is re-used from ECC_HW.
N * These methods read/write ECC from the OOB area, unlike the
N * ECC_HW_SYNDROME support with multiple ECC steps, follows the
N * "infix ECC" scheme and reads/writes ECC from the data area, by
N * overwriting the NAND manufacturer bad block markings.
N */
Nstatic int nand_read_page_hwecc_oob_first(struct mtd_info *mtd,
N	struct nand_chip *chip, uint8_t *buf, int page)
N{
N	int i, eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	int eccsteps = chip->ecc.steps;
N	uint8_t *p = buf;
N	uint8_t *ecc_code = chip->buffers->ecccode;
N	uint32_t *eccpos = chip->ecc.layout->eccpos;
N	uint8_t *ecc_calc = chip->buffers->ecccalc;
N
N	/* Read the OOB area first */
N	chip->cmdfunc(mtd, NAND_CMD_READOOB, 0, page);
X	chip->cmdfunc(mtd, 0x50, 0, page);
N	chip->read_buf(mtd, chip->oob_poi, mtd->oobsize);
N	chip->cmdfunc(mtd, NAND_CMD_READ0, 0, page);
X	chip->cmdfunc(mtd, 0, 0, page);
N
N	for (i = 0; i < chip->ecc.total; i++)
N		ecc_code[i] = chip->oob_poi[eccpos[i]];
N
N	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
N		int stat;
N
N		chip->ecc.hwctl(mtd, NAND_ECC_READ);
X		chip->ecc.hwctl(mtd, 0);
N		chip->read_buf(mtd, p, eccsize);
N		chip->ecc.calculate(mtd, p, &ecc_calc[i]);
N
N		stat = chip->ecc.correct(mtd, p, &ecc_code[i], NULL);
X		stat = chip->ecc.correct(mtd, p, &ecc_code[i], 0);
N		if (stat < 0)
N			mtd->ecc_stats.failed++;
N		else
N			mtd->ecc_stats.corrected += stat;
N	}
N	return 0;
N}
N
N/**
N * nand_read_page_syndrome - [REPLACABLE] hardware ecc syndrom based page read
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	buffer to store read data
N * @page:	page number to read
N *
N * The hw generator calculates the error syndrome automatically. Therefor
N * we need a special oob layout and handling.
N */
Nstatic int nand_read_page_syndrome(struct mtd_info *mtd, struct nand_chip *chip,
N				   uint8_t *buf, int page)
N{
N	int i, eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	int eccsteps = chip->ecc.steps;
N	uint8_t *p = buf;
N	uint8_t *oob = chip->oob_poi;
N
N	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
N		int stat;
N
N		chip->ecc.hwctl(mtd, NAND_ECC_READ);
X		chip->ecc.hwctl(mtd, 0);
N		chip->read_buf(mtd, p, eccsize);
N
N		if (chip->ecc.prepad) {
N			chip->read_buf(mtd, oob, chip->ecc.prepad);
N			oob += chip->ecc.prepad;
N		}
N
N		chip->ecc.hwctl(mtd, NAND_ECC_READSYN);
X		chip->ecc.hwctl(mtd, 2);
N		chip->read_buf(mtd, oob, eccbytes);
N		stat = chip->ecc.correct(mtd, p, oob, NULL);
X		stat = chip->ecc.correct(mtd, p, oob, 0);
N
N		if (stat < 0)
N			mtd->ecc_stats.failed++;
N		else
N			mtd->ecc_stats.corrected += stat;
N
N		oob += eccbytes;
N
N		if (chip->ecc.postpad) {
N			chip->read_buf(mtd, oob, chip->ecc.postpad);
N			oob += chip->ecc.postpad;
N		}
N	}
N
N	/* Calculate remaining oob bytes */
N	i = mtd->oobsize - (oob - chip->oob_poi);
N	if (i)
N		chip->read_buf(mtd, oob, i);
N
N	return 0;
N}
N
N/**
N * nand_transfer_oob - [Internal] Transfer oob to client buffer
N * @chip:	nand chip structure
N * @oob:	oob destination address
N * @ops:	oob ops structure
N * @len:	size of oob to transfer
N */
Nstatic uint8_t *nand_transfer_oob(struct nand_chip *chip, uint8_t *oob,
N				  struct mtd_oob_ops *ops, size_t len)
N{
N	switch (ops->mode) {
N
N	case MTD_OOB_PLACE:
N	case MTD_OOB_RAW:
N		memcpy(oob, chip->oob_poi + ops->ooboffs, len);
N		return oob + len;
N
N	case MTD_OOB_AUTO: {
N		struct nand_oobfree *free = chip->ecc.layout->oobfree;
N		uint32_t boffs = 0, roffs = ops->ooboffs;
N		size_t bytes = 0;
N
N		for (; free->length && len; free++, len -= bytes) {
N			/* Read request not from offset 0 ? */
N			if (roffs) {
N				if (roffs >= free->length) {
N					roffs -= free->length;
N					continue;
N				}
N				boffs = free->offset + roffs;
N				bytes = min_t(size_t, len,(free->length - roffs));
X				bytes = ((size_t)len < (size_t)(free ->length - roffs) ? (size_t) len: (size_t)(free ->length - roffs));
N				roffs = 0;
N			} else {
N				bytes = min_t(size_t, len, free->length);
X				bytes = ((size_t)len < (size_t)free ->length ? (size_t) len: (size_t)free ->length);
N				boffs = free->offset;
N			}
N			memcpy(oob, chip->oob_poi + boffs, bytes);
N			oob += bytes;
N		}
N		return oob;
N	}
N	default:
N		BUG();
X		do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\nand_base.c", 1156); } while (0);
N	}
N	return NULL;
X	return 0;
N}
N
N/**
N * nand_do_read_ops - [Internal] Read data with ECC
N *
N * @mtd:	MTD device structure
N * @from:	offset to read from
N * @ops:	oob ops structure
N *
N * Internal function. Called with chip held.
N */
Nstatic int nand_do_read_ops(struct mtd_info *mtd, loff_t from,
N			    struct mtd_oob_ops *ops)
N{
N	int chipnr, page, realpage, col, bytes, aligned;
N	struct nand_chip *chip = mtd->priv;
N	struct mtd_ecc_stats stats;
N	int blkcheck = (1 << (chip->phys_erase_shift - chip->page_shift)) - 1;
N	int sndcmd = 1;
N	int ret = 0;
N	uint32_t readlen = ops->len;
N	uint32_t oobreadlen = ops->ooblen;
N	uint32_t max_oobsize = ops->mode == MTD_OOB_AUTO ?
N		mtd->oobavail : mtd->oobsize;
N
N	uint8_t *bufpoi, *oob, *buf;
N
N	stats = mtd->ecc_stats;
N
N	chipnr = (int)(from >> chip->chip_shift);
N	chip->select_chip(mtd, chipnr);
N
N	realpage = (int)(from >> chip->page_shift);
N	page = realpage & chip->pagemask;
N
N	col = (int)(from & (mtd->writesize - 1));
N
N	buf = ops->datbuf;
N	oob = ops->oobbuf;
N
N	while (1) {
N		bytes = min(mtd->writesize - col, readlen);
X		bytes = ( ((mtd->writesize - col) > (readlen)) ? (readlen) : (mtd->writesize - col) );
N		aligned = (bytes == mtd->writesize);
N
N		/* Is the current page in the buffer ? */
N		if (realpage != chip->pagebuf || oob) {
N			bufpoi = aligned ? buf : chip->buffers->databuf;
N
N			if (sndcmd) {
N				chip->cmdfunc(mtd, NAND_CMD_READ0, 0x00, page);
X				chip->cmdfunc(mtd, 0, 0x00, page);
N				sndcmd = 0;
N			}
N
N			/* Now read the page into the buffer */
N			if (ops->mode == MTD_OOB_RAW)
N				ret = chip->ecc.read_page_raw(mtd, chip,
N							      bufpoi, page);
N			else if (!aligned && NAND_HAS_SUBPAGE_READ(chip) &&
X			else if (!aligned && ((chip->options & 0x00001000)) &&
N			    !oob)
N				ret = chip->ecc.read_subpage(mtd, chip,
N							col, bytes, bufpoi);
N			else
N				ret = chip->ecc.read_page(mtd, chip, bufpoi,
N							  page);
N			if (ret < 0)
N				break;
N
N			/* Transfer not aligned data */
N			if (!aligned) {
N				if (!NAND_HAS_SUBPAGE_READ(chip) && !oob &&
X				if (!((chip->options & 0x00001000)) && !oob &&
N				    !(mtd->ecc_stats.failed - stats.failed))
N					chip->pagebuf = realpage;
N				memcpy(buf, chip->buffers->databuf + col, bytes);
N			}
N
N			buf += bytes;
N
N			if (oob) {
N
N				int toread = min(oobreadlen, max_oobsize);
X				int toread = ( ((oobreadlen) > (max_oobsize)) ? (max_oobsize) : (oobreadlen) );
N
N				if (toread) {
N					oob = nand_transfer_oob(chip,
N						oob, ops, toread);
N					oobreadlen -= toread;
N				}
N			}
N
N			if (!(chip->options & NAND_NO_READRDY)) {
X			if (!(chip->options & 0x00000100)) {
N				/*
N				 * Apply delay or wait for ready/busy pin. Do
N				 * this before the AUTOINCR check, so no
N				 * problems arise if a chip which does auto
N				 * increment is marked as NOAUTOINCR by the
N				 * board driver.
N				 */
N				if (!chip->dev_ready)
N					udelay(chip->chip_delay);
N				else
N					nand_wait_ready(mtd);
N			}
N		} else {
N			memcpy(buf, chip->buffers->databuf + col, bytes);
N			buf += bytes;
N		}
N
N		readlen -= bytes;
N
N		if (!readlen)
N			break;
N
N		/* For subsequent reads align to page boundary. */
N		col = 0;
N		/* Increment page address */
N		realpage++;
N
N		page = realpage & chip->pagemask;
N		/* Check, if we cross a chip boundary */
N		if (!page) {
N			chipnr++;
N			chip->select_chip(mtd, -1);
N			chip->select_chip(mtd, chipnr);
N		}
N
N		/* Check, if the chip supports auto page increment
N		 * or if we have hit a block boundary.
N		 */
N		if (!NAND_CANAUTOINCR(chip) || !(page & blkcheck))
X		if (!(!(chip->options & 0x00000001)) || !(page & blkcheck))
N			sndcmd = 1;
N	}
N
N	ops->retlen = ops->len - (size_t) readlen;
N	if (oob)
N		ops->oobretlen = ops->ooblen - oobreadlen;
N
N	if (ret)
N		return ret;
N
N	if (mtd->ecc_stats.failed - stats.failed)
N		return -EBADMSG;
X		return -74;
N
N	return  mtd->ecc_stats.corrected - stats.corrected ? -EUCLEAN : 0;
X	return  mtd->ecc_stats.corrected - stats.corrected ? -117 : 0;
N}
N
N/**
N * nand_read - [MTD Interface] MTD compatibility function for nand_do_read_ecc
N * @mtd:	MTD device structure
N * @from:	offset to read from
N * @len:	number of bytes to read
N * @retlen:	pointer to variable to store the number of read bytes
N * @buf:	the databuffer to put data
N *
N * Get hold of the chip and call nand_do_read
N */
Nstatic int nand_read(struct mtd_info *mtd, loff_t from, size_t len,
N		     size_t *retlen, uint8_t *buf)
N{
N	struct nand_chip *chip = mtd->priv;
N	int ret;
N
N	/* Do not allow reads past end of device */
N	if ((from + len) > mtd->size)
N		return -EINVAL;
X		return -22;
N	if (!len)
N		return 0;
N
N	nand_get_device(chip, mtd, FL_READING);
N
N	chip->ops.len = len;
N	chip->ops.datbuf = buf;
N	chip->ops.oobbuf = NULL;
X	chip->ops.oobbuf = 0;
N
N	ret = nand_do_read_ops(mtd, from, &chip->ops);
N
N	*retlen = chip->ops.retlen;
N
N	nand_release_device(mtd);
N
N	return ret;
N}
N
N/**
N * nand_read_oob_std - [REPLACABLE] the most common OOB data read function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @page:	page number to read
N * @sndcmd:	flag whether to issue read command or not
N */
Nstatic int nand_read_oob_std(struct mtd_info *mtd, struct nand_chip *chip,
N			     int page, int sndcmd)
N{
N	if (sndcmd) {
N		chip->cmdfunc(mtd, NAND_CMD_READOOB, 0, page);
X		chip->cmdfunc(mtd, 0x50, 0, page);
N		sndcmd = 0;
N	}
N	chip->read_buf(mtd, chip->oob_poi, mtd->oobsize);
N	return sndcmd;
N}
N
N/**
N * nand_read_oob_syndrome - [REPLACABLE] OOB data read function for HW ECC
N *			    with syndromes
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @page:	page number to read
N * @sndcmd:	flag whether to issue read command or not
N */
Nstatic int nand_read_oob_syndrome(struct mtd_info *mtd, struct nand_chip *chip,
N				  int page, int sndcmd)
N{
N	uint8_t *buf = chip->oob_poi;
N	int length = mtd->oobsize;
N	int chunk = chip->ecc.bytes + chip->ecc.prepad + chip->ecc.postpad;
N	int eccsize = chip->ecc.size;
N	uint8_t *bufpoi = buf;
N	int i, toread, sndrnd = 0, pos;
N
N	chip->cmdfunc(mtd, NAND_CMD_READ0, chip->ecc.size, page);
X	chip->cmdfunc(mtd, 0, chip->ecc.size, page);
N	for (i = 0; i < chip->ecc.steps; i++) {
N		if (sndrnd) {
N			pos = eccsize + i * (eccsize + chunk);
N			if (mtd->writesize > 512)
N				chip->cmdfunc(mtd, NAND_CMD_RNDOUT, pos, -1);
X				chip->cmdfunc(mtd, 5, pos, -1);
N			else
N				chip->cmdfunc(mtd, NAND_CMD_READ0, pos, page);
X				chip->cmdfunc(mtd, 0, pos, page);
N		} else
N			sndrnd = 1;
N		toread = min_t(int, length, chunk);
X		toread = ((int)length < (int)chunk ? (int) length: (int)chunk);
N		chip->read_buf(mtd, bufpoi, toread);
N		bufpoi += toread;
N		length -= toread;
N	}
N	if (length > 0)
N		chip->read_buf(mtd, bufpoi, length);
N
N	return 1;
N}
N
N/**
N * nand_write_oob_std - [REPLACABLE] the most common OOB data write function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @page:	page number to write
N */
Nstatic int nand_write_oob_std(struct mtd_info *mtd, struct nand_chip *chip,
N			      int page)
N{
N	int status = 0;
N	const uint8_t *buf = chip->oob_poi;
N	int length = mtd->oobsize;
N
N	chip->cmdfunc(mtd, NAND_CMD_SEQIN, mtd->writesize, page);
X	chip->cmdfunc(mtd, 0x80, mtd->writesize, page);
N	chip->write_buf(mtd, buf, length);
N	/* Send command to program the OOB data */
N	chip->cmdfunc(mtd, NAND_CMD_PAGEPROG, -1, -1);
X	chip->cmdfunc(mtd, 0x10, -1, -1);
N
N	status = chip->waitfunc(mtd, chip);
N
N	return status & NAND_STATUS_FAIL ? -EIO : 0;
X	return status & 0x01 ? -5 : 0;
N}
N
N/**
N * nand_write_oob_syndrome - [REPLACABLE] OOB data write function for HW ECC
N *			     with syndrome - only for large page flash !
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @page:	page number to write
N */
Nstatic int nand_write_oob_syndrome(struct mtd_info *mtd,
N				   struct nand_chip *chip, int page)
N{
N	int chunk = chip->ecc.bytes + chip->ecc.prepad + chip->ecc.postpad;
N	int eccsize = chip->ecc.size, length = mtd->oobsize;
N	int i, len, pos, status = 0, sndcmd = 0, steps = chip->ecc.steps;
N	const uint8_t *bufpoi = chip->oob_poi;
N
N	/*
N	 * data-ecc-data-ecc ... ecc-oob
N	 * or
N	 * data-pad-ecc-pad-data-pad .... ecc-pad-oob
N	 */
N	if (!chip->ecc.prepad && !chip->ecc.postpad) {
N		pos = steps * (eccsize + chunk);
N		steps = 0;
N	} else
N		pos = eccsize;
N
N	chip->cmdfunc(mtd, NAND_CMD_SEQIN, pos, page);
X	chip->cmdfunc(mtd, 0x80, pos, page);
N	for (i = 0; i < steps; i++) {
N		if (sndcmd) {
N			if (mtd->writesize <= 512) {
N				uint32_t fill = 0xFFFFFFFF;
N
N				len = eccsize;
N				while (len > 0) {
N					int num = min_t(int, len, 4);
X					int num = ((int)len < (int)4 ? (int) len: (int)4);
N					chip->write_buf(mtd, (uint8_t *)&fill,
N							num);
N					len -= num;
N				}
N			} else {
N				pos = eccsize + i * (eccsize + chunk);
N				chip->cmdfunc(mtd, NAND_CMD_RNDIN, pos, -1);
X				chip->cmdfunc(mtd, 0x85, pos, -1);
N			}
N		} else
N			sndcmd = 1;
N		len = min_t(int, length, chunk);
X		len = ((int)length < (int)chunk ? (int) length: (int)chunk);
N		chip->write_buf(mtd, bufpoi, len);
N		bufpoi += len;
N		length -= len;
N	}
N	if (length > 0)
N		chip->write_buf(mtd, bufpoi, length);
N
N	chip->cmdfunc(mtd, NAND_CMD_PAGEPROG, -1, -1);
X	chip->cmdfunc(mtd, 0x10, -1, -1);
N	status = chip->waitfunc(mtd, chip);
N
N	return status & NAND_STATUS_FAIL ? -EIO : 0;
X	return status & 0x01 ? -5 : 0;
N}
N
N/**
N * nand_do_read_oob - [Intern] NAND read out-of-band
N * @mtd:	MTD device structure
N * @from:	offset to read from
N * @ops:	oob operations description structure
N *
N * NAND read out-of-band data from the spare area
N */
Nstatic int nand_do_read_oob(struct mtd_info *mtd, loff_t from,
N			    struct mtd_oob_ops *ops)
N{
N	int page, realpage, chipnr, sndcmd = 1;
N	struct nand_chip *chip = mtd->priv;
N	int blkcheck = (1 << (chip->phys_erase_shift - chip->page_shift)) - 1;
N	int readlen = ops->ooblen;
N	int len;
N	uint8_t *buf = ops->oobbuf;
N
N	MTDDEBUG(MTD_DEBUG_LEVEL3, "%s: from = 0x%08Lx, len = %i\n",
N			__func__, (unsigned long long)from, readlen);
X	do { if (0) sysprintf("%s: from = 0x%08Lx, len = %i\n", __func__, (unsigned long long)from, readlen); } while(0);
N
N	if (ops->mode == MTD_OOB_AUTO)
N		len = chip->ecc.layout->oobavail;
N	else
N		len = mtd->oobsize;
N
N	if (ops->ooboffs >= len) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Attempt to start read "
N					"outside oob\n", __func__);
X		do { if (0) sysprintf("%s: Attempt to start read " "outside oob\n", __func__); } while(0);
N		return -EINVAL;
X		return -22;
N	}
N
N	/* Do not allow reads past end of device */
N	if (from >= mtd->size || ops->ooboffs + readlen > ((mtd->size >> chip->page_shift) - (from >> chip->page_shift)) * len) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Attempt read beyond end "
N					"of device\n", __func__);
X		do { if (0) sysprintf("%s: Attempt read beyond end " "of device\n", __func__); } while(0);
N		return -EINVAL;
X		return -22;
N	}
N
N	chipnr = (int)(from >> chip->chip_shift);
N	chip->select_chip(mtd, chipnr);
N
N	/* Shift to get page */
N	realpage = (int)(from >> chip->page_shift);
N	page = realpage & chip->pagemask;
N
N	while (1) {
N		sndcmd = chip->ecc.read_oob(mtd, chip, page, sndcmd);
N
N		len = min(len, readlen);
X		len = ( ((len) > (readlen)) ? (readlen) : (len) );
N		buf = nand_transfer_oob(chip, buf, ops, len);
N
N		if (!(chip->options & NAND_NO_READRDY)) {
X		if (!(chip->options & 0x00000100)) {
N			/*
N			 * Apply delay or wait for ready/busy pin. Do this
N			 * before the AUTOINCR check, so no problems arise if a
N			 * chip which does auto increment is marked as
N			 * NOAUTOINCR by the board driver.
N			 */
N			if (!chip->dev_ready)
N				udelay(chip->chip_delay);
N			else
N				nand_wait_ready(mtd);
N		}
N
N		readlen -= len;
N		if (!readlen)
N			break;
N
N		/* Increment page address */
N		realpage++;
N
N		page = realpage & chip->pagemask;
N		/* Check, if we cross a chip boundary */
N		if (!page) {
N			chipnr++;
N			chip->select_chip(mtd, -1);
N			chip->select_chip(mtd, chipnr);
N		}
N
N		/* Check, if the chip supports auto page increment
N		 * or if we have hit a block boundary.
N		 */
N		if (!NAND_CANAUTOINCR(chip) || !(page & blkcheck))
X		if (!(!(chip->options & 0x00000001)) || !(page & blkcheck))
N			sndcmd = 1;
N	}
N
N	ops->oobretlen = ops->ooblen;
N	return 0;
N}
N
N/**
N * nand_read_oob - [MTD Interface] NAND read data and/or out-of-band
N * @mtd:	MTD device structure
N * @from:	offset to read from
N * @ops:	oob operation description structure
N *
N * NAND read data and/or out-of-band data
N */
Nstatic int nand_read_oob(struct mtd_info *mtd, loff_t from,
N			 struct mtd_oob_ops *ops)
N{
N	struct nand_chip *chip = mtd->priv;
N	int ret = -ENOTSUPP;
X	int ret = -524;
N
N	ops->retlen = 0;
N
N	/* Do not allow reads past end of device */
N	if (ops->datbuf && (from + ops->len) > mtd->size) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Attempt read "
N				"beyond end of device\n", __func__);
X		do { if (0) sysprintf("%s: Attempt read " "beyond end of device\n", __func__); } while(0);
N		return -EINVAL;
X		return -22;
N	}
N
N	nand_get_device(chip, mtd, FL_READING);
N
N	switch (ops->mode) {
N	case MTD_OOB_PLACE:
N	case MTD_OOB_AUTO:
N	case MTD_OOB_RAW:
N		break;
N
N	default:
N		goto out;
N	}
N
N	if (!ops->datbuf)
N		ret = nand_do_read_oob(mtd, from, ops);
N	else
N		ret = nand_do_read_ops(mtd, from, ops);
N
Nout:
N	nand_release_device(mtd);
N	return ret;
N}
N
N
N/**
N * nand_write_page_raw - [Intern] raw page write function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	data buffer
N *
N * Not for syndrome calculating ecc controllers, which use a special oob layout
N */
Nstatic void nand_write_page_raw(struct mtd_info *mtd, struct nand_chip *chip,
N				const uint8_t *buf)
N{
N	chip->write_buf(mtd, buf, mtd->writesize);
N	chip->write_buf(mtd, chip->oob_poi, mtd->oobsize);
N}
N
N/**
N * nand_write_page_raw_syndrome - [Intern] raw page write function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	data buffer
N *
N * We need a special oob layout and handling even when ECC isn't checked.
N */
Nstatic void nand_write_page_raw_syndrome(struct mtd_info *mtd,
N					struct nand_chip *chip,
N					const uint8_t *buf)
N{
N	int eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	uint8_t *oob = chip->oob_poi;
N	int steps, size;
N
N	for (steps = chip->ecc.steps; steps > 0; steps--) {
N		chip->write_buf(mtd, buf, eccsize);
N		buf += eccsize;
N
N		if (chip->ecc.prepad) {
N			chip->write_buf(mtd, oob, chip->ecc.prepad);
N			oob += chip->ecc.prepad;
N		}
N
N		chip->read_buf(mtd, oob, eccbytes);
N		oob += eccbytes;
N
N		if (chip->ecc.postpad) {
N			chip->write_buf(mtd, oob, chip->ecc.postpad);
N			oob += chip->ecc.postpad;
N		}
N	}
N
N	size = mtd->oobsize - (oob - chip->oob_poi);
N	if (size)
N		chip->write_buf(mtd, oob, size);
N}
N/**
N * nand_write_page_swecc - [REPLACABLE] software ecc based page write function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	data buffer
N */
Nstatic void nand_write_page_swecc(struct mtd_info *mtd, struct nand_chip *chip,
N				  const uint8_t *buf)
N{
N	int i, eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	int eccsteps = chip->ecc.steps;
N	uint8_t *ecc_calc = chip->buffers->ecccalc;
N	const uint8_t *p = buf;
N	uint32_t *eccpos = chip->ecc.layout->eccpos;
N
N	/* Software ecc calculation */
N	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize)
N		chip->ecc.calculate(mtd, p, &ecc_calc[i]);
N
N	for (i = 0; i < chip->ecc.total; i++)
N		chip->oob_poi[eccpos[i]] = ecc_calc[i];
N
N	chip->ecc.write_page_raw(mtd, chip, buf);
N}
N
N/**
N * nand_write_page_hwecc - [REPLACABLE] hardware ecc based page write function
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	data buffer
N */
Nstatic void nand_write_page_hwecc(struct mtd_info *mtd, struct nand_chip *chip,
N				  const uint8_t *buf)
N{
N	int i, eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	int eccsteps = chip->ecc.steps;
N	uint8_t *ecc_calc = chip->buffers->ecccalc;
N	const uint8_t *p = buf;
N	uint32_t *eccpos = chip->ecc.layout->eccpos;
N
N	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
N		chip->ecc.hwctl(mtd, NAND_ECC_WRITE);
X		chip->ecc.hwctl(mtd, 1);
N		chip->write_buf(mtd, p, eccsize);
N		chip->ecc.calculate(mtd, p, &ecc_calc[i]);
N	}
N
N	for (i = 0; i < chip->ecc.total; i++)
N		chip->oob_poi[eccpos[i]] = ecc_calc[i];
N
N	chip->write_buf(mtd, chip->oob_poi, mtd->oobsize);
N}
N
N/**
N * nand_write_page_syndrome - [REPLACABLE] hardware ecc syndrom based page write
N * @mtd:	mtd info structure
N * @chip:	nand chip info structure
N * @buf:	data buffer
N *
N * The hw generator calculates the error syndrome automatically. Therefor
N * we need a special oob layout and handling.
N */
Nstatic void nand_write_page_syndrome(struct mtd_info *mtd,
N				    struct nand_chip *chip, const uint8_t *buf)
N{
N	int i, eccsize = chip->ecc.size;
N	int eccbytes = chip->ecc.bytes;
N	int eccsteps = chip->ecc.steps;
N	const uint8_t *p = buf;
N	uint8_t *oob = chip->oob_poi;
N
N	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
N
N		chip->ecc.hwctl(mtd, NAND_ECC_WRITE);
X		chip->ecc.hwctl(mtd, 1);
N		chip->write_buf(mtd, p, eccsize);
N
N		if (chip->ecc.prepad) {
N			chip->write_buf(mtd, oob, chip->ecc.prepad);
N			oob += chip->ecc.prepad;
N		}
N
N		chip->ecc.calculate(mtd, p, oob);
N		chip->write_buf(mtd, oob, eccbytes);
N		oob += eccbytes;
N
N		if (chip->ecc.postpad) {
N			chip->write_buf(mtd, oob, chip->ecc.postpad);
N			oob += chip->ecc.postpad;
N		}
N	}
N
N	/* Calculate remaining oob bytes */
N	i = mtd->oobsize - (oob - chip->oob_poi);
N	if (i)
N		chip->write_buf(mtd, oob, i);
N}
N
N/**
N * nand_write_page - [REPLACEABLE] write one page
N * @mtd:	MTD device structure
N * @chip:	NAND chip descriptor
N * @buf:	the data to write
N * @page:	page number to write
N * @cached:	cached programming
N * @raw:	use _raw version of write_page
N */
Nstatic int nand_write_page(struct mtd_info *mtd, struct nand_chip *chip,
N			   const uint8_t *buf, int page, int cached, int raw)
N{
N	int status;
N
N	chip->cmdfunc(mtd, NAND_CMD_SEQIN, 0x00, page);
X	chip->cmdfunc(mtd, 0x80, 0x00, page);
N
N	if (raw)
N		chip->ecc.write_page_raw(mtd, chip, buf);
N	else
N		chip->ecc.write_page(mtd, chip, buf);
N
N	/*
N	 * Cached progamming disabled for now, Not sure if its worth the
N	 * trouble. The speed gain is not very impressive. (2.3->2.6Mib/s)
N	 */
N	cached = 0;
N
N	if (!cached || !(chip->options & NAND_CACHEPRG)) {
X	if (!cached || !(chip->options & 0x00000008)) {
N
N		chip->cmdfunc(mtd, NAND_CMD_PAGEPROG, -1, -1);
X		chip->cmdfunc(mtd, 0x10, -1, -1);
N		status = chip->waitfunc(mtd, chip);
N		/*
N		 * See if operation failed and additional status checks are
N		 * available
N		 */
N		if ((status & NAND_STATUS_FAIL) && (chip->errstat))
X		if ((status & 0x01) && (chip->errstat))
N			status = chip->errstat(mtd, chip, FL_WRITING, status,
N					       page);
N
N		if (status & NAND_STATUS_FAIL)
X		if (status & 0x01)
N			return -EIO;
X			return -5;
N	} else {
N		chip->cmdfunc(mtd, NAND_CMD_CACHEDPROG, -1, -1);
X		chip->cmdfunc(mtd, 0x15, -1, -1);
N		status = chip->waitfunc(mtd, chip);
N	}
N
N#ifdef CONFIG_MTD_NAND_VERIFY_WRITE
S	/* Send command to read back the data */
S	chip->cmdfunc(mtd, NAND_CMD_READ0, 0, page);
S
S	if (chip->verify_buf(mtd, buf, mtd->writesize))
S		return -EIO;
N#endif
N	return 0;
N}
N
N/**
N * nand_fill_oob - [Internal] Transfer client buffer to oob
N * @chip:	nand chip structure
N * @oob:	oob data buffer
N * @len:	oob data write length
N * @ops:	oob ops structure
N */
Nstatic uint8_t *nand_fill_oob(struct nand_chip *chip, uint8_t *oob, size_t len,
N						struct mtd_oob_ops *ops)
N{
N	switch (ops->mode) {
N
N	case MTD_OOB_PLACE:
N	case MTD_OOB_RAW:
N		memcpy(chip->oob_poi + ops->ooboffs, oob, len);
N		return oob + len;
N
N	case MTD_OOB_AUTO: {
N		struct nand_oobfree *free = chip->ecc.layout->oobfree;
N		uint32_t boffs = 0, woffs = ops->ooboffs;
N		size_t bytes = 0;
N
N		for (; free->length && len; free++, len -= bytes) {
N			/* Write request not from offset 0 ? */
N			if (woffs) {
N				if (woffs >= free->length) {
N					woffs -= free->length;
N					continue;
N				}
N				boffs = free->offset + woffs;
N				bytes = min_t(size_t, len,
N					      (free->length - woffs));
X				bytes = ((size_t)len < (size_t)(free ->length - woffs) ? (size_t) len: (size_t)(free ->length - woffs));
N				woffs = 0;
N			} else {
N				bytes = min_t(size_t, len, free->length);
X				bytes = ((size_t)len < (size_t)free ->length ? (size_t) len: (size_t)free ->length);
N				boffs = free->offset;
N			}
N			memcpy(chip->oob_poi + boffs, oob, bytes);
N			oob += bytes;
N		}
N		return oob;
N	}
N	default:
N		BUG();
X		do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\nand_base.c", 1867); } while (0);
N	}
N	return NULL;
X	return 0;
N}
N
N#define NOTALIGNED(x)	((x & (chip->subpagesize - 1)) != 0)
N
N/**
N * nand_do_write_ops - [Internal] NAND write with ECC
N * @mtd:	MTD device structure
N * @to:		offset to write to
N * @ops:	oob operations description structure
N *
N * NAND write with ECC
N */
Nstatic int nand_do_write_ops(struct mtd_info *mtd, loff_t to,
N			     struct mtd_oob_ops *ops)
N{
N	int chipnr, realpage, page, blockmask, column;
N	struct nand_chip *chip = mtd->priv;
N	uint32_t writelen = ops->len;
N
N	uint32_t oobwritelen = ops->ooblen;
N	uint32_t oobmaxlen = ops->mode == MTD_OOB_AUTO ?
N				mtd->oobavail : mtd->oobsize;
N
N	uint8_t *oob = ops->oobbuf;
N	uint8_t *buf = ops->datbuf;
N	int ret, subpage;
N
N	ops->retlen = 0;
N	if (!writelen)
N		return 0;
N
N	column = to & (mtd->writesize - 1);
N	subpage = column || (writelen & (mtd->writesize - 1));
N
N	if (subpage && oob)
N		return -EINVAL;
X		return -22;
N
N	chipnr = (int)(to >> chip->chip_shift);
N	chip->select_chip(mtd, chipnr);
N
N	/* Check, if it is write protected */
N	if (nand_check_wp(mtd)) {
N		printk (KERN_NOTICE "nand_do_write_ops: Device is write protected\n");
X		sysprintf ( "nand_do_write_ops: Device is write protected\n");
N		return -EIO;
X		return -5;
N	}
N
N	realpage = (int)(to >> chip->page_shift);
N	page = realpage & chip->pagemask;
N	blockmask = (1 << (chip->phys_erase_shift - chip->page_shift)) - 1;
N
N	/* Invalidate the page cache, when we write to the cached page */
N	if (to <= (chip->pagebuf << chip->page_shift) &&
N	    (chip->pagebuf << chip->page_shift) < (to + ops->len))
N		chip->pagebuf = -1;
N
N	/* If we're not given explicit OOB data, let it be 0xFF */
N	if (!oob)
N		memset(chip->oob_poi, 0xff, mtd->oobsize);
N
N	/* Don't allow multipage oob writes with offset */
N	if (oob && ops->ooboffs && (ops->ooboffs + ops->ooblen > oobmaxlen))
N		return -EINVAL;
X		return -22;
N
N	while (1) {
N		int bytes = mtd->writesize;
N		int cached = writelen > bytes && page != blockmask;
N		uint8_t *wbuf = buf;
N
N		/* Partial page write ? */
N		if (column || writelen < (mtd->writesize - 1)) {
N			cached = 0;
N			bytes = min_t(int, bytes - column, (int) writelen);
X			bytes = ((int)bytes - column < (int)(int) writelen ? (int) bytes - column: (int)(int) writelen);
N			chip->pagebuf = -1;
N			memset(chip->buffers->databuf, 0xff, mtd->writesize);
N			memcpy(&chip->buffers->databuf[column], buf, bytes);
N			wbuf = chip->buffers->databuf;
N		}
N
N		if (oob) {
N			size_t len = min(oobwritelen, oobmaxlen);
X			size_t len = ( ((oobwritelen) > (oobmaxlen)) ? (oobmaxlen) : (oobwritelen) );
N			oob = nand_fill_oob(chip, oob, len, ops);
N			oobwritelen -= len;
N		}
N
N		ret = chip->write_page(mtd, chip, wbuf, page, cached,
N				       (ops->mode == MTD_OOB_RAW));
N		if (ret)
N			break;
N
N		writelen -= bytes;
N		if (!writelen)
N			break;
N
N		column = 0;
N		buf += bytes;
N		realpage++;
N
N		page = realpage & chip->pagemask;
N		/* Check, if we cross a chip boundary */
N		if (!page) {
N			chipnr++;
N			chip->select_chip(mtd, -1);
N			chip->select_chip(mtd, chipnr);
N		}
N	}
N
N	ops->retlen = ops->len - writelen;
N	if (oob)
N		ops->oobretlen = ops->ooblen;
N	return ret;
N}
N
N/**
N * nand_write - [MTD Interface] NAND write with ECC
N * @mtd:	MTD device structure
N * @to:		offset to write to
N * @len:	number of bytes to write
N * @retlen:	pointer to variable to store the number of written bytes
N * @buf:	the data to write
N *
N * NAND write with ECC
N */
Nstatic int nand_write(struct mtd_info *mtd, loff_t to, size_t len,
N			  size_t *retlen, const uint8_t *buf)
N{
N	struct nand_chip *chip = mtd->priv;
N	int ret;
N
N	/* Do not allow writes past end of device */
N	if ((to + len) > mtd->size)
N		return -EINVAL;
X		return -22;
N	if (!len)
N		return 0;
N
N	nand_get_device(chip, mtd, FL_WRITING);
N
N	chip->ops.len = len;
N	chip->ops.datbuf = (uint8_t *)buf;
N	chip->ops.oobbuf = NULL;
X	chip->ops.oobbuf = 0;
N
N	ret = nand_do_write_ops(mtd, to, &chip->ops);
N
N	*retlen = chip->ops.retlen;
N
N	nand_release_device(mtd);
N
N	return ret;
N}
N
N/**
N * nand_do_write_oob - [MTD Interface] NAND write out-of-band
N * @mtd:	MTD device structure
N * @to:		offset to write to
N * @ops:	oob operation description structure
N *
N * NAND write out-of-band
N */
Nstatic int nand_do_write_oob(struct mtd_info *mtd, loff_t to,
N			     struct mtd_oob_ops *ops)
N{
N	int chipnr, page, status, len;
N	struct nand_chip *chip = mtd->priv;
N
N	MTDDEBUG(MTD_DEBUG_LEVEL3, "%s: to = 0x%08x, len = %i\n",
N			 __func__, (unsigned int)to, (int)ops->ooblen);
X	do { if (0) sysprintf("%s: to = 0x%08x, len = %i\n", __func__, (unsigned int)to, (int)ops->ooblen); } while(0);
N
N	if (ops->mode == MTD_OOB_AUTO)
N		len = chip->ecc.layout->oobavail;
N	else
N		len = mtd->oobsize;
N
N	/* Do not allow write past end of page */
N	if ((ops->ooboffs + ops->ooblen) > len) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Attempt to write "
N				"past end of page\n", __func__);
X		do { if (0) sysprintf("%s: Attempt to write " "past end of page\n", __func__); } while(0);
N		return -EINVAL;
X		return -22;
N	}
N
N	if (ops->ooboffs >= len) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Attempt to start "
N				"write outside oob\n", __func__);
X		do { if (0) sysprintf("%s: Attempt to start " "write outside oob\n", __func__); } while(0);
N		return -EINVAL;
X		return -22;
N	}
N
N	/* Do not allow write past end of device */
N	if (to >= mtd->size || ops->ooboffs + ops->ooblen > ((mtd->size >> chip->page_shift) - (to >> chip->page_shift)) * len) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Attempt write beyond "
N				"end of device\n", __func__);
X		do { if (0) sysprintf("%s: Attempt write beyond " "end of device\n", __func__); } while(0);
N		return -EINVAL;
X		return -22;
N	}
N
N	chipnr = (int)(to >> chip->chip_shift);
N	chip->select_chip(mtd, chipnr);
N
N	/* Shift to get page */
N	page = (int)(to >> chip->page_shift);
N
N	/*
N	 * Reset the chip. Some chips (like the Toshiba TC5832DC found in one
N	 * of my DiskOnChip 2000 test units) will clear the whole data page too
N	 * if we don't do this. I have no clue why, but I seem to have 'fixed'
N	 * it in the doc2000 driver in August 1999.  dwmw2.
N	 */
N	chip->cmdfunc(mtd, NAND_CMD_RESET, -1, -1);
X	chip->cmdfunc(mtd, 0xff, -1, -1);
N
N	/* Check, if it is write protected */
N	if (nand_check_wp(mtd))
N		return -EROFS;
X		return -30;
N
N	/* Invalidate the page cache, if we write to the cached page */
N	if (page == chip->pagebuf)
N		chip->pagebuf = -1;
N
N	memset(chip->oob_poi, 0xff, mtd->oobsize);
N	nand_fill_oob(chip, ops->oobbuf, ops->ooblen, ops);
N	status = chip->ecc.write_oob(mtd, chip, page & chip->pagemask);
N	memset(chip->oob_poi, 0xff, mtd->oobsize);
N
N	if (status)
N		return status;
N
N	ops->oobretlen = ops->ooblen;
N
N	return 0;
N}
N
N/**
N * nand_write_oob - [MTD Interface] NAND write data and/or out-of-band
N * @mtd:	MTD device structure
N * @to:		offset to write to
N * @ops:	oob operation description structure
N */
Nstatic int nand_write_oob(struct mtd_info *mtd, loff_t to,
N			  struct mtd_oob_ops *ops)
N{
N	struct nand_chip *chip = mtd->priv;
N	int ret = -ENOTSUPP;
X	int ret = -524;
N
N	ops->retlen = 0;
N
N	/* Do not allow writes past end of device */
N	if (ops->datbuf && (to + ops->len) > mtd->size) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Attempt write beyond "
N				"end of device\n", __func__);
X		do { if (0) sysprintf("%s: Attempt write beyond " "end of device\n", __func__); } while(0);
N		return -EINVAL;
X		return -22;
N	}
N
N	nand_get_device(chip, mtd, FL_WRITING);
N
N	switch (ops->mode) {
N	case MTD_OOB_PLACE:
N	case MTD_OOB_AUTO:
N	case MTD_OOB_RAW:
N		break;
N
N	default:
N		goto out;
N	}
N
N	if (!ops->datbuf)
N		ret = nand_do_write_oob(mtd, to, ops);
N	else
N		ret = nand_do_write_ops(mtd, to, ops);
N
Nout:
N	nand_release_device(mtd);
N	return ret;
N}
N
N/**
N * single_erease_cmd - [GENERIC] NAND standard block erase command function
N * @mtd:	MTD device structure
N * @page:	the page address of the block which will be erased
N *
N * Standard erase command for NAND chips
N */
Nstatic void single_erase_cmd(struct mtd_info *mtd, int page)
N{
N	struct nand_chip *chip = mtd->priv;
N	/* Send commands to erase a block */
N	chip->cmdfunc(mtd, NAND_CMD_ERASE1, -1, page);
X	chip->cmdfunc(mtd, 0x60, -1, page);
N	chip->cmdfunc(mtd, NAND_CMD_ERASE2, -1, -1);
X	chip->cmdfunc(mtd, 0xd0, -1, -1);
N}
N
N/**
N * multi_erease_cmd - [GENERIC] AND specific block erase command function
N * @mtd:	MTD device structure
N * @page:	the page address of the block which will be erased
N *
N * AND multi block erase command function
N * Erase 4 consecutive blocks
N */
Nstatic void multi_erase_cmd(struct mtd_info *mtd, int page)
N{
N	struct nand_chip *chip = mtd->priv;
N	/* Send commands to erase a block */
N	chip->cmdfunc(mtd, NAND_CMD_ERASE1, -1, page++);
X	chip->cmdfunc(mtd, 0x60, -1, page++);
N	chip->cmdfunc(mtd, NAND_CMD_ERASE1, -1, page++);
X	chip->cmdfunc(mtd, 0x60, -1, page++);
N	chip->cmdfunc(mtd, NAND_CMD_ERASE1, -1, page++);
X	chip->cmdfunc(mtd, 0x60, -1, page++);
N	chip->cmdfunc(mtd, NAND_CMD_ERASE1, -1, page);
X	chip->cmdfunc(mtd, 0x60, -1, page);
N	chip->cmdfunc(mtd, NAND_CMD_ERASE2, -1, -1);
X	chip->cmdfunc(mtd, 0xd0, -1, -1);
N}
N
N/**
N * nand_erase - [MTD Interface] erase block(s)
N * @mtd:	MTD device structure
N * @instr:	erase instruction
N *
N * Erase one ore more blocks
N */
Nstatic int nand_erase(struct mtd_info *mtd, struct erase_info *instr)
N{
N	return nand_erase_nand(mtd, instr, 0);
N}
N
N#define BBT_PAGE_MASK	0xffffff3f
N/**
N * nand_erase_nand - [Internal] erase block(s)
N * @mtd:	MTD device structure
N * @instr:	erase instruction
N * @allowbbt:	allow erasing the bbt area
N *
N * Erase one ore more blocks
N */
Nint nand_erase_nand(struct mtd_info *mtd, struct erase_info *instr,
N		    int allowbbt)
N{
N	int page, status, pages_per_block, ret, chipnr;
N	struct nand_chip *chip = mtd->priv;
N	loff_t rewrite_bbt[CONFIG_SYS_NAND_MAX_CHIPS] = {0};
X	loff_t rewrite_bbt[1] = {0};
N	unsigned int bbt_masked_page = 0xffffffff;
N	loff_t len;
N
N	MTDDEBUG(MTD_DEBUG_LEVEL3, "%s: start = 0x%012llx, len = %llu\n",
N				__func__, (unsigned long long)instr->addr,
N				(unsigned long long)instr->len);
X	do { if (0) sysprintf("%s: start = 0x%012llx, len = %llu\n", __func__, (unsigned long long)instr->addr, (unsigned long long)instr->len); } while(0);
N
N	if (check_offs_len(mtd, instr->addr, instr->len))
N		return -EINVAL;
X		return -22;
N
W "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 2210 21 integer conversion resulted in a change of sign
N	instr->fail_addr = MTD_FAIL_ADDR_UNKNOWN;
X	instr->fail_addr = -1LL;
N
N	/* Grab the lock and see if the device is available */
N	nand_get_device(chip, mtd, FL_ERASING);
N
N	/* Shift to get first page */
N	page = (int)(instr->addr >> chip->page_shift);
N	chipnr = (int)(instr->addr >> chip->chip_shift);
N
N	/* Calculate pages in each block */
N	pages_per_block = 1 << (chip->phys_erase_shift - chip->page_shift);
N
N	/* Select the NAND device */
N	chip->select_chip(mtd, chipnr);
N
N	/* Check, if it is write protected */
N	if (nand_check_wp(mtd)) {
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Device is write protected!!!\n",
N					__func__);
X		do { if (0) sysprintf("%s: Device is write protected!!!\n", __func__); } while(0);
N		instr->state = MTD_ERASE_FAILED;
X		instr->state = 0x10;
N		goto erase_exit;
N	}
N
N	/*
N	 * If BBT requires refresh, set the BBT page mask to see if the BBT
N	 * should be rewritten. Otherwise the mask is set to 0xffffffff which
N	 * can not be matched. This is also done when the bbt is actually
N	 * erased to avoid recusrsive updates
N	 */
N	if (chip->options & BBT_AUTO_REFRESH && !allowbbt)
X	if (chip->options & 0x00000080 && !allowbbt)
N		bbt_masked_page = chip->bbt_td->pages[chipnr] & BBT_PAGE_MASK;
X		bbt_masked_page = chip->bbt_td->pages[chipnr] & 0xffffff3f;
N
N	/* Loop through the pages */
N	len = instr->len;
N
N	instr->state = MTD_ERASING;
X	instr->state = 0x02;
N
N	while (len) {
N		/*
N		 * heck if we have a bad block, we do not erase bad blocks !
N		 */
N		if (!instr->scrub && nand_block_checkbad(mtd, ((loff_t) page) <<
N					chip->page_shift, 0, allowbbt)) {
N			printk(KERN_WARNING "%s: attempt to erase a bad block "
X			sysprintf( "%s: attempt to erase a bad block "
N					"at page 0x%08x\n", __func__, page);
N			instr->state = MTD_ERASE_FAILED;
X			instr->state = 0x10;
N			goto erase_exit;
N		}
N
N		/*
N		 * Invalidate the page cache, if we erase the block which
N		 * contains the current cached page
N		 */
N		if (page <= chip->pagebuf && chip->pagebuf <
N		    (page + pages_per_block))
N			chip->pagebuf = -1;
N
N		chip->erase_cmd(mtd, page & chip->pagemask);
N
N		status = chip->waitfunc(mtd, chip);
N
N		/*
N		 * See if operation failed and additional status checks are
N		 * available
N		 */
N		if ((status & NAND_STATUS_FAIL) && (chip->errstat))
X		if ((status & 0x01) && (chip->errstat))
N			status = chip->errstat(mtd, chip, FL_ERASING,
N					       status, page);
N
N		/* See if block erase succeeded */
N		if (status & NAND_STATUS_FAIL) {
X		if (status & 0x01) {
N			MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: Failed erase, "
N					"page 0x%08x\n", __func__, page);
X			do { if (0) sysprintf("%s: Failed erase, " "page 0x%08x\n", __func__, page); } while(0);
N			instr->state = MTD_ERASE_FAILED;
X			instr->state = 0x10;
N			instr->fail_addr =
N				((loff_t)page << chip->page_shift);
N			goto erase_exit;
N		}
N
N		/*
N		 * If BBT requires refresh, set the BBT rewrite flag to the
N		 * page being erased
N		 */
N		if (bbt_masked_page != 0xffffffff &&
N		    (page & BBT_PAGE_MASK) == bbt_masked_page)
X		    (page & 0xffffff3f) == bbt_masked_page)
N			rewrite_bbt[chipnr] =
N				((loff_t)page << chip->page_shift);
N
N		/* Increment page address and decrement length */
N		len -= (1 << chip->phys_erase_shift);
N		page += pages_per_block;
N
N		/* Check, if we cross a chip boundary */
N		if (len && !(page & chip->pagemask)) {
N			chipnr++;
N			chip->select_chip(mtd, -1);
N			chip->select_chip(mtd, chipnr);
N
N			/*
N			 * If BBT requires refresh and BBT-PERCHIP, set the BBT
N			 * page mask to see if this BBT should be rewritten
N			 */
N			if (bbt_masked_page != 0xffffffff &&
N			    (chip->bbt_td->options & NAND_BBT_PERCHIP))
X			    (chip->bbt_td->options & 0x00000080))
N				bbt_masked_page = chip->bbt_td->pages[chipnr] &
N					BBT_PAGE_MASK;
X					0xffffff3f;
N		}
N	}
N	instr->state = MTD_ERASE_DONE;
X	instr->state = 0x08;
N
Nerase_exit:
N
N	ret = instr->state == MTD_ERASE_DONE ? 0 : -EIO;
X	ret = instr->state == 0x08 ? 0 : -5;
N
N	/* Deselect and wake up anyone waiting on the device */
N	nand_release_device(mtd);
N
N	/* Do call back function */
N	if (!ret)
N		mtd_erase_callback(instr);
N
N	/*
N	 * If BBT requires refresh and erase was successful, rewrite any
N	 * selected bad block tables
N	 */
N	if (bbt_masked_page == 0xffffffff || ret)
N		return ret;
N
N	for (chipnr = 0; chipnr < chip->numchips; chipnr++) {
N		if (!rewrite_bbt[chipnr])
N			continue;
N		/* update the BBT for chip */
N		MTDDEBUG(MTD_DEBUG_LEVEL0, "%s: nand_update_bbt "
N			"(%d:0x%0llx 0x%0x)\n", __func__, chipnr,
N			rewrite_bbt[chipnr], chip->bbt_td->pages[chipnr]);
X		do { if (0) sysprintf("%s: nand_update_bbt " "(%d:0x%0llx 0x%0x)\n", __func__, chipnr, rewrite_bbt[chipnr], chip->bbt_td->pages[chipnr]); } while(0);
N		nand_update_bbt(mtd, rewrite_bbt[chipnr]);
N	}
N
N	/* Return more or less happy */
N	return ret;
N}
N
N/**
N * nand_sync - [MTD Interface] sync
N * @mtd:	MTD device structure
N *
N * Sync is actually a wait for chip ready function
N */
Nstatic void nand_sync(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N
N	MTDDEBUG(MTD_DEBUG_LEVEL3, "%s: called\n", __func__);
X	do { if (0) sysprintf("%s: called\n", __func__); } while(0);
N
N	/* Grab the lock and see if the device is available */
N	nand_get_device(chip, mtd, FL_SYNCING);
N	/* Release it and go back */
N	nand_release_device(mtd);
N}
N
N/**
N * nand_block_isbad - [MTD Interface] Check if block at offset is bad
N * @mtd:	MTD device structure
N * @offs:	offset relative to mtd start
N */
Nstatic int nand_block_isbad(struct mtd_info *mtd, loff_t offs)
N{
N	/* Check for invalid offset */
N	if (offs > mtd->size)
N		return -EINVAL;
X		return -22;
N
N	return nand_block_checkbad(mtd, offs, 1, 0);
N}
N
N/**
N * nand_block_markbad - [MTD Interface] Mark block at the given offset as bad
N * @mtd:	MTD device structure
N * @ofs:	offset relative to mtd start
N */
Nstatic int nand_block_markbad(struct mtd_info *mtd, loff_t ofs)
N{
N	struct nand_chip *chip = mtd->priv;
N	int ret;
N
N	ret = nand_block_isbad(mtd, ofs);
N	if (ret) {
N		/* If it was bad already, return success and do nothing. */
N		if (ret > 0)
N			return 0;
N		return ret;
N	}
N
N	return chip->block_markbad(mtd, ofs);
N}
N
N/*
N * Set default functions
N */
Nstatic void nand_set_defaults(struct nand_chip *chip, int busw)
N{
N	/* check for proper chip_delay setup, set 20us if not */
N	if (!chip->chip_delay)
N		chip->chip_delay = 20;
N
N	/* check, if a user supplied command function given */
N	if (chip->cmdfunc == NULL)
X	if (chip->cmdfunc == 0)
N		chip->cmdfunc = nand_command;
N
N	/* check, if a user supplied wait function given */
N	if (chip->waitfunc == NULL)
X	if (chip->waitfunc == 0)
N		chip->waitfunc = nand_wait;
N
N	if (!chip->select_chip)
N		chip->select_chip = nand_select_chip;
N	if (!chip->read_byte)
N		chip->read_byte = busw ? nand_read_byte16 : nand_read_byte;
N	if (!chip->read_word)
N		chip->read_word = nand_read_word;
N	if (!chip->block_bad)
N		chip->block_bad = nand_block_bad;
N	if (!chip->block_markbad)
N		chip->block_markbad = nand_default_block_markbad;
N	if (!chip->write_buf)
N		chip->write_buf = busw ? nand_write_buf16 : nand_write_buf;
N	if (!chip->read_buf)
N		chip->read_buf = busw ? nand_read_buf16 : nand_read_buf;
N	if (!chip->verify_buf)
N		chip->verify_buf = busw ? nand_verify_buf16 : nand_verify_buf;
N	if (!chip->scan_bbt)
N		chip->scan_bbt = nand_default_bbt;
N	if (!chip->controller)
N		chip->controller = &chip->hwcontrol;
N}
N
N#ifdef CONFIG_SYS_NAND_ONFI_DETECTION
S/*
S * sanitize ONFI strings so we can safely print them
S */
Sstatic void sanitize_string(char *s, size_t len)
S{
S	ssize_t i;
S
S	/* null terminate */
S	s[len - 1] = 0;
S
S	/* remove non printable chars */
S	for (i = 0; i < len - 1; i++) {
S		if (s[i] < ' ' || s[i] > 127)
S			s[i] = '?';
S	}
S
S	/* remove trailing spaces */
S	strim(s);
S}
S
Sstatic u16 onfi_crc16(u16 crc, u8 const *p, size_t len)
S{
S	int i;
S	while (len--) {
S		crc ^= *p++ << 8;
S		for (i = 0; i < 8; i++)
S			crc = (crc << 1) ^ ((crc & 0x8000) ? 0x8005 : 0);
S	}
S
S	return crc;
S}
S
S/*
S * Check if the NAND chip is ONFI compliant, returns 1 if it is, 0 otherwise
S */
Sstatic int nand_flash_detect_onfi(struct mtd_info *mtd, struct nand_chip *chip,
S					int *busw)
S{
S	struct nand_onfi_params *p = &chip->onfi_params;
S	int i;
S	int val;
S
S	/* try ONFI for unknow chip or LP */
S	chip->cmdfunc(mtd, NAND_CMD_READID, 0x20, -1);
S	if (chip->read_byte(mtd) != 'O' || chip->read_byte(mtd) != 'N' ||
S		chip->read_byte(mtd) != 'F' || chip->read_byte(mtd) != 'I')
S		return 0;
S
S	MTDDEBUG(MTD_DEBUG_LEVEL0, "ONFI flash detected\n");
S	chip->cmdfunc(mtd, NAND_CMD_PARAM, 0, -1);
S	for (i = 0; i < 3; i++) {
S		chip->read_buf(mtd, (uint8_t *)p, sizeof(*p));
S		if (onfi_crc16(ONFI_CRC_BASE, (uint8_t *)p, 254) ==
S				le16_to_cpu(p->crc)) {
S			MTDDEBUG(MTD_DEBUG_LEVEL0,
S				 "ONFI param page %d valid\n", i);
S			break;
S		}
S	}
S
S	if (i == 3)
S		return 0;
S
S	/* check version */
S	val = le16_to_cpu(p->revision);
S	if (val & (1 << 5))
S		chip->onfi_version = 23;
S	else if (val & (1 << 4))
S		chip->onfi_version = 22;
S	else if (val & (1 << 3))
S		chip->onfi_version = 21;
S	else if (val & (1 << 2))
S		chip->onfi_version = 20;
S	else if (val & (1 << 1))
S		chip->onfi_version = 10;
S	else
S		chip->onfi_version = 0;
S
S	if (!chip->onfi_version) {
S		printk(KERN_INFO "%s: unsupported ONFI version: %d\n",
S								__func__, val);
S		return 0;
S	}
S
S	sanitize_string(p->manufacturer, sizeof(p->manufacturer));
S	sanitize_string(p->model, sizeof(p->model));
S	if (!mtd->name)
S		mtd->name = p->model;
S	mtd->writesize = le32_to_cpu(p->byte_per_page);
S	mtd->erasesize = le32_to_cpu(p->pages_per_block) * mtd->writesize;
S	mtd->oobsize = le16_to_cpu(p->spare_bytes_per_page);
S	chip->chipsize = le32_to_cpu(p->blocks_per_lun);
S	chip->chipsize *= (uint64_t)mtd->erasesize * p->lun_count;
S	*busw = 0;
S	if (le16_to_cpu(p->features) & 1)
S		*busw = NAND_BUSWIDTH_16;
S
S	chip->options |= NAND_NO_READRDY | NAND_NO_AUTOINCR;
S
S	return 1;
S}
N#else
Nstatic __inline int nand_flash_detect_onfi(struct mtd_info *mtd,
N					struct nand_chip *chip,
N					int *busw)
N{
N	return 0;
N}
N#endif
N
N/*
N * Get the flash and manufacturer id and lookup if the type is supported
N */
Nstatic const struct nand_flash_dev *nand_get_flash_type(struct mtd_info *mtd,
N						  struct nand_chip *chip,
N						  int busw,
N						  int *maf_id, int *dev_id,
N						  const struct nand_flash_dev *type)
N{
N	const char *name;
N	int i, maf_idx;
N	u8 id_data[8];
N	int ret;
N
N	/* Select the device */
N	chip->select_chip(mtd, 0);
N
N	/*
N	 * Reset the chip, required by some chips (e.g. Micron MT29FxGxxxxx)
N	 * after power-up
N	 */
N	chip->cmdfunc(mtd, NAND_CMD_RESET, -1, -1);
X	chip->cmdfunc(mtd, 0xff, -1, -1);
N
N	/* Send the command for reading device ID */
N	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
X	chip->cmdfunc(mtd, 0x90, 0x00, -1);
N
N	/* Read manufacturer and device IDs */
N	*maf_id = chip->read_byte(mtd);
N	*dev_id = chip->read_byte(mtd);
N
N	/* Try again to make sure, as some systems the bus-hold or other
N	 * interface concerns can cause random data which looks like a
N	 * possibly credible NAND flash to appear. If the two results do
N	 * not match, ignore the device completely.
N	 */
N
N	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
X	chip->cmdfunc(mtd, 0x90, 0x00, -1);
N
N	for (i = 0; i < 2; i++)
N		id_data[i] = chip->read_byte(mtd);
N
N	if (id_data[0] != *maf_id || id_data[1] != *dev_id) {
N		printk(KERN_INFO "%s: second ID read did not match "
X		sysprintf( "%s: second ID read did not match "
N		       "%02x,%02x against %02x,%02x\n", __func__,
N		       *maf_id, *dev_id, id_data[0], id_data[1]);
N		return ERR_PTR(-ENODEV);
X		return ERR_PTR(-19);
N	}
N
N	if (!type)
N		type = nand_flash_ids;
N
N	for (; type->name != NULL; type++)
X	for (; type->name != 0; type++)
N		if (*dev_id == type->id)
N			break;
N
N	chip->onfi_version = 0;
N	if (!type->name || !type->pagesize) {
N		/* Check is chip is ONFI compliant */
N		ret = nand_flash_detect_onfi(mtd, chip, &busw);
N		if (ret)
N			goto ident_done;
N	}
N
N	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
X	chip->cmdfunc(mtd, 0x90, 0x00, -1);
N
N	/* Read entire ID string */
N
N	for (i = 0; i < 8; i++)
N		id_data[i] = chip->read_byte(mtd);
N
N	if (!type->name)
N		return ERR_PTR(-ENODEV);
X		return ERR_PTR(-19);
N
N	if (!mtd->name)
N		mtd->name = type->name;
N
N	chip->chipsize = (uint64_t)type->chipsize << 20;
Nchip->init_size = 0; //CWWeng
N	if (!type->pagesize && chip->init_size) {
N		/* set the pagesize, oobsize, erasesize by the driver*/
N		busw = chip->init_size(mtd, chip, id_data);
N	} else if (!type->pagesize) {
N		int extid;
N		/* The 3rd id byte holds MLC / multichip data */
N		chip->cellinfo = id_data[2];
N		/* The 4th id byte is the important one */
N		extid = id_data[3];
N
N		/*
N		 * Field definitions are in the following datasheets:
N		 * Old style (4,5 byte ID): Samsung K9GAG08U0M (p.32)
N		 * New style   (6 byte ID): Samsung K9GBG08U0M (p.40)
N		 *
N		 * Check for wraparound + Samsung ID + nonzero 6th byte
N		 * to decide what to do.
N		 */
N		if (id_data[0] == id_data[6] && id_data[1] == id_data[7] &&
N				id_data[0] == NAND_MFR_SAMSUNG &&
X				id_data[0] == 0xec &&
N				(chip->cellinfo & NAND_CI_CELLTYPE_MSK) &&
X				(chip->cellinfo & 0x0C) &&
N				id_data[5] != 0x00) {
N			/* Calc pagesize */
N			mtd->writesize = 2048 << (extid & 0x03);
N			extid >>= 2;
N			/* Calc oobsize */
N			switch (extid & 0x03) {
N			case 1:
N				mtd->oobsize = 128;
N				break;
N			case 2:
N				mtd->oobsize = 218;
N				break;
N			case 3:
N				mtd->oobsize = 400;
N				break;
N			default:
N				mtd->oobsize = 436;
N				break;
N			}
N			extid >>= 2;
N			/* Calc blocksize */
N			mtd->erasesize = (128 * 1024) <<
N				(((extid >> 1) & 0x04) | (extid & 0x03));
N			busw = 0;
N		} else {
N			/* Calc pagesize */
N			mtd->writesize = 1024 << (extid & 0x03);
N			extid >>= 2;
N			/* Calc oobsize */
N			mtd->oobsize = (8 << (extid & 0x01)) *
N				(mtd->writesize >> 9);
N			extid >>= 2;
N			/* Calc blocksize. Blocksize is multiples of 64KiB */
N			mtd->erasesize = (64 * 1024) << (extid & 0x03);
N			extid >>= 2;
N			/* Get buswidth information */
N			busw = (extid & 0x01) ? NAND_BUSWIDTH_16 : 0;
X			busw = (extid & 0x01) ? 0x00000002 : 0;
N		}
N	} else {
N		/*
N		 * Old devices have chip data hardcoded in the device id table
N		 */
N		mtd->erasesize = type->erasesize;
N		mtd->writesize = type->pagesize;
N		mtd->oobsize = mtd->writesize / 32;
N		busw = type->options & NAND_BUSWIDTH_16;
X		busw = type->options & 0x00000002;
N
N		/*
N		 * Check for Spansion/AMD ID + repeating 5th, 6th byte since
N		 * some Spansion chips have erasesize that conflicts with size
N		 * listed in nand_ids table
N		 * Data sheet (5 byte ID): Spansion S30ML-P ORNAND (p.39)
N		 */
N		if (*maf_id == NAND_MFR_AMD && id_data[4] != 0x00 &&
X		if (*maf_id == 0x01 && id_data[4] != 0x00 &&
N				id_data[5] == 0x00 && id_data[6] == 0x00 &&
N				id_data[7] == 0x00 && mtd->writesize == 512) {
N			mtd->erasesize = 128 * 1024;
N			mtd->erasesize <<= ((id_data[3] & 0x03) << 1);
N		}
N	}
N	/* Get chip options, preserve non chip based options */
N	chip->options |= type->options;
N
N	/* Check if chip is a not a samsung device. Do not clear the
N	 * options for chips which are not having an extended id.
N	 */
N	if (*maf_id != NAND_MFR_SAMSUNG && !type->pagesize)
X	if (*maf_id != 0xec && !type->pagesize)
N		chip->options &= ~NAND_SAMSUNG_LP_OPTIONS;
X		chip->options &= ~(0x00000004 | 0x00000008 | 0x00000010);
Nident_done:
N
N	/*
N	 * Set chip as a default. Board drivers can override it, if necessary
N	 */
N	chip->options |= NAND_NO_AUTOINCR;
X	chip->options |= 0x00000001;
N
N	/* Try to identify manufacturer */
N	for (maf_idx = 0; nand_manuf_ids[maf_idx].id != 0x0; maf_idx++) {
N		if (nand_manuf_ids[maf_idx].id == *maf_id)
N			break;
N	}
N
N	/*
N	 * Check, if buswidth is correct. Hardware drivers should set
N	 * chip correct !
N	 */
N	if (busw != (chip->options & NAND_BUSWIDTH_16)) {
X	if (busw != (chip->options & 0x00000002)) {
N		printk(KERN_INFO "NAND device: Manufacturer ID:"
X		sysprintf( "NAND device: Manufacturer ID:"
N		       " 0x%02x, Chip ID: 0x%02x (%s %s)\n", *maf_id,
N		       *dev_id, nand_manuf_ids[maf_idx].name, mtd->name);
N		printk(KERN_WARNING "NAND bus width %d instead %d bit\n",
X		sysprintf( "NAND bus width %d instead %d bit\n",
N		       (chip->options & NAND_BUSWIDTH_16) ? 16 : 8,
X		       (chip->options & 0x00000002) ? 16 : 8,
N		       busw ? 16 : 8);
N		return ERR_PTR(-EINVAL);
X		return ERR_PTR(-22);
N	}
N
N	/* Calculate the address shift from the page size */
N	chip->page_shift = ffs(mtd->writesize) - 1;
X	chip->page_shift = generic_ffs(mtd->writesize) - 1;
N	/* Convert chipsize to number of pages per chip -1. */
N	chip->pagemask = (chip->chipsize >> chip->page_shift) - 1;
N
N	chip->bbt_erase_shift = chip->phys_erase_shift =
N		ffs(mtd->erasesize) - 1;
X		generic_ffs(mtd->erasesize) - 1;
N	if (chip->chipsize & 0xffffffff)
N		chip->chip_shift = ffs((unsigned)chip->chipsize) - 1;
X		chip->chip_shift = generic_ffs((unsigned)chip->chipsize) - 1;
N	else {
N		chip->chip_shift = ffs((unsigned)(chip->chipsize >> 32));
X		chip->chip_shift = generic_ffs((unsigned)(chip->chipsize >> 32));
N		chip->chip_shift += 32 - 1;
N	}
N
N	chip->badblockbits = 8;
N
N	/* Set the bad block position */
N	if (mtd->writesize > 512 || (busw & NAND_BUSWIDTH_16))
X	if (mtd->writesize > 512 || (busw & 0x00000002))
N		chip->badblockpos = NAND_LARGE_BADBLOCK_POS;
X		chip->badblockpos = 0;
N	else
N		chip->badblockpos = NAND_SMALL_BADBLOCK_POS;
X		chip->badblockpos = 5;
N
N	/*
N	 * Bad block marker is stored in the last page of each block
N	 * on Samsung and Hynix MLC devices; stored in first two pages
N	 * of each block on Micron devices with 2KiB pages and on
N	 * SLC Samsung, Hynix, Toshiba and AMD/Spansion. All others scan
N	 * only the first page.
N	 */
N	if ((chip->cellinfo & NAND_CI_CELLTYPE_MSK) &&
X	if ((chip->cellinfo & 0x0C) &&
N			(*maf_id == NAND_MFR_SAMSUNG ||
X			(*maf_id == 0xec ||
N			 *maf_id == NAND_MFR_HYNIX))
X			 *maf_id == 0xad))
N		chip->options |= NAND_BBT_SCANLASTPAGE;
X		chip->options |= 0x00008000;
N	else if ((!(chip->cellinfo & NAND_CI_CELLTYPE_MSK) &&
X	else if ((!(chip->cellinfo & 0x0C) &&
N				(*maf_id == NAND_MFR_SAMSUNG ||
X				(*maf_id == 0xec ||
N				 *maf_id == NAND_MFR_HYNIX ||
X				 *maf_id == 0xad ||
N				 *maf_id == NAND_MFR_TOSHIBA ||
X				 *maf_id == 0x98 ||
N				 *maf_id == NAND_MFR_AMD)) ||
X				 *maf_id == 0x01)) ||
N			(mtd->writesize == 2048 &&
N			 *maf_id == NAND_MFR_MICRON))
X			 *maf_id == 0x2c))
N		chip->options |= NAND_BBT_SCAN2NDPAGE;
X		chip->options |= 0x00004000;
N
N	/*
N	 * Numonyx/ST 2K pages, x8 bus use BOTH byte 1 and 6
N	 */
N	if (!(busw & NAND_BUSWIDTH_16) &&
X	if (!(busw & 0x00000002) &&
N			*maf_id == NAND_MFR_STMICRO &&
X			*maf_id == 0x20 &&
N			mtd->writesize == 2048) {
N		chip->options |= NAND_BBT_SCANBYTE1AND6;
X		chip->options |= 0x00100000;
N		chip->badblockpos = 0;
N	}
N
N	/* Check for AND chips with 4 page planes */
N	if (chip->options & NAND_4PAGE_ARRAY)
X	if (chip->options & 0x00000040)
N		chip->erase_cmd = multi_erase_cmd;
N	else
N		chip->erase_cmd = single_erase_cmd;
N
N	/* Do not replace user supplied command function ! */
N	if (mtd->writesize > 512 && chip->cmdfunc == nand_command)
N		chip->cmdfunc = nand_command_lp;
N
N	/* TODO onfi flash name */
N	name = type->name;
N#ifdef CONFIG_SYS_NAND_ONFI_DETECTION
S	if (chip->onfi_version)
S		name = chip->onfi_params.model;
N#endif
N	MTDDEBUG(MTD_DEBUG_LEVEL0, "NAND device: Manufacturer ID:"
N		 " 0x%02x, Chip ID: 0x%02x (%s %s)\n", *maf_id, *dev_id,
N		 nand_manuf_ids[maf_idx].name, name);
X	do { if (0) sysprintf("NAND device: Manufacturer ID:" " 0x%02x, Chip ID: 0x%02x (%s %s)\n", *maf_id, *dev_id, nand_manuf_ids[maf_idx]. name, name); } while(0);
N
N	return type;
N}
N
N/**
N * nand_scan_ident - [NAND Interface] Scan for the NAND device
N * @mtd:	     MTD device structure
N * @maxchips:	     Number of chips to scan for
N * @table:	     Alternative NAND ID table
N *
N * This is the first phase of the normal nand_scan() function. It
N * reads the flash ID and sets up MTD fields accordingly.
N *
N * The mtd->owner field must be set to the module of the caller.
N */
Nint nand_scan_ident(struct mtd_info *mtd, int maxchips,
N		    const struct nand_flash_dev *table)
N{
N	int i, busw, nand_maf_id, nand_dev_id;
N	struct nand_chip *chip = mtd->priv;
N	const struct nand_flash_dev *type;
N
N	/* Get buswidth to select the correct functions */
N	busw = chip->options & NAND_BUSWIDTH_16;
X	busw = chip->options & 0x00000002;
N	/* Set the default functions */
N	nand_set_defaults(chip, busw);
N
N	/* Read the flash type */
N	type = nand_get_flash_type(mtd, chip, busw,
N				&nand_maf_id, &nand_dev_id, table);
N
N	//printf("did=0x%x\n",nand_dev_id); //CWWeng
N
N	if (IS_ERR(type)) {
N#ifndef CONFIG_SYS_NAND_QUIET_TEST
N		printk(KERN_WARNING "No NAND device found!!!\n");
X		sysprintf( "No NAND device found!!!\n");
N#endif
N		chip->select_chip(mtd, -1);
N		return PTR_ERR(type);
N	}
N
N	/* Check for a chip array */
N	for (i = 1; i < maxchips; i++) {
N		chip->select_chip(mtd, i);
N		/* See comment in nand_get_flash_type for reset */
N		chip->cmdfunc(mtd, NAND_CMD_RESET, -1, -1);
X		chip->cmdfunc(mtd, 0xff, -1, -1);
N		/* Send the command for reading device ID */
N		chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
X		chip->cmdfunc(mtd, 0x90, 0x00, -1);
N		/* Read manufacturer and device IDs */
N		if (nand_maf_id != chip->read_byte(mtd) ||
N		    nand_dev_id != chip->read_byte(mtd))
N			break;
N	}
N#ifdef DEBUG
S	if (i > 1)
S		printk(KERN_INFO "%d NAND chips detected\n", i);
N#endif
N
N	/* Store the number of chips and calc total size for mtd */
N	chip->numchips = i;
N	mtd->size = i * chip->chipsize;
N
N	return 0;
N}
N
N
N/**
N * nand_scan_tail - [NAND Interface] Scan for the NAND device
N * @mtd:	    MTD device structure
N *
N * This is the second phase of the normal nand_scan() function. It
N * fills out all the uninitialized function pointers with the defaults
N * and scans for a bad block table if appropriate.
N */
Nint nand_scan_tail(struct mtd_info *mtd)
N{
N	int volatile i;
N	struct nand_chip *chip = mtd->priv;
N
N	if (!(chip->options & NAND_OWN_BUFFERS))
X	if (!(chip->options & 0x00040000))
N	{
N		//chip->buffers = memalign(ARCH_DMA_MINALIGN,
N		//			 sizeof(*chip->buffers));
N		chip->buffers = (struct nand_buffers *)0x1000000; //CWWeng
N		memset((void*)chip->buffers,0,sizeof(*chip->buffers)); //CWWeng
N	}
N
N	if (!chip->buffers)
N		return -ENOMEM;
X		return -12;
N
N	/* Set the internal oob buffer location, just after the page data */
N	chip->oob_poi = chip->buffers->databuf + mtd->writesize;
N
N    nand_oob_8.eccbytes = 3;
N    for (i=0; i<3; i++)
N        nand_oob_8.eccpos[i] = i;
N	nand_oob_8.oobfree[0].offset = 3;
N    nand_oob_8.oobfree[0].length = 2;
N	nand_oob_8.oobfree[1].offset = 6;
N    nand_oob_8.oobfree[1].length = 2;
N
N    nand_oob_16.eccbytes = 6;
N    for (i=0; i<4; i++)
N        nand_oob_16.eccpos[i] = i;
N    nand_oob_16.eccpos[4] = 6;
N    nand_oob_16.eccpos[5] = 7;
N	nand_oob_16.oobfree[0].offset = 8;
N    nand_oob_16.oobfree[0].length = 8;
N
N    nand_oob_64.eccbytes = 24;
N    for (i=0; i<24; i++)
N        nand_oob_64.eccpos[i] = 40 + i;
N	nand_oob_64.oobfree[0].offset = 2;
N    nand_oob_64.oobfree[0].length = 38;
N
N    nand_oob_128.eccbytes = 48;
N    for (i=0; i<48; i++)
N        nand_oob_128.eccpos[i] = 80 + i;
N  
N	nand_oob_128.oobfree[0].offset = 2;
N	nand_oob_128.oobfree[0].length = 78;
N
N
N	/*
N	 * If no default placement scheme is given, select an appropriate one
N	 */
N	if (!chip->ecc.layout && (chip->ecc.mode != NAND_ECC_SOFT_BCH)) {
N		switch (mtd->oobsize) {
N		case 8:
N			chip->ecc.layout = &nand_oob_8;
N			break;
N		case 16:
N			chip->ecc.layout = &nand_oob_16;
N			break;
N		case 64:
N			chip->ecc.layout = &nand_oob_64;
N			break;
N		case 128:
N			chip->ecc.layout = &nand_oob_128;
N			break;
N		default:
N			printk(KERN_WARNING "No oob scheme defined for "
X			sysprintf( "No oob scheme defined for "
N			       "oobsize %d\n", mtd->oobsize);
N		}
N	}
N
N	if (!chip->write_page)
N		chip->write_page = nand_write_page;
N
N	/*
N	 * check ECC mode, default to software if 3byte/512byte hardware ECC is
N	 * selected and we have 256 byte pagesize fallback to software ECC
N	 */
N
N	switch (chip->ecc.mode) {
N	case NAND_ECC_HW_OOB_FIRST:
N		/* Similar to NAND_ECC_HW, but a separate read_page handle */
N		if (!chip->ecc.calculate || !chip->ecc.correct ||
N		     !chip->ecc.hwctl) {
N			printk(KERN_WARNING "No ECC functions supplied; "
X			sysprintf( "No ECC functions supplied; "
N			       "Hardware ECC not possible\n");
N			BUG();
X			do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\nand_base.c", 2981); } while (0);
N		}
N		if (!chip->ecc.read_page)
N			chip->ecc.read_page = nand_read_page_hwecc_oob_first;
N
N	case NAND_ECC_HW:
N		/* Use standard hwecc read page function ? */
N		if (!chip->ecc.read_page)
N			chip->ecc.read_page = nand_read_page_hwecc;
N		if (!chip->ecc.write_page)
N			chip->ecc.write_page = nand_write_page_hwecc;
N		if (!chip->ecc.read_page_raw)
N			chip->ecc.read_page_raw = nand_read_page_raw;
N		if (!chip->ecc.write_page_raw)
N			chip->ecc.write_page_raw = nand_write_page_raw;
N		if (!chip->ecc.read_oob)
N			chip->ecc.read_oob = nand_read_oob_std;
N		if (!chip->ecc.write_oob)
N			chip->ecc.write_oob = nand_write_oob_std;
N
N	case NAND_ECC_HW_SYNDROME:
N		if ((!chip->ecc.calculate || !chip->ecc.correct ||
N		     !chip->ecc.hwctl) &&
N		    (!chip->ecc.read_page ||
N		     chip->ecc.read_page == nand_read_page_hwecc ||
N		     !chip->ecc.write_page ||
N		     chip->ecc.write_page == nand_write_page_hwecc)) {
N			printk(KERN_WARNING "No ECC functions supplied; "
X			sysprintf( "No ECC functions supplied; "
N			       "Hardware ECC not possible\n");
N			BUG();
X			do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\nand_base.c", 3010); } while (0);
N		}
N		/* Use standard syndrome read/write page function ? */
N		if (!chip->ecc.read_page)
N			chip->ecc.read_page = nand_read_page_syndrome;
N		if (!chip->ecc.write_page)
N			chip->ecc.write_page = nand_write_page_syndrome;
N		if (!chip->ecc.read_page_raw)
N			chip->ecc.read_page_raw = nand_read_page_raw_syndrome;
N		if (!chip->ecc.write_page_raw)
N			chip->ecc.write_page_raw = nand_write_page_raw_syndrome;
N		if (!chip->ecc.read_oob)
N			chip->ecc.read_oob = nand_read_oob_syndrome;
N		if (!chip->ecc.write_oob)
N			chip->ecc.write_oob = nand_write_oob_syndrome;
N
N		if (mtd->writesize >= chip->ecc.size)
N			break;
N		printk(KERN_WARNING "%d byte HW ECC not possible on "
X		sysprintf( "%d byte HW ECC not possible on "
N		       "%d byte page size, fallback to SW ECC\n",
N		       chip->ecc.size, mtd->writesize);
N		chip->ecc.mode = NAND_ECC_SOFT;
N
N	case NAND_ECC_SOFT:
N		//chip->ecc.calculate = nand_calculate_ecc; //CWWeng temp mark it
N		//chip->ecc.correct = nand_correct_data;
N		chip->ecc.read_page = nand_read_page_swecc;
N		chip->ecc.read_subpage = nand_read_subpage;
N		chip->ecc.write_page = nand_write_page_swecc;
N		chip->ecc.read_page_raw = nand_read_page_raw;
N		chip->ecc.write_page_raw = nand_write_page_raw;
N		chip->ecc.read_oob = nand_read_oob_std;
N		chip->ecc.write_oob = nand_write_oob_std;
N		if (!chip->ecc.size)
N			chip->ecc.size = 256;
N		chip->ecc.bytes = 3;
N		break;
N
N	case NAND_ECC_SOFT_BCH:
N		if (!mtd_nand_has_bch()) {
N			printk(KERN_WARNING "CONFIG_MTD_ECC_BCH not enabled\n");
X			sysprintf( "CONFIG_MTD_ECC_BCH not enabled\n");
N			return -EINVAL;
X			return -22;
N		}
N		chip->ecc.calculate = nand_bch_calculate_ecc;
N		chip->ecc.correct = nand_bch_correct_data;
N		chip->ecc.read_page = nand_read_page_swecc;
N		chip->ecc.read_subpage = nand_read_subpage;
N		chip->ecc.write_page = nand_write_page_swecc;
N		chip->ecc.read_page_raw = nand_read_page_raw;
N		chip->ecc.write_page_raw = nand_write_page_raw;
N		chip->ecc.read_oob = nand_read_oob_std;
N		chip->ecc.write_oob = nand_write_oob_std;
N		/*
N		 * Board driver should supply ecc.size and ecc.bytes values to
N		 * select how many bits are correctable; see nand_bch_init()
N		 * for details.
N		 * Otherwise, default to 4 bits for large page devices
N		 */
N		if (!chip->ecc.size && (mtd->oobsize >= 64)) {
N			chip->ecc.size = 512;
N			chip->ecc.bytes = 7;
N		}
N		chip->ecc.priv = nand_bch_init(mtd,
N					       chip->ecc.size,
N					       chip->ecc.bytes,
N					       &chip->ecc.layout);
N		if (!chip->ecc.priv)
N			printk(KERN_WARNING "BCH ECC initialization failed!\n");
X			sysprintf( "BCH ECC initialization failed!\n");
N
N		break;
N
N	case NAND_ECC_NONE:
N		printk(KERN_WARNING "NAND_ECC_NONE selected by board driver. "
X		sysprintf( "NAND_ECC_NONE selected by board driver. "
N		       "This is not recommended !!\n");
N		chip->ecc.read_page = nand_read_page_raw;
N		chip->ecc.write_page = nand_write_page_raw;
N		chip->ecc.read_oob = nand_read_oob_std;
N		chip->ecc.read_page_raw = nand_read_page_raw;
N		chip->ecc.write_page_raw = nand_write_page_raw;
N		chip->ecc.write_oob = nand_write_oob_std;
N		chip->ecc.size = mtd->writesize;
N		chip->ecc.bytes = 0;
N		break;
N
N	default:
N		printk(KERN_WARNING "Invalid NAND_ECC_MODE %d\n",
X		sysprintf( "Invalid NAND_ECC_MODE %d\n",
N		       chip->ecc.mode);
N		BUG();
X		do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\nand_base.c", 3097); } while (0);
N	}
N
N	/*
N	 * The number of bytes available for a client to place data into
N	 * the out of band area
N	 */
N	chip->ecc.layout->oobavail = 0;
N	for (i = 0; chip->ecc.layout->oobfree[i].length
N			&& i < ARRAY_SIZE(chip->ecc.layout->oobfree); i++)
X			&& i < (sizeof(chip->ecc . layout->oobfree) / sizeof((chip->ecc . layout->oobfree)[0])); i++)
N		chip->ecc.layout->oobavail +=
N			chip->ecc.layout->oobfree[i].length;
N	mtd->oobavail = chip->ecc.layout->oobavail;
N
N	/*
N	 * Set the number of read / write steps for one page depending on ECC
N	 * mode
N	 */
N	chip->ecc.steps = mtd->writesize / chip->ecc.size;
N	if (chip->ecc.steps * chip->ecc.size != mtd->writesize) {
N		printk(KERN_WARNING "Invalid ecc parameters\n");
X		sysprintf( "Invalid ecc parameters\n");
N		BUG();
X		do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\nand_base.c", 3118); } while (0);
N	}
N	chip->ecc.total = chip->ecc.steps * chip->ecc.bytes;
N
N	/*
N	 * Allow subpage writes up to ecc.steps. Not possible for MLC
N	 * FLASH.
N	 */
N	if (!(chip->options & NAND_NO_SUBPAGE_WRITE) &&
X	if (!(chip->options & 0x00000200) &&
N	    !(chip->cellinfo & NAND_CI_CELLTYPE_MSK)) {
X	    !(chip->cellinfo & 0x0C)) {
N		switch (chip->ecc.steps) {
N		case 2:
N			mtd->subpage_sft = 1;
N			break;
N		case 4:
N		case 8:
N		case 16:
N			mtd->subpage_sft = 2;
N			break;
N		}
N	}
N	chip->subpagesize = mtd->writesize >> mtd->subpage_sft;
N
N	/* Initialize state */
N	chip->state = FL_READY;
N
N	/* De-select the device */
N	chip->select_chip(mtd, -1);
N
N	/* Invalidate the pagebuffer reference */
N	chip->pagebuf = -1;
N
N	/* Large page NAND with SOFT_ECC should support subpage reads */
N	if ((chip->ecc.mode == NAND_ECC_SOFT) && (chip->page_shift > 9))
N		chip->options |= NAND_SUBPAGE_READ;
X		chip->options |= 0x00001000;
N
N	/* Fill in remaining MTD driver data */
N	mtd->type = MTD_NANDFLASH;
X	mtd->type = 4;
N	mtd->flags = (chip->options & NAND_ROM) ? MTD_CAP_ROM :
X	mtd->flags = (chip->options & 0x00000800) ? 0 :
N						MTD_CAP_NANDFLASH;
X						(0x400);
N	mtd->erase = nand_erase;
N	mtd->point = NULL;
X	mtd->point = 0;
N	mtd->unpoint = NULL;
X	mtd->unpoint = 0;
N	mtd->read = nand_read;
N	mtd->write = nand_write;
N	mtd->read_oob = nand_read_oob;
N	mtd->write_oob = nand_write_oob;
N	mtd->sync = nand_sync;
N	mtd->lock = NULL;
X	mtd->lock = 0;
N	mtd->unlock = NULL;
X	mtd->unlock = 0;
N	mtd->block_isbad = nand_block_isbad;
N	mtd->block_markbad = nand_block_markbad;
N
N	/* propagate ecc.layout to mtd_info */
N	mtd->ecclayout = chip->ecc.layout;
N
N	/* Check, if we should skip the bad block table scan */
N	if (chip->options & NAND_SKIP_BBTSCAN)
X	if (chip->options & 0x00020000)
N		chip->options |= NAND_BBT_SCANNED;
X		chip->options |= 0x40000000;
N
N	return 0;
N}
N
N/**
N * nand_scan - [NAND Interface] Scan for the NAND device
N * @mtd:	MTD device structure
N * @maxchips:	Number of chips to scan for
N *
N * This fills out all the uninitialized function pointers
N * with the defaults.
N * The flash ID is read and the mtd/chip structures are
N * filled with the appropriate values.
N * The mtd->owner field must be set to the module of the caller
N *
N */
Nint nand_scan(struct mtd_info *mtd, int maxchips)
N{
N	int ret;
N
N	ret = nand_scan_ident(mtd, maxchips, NULL);
X	ret = nand_scan_ident(mtd, maxchips, 0);
N	if (!ret)
N		ret = nand_scan_tail(mtd);
N	return ret;
N}
N
N/**
N * nand_release - [NAND Interface] Free resources held by the NAND device
N * @mtd:	MTD device structure
N*/
Nvoid nand_release(struct mtd_info *mtd)
N{
N	struct nand_chip *chip = mtd->priv;
N
N	if (chip->ecc.mode == NAND_ECC_SOFT_BCH)
N		nand_bch_free((struct nand_bch_control *)chip->ecc.priv);
N
N	/* Deregister partitions */
N	del_mtd_partitions(mtd);
N
N	/* Free bad block table memory */
W "..\..\common\src\BSP\ThirdParty\yaffs2\nand_base.c" 3218 2 function "yaffs_free" declared implicitly
N	yaffs_free(chip->bbt);
N	if (!(chip->options & NAND_OWN_BUFFERS))
X	if (!(chip->options & 0x00040000))
N		yaffs_free(chip->buffers);
N
N	/* Free bad block descriptor memory */
N	if (chip->badblock_pattern && chip->badblock_pattern->options
N			& NAND_BBT_DYNAMICSTRUCT)
X			& 0x00200000)
N		yaffs_free(chip->badblock_pattern);
N}
