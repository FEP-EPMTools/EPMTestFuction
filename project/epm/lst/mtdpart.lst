L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c"
N/*
N * Simple MTD partitioning layer
N *
N * (C) 2000 Nicolas Pitre <nico@cam.org>
N *
N * This code is GPL
N *
N * 	02-21-2002	Thomas Gleixner <gleixner@autronix.de>
N *			added support for read_oob, write_oob
N */
N
N#include "common.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\common.h" 1
N/*
N * (C) Copyright 2000-2009
N * Wolfgang Denk, DENX Software Engineering, wd@denx.de.
N *
N * See file CREDITS for list of people who contributed to this
N * project.
N *
N * This program is free software; you can redistribute it and/or
N * modify it under the terms of the GNU General Public License as
N * published by the Free Software Foundation; either version 2 of
N * the License, or (at your option) any later version.
N *
N * This program is distributed in the hope that it will be useful,
N * but WITHOUT ANY WARRANTY; without even the implied warranty of
N * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	 See the
N * GNU General Public License for more details.
N *
N * You should have received a copy of the GNU General Public License
N * along with this program; if not, write to the Free Software
N * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
N * MA 02111-1307 USA
N */
N#if 0
S
S#ifndef __COMMON_H_
S#define __COMMON_H_	1
S
S#undef	_LINUX_CONFIG_H
S#define _LINUX_CONFIG_H 1	/* avoid reading Linux autoconf.h file	*/
S
S#ifndef __ASSEMBLY__		/* put C only stuff in this section */
S
Stypedef unsigned char		uchar;
Stypedef volatile unsigned long	vu_long;
Stypedef volatile unsigned short vu_short;
Stypedef volatile unsigned char	vu_char;
S
S#include "config.h"
S//#include <asm-offsets.h>
S#include <linux/bitops.h>
S#include <linux/types.h>
S#include <linux/string.h>
S#include <linux/stringify.h>
S#include <asm/ptrace.h>
S#include <stdarg.h>
S#if defined(CONFIG_PCI) && defined(CONFIG_4xx)
S#include <pci.h>
S#endif
S#if defined(CONFIG_8xx)
S#include <asm/8xx_immap.h>
S#if defined(CONFIG_MPC852)	|| defined(CONFIG_MPC852T)	|| \
S    defined(CONFIG_MPC859)	|| defined(CONFIG_MPC859T)	|| \
S    defined(CONFIG_MPC859DSL)	|| \
S    defined(CONFIG_MPC866)	|| defined(CONFIG_MPC866T)	|| \
S    defined(CONFIG_MPC866P)
X#if defined(CONFIG_MPC852)	|| defined(CONFIG_MPC852T)	||     defined(CONFIG_MPC859)	|| defined(CONFIG_MPC859T)	||     defined(CONFIG_MPC859DSL)	||     defined(CONFIG_MPC866)	|| defined(CONFIG_MPC866T)	||     defined(CONFIG_MPC866P)
S# define CONFIG_MPC866_FAMILY 1
S#elif defined(CONFIG_MPC870) \
S   || defined(CONFIG_MPC875) \
S   || defined(CONFIG_MPC880) \
S   || defined(CONFIG_MPC885)
X#elif defined(CONFIG_MPC870)    || defined(CONFIG_MPC875)    || defined(CONFIG_MPC880)    || defined(CONFIG_MPC885)
S# define CONFIG_MPC885_FAMILY   1
S#endif
S#if   defined(CONFIG_MPC860)	   \
S   || defined(CONFIG_MPC860T)	   \
S   || defined(CONFIG_MPC866_FAMILY) \
S   || defined(CONFIG_MPC885_FAMILY)
X#if   defined(CONFIG_MPC860)	      || defined(CONFIG_MPC860T)	      || defined(CONFIG_MPC866_FAMILY)    || defined(CONFIG_MPC885_FAMILY)
S# define CONFIG_MPC86x 1
S#endif
S#elif defined(CONFIG_5xx)
S#include <asm/5xx_immap.h>
S#elif defined(CONFIG_MPC5xxx)
S#include <mpc5xxx.h>
S#elif defined(CONFIG_MPC512X)
S#include <asm/immap_512x.h>
S#elif defined(CONFIG_MPC8220)
S#include <asm/immap_8220.h>
S#elif defined(CONFIG_8260)
S#if   defined(CONFIG_MPC8247) \
S   || defined(CONFIG_MPC8248) \
S   || defined(CONFIG_MPC8271) \
S   || defined(CONFIG_MPC8272)
X#if   defined(CONFIG_MPC8247)    || defined(CONFIG_MPC8248)    || defined(CONFIG_MPC8271)    || defined(CONFIG_MPC8272)
S#define CONFIG_MPC8272_FAMILY	1
S#endif
S#if defined(CONFIG_MPC8272_FAMILY)
S#define CONFIG_MPC8260	1
S#endif
S#include <asm/immap_8260.h>
S#endif
S#ifdef CONFIG_MPC86xx
S#include <mpc86xx.h>
S#include <asm/immap_86xx.h>
S#endif
S#ifdef CONFIG_MPC85xx
S#include <mpc85xx.h>
S#include <asm/immap_85xx.h>
S#endif
S#ifdef CONFIG_MPC83xx
S#include <mpc83xx.h>
S#include <asm/immap_83xx.h>
S#endif
S#ifdef	CONFIG_4xx
S#include <asm/ppc4xx.h>
S#endif
S#ifdef CONFIG_HYMOD
S#include <board/hymod/hymod.h>
S#endif
S#ifdef CONFIG_ARM
S#define asmlinkage	/* nothing */
S#endif
S#ifdef CONFIG_BLACKFIN
S#include <asm/blackfin.h>
S#endif
S#ifdef CONFIG_SOC_DA8XX
S#include <asm/arch/hardware.h>
S#endif
S
S#include "part.h"
S#include "flash.h"
S#include "image.h"
S
S#ifdef DEBUG
S#define _DEBUG	1
S#else
S#define _DEBUG	0
S#endif
S
S/*
S * Output a debug text when condition "cond" is met. The "cond" should be
S * computed by a preprocessor in the best case, allowing for the best
S * optimization.
S */
S#define debug_cond(cond, fmt, args...)		\
S	do {					\
S		if (cond)			\
S			sysprintf(fmt, ##args);	\
S	} while (0)
X#define debug_cond(cond, fmt, args...)			do {							if (cond)						sysprintf(fmt, ##args);		} while (0)
S
S#define debug(fmt, args...)			\
S	debug_cond(_DEBUG, fmt, ##args)
X#define debug(fmt, args...)				debug_cond(_DEBUG, fmt, ##args)
S
S/*
S * An assertion is run-time check done in debug mode only. If DEBUG is not
S * defined then it is skipped. If DEBUG is defined and the assertion fails,
S * then it calls panic*( which may or may not reset/halt U-Boot (see
S * CONFIG_PANIC_HANG), It is hoped that all failing assertions are found
S * before release, and after release it is hoped that they don't matter. But
S * in any case these failing assertions cannot be fixed with a reset (which
S * may just do the same assertion again).
S */
Svoid __assert_fail(const char *assertion, const char *file, unsigned line,
S		   const char *function);
S#define assert(x) \
S	({ if (!(x) && _DEBUG) \
S		__assert_fail(#x, __FILE__, __LINE__, __func__); })
X#define assert(x) 	({ if (!(x) && _DEBUG) 		__assert_fail(#x, __FILE__, __LINE__, __func__); })
S
S#define error(fmt, args...) do {					\
S		sysprintf("ERROR: " fmt "\nat %s:%d/%s()\n",		\
S			##args, __FILE__, __LINE__, __func__);		\
S} while (0)
X#define error(fmt, args...) do {							sysprintf("ERROR: " fmt "\nat %s:%d/%s()\n",					##args, __FILE__, __LINE__, __func__);		} while (0)
S
S#ifndef BUG
S#define BUG() do { \
S	sysprintf("BUG: failure at %s:%d/%s()!\n", __FILE__, __LINE__, __FUNCTION__); \
S	panic("BUG!"); \
S} while (0)
X#define BUG() do { 	sysprintf("BUG: failure at %s:%d/%s()!\n", __FILE__, __LINE__, __FUNCTION__); 	panic("BUG!"); } while (0)
S#define BUG_ON(condition) do { if (unlikely((condition)!=0)) BUG(); } while(0)
S#endif /* BUG */
S
S/* Force a compilation error if condition is true */
S#define BUILD_BUG_ON(condition) ((void)sizeof(char[1 - 2*!!(condition)]))
S
Stypedef void (interrupt_handler_t)(void *);
S
S#include <asm/u-boot.h> /* boot information for Linux kernel */
S#include <asm/global_data.h>	/* global data used for startup functions */
S
S/*
S * enable common handling for all TQM8xxL/M boards:
S * - CONFIG_TQM8xxM will be defined for all TQM8xxM boards
S * - CONFIG_TQM8xxL will be defined for all TQM8xxL _and_ TQM8xxM boards
S *                  and for the TQM885D board
S */
S#if defined(CONFIG_TQM823M) || defined(CONFIG_TQM850M) || \
S    defined(CONFIG_TQM855M) || defined(CONFIG_TQM860M) || \
S    defined(CONFIG_TQM862M) || defined(CONFIG_TQM866M)
X#if defined(CONFIG_TQM823M) || defined(CONFIG_TQM850M) ||     defined(CONFIG_TQM855M) || defined(CONFIG_TQM860M) ||     defined(CONFIG_TQM862M) || defined(CONFIG_TQM866M)
S# ifndef CONFIG_TQM8xxM
S#  define CONFIG_TQM8xxM
S# endif
S#endif
S#if defined(CONFIG_TQM823L) || defined(CONFIG_TQM850L) || \
S    defined(CONFIG_TQM855L) || defined(CONFIG_TQM860L) || \
S    defined(CONFIG_TQM862L) || defined(CONFIG_TQM8xxM) || \
S    defined(CONFIG_TQM885D)
X#if defined(CONFIG_TQM823L) || defined(CONFIG_TQM850L) ||     defined(CONFIG_TQM855L) || defined(CONFIG_TQM860L) ||     defined(CONFIG_TQM862L) || defined(CONFIG_TQM8xxM) ||     defined(CONFIG_TQM885D)
S# ifndef CONFIG_TQM8xxL
S#  define CONFIG_TQM8xxL
S# endif
S#endif
S
S/*
S * General Purpose Utilities
S */
S#define min(X, Y)				\
S	({ typeof (X) __x = (X);		\
S		typeof (Y) __y = (Y);		\
S		(__x < __y) ? __x : __y; })
X#define min(X, Y)					({ typeof (X) __x = (X);				typeof (Y) __y = (Y);				(__x < __y) ? __x : __y; })
S
S#define max(X, Y)				\
S	({ typeof (X) __x = (X);		\
S		typeof (Y) __y = (Y);		\
S		(__x > __y) ? __x : __y; })
X#define max(X, Y)					({ typeof (X) __x = (X);				typeof (Y) __y = (Y);				(__x > __y) ? __x : __y; })
S
S#define MIN(x, y)  min(x, y)
S#define MAX(x, y)  max(x, y)
S
S/*
S * Return the absolute value of a number.
S *
S * This handles unsigned and signed longs, ints, shorts and chars.  For all
S * input types abs() returns a signed long.
S *
S * For 64-bit types, use abs64()
S */
S#define abs(x) ({						\
S		long ret;					\
S		if (sizeof(x) == sizeof(long)) {		\
S			long __x = (x);				\
S			ret = (__x < 0) ? -__x : __x;		\
S		} else {					\
S			int __x = (x);				\
S			ret = (__x < 0) ? -__x : __x;		\
S		}						\
S		ret;						\
S	})
X#define abs(x) ({								long ret;							if (sizeof(x) == sizeof(long)) {					long __x = (x);							ret = (__x < 0) ? -__x : __x;				} else {								int __x = (x);							ret = (__x < 0) ? -__x : __x;				}								ret;							})
S
S#define abs64(x) ({				\
S		s64 __x = (x);			\
S		(__x < 0) ? -__x : __x;		\
S	})
X#define abs64(x) ({						s64 __x = (x);					(__x < 0) ? -__x : __x;			})
S
S#if defined(CONFIG_ENV_IS_EMBEDDED)
S#define TOTAL_MALLOC_LEN	CONFIG_SYS_MALLOC_LEN
S#elif ( ((CONFIG_ENV_ADDR+CONFIG_ENV_SIZE) < CONFIG_SYS_MONITOR_BASE) || \
S	(CONFIG_ENV_ADDR >= (CONFIG_SYS_MONITOR_BASE + CONFIG_SYS_MONITOR_LEN)) ) || \
S      defined(CONFIG_ENV_IS_IN_NVRAM)
X#elif ( ((CONFIG_ENV_ADDR+CONFIG_ENV_SIZE) < CONFIG_SYS_MONITOR_BASE) || 	(CONFIG_ENV_ADDR >= (CONFIG_SYS_MONITOR_BASE + CONFIG_SYS_MONITOR_LEN)) ) ||       defined(CONFIG_ENV_IS_IN_NVRAM)
S#define	TOTAL_MALLOC_LEN	(CONFIG_SYS_MALLOC_LEN + CONFIG_ENV_SIZE)
S#else
S#define	TOTAL_MALLOC_LEN	CONFIG_SYS_MALLOC_LEN
S#endif
S
S/**
S * container_of - cast a member of a structure out to the containing structure
S * @ptr:	the pointer to the member.
S * @type:	the type of the container struct this is embedded in.
S * @member:	the name of the member within the struct.
S *
S */
S#define container_of(ptr, type, member) ({			\
S	const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
S	(type *)( (char *)__mptr - offsetof(type,member) );})
X#define container_of(ptr, type, member) ({				const typeof( ((type *)0)->member ) *__mptr = (ptr);		(type *)( (char *)__mptr - offsetof(type,member) );})
S
S/*
S * Function Prototypes
S */
S
Svoid	hang		(void) __attribute__ ((noreturn));
S
Sint	timer_init(void);
Sint	cpu_init(void);
S
S/* */
S// phys_size_t initdram (int);
Sint	display_options (void);
Svoid	print_size(unsigned long long, const char *);
Sint print_buffer(ulong addr, const void *data, uint width, uint count,
S		 uint linelen);
S
S/* common/main.c */
Svoid	main_loop	(void);
Sint run_command(const char *cmd, int flag);
S
S/**
S * Run a list of commands separated by ; or even \0
S *
S * Note that if 'len' is not -1, then the command does not need to be nul
S * terminated, Memory will be allocated for the command in that case.
S *
S * @param cmd	List of commands to run, each separated bu semicolon
S * @param len	Length of commands excluding terminator if known (-1 if not)
S * @param flag	Execution flags (CMD_FLAG_...)
S * @return 0 on success, or != 0 on error.
S */
Sint run_command_list(const char *cmd, int len, int flag);
Sint	readline	(const char *const prompt);
Sint	readline_into_buffer(const char *const prompt, char *buffer,
S			int timeout);
Sint	parse_line (char *, char *[]);
Svoid	init_cmd_timeout(void);
Svoid	reset_cmd_timeout(void);
S#ifdef CONFIG_MENU
Sint	abortboot(int bootdelay);
S#endif
Sextern char console_buffer[];
S
S/* arch/$(ARCH)/lib/board.c */
S// void	board_init_f(ulong);
S// void	board_init_r  (gd_t *, ulong) __attribute__ ((noreturn));
S// int	checkboard    (void);
S// int	checkflash    (void);
S// int	checkdram     (void);
S// int	last_stage_init(void);
S// extern ulong monitor_flash_len;
S// int mac_read_from_eeprom(void);
S// extern u8 _binary_dt_dtb_start[];	/* embedded device tree blob */
S// int set_cpu_clk_info(void);
S// int print_cpuinfo(void);
S// int update_flash_size(int flash_size);
S
S/**
S * Show the DRAM size in a board-specific way
S *
S * This is used by boards to display DRAM information in their own way.
S *
S * @param size	Size of DRAM (which should be displayed along with other info)
S */
Svoid board_show_dram(ulong size);
S
S/* common/flash.c */
Svoid flash_perror (int);
S
S/* common/cmd_source.c */
Sint	source (ulong addr, const char *fit_uname);
S
Sextern ulong load_addr;		/* Default Load Address */
Sextern ulong save_addr;		/* Default Save Address */
Sextern ulong save_size;		/* Default Save Size */
S
S/* common/cmd_doc.c */
S// void	doc_probe(unsigned long physadr);
S
S/* common/cmd_net.c */
S// int do_tftpb(cmd_tbl_t *cmdtp, int flag, int argc, char * const argv[]);
S
S/* common/cmd_fat.c */
S// int do_fat_fsload(cmd_tbl_t *, int, int, char * const []);
S
S/* common/cmd_ext2.c */
S// int do_ext2load(cmd_tbl_t *, int, int, char * const []);
S
S/* common/cmd_nvedit.c */
S// int	env_init     (void);
S// void	env_relocate (void);
S// int	envmatch     (uchar *, int);
S// char	*getenv	     (const char *);
S// int	getenv_f     (const char *name, char *buf, unsigned len);
S// ulong getenv_ulong(const char *name, int base, ulong default_val);
S/*
S * Read an environment variable as a boolean
S * Return -1 if variable does not exist (default to true)
S */
Sint getenv_yesno(const char *var);
Sint	saveenv	     (void);
Sint	setenv	     (const char *, const char *);
Sint setenv_ulong(const char *varname, ulong value);
Sint setenv_hex(const char *varname, ulong value);
S/**
S * setenv_addr - Set an environment variable to an address in hex
S *
S * @varname:	Environmet variable to set
S * @addr:	Value to set it to
S * @return 0 if ok, 1 on error
S */
Sstatic __inline int setenv_addr(const char *varname, const void *addr)
S{
S	return setenv_hex(varname, (ulong)addr);
S}
S
S#ifdef CONFIG_ARM
S# include <asm/mach-types.h>
S# include <asm/setup.h>
S# include <asm/u-boot-arm.h>	/* ARM version to be fixed! */
S#endif /* CONFIG_ARM */
S#ifdef CONFIG_X86		/* x86 version to be fixed! */
S# include <asm/u-boot-x86.h>
S#endif /* CONFIG_X86 */
S#ifdef CONFIG_SANDBOX
S# include <asm/u-boot-sandbox.h>	/* TODO(sjg) what needs to be fixed? */
S#endif
S#ifdef CONFIG_NDS32
S# include <asm/mach-types.h>
S# include <asm/u-boot-nds32.h>
S#endif /* CONFIG_NDS32 */
S#ifdef CONFIG_MIPS
S# include <asm/u-boot-mips.h>
S#endif /* CONFIG_MIPS */
S
S#ifdef CONFIG_AUTO_COMPLETE
Sint env_complete(char *var, int maxv, char *cmdv[], int maxsz, char *buf);
S#endif
Sint get_env_id (void);
S
Svoid	pci_init      (void);
Svoid	pci_init_board(void);
Svoid	pciinfo	      (int, int);
S
S#if defined(CONFIG_PCI) && defined(CONFIG_4xx)
S    int	   pci_pre_init	       (struct pci_controller *);
S    int	   is_pci_host	       (struct pci_controller *);
S#endif
S
S#if defined(CONFIG_PCI) && (defined(CONFIG_440) || defined(CONFIG_405EX))
S#   if defined(CONFIG_SYS_PCI_TARGET_INIT)
S	void	pci_target_init	     (struct pci_controller *);
S#   endif
S#   if defined(CONFIG_SYS_PCI_MASTER_INIT)
S	void	pci_master_init	     (struct pci_controller *);
S#   endif
S#if defined(CONFIG_440SPE) || \
S    defined(CONFIG_460EX) || defined(CONFIG_460GT) || \
S    defined(CONFIG_405EX)
X#if defined(CONFIG_440SPE) ||     defined(CONFIG_460EX) || defined(CONFIG_460GT) ||     defined(CONFIG_405EX)
S   void pcie_setup_hoses(int busno);
S#endif
S#endif
S
Sint	misc_init_f   (void);
Sint	misc_init_r   (void);
S
S/* common/exports.c */
Svoid	jumptable_init(void);
S
S/* common/kallsysm.c */
Sconst char *symbol_lookup(unsigned long addr, unsigned long *caddr);
S
S/* api/api.c */
Svoid	api_init (void);
S
S/* common/memsize.c */
Slong	get_ram_size  (long *, long);
S
S/* $(BOARD)/$(BOARD).c */
Svoid	reset_phy     (void);
Svoid	fdc_hw_init   (void);
S
S/* $(BOARD)/eeprom.c */
Svoid eeprom_init  (void);
S#ifndef CONFIG_SPI
Sint  eeprom_probe (unsigned dev_addr, unsigned offset);
S#endif
Sint  eeprom_read  (unsigned dev_addr, unsigned offset, uchar *buffer, unsigned cnt);
Sint  eeprom_write (unsigned dev_addr, unsigned offset, uchar *buffer, unsigned cnt);
S#ifdef CONFIG_LWMON
Sextern uchar pic_read  (uchar reg);
Sextern void  pic_write (uchar reg, uchar val);
S#endif
S
S/*
S * Set this up regardless of board
S * type, to prevent errors.
S */
S#if defined(CONFIG_SPI) || !defined(CONFIG_SYS_I2C_EEPROM_ADDR)
S# define CONFIG_SYS_DEF_EEPROM_ADDR 0
S#else
S#if !defined(CONFIG_ENV_EEPROM_IS_ON_I2C)
S# define CONFIG_SYS_DEF_EEPROM_ADDR CONFIG_SYS_I2C_EEPROM_ADDR
S#endif
S#endif /* CONFIG_SPI || !defined(CONFIG_SYS_I2C_EEPROM_ADDR) */
S
S#if defined(CONFIG_SPI)
Sextern void spi_init_f (void);
Sextern void spi_init_r (void);
Sextern ssize_t spi_read	 (uchar *, int, uchar *, int);
Sextern ssize_t spi_write (uchar *, int, uchar *, int);
S#endif
S
S#ifdef CONFIG_RPXCLASSIC
Svoid rpxclassic_init (void);
S#endif
S
Svoid rpxlite_init (void);
S
S#ifdef CONFIG_MBX
S/* $(BOARD)/mbx8xx.c */
Svoid	mbx_init (void);
Svoid	board_serial_init (void);
Svoid	board_ether_init (void);
S#endif
S
S#ifdef CONFIG_HERMES
S/* $(BOARD)/hermes.c */
Svoid hermes_start_lxt980 (int speed);
S#endif
S
S#ifdef CONFIG_EVB64260
Svoid  evb64260_init(void);
Svoid  debug_led(int, int);
Svoid  display_mem_map(void);
Svoid  perform_soft_reset(void);
S#endif
S
S/* $(BOARD)/$(BOARD).c */
Sint board_early_init_f (void);
Sint board_late_init (void);
Sint board_postclk_init (void); /* after clocks/timebase, before env/serial */
Sint board_early_init_r (void);
Svoid board_poweroff (void);
S
S#if defined(CONFIG_SYS_DRAM_TEST)
Sint testdram(void);
S#endif /* CONFIG_SYS_DRAM_TEST */
S
S/* $(CPU)/start.S */
S#if defined(CONFIG_5xx) || \
S    defined(CONFIG_8xx)
X#if defined(CONFIG_5xx) ||     defined(CONFIG_8xx)
Suint	get_immr      (uint);
S#endif
Suint	get_pir	      (void);
S#if defined(CONFIG_MPC5xxx)
Suint	get_svr       (void);
S#endif
Suint	get_pvr	      (void);
Suint	get_svr	      (void);
Suint	rd_ic_cst     (void);
Svoid	wr_ic_cst     (uint);
Svoid	wr_ic_adr     (uint);
Suint	rd_dc_cst     (void);
Svoid	wr_dc_cst     (uint);
Svoid	wr_dc_adr     (uint);
Sint	icache_status (void);
Svoid	icache_enable (void);
Svoid	icache_disable(void);
Sint	dcache_status (void);
Svoid	dcache_enable (void);
Svoid	dcache_disable(void);
Svoid	mmu_disable(void);
Svoid	relocate_code (ulong, gd_t *, ulong) __attribute__ ((noreturn));
Sulong	get_endaddr   (void);
Svoid	trap_init     (ulong);
S#if defined (CONFIG_4xx)	|| \
S    defined (CONFIG_MPC5xxx)	|| \
S    defined (CONFIG_74xx_7xx)	|| \
S    defined (CONFIG_74x)	|| \
S    defined (CONFIG_75x)	|| \
S    defined (CONFIG_74xx)	|| \
S    defined (CONFIG_MPC8220)	|| \
S    defined (CONFIG_MPC85xx)	|| \
S    defined (CONFIG_MPC86xx)	|| \
S    defined (CONFIG_MPC83xx)
X#if defined (CONFIG_4xx)	||     defined (CONFIG_MPC5xxx)	||     defined (CONFIG_74xx_7xx)	||     defined (CONFIG_74x)	||     defined (CONFIG_75x)	||     defined (CONFIG_74xx)	||     defined (CONFIG_MPC8220)	||     defined (CONFIG_MPC85xx)	||     defined (CONFIG_MPC86xx)	||     defined (CONFIG_MPC83xx)
Sunsigned char	in8(unsigned int);
Svoid		out8(unsigned int, unsigned char);
Sunsigned short	in16(unsigned int);
Sunsigned short	in16r(unsigned int);
Svoid		out16(unsigned int, unsigned short value);
Svoid		out16r(unsigned int, unsigned short value);
Sunsigned long	in32(unsigned int);
Sunsigned long	in32r(unsigned int);
Svoid		out32(unsigned int, unsigned long value);
Svoid		out32r(unsigned int, unsigned long value);
Svoid		ppcDcbf(unsigned long value);
Svoid		ppcDcbi(unsigned long value);
Svoid		ppcSync(void);
Svoid		ppcDcbz(unsigned long value);
S#endif
S#if defined (CONFIG_MICROBLAZE)
Sunsigned short	in16(unsigned int);
Svoid		out16(unsigned int, unsigned short value);
S#endif
S
S#if defined (CONFIG_MPC83xx)
Svoid		ppcDWload(unsigned int *addr, unsigned int *ret);
Svoid		ppcDWstore(unsigned int *addr, unsigned int *value);
Svoid disable_addr_trans(void);
Svoid enable_addr_trans(void);
S#if defined(CONFIG_DDR_ECC) && !defined(CONFIG_ECC_INIT_VIA_DDRCONTROLLER)
Svoid ddr_enable_ecc(unsigned int dram_size);
S#endif
S#endif
S
S/* $(CPU)/cpu.c */
Sstatic __inline int cpumask_next(int cpu, unsigned int mask)
S{
S	for (cpu++; !((1 << cpu) & mask); cpu++)
S		;
S
S	return cpu;
S}
S
S#define for_each_cpu(iter, cpu, num_cpus, mask) \
S	for (iter = 0, cpu = cpumask_next(-1, mask); \
S		iter < num_cpus; \
S		iter++, cpu = cpumask_next(cpu, mask)) \
S
X#define for_each_cpu(iter, cpu, num_cpus, mask) 	for (iter = 0, cpu = cpumask_next(-1, mask); 		iter < num_cpus; 		iter++, cpu = cpumask_next(cpu, mask)) 
Sint	cpu_numcores  (void);
Su32	cpu_mask      (void);
Sint	is_core_valid (unsigned int);
Sint	probecpu      (void);
Sint	checkcpu      (void);
Sint	checkicache   (void);
Sint	checkdcache   (void);
Svoid	upmconfig     (unsigned int, unsigned int *, unsigned int);
Sulong	get_tbclk     (void);
Svoid	reset_cpu     (ulong addr);
S#if defined (CONFIG_OF_LIBFDT) && defined (CONFIG_OF_BOARD_SETUP)
Svoid ft_cpu_setup(void *blob, bd_t *bd);
S#ifdef CONFIG_PCI
Svoid ft_pci_setup(void *blob, bd_t *bd);
S#endif
S#endif
S
S
S/* $(CPU)/serial.c */
Sint	serial_init   (void);
Svoid	serial_setbrg (void);
Svoid	serial_putc   (const char);
Svoid	serial_putc_raw(const char);
Svoid	serial_puts   (const char *);
Sint	serial_getc   (void);
Sint	serial_tstc   (void);
S
Svoid	_serial_setbrg (const int);
Svoid	_serial_putc   (const char, const int);
Svoid	_serial_putc_raw(const char, const int);
Svoid	_serial_puts   (const char *, const int);
Sint	_serial_getc   (const int);
Sint	_serial_tstc   (const int);
S
S/* $(CPU)/speed.c */
Sint	get_clocks (void);
Sint	get_clocks_866 (void);
Sint	sdram_adjust_866 (void);
Sint	adjust_sdram_tbs_8xx (void);
S#if defined(CONFIG_8260)
Sint	prt_8260_clks (void);
S#elif defined(CONFIG_MPC5xxx)
Sint	prt_mpc5xxx_clks (void);
S#endif
S#if defined(CONFIG_MPC512X)
Sint	prt_mpc512xxx_clks (void);
S#endif
S#if defined(CONFIG_MPC8220)
Sint	prt_mpc8220_clks (void);
S#endif
S#ifdef CONFIG_4xx
Sulong	get_OPB_freq (void);
Sulong	get_PCI_freq (void);
S#endif
S#if defined(CONFIG_S3C24X0) || \
S    defined(CONFIG_LH7A40X) || \
S    defined(CONFIG_S3C6400) || \
S    defined(CONFIG_EP93XX)
X#if defined(CONFIG_S3C24X0) ||     defined(CONFIG_LH7A40X) ||     defined(CONFIG_S3C6400) ||     defined(CONFIG_EP93XX)
Sulong	get_FCLK (void);
Sulong	get_HCLK (void);
Sulong	get_PCLK (void);
Sulong	get_UCLK (void);
S#endif
S#if defined(CONFIG_LH7A40X)
Sulong	get_PLLCLK (void);
S#endif
S#if defined CONFIG_INCA_IP
Suint	incaip_get_cpuclk (void);
S#endif
S#if defined(CONFIG_IMX)
Sulong get_systemPLLCLK(void);
Sulong get_FCLK(void);
Sulong get_HCLK(void);
Sulong get_BCLK(void);
Sulong get_PERCLK1(void);
Sulong get_PERCLK2(void);
Sulong get_PERCLK3(void);
S#endif
Sulong	get_bus_freq  (ulong);
Sint get_serial_clock(void);
S
S#if defined(CONFIG_MPC83xx) || defined(CONFIG_MPC85xx)
Sulong get_ddr_freq(ulong);
S#endif
S#if defined(CONFIG_MPC85xx)
Stypedef MPC85xx_SYS_INFO sys_info_t;
Svoid	get_sys_info  ( sys_info_t * );
S#endif
S#if defined(CONFIG_MPC86xx)
Stypedef MPC86xx_SYS_INFO sys_info_t;
Svoid   get_sys_info  ( sys_info_t * );
Sstatic __inline ulong get_ddr_freq(ulong dummy)
S{
S	return get_bus_freq(dummy);
S}
S#endif
S
S#if defined(CONFIG_4xx)
S#  if defined(CONFIG_440)
S#	if defined(CONFIG_440SPE)
S	 unsigned long determine_sysper(void);
S	 unsigned long determine_pci_clock_per(void);
S#	endif
S#  endif
Stypedef PPC4xx_SYS_INFO sys_info_t;
Sint	ppc440spe_revB(void);
Svoid	get_sys_info  ( sys_info_t * );
S#endif
S
S/* $(CPU)/cpu_init.c */
S#if defined(CONFIG_8xx) || defined(CONFIG_8260)
Svoid	cpu_init_f    (volatile immap_t *immr);
S#endif
S#if defined(CONFIG_4xx) || defined(CONFIG_MPC85xx) || defined(CONFIG_MCF52x2) ||defined(CONFIG_MPC86xx)
Svoid	cpu_init_f    (void);
S#endif
S
Sint	cpu_init_r    (void);
S#if defined(CONFIG_8260)
Sint	prt_8260_rsr  (void);
S#elif defined(CONFIG_MPC83xx)
Sint	prt_83xx_rsr  (void);
S#endif
S
S/* $(CPU)/interrupts.c */
Sint	interrupt_init	   (void);
Svoid	timer_interrupt	   (struct pt_regs *);
Svoid	external_interrupt (struct pt_regs *);
Svoid	irq_install_handler(int, interrupt_handler_t *, void *);
Svoid	irq_free_handler   (int);
Svoid	reset_timer	   (void);
Sulong	get_timer	   (ulong base);
Svoid	enable_interrupts  (void);
Sint	disable_interrupts (void);
S
S/* $(CPU)/.../commproc.c */
Sint	dpram_init (void);
Suint	dpram_base(void);
Suint	dpram_base_align(uint align);
Suint	dpram_alloc(uint size);
Suint	dpram_alloc_align(uint size,uint align);
Svoid	bootcount_store (ulong);
Sulong	bootcount_load (void);
S#define BOOTCOUNT_MAGIC		0xB001C041
S
S/* $(CPU)/.../<eth> */
Svoid mii_init (void);
S
S/* $(CPU)/.../lcd.c */
Sulong	lcd_setmem (ulong);
S
S/* $(CPU)/.../video.c */
Sulong	video_setmem (ulong);
S
S/* arch/$(ARCH)/lib/cache.c */
Svoid	enable_caches(void);
Svoid	flush_cache   (unsigned long, unsigned long);
Svoid	flush_dcache_all(void);
Svoid	flush_dcache_range(unsigned long start, unsigned long stop);
Svoid	invalidate_dcache_range(unsigned long start, unsigned long stop);
Svoid	invalidate_dcache_all(void);
Svoid	invalidate_icache_all(void);
S
S/* arch/$(ARCH)/lib/ticks.S */
Sunsigned long long get_ticks(void);
Svoid	wait_ticks    (unsigned long);
S
S/* arch/$(ARCH)/lib/time.c */
Svoid	__udelay      (unsigned long);
Sulong	usec2ticks    (unsigned long usec);
Sulong	ticks2usec    (unsigned long ticks);
Sint	init_timebase (void);
S
S/* lib/gunzip.c */
Sint gunzip(void *, int, unsigned char *, unsigned long *);
Sint zunzip(void *dst, int dstlen, unsigned char *src, unsigned long *lenp,
S						int stoponerr, int offset);
S
S/* lib/qsort.c */
Svoid qsort(void *base, size_t nmemb, size_t size,
S	   int(*compar)(const void *, const void *));
Sint strcmp_compar(const void *, const void *);
S
S/* lib/time.c */
Svoid	udelay        (unsigned long);
Svoid mdelay(unsigned long);
S
S/* lib/uuid.c */
Svoid uuid_str_to_bin(const char *uuid, unsigned char *out);
Sint uuid_str_valid(const char *uuid);
S
S/* lib/vsprintf.c */
S#include "vsprintf.h"
S
S/* lib/strmhz.c */
Schar *	strmhz(char *buf, unsigned long hz);
S
S/* lib/crc32.c */
S#include "crc.h"
S
S/* lib/rand.c */
S#if defined(CONFIG_RANDOM_MACADDR) || \
S	defined(CONFIG_BOOTP_RANDOM_DELAY) || \
S	defined(CONFIG_CMD_LINK_LOCAL)
X#if defined(CONFIG_RANDOM_MACADDR) || 	defined(CONFIG_BOOTP_RANDOM_DELAY) || 	defined(CONFIG_CMD_LINK_LOCAL)
S#define RAND_MAX -1U
Svoid srand(unsigned int seed);
Sunsigned int rand(void);
Sunsigned int rand_r(unsigned int *seedp);
S#endif
S
S/* common/console.c */
Sint	console_init_f(void);	/* Before relocation; uses the serial  stuff	*/
Sint	console_init_r(void);	/* After  relocation; uses the console stuff	*/
Sint	console_assign(int file, const char *devname);	/* Assign the console	*/
Sint	ctrlc (void);
Sint	had_ctrlc (void);	/* have we had a Control-C since last clear? */
Svoid	clear_ctrlc (void);	/* clear the Control-C condition */
Sint	disable_ctrlc (int);	/* 1 to disable, 0 to enable Control-C detect */
S
S/*
S * STDIO based functions (can always be used)
S */
S/* serial stuff */
Sint	serial_printf (const char *fmt, ...)
S		__attribute__ ((format (__printf__, 1, 2)));
S/* stdin */
S// int	getc(void);
S// int	tstc(void);
S
S/* stdout */
S// void	putc(const char c);
S// void	puts(const char *s);
S// int	printf(const char *fmt, ...)
S// 		__attribute__ ((format (__printf__, 1, 2)));
Sint	vprintf(const char *fmt, va_list args);
S
S/* stderr */
S#define eputc(c)		fputc(stderr, c)
S#define eputs(s)		fputs(stderr, s)
S#define eprintf(fmt,args...)	fprintf(stderr,fmt ,##args)
S
S/*
S * FILE based functions (can only be used AFTER relocation!)
S */
S#define stdin		0
S#define stdout		1
S#define stderr		2
S#define MAX_FILES	3
S
Sint	fprintf(int file, const char *fmt, ...)
S		__attribute__ ((format (__printf__, 2, 3)));
Svoid	fputs(int file, const char *s);
Svoid	fputc(int file, const char c);
Sint	ftstc(int file);
Sint	fgetc(int file);
S
S/* lib/gzip.c */
Sint gzip(void *dst, unsigned long *lenp,
S		unsigned char *src, unsigned long srclen);
Sint zzip(void *dst, unsigned long *lenp, unsigned char *src,
S		unsigned long srclen, int stoponerr,
S		int (*func)(unsigned long, unsigned long));
S
S/* lib/net_utils.c */
S// #include <net.h>
S// static __inline IPaddr_t getenv_IPaddr(char *var)
S// {
S// 	return string_to_ip(getenv(var));
S// }
S
S/*
S * CONSOLE multiplexing.
S */
S#ifdef CONFIG_CONSOLE_MUX
S#include <iomux.h>
S#endif
S
Sint	pcmcia_init (void);
S
S#ifdef CONFIG_STATUS_LED
S# include <status_led.h>
S#endif
S
S#include "bootstage.h"
S
S#ifdef CONFIG_SHOW_ACTIVITY
Svoid show_activity(int arg);
S#endif
S
S/* Multicore arch functions */
S#ifdef CONFIG_MP
Sint cpu_status(int nr);
Sint cpu_reset(int nr);
Sint cpu_disable(int nr);
Sint cpu_release(int nr, int argc, char * const argv[]);
S#endif
S
S/* Define a null map_sysmem() if the architecture doesn't use it */
S# ifndef CONFIG_ARCH_MAP_SYSMEM
Sstatic __inline void *map_sysmem(phys_addr_t paddr, unsigned long len)
S{
S	return (void *)(uintptr_t)paddr;
S}
S
Sstatic __inline void unmap_sysmem(const void *vaddr)
S{
S}
S# endif
S
S#endif /* __ASSEMBLY__ */
S
S#ifdef CONFIG_PPC
S/*
S * Has to be included outside of the #ifndef __ASSEMBLY__ section.
S * Otherwise might lead to compilation errors in assembler files.
S */
S#include <asm/cache.h>
S#endif
S
S/* Put only stuff here that the assembler can digest */
S
S#ifdef CONFIG_POST
S#define CONFIG_HAS_POST
S#ifndef CONFIG_POST_ALT_LIST
S#define CONFIG_POST_STD_LIST
S#endif
S#endif
S
S#ifdef CONFIG_INIT_CRITICAL
S#error CONFIG_INIT_CRITICAL is deprecated!
S#error Read section CONFIG_SKIP_LOWLEVEL_INIT in README.
S#endif
S
S#define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))
S
S#define ROUND(a,b)		(((a) + (b) - 1) & ~((b) - 1))
S#define DIV_ROUND(n,d)		(((n) + ((d)/2)) / (d))
S#define DIV_ROUND_UP(n,d)	(((n) + (d) - 1) / (d))
S#define roundup(x, y)		((((x) + ((y) - 1)) / (y)) * (y))
S
S#define ALIGN(x,a)		__ALIGN_MASK((x),(typeof(x))(a)-1)
S#define __ALIGN_MASK(x,mask)	(((x)+(mask))&~(mask))
S
S/*
S * ARCH_DMA_MINALIGN is defined in asm/cache.h for each architecture.  It
S * is used to align DMA buffers.
S */
S#ifndef __ASSEMBLY__
S#include "asm/cache.h"
S#endif
S
S/*
S * The ALLOC_CACHE_ALIGN_BUFFER macro is used to allocate a buffer on the
S * stack that meets the minimum architecture alignment requirements for DMA.
S * Such a buffer is useful for DMA operations where flushing and invalidating
S * the cache before and after a read and/or write operation is required for
S * correct operations.
S *
S * When called the macro creates an array on the stack that is sized such
S * that:
S *
S * 1) The beginning of the array can be advanced enough to be aligned.
S *
S * 2) The size of the aligned portion of the array is a multiple of the minimum
S *    architecture alignment required for DMA.
S *
S * 3) The aligned portion contains enough space for the original number of
S *    elements requested.
S *
S * The macro then creates a pointer to the aligned portion of this array and
S * assigns to the pointer the address of the first element in the aligned
S * portion of the array.
S *
S * Calling the macro as:
S *
S *     ALLOC_CACHE_ALIGN_BUFFER(uint32_t, buffer, 1024);
S *
S * Will result in something similar to saying:
S *
S *     uint32_t    buffer[1024];
S *
S * The following differences exist:
S *
S * 1) The resulting buffer is guaranteed to be aligned to the value of
S *    ARCH_DMA_MINALIGN.
S *
S * 2) The buffer variable created by the macro is a pointer to the specified
S *    type, and NOT an array of the specified type.  This can be very important
S *    if you want the address of the buffer, which you probably do, to pass it
S *    to the DMA hardware.  The value of &buffer is different in the two cases.
S *    In the macro case it will be the address of the pointer, not the address
S *    of the space reserved for the buffer.  However, in the second case it
S *    would be the address of the buffer.  So if you are replacing hard coded
S *    stack buffers with this macro you need to make sure you remove the & from
S *    the locations where you are taking the address of the buffer.
S *
S * Note that the size parameter is the number of array elements to allocate,
S * not the number of bytes.
S *
S * This macro can not be used outside of function scope, or for the creation
S * of a function scoped static buffer.  It can not be used to create a cache
S * line aligned global buffer.
S */
S#define ALLOC_ALIGN_BUFFER(type, name, size, align)			\
S	char __##name[ROUND(size * sizeof(type), align) + (align - 1)];	\
S									\
S	type *name = (type *) ALIGN((uintptr_t)__##name, align)
X#define ALLOC_ALIGN_BUFFER(type, name, size, align)				char __##name[ROUND(size * sizeof(type), align) + (align - 1)];											type *name = (type *) ALIGN((uintptr_t)__##name, align)
S#define ALLOC_CACHE_ALIGN_BUFFER(type, name, size)			\
S	ALLOC_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
X#define ALLOC_CACHE_ALIGN_BUFFER(type, name, size)				ALLOC_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
S
S/*
S * DEFINE_CACHE_ALIGN_BUFFER() is similar to ALLOC_CACHE_ALIGN_BUFFER, but it's
S * purpose is to allow allocating aligned buffers outside of function scope.
S * Usage of this macro shall be avoided or used with extreme care!
S */
S#define DEFINE_ALIGN_BUFFER(type, name, size, align)			\
S	static char __##name[roundup(size * sizeof(type), align)]	\
S			__attribute__((aligned(align)));				\
S									\
S	static type *name = (type *)__##name
X#define DEFINE_ALIGN_BUFFER(type, name, size, align)				static char __##name[roundup(size * sizeof(type), align)]				__attribute__((aligned(align)));														static type *name = (type *)__##name
S#define DEFINE_CACHE_ALIGN_BUFFER(type, name, size)			\
S	DEFINE_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
X#define DEFINE_CACHE_ALIGN_BUFFER(type, name, size)				DEFINE_ALIGN_BUFFER(type, name, size, ARCH_DMA_MINALIGN)
S
S/* Pull in stuff for the build system */
S#ifdef DO_DEPS_ONLY
S# include <environment.h>
S#endif
S
S#endif	/* __COMMON_H_ */
N#endif // if 0
L 13 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N#include "malloc.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\malloc.h" 1
N/*
N  A version of malloc/free/realloc written by Doug Lea and released to the
N  public domain.  Send questions/comments/complaints/performance data
N  to dl@cs.oswego.edu
N
N* VERSION 2.6.6  Sun Mar  5 19:10:03 2000  Doug Lea  (dl at gee)
N
N   Note: There may be an updated version of this malloc obtainable at
N	   ftp://g.oswego.edu/pub/misc/malloc.c
N	 Check before installing!
N
N* Why use this malloc?
N
N  This is not the fastest, most space-conserving, most portable, or
N  most tunable malloc ever written. However it is among the fastest
N  while also being among the most space-conserving, portable and tunable.
N  Consistent balance across these factors results in a good general-purpose
N  allocator. For a high-level description, see
N     http://g.oswego.edu/dl/html/malloc.html
N
N* Synopsis of public routines
N
N  (Much fuller descriptions are contained in the program documentation below.)
N
N  malloc(size_t n);
N     Return a pointer to a newly allocated chunk of at least n bytes, or null
N     if no space is available.
N  free(Void_t* p);
N     Release the chunk of memory pointed to by p, or no effect if p is null.
N  realloc(Void_t* p, size_t n);
N     Return a pointer to a chunk of size n that contains the same data
N     as does chunk p up to the minimum of (n, p's size) bytes, or null
N     if no space is available. The returned pointer may or may not be
N     the same as p. If p is null, equivalent to malloc.  Unless the
N     #define REALLOC_ZERO_BYTES_FREES below is set, realloc with a
N     size argument of zero (re)allocates a minimum-sized chunk.
N  memalign(size_t alignment, size_t n);
N     Return a pointer to a newly allocated chunk of n bytes, aligned
N     in accord with the alignment argument, which must be a power of
N     two.
N  valloc(size_t n);
N     Equivalent to memalign(pagesize, n), where pagesize is the page
N     size of the system (or as near to this as can be figured out from
N     all the includes/defines below.)
N  pvalloc(size_t n);
N     Equivalent to valloc(minimum-page-that-holds(n)), that is,
N     round up n to nearest pagesize.
N  calloc(size_t unit, size_t quantity);
N     Returns a pointer to quantity * unit bytes, with all locations
N     set to zero.
N  cfree(Void_t* p);
N     Equivalent to free(p).
N  malloc_trim(size_t pad);
N     Release all but pad bytes of freed top-most memory back
N     to the system. Return 1 if successful, else 0.
N  malloc_usable_size(Void_t* p);
N     Report the number usable allocated bytes associated with allocated
N     chunk p. This may or may not report more bytes than were requested,
N     due to alignment and minimum size constraints.
N  malloc_stats();
N     Prints brief summary statistics on stderr.
N  mallinfo()
N     Returns (by copy) a struct containing various summary statistics.
N  mallopt(int parameter_number, int parameter_value)
N     Changes one of the tunable parameters described below. Returns
N     1 if successful in changing the parameter, else 0.
N
N* Vital statistics:
N
N  Alignment:                            8-byte
N       8 byte alignment is currently hardwired into the design.  This
N       seems to suffice for all current machines and C compilers.
N
N  Assumed pointer representation:       4 or 8 bytes
N       Code for 8-byte pointers is untested by me but has worked
N       reliably by Wolfram Gloger, who contributed most of the
N       changes supporting this.
N
N  Assumed size_t  representation:       4 or 8 bytes
N       Note that size_t is allowed to be 4 bytes even if pointers are 8.
N
N  Minimum overhead per allocated chunk: 4 or 8 bytes
N       Each malloced chunk has a hidden overhead of 4 bytes holding size
N       and status information.
N
N  Minimum allocated size: 4-byte ptrs:  16 bytes    (including 4 overhead)
N			  8-byte ptrs:  24/32 bytes (including, 4/8 overhead)
N
N       When a chunk is freed, 12 (for 4byte ptrs) or 20 (for 8 byte
N       ptrs but 4 byte size) or 24 (for 8/8) additional bytes are
N       needed; 4 (8) for a trailing size field
N       and 8 (16) bytes for free list pointers. Thus, the minimum
N       allocatable size is 16/24/32 bytes.
N
N       Even a request for zero bytes (i.e., malloc(0)) returns a
N       pointer to something of the minimum allocatable size.
N
N  Maximum allocated size: 4-byte size_t: 2^31 -  8 bytes
N			  8-byte size_t: 2^63 - 16 bytes
N
N       It is assumed that (possibly signed) size_t bit values suffice to
N       represent chunk sizes. `Possibly signed' is due to the fact
N       that `size_t' may be defined on a system as either a signed or
N       an unsigned type. To be conservative, values that would appear
N       as negative numbers are avoided.
N       Requests for sizes with a negative sign bit when the request
N       size is treaded as a long will return null.
N
N  Maximum overhead wastage per allocated chunk: normally 15 bytes
N
N       Alignnment demands, plus the minimum allocatable size restriction
N       make the normal worst-case wastage 15 bytes (i.e., up to 15
N       more bytes will be allocated than were requested in malloc), with
N       two exceptions:
N	 1. Because requests for zero bytes allocate non-zero space,
N	    the worst case wastage for a request of zero bytes is 24 bytes.
N	 2. For requests >= mmap_threshold that are serviced via
N	    mmap(), the worst case wastage is 8 bytes plus the remainder
N	    from a system page (the minimal mmap unit); typically 4096 bytes.
N
N* Limitations
N
N    Here are some features that are NOT currently supported
N
N    * No user-definable hooks for callbacks and the like.
N    * No automated mechanism for fully checking that all accesses
N      to malloced memory stay within their bounds.
N    * No support for compaction.
N
N* Synopsis of compile-time options:
N
N    People have reported using previous versions of this malloc on all
N    versions of Unix, sometimes by tweaking some of the defines
N    below. It has been tested most extensively on Solaris and
N    Linux. It is also reported to work on WIN32 platforms.
N    People have also reported adapting this malloc for use in
N    stand-alone embedded systems.
N
N    The implementation is in straight, hand-tuned ANSI C.  Among other
N    consequences, it uses a lot of macros.  Because of this, to be at
N    all usable, this code should be compiled using an optimizing compiler
N    (for example gcc -O2) that can simplify expressions and control
N    paths.
N
N  __STD_C                  (default: derived from C compiler defines)
N     Nonzero if using ANSI-standard C compiler, a C++ compiler, or
N     a C compiler sufficiently close to ANSI to get away with it.
N  DEBUG                    (default: NOT defined)
N     Define to enable debugging. Adds fairly extensive assertion-based
N     checking to help track down memory errors, but noticeably slows down
N     execution.
N  REALLOC_ZERO_BYTES_FREES (default: NOT defined)
N     Define this if you think that realloc(p, 0) should be equivalent
N     to free(p). Otherwise, since malloc returns a unique pointer for
N     malloc(0), so does realloc(p, 0).
N  HAVE_MEMCPY               (default: defined)
N     Define if you are not otherwise using ANSI STD C, but still
N     have memcpy and memset in your C library and want to use them.
N     Otherwise, simple internal versions are supplied.
N  USE_MEMCPY               (default: 1 if HAVE_MEMCPY is defined, 0 otherwise)
N     Define as 1 if you want the C library versions of memset and
N     memcpy called in realloc and calloc (otherwise macro versions are used).
N     At least on some platforms, the simple macro versions usually
N     outperform libc versions.
N  HAVE_MMAP                 (default: defined as 1)
N     Define to non-zero to optionally make malloc() use mmap() to
N     allocate very large blocks.
N  HAVE_MREMAP                 (default: defined as 0 unless Linux libc set)
N     Define to non-zero to optionally make realloc() use mremap() to
N     reallocate very large blocks.
N  malloc_getpagesize        (default: derived from system #includes)
N     Either a constant or routine call returning the system page size.
N  HAVE_USR_INCLUDE_MALLOC_H (default: NOT defined)
N     Optionally define if you are on a system with a /usr/include/malloc.h
N     that declares struct mallinfo. It is not at all necessary to
N     define this even if you do, but will ensure consistency.
N  INTERNAL_SIZE_T           (default: size_t)
N     Define to a 32-bit type (probably `unsigned int') if you are on a
N     64-bit machine, yet do not want or need to allow malloc requests of
N     greater than 2^31 to be handled. This saves space, especially for
N     very small chunks.
N  INTERNAL_LINUX_C_LIB      (default: NOT defined)
N     Defined only when compiled as part of Linux libc.
N     Also note that there is some odd internal name-mangling via defines
N     (for example, internally, `malloc' is named `mALLOc') needed
N     when compiling in this case. These look funny but don't otherwise
N     affect anything.
N  WIN32                     (default: undefined)
N     Define this on MS win (95, nt) platforms to compile in sbrk emulation.
N  LACKS_UNISTD_H            (default: undefined if not WIN32)
N     Define this if your system does not have a <unistd.h>.
N  LACKS_SYS_PARAM_H         (default: undefined if not WIN32)
N     Define this if your system does not have a <sys/param.h>.
N  MORECORE                  (default: sbrk)
N     The name of the routine to call to obtain more memory from the system.
N  MORECORE_FAILURE          (default: -1)
N     The value returned upon failure of MORECORE.
N  MORECORE_CLEARS           (default 1)
N     true (1) if the routine mapped to MORECORE zeroes out memory (which
N     holds for sbrk).
N  DEFAULT_TRIM_THRESHOLD
N  DEFAULT_TOP_PAD
N  DEFAULT_MMAP_THRESHOLD
N  DEFAULT_MMAP_MAX
N     Default values of tunable parameters (described in detail below)
N     controlling interaction with host system routines (sbrk, mmap, etc).
N     These values may also be changed dynamically via mallopt(). The
N     preset defaults are those that give best performance for typical
N     programs/systems.
N  USE_DL_PREFIX             (default: undefined)
N     Prefix all public routines with the string 'dl'.  Useful to
N     quickly avoid procedure declaration conflicts and linker symbol
N     conflicts with existing memory allocation routines.
N
N
N*/
N
N
N#ifndef __MALLOC_H__
N#define __MALLOC_H__
N
N/* Preliminaries */
N
N#ifndef __STD_C
N#ifdef __STDC__
N#define __STD_C     1
N#else
S#if __cplusplus
S#define __STD_C     1
S#else
S#define __STD_C     0
S#endif /*__cplusplus*/
N#endif /*__STDC__*/
N#endif /*__STD_C*/
N
N#ifndef Void_t
N#if (__STD_C || defined(WIN32))
X#if (1 || 0L)
N#define Void_t      void
N#else
S#define Void_t      char
N#endif
N#endif /*Void_t*/
N
N#if __STD_C
X#if 1
N#include <linux/stddef.h>	/* for size_t */
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/stddef.h" 1
N#ifndef _LINUX_STDDEF_H
N#define _LINUX_STDDEF_H
N
N#undef NULL
N#if defined(__cplusplus)
X#if 0L
S#define NULL 0
N#else
N#define NULL ((void *)0)
N#endif
N
N#ifndef _SIZE_T
N#include "linux\types.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\types.h" 1
N#ifndef _LINUX_TYPES_H
N#define _LINUX_TYPES_H
N
N#ifdef	__KERNEL__
S#include <linux/config.h>
N#endif
N
N#include "linux\posix_types.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\posix_types.h" 1
N#ifndef _LINUX_POSIX_TYPES_H
N#define _LINUX_POSIX_TYPES_H
N
N#include <linux/stddef.h>
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/stddef.h" 1
N#ifndef _LINUX_STDDEF_H
S#define _LINUX_STDDEF_H
S
S#undef NULL
S#if defined(__cplusplus)
S#define NULL 0
S#else
S#define NULL ((void *)0)
S#endif
S
S#ifndef _SIZE_T
S#include "linux\types.h"
S#endif
S
S#ifndef __CHECKER__
S#undef offsetof
S#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
S#endif
S
N#endif
L 5 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\posix_types.h" 2
N
N/*
N * This allows for 1024 file descriptors: if NR_OPEN is ever grown
N * beyond that you'll have to change this too. But 1024 fd's seem to be
N * enough even for such "real" unices like OSF/1, so hopefully this is
N * one limit that doesn't have to be changed [again].
N *
N * Note that POSIX wants the FD_CLEAR(fd,fdsetp) defines to be in
N * <sys/time.h> (and thus <linux/time.h>) - but this is a more logical
N * place for them. Solved by having dummy defines in <sys/time.h>.
N */
N
N/*
N * Those macros may have been defined in <gnu/types.h>. But we always
N * use the ones here.
N */
N#undef __NFDBITS
N#define __NFDBITS	(8 * sizeof(unsigned long))
N
N#undef __FD_SETSIZE
N#define __FD_SETSIZE	1024
N
N#undef __FDSET_LONGS
N#define __FDSET_LONGS	(__FD_SETSIZE/__NFDBITS)
N
N#undef __FDELT
N#define	__FDELT(d)	((d) / __NFDBITS)
N
N#undef __FDMASK
N#define	__FDMASK(d)	(1UL << ((d) % __NFDBITS))
N
Ntypedef struct {
N	unsigned long fds_bits [__FDSET_LONGS];
X	unsigned long fds_bits [(1024/(8 * sizeof(unsigned long)))];
N} __kernel_fd_set;
N
N/* Type of a signal handler.  */
Ntypedef void (*__kernel_sighandler_t)(int);
N
N/* Type of a SYSV IPC key.  */
Ntypedef int __kernel_key_t;
N
N#include <asm/posix_types.h>
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm/posix_types.h" 1
N/*
N *  linux/include/asm-arm/posix_types.h
N *
N *  Copyright (C) 1996-1998 Russell King.
N *
N * This program is free software; you can redistribute it and/or modify
N * it under the terms of the GNU General Public License version 2 as
N * published by the Free Software Foundation.
N *
N *  Changelog:
N *   27-06-1996	RMK	Created
N */
N#ifndef __ARCH_ARM_POSIX_TYPES_H
N#define __ARCH_ARM_POSIX_TYPES_H
N
N/*
N * This file is generally used by user-level software, so you need to
N * be a little careful about namespace pollution etc.  Also, we cannot
N * assume GCC is being used.
N */
N
Ntypedef unsigned short		__kernel_dev_t;
Ntypedef unsigned long		__kernel_ino_t;
Ntypedef unsigned short		__kernel_mode_t;
Ntypedef unsigned short		__kernel_nlink_t;
Ntypedef long			__kernel_off_t;
Ntypedef int			__kernel_pid_t;
Ntypedef unsigned short		__kernel_ipc_pid_t;
Ntypedef unsigned short		__kernel_uid_t;
Ntypedef unsigned short		__kernel_gid_t;
Ntypedef unsigned int		__kernel_size_t;
Ntypedef int			__kernel_ssize_t;
Ntypedef int			__kernel_ptrdiff_t;
Ntypedef long			__kernel_time_t;
Ntypedef long			__kernel_suseconds_t;
Ntypedef long			__kernel_clock_t;
Ntypedef int			__kernel_daddr_t;
Ntypedef char *			__kernel_caddr_t;
Ntypedef unsigned short		__kernel_uid16_t;
Ntypedef unsigned short		__kernel_gid16_t;
Ntypedef unsigned int		__kernel_uid32_t;
Ntypedef unsigned int		__kernel_gid32_t;
N
Ntypedef unsigned short		__kernel_old_uid_t;
Ntypedef unsigned short		__kernel_old_gid_t;
N
N#ifdef __GNUC__
Stypedef long long		__kernel_loff_t;
N#endif
N
Ntypedef struct {
N#if defined(__KERNEL__) || defined(__USE_ALL)
X#if 0L || 0L
S	int	val[2];
N#else /* !defined(__KERNEL__) && !defined(__USE_ALL) */
N	int	__val[2];
N#endif /* !defined(__KERNEL__) && !defined(__USE_ALL) */
N} __kernel_fsid_t;
N
N#if defined(__KERNEL__) || !defined(__GLIBC__) || (__GLIBC__ < 2)
X#if 0L || !0L || (__GLIBC__ < 2)
N
N#undef	__FD_SET
N#define __FD_SET(fd, fdsetp) \
N		(((fd_set *)fdsetp)->fds_bits[fd >> 5] |= (1<<(fd & 31)))
X#define __FD_SET(fd, fdsetp) 		(((fd_set *)fdsetp)->fds_bits[fd >> 5] |= (1<<(fd & 31)))
N
N#undef	__FD_CLR
N#define __FD_CLR(fd, fdsetp) \
N		(((fd_set *)fdsetp)->fds_bits[fd >> 5] &= ~(1<<(fd & 31)))
X#define __FD_CLR(fd, fdsetp) 		(((fd_set *)fdsetp)->fds_bits[fd >> 5] &= ~(1<<(fd & 31)))
N
N#undef	__FD_ISSET
N#define __FD_ISSET(fd, fdsetp) \
N		((((fd_set *)fdsetp)->fds_bits[fd >> 5] & (1<<(fd & 31))) != 0)
X#define __FD_ISSET(fd, fdsetp) 		((((fd_set *)fdsetp)->fds_bits[fd >> 5] & (1<<(fd & 31))) != 0)
N
N#undef	__FD_ZERO
N#define __FD_ZERO(fdsetp) \
N		(memset (fdsetp, 0, sizeof (*(fd_set *)fdsetp)))
X#define __FD_ZERO(fdsetp) 		(memset (fdsetp, 0, sizeof (*(fd_set *)fdsetp)))
N
N#endif
N
N#endif
L 47 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\posix_types.h" 2
N
N#endif /* _LINUX_POSIX_TYPES_H */
L 9 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\types.h" 2
N#include "asm\types.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm\types.h" 1
N#ifndef __ASM_ARM_TYPES_H
N#define __ASM_ARM_TYPES_H
N
Ntypedef unsigned short umode_t;
N
N/*
N * __xx is ok: it doesn't pollute the POSIX namespace. Use these in the
N * header files exported to user space
N */
N
Ntypedef char __s8;
Ntypedef unsigned char __u8;
N
Ntypedef short __s16;
Ntypedef unsigned short __u16;
N
Ntypedef int __s32;
Ntypedef unsigned int __u32;
N
Ntypedef long long __s64;
Ntypedef unsigned long long __u64;
N
N#if defined(__GNUC__)
X#if 0L
S__extension__ typedef __signed__ long long __s64;
S__extension__ typedef unsigned long long __u64;
N#endif
N
N/*
N * These aren't exported outside the kernel to avoid name space clashes
N */
N// #ifdef __KERNEL__
N
Ntypedef signed char s8;
Ntypedef unsigned char u8;
N
Ntypedef signed short s16;
Ntypedef unsigned short u16;
N
Ntypedef signed int s32;
Ntypedef unsigned int u32;
N
Ntypedef signed long long s64;
Ntypedef unsigned long long u64;
N
N#define BITS_PER_LONG 32
N
N/* Dma addresses are 32-bits wide.  */
N
Ntypedef u32 dma_addr_t;
N
Ntypedef unsigned long phys_addr_t;
Ntypedef unsigned long phys_size_t;
N
N// #endif /* __KERNEL__ */
N
N#endif
L 10 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\types.h" 2
N//#include "stdbool.h"
N
N#ifndef __KERNEL_STRICT_NAMES
N
Ntypedef __kernel_fd_set		fd_set;
Ntypedef __kernel_dev_t		dev_t;
Ntypedef __kernel_ino_t		ino_t;
Ntypedef __kernel_mode_t		mode_t;
Ntypedef __kernel_nlink_t	nlink_t;
Ntypedef __kernel_off_t		off_t;
Ntypedef __kernel_pid_t		pid_t;
Ntypedef __kernel_daddr_t	daddr_t;
Ntypedef __kernel_key_t		key_t;
Ntypedef __kernel_suseconds_t	suseconds_t;
N
N#ifdef __KERNEL__
Stypedef __kernel_uid32_t	uid_t;
Stypedef __kernel_gid32_t	gid_t;
Stypedef __kernel_uid16_t        uid16_t;
Stypedef __kernel_gid16_t        gid16_t;
S
S#ifdef CONFIG_UID16
S/* This is defined by include/asm-{arch}/posix_types.h */
Stypedef __kernel_old_uid_t	old_uid_t;
Stypedef __kernel_old_gid_t	old_gid_t;
S#endif /* CONFIG_UID16 */
S
S/* libc5 includes this file to define uid_t, thus uid_t can never change
S * when it is included by non-kernel code
S */
N#else
Ntypedef __kernel_uid_t		uid_t;
Ntypedef __kernel_gid_t		gid_t;
N#endif /* __KERNEL__ */
N
N#if defined(__GNUC__) && !defined(__STRICT_ANSI__)
X#if 0L && !0L
Stypedef __kernel_loff_t		loff_t;
N#endif
Ntypedef long long		loff_t;
N
N/*
N * The following typedefs are also protected by individual ifdefs for
N * historical reasons:
N */
N#ifndef _SIZE_T
N#define _SIZE_T
Ntypedef __kernel_size_t		size_t;
N#endif
N
N#ifndef _SSIZE_T
N#define _SSIZE_T
Ntypedef __kernel_ssize_t	ssize_t;
N#endif
N
N#ifndef _PTRDIFF_T
N#define _PTRDIFF_T
Ntypedef __kernel_ptrdiff_t	ptrdiff_t;
N#endif
N
N#ifndef _TIME_T
N#define _TIME_T
Ntypedef __kernel_time_t		time_t;
N#endif
N
N#ifndef _CLOCK_T
N#define _CLOCK_T
Ntypedef __kernel_clock_t	clock_t;
N#endif
N
N#ifndef _CADDR_T
N#define _CADDR_T
Ntypedef __kernel_caddr_t	caddr_t;
N#endif
N
N/* bsd */
Ntypedef unsigned char		u_char;
Ntypedef unsigned short		u_short;
Ntypedef unsigned int		u_int;
Ntypedef unsigned long		u_long;
N
N/* sysv */
Ntypedef unsigned char		unchar;
Ntypedef unsigned short		ushort;
Ntypedef unsigned int		uint;
Ntypedef unsigned long		ulong;
N
N#ifndef __BIT_TYPES_DEFINED__
N#define __BIT_TYPES_DEFINED__
N
Ntypedef		__u8		u_int8_t;
N// typedef		__s8		int8_t;
Ntypedef		__u16		u_int16_t;
N// typedef		__s16		int16_t;
Ntypedef		__u32		u_int32_t;
N// typedef		__s32		int32_t;
N
N#endif /* !(__BIT_TYPES_DEFINED__) */
N
N// typedef		__u8		uint8_t;
N// typedef		__u16		uint16_t;
N// typedef		__u32		uint32_t;
N
N// #if defined(__GNUC__) && !defined(__STRICT_ANSI__)
Ntypedef		__u64		uint64_t;
Ntypedef		__u64		u_int64_t;
Ntypedef		__s64		int64_t;
N// #endif
N
N#endif /* __KERNEL_STRICT_NAMES */
N
N/*
N * Below are truly Linux-specific types that should never collide with
N * any application/library that wants linux/types.h.
N */
N#ifdef __CHECKER__
S#define __bitwise__ __attribute__((bitwise))
N#else
N#define __bitwise__
N#endif
N#ifdef __CHECK_ENDIAN__
S#define __bitwise __bitwise__
N#else
N#define __bitwise
N#endif
N
Ntypedef __u16 __bitwise __le16;
Xtypedef __u16  __le16;
Ntypedef __u16 __bitwise __be16;
Xtypedef __u16  __be16;
Ntypedef __u32 __bitwise __le32;
Xtypedef __u32  __le32;
Ntypedef __u32 __bitwise __be32;
Xtypedef __u32  __be32;
N// #if defined(__GNUC__)
Ntypedef __u64 __bitwise __le64;
Xtypedef __u64  __le64;
Ntypedef __u64 __bitwise __be64;
Xtypedef __u64  __be64;
N// #endif
Ntypedef __u16 __bitwise __sum16;
Xtypedef __u16  __sum16;
Ntypedef __u32 __bitwise __wsum;
Xtypedef __u32  __wsum;
N
N
Ntypedef unsigned __bitwise__	gfp_t;
Xtypedef unsigned 	gfp_t;
N
Nstruct ustat {
N	__kernel_daddr_t	f_tfree;
N	__kernel_ino_t		f_tinode;
N	char			f_fname[6];
N	char			f_fpack[6];
N};
N
N#endif /* _LINUX_TYPES_H */
L 13 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/stddef.h" 2
N#endif
N
N#ifndef __CHECKER__
N#undef offsetof
N#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
N#endif
N
N#endif
L 246 "..\..\common\src\BSP\ThirdParty\yaffs2\include\malloc.h" 2
N#else
S#include <sys/types.h>
N#endif	/* __STD_C */
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N#if 0	/* not for U-Boot */
S#include <stdio.h>	/* needed for malloc_stats */
N#endif
N
N
N/*
N  Compile-time options
N*/
N
N
N/*
N    Debugging:
N
N    Because freed chunks may be overwritten with link fields, this
N    malloc will often die when freed memory is overwritten by user
N    programs.  This can be very effective (albeit in an annoying way)
N    in helping track down dangling pointers.
N
N    If you compile with -DDEBUG, a number of assertion checks are
N    enabled that will catch more memory errors. You probably won't be
N    able to make much sense of the actual assertion errors, but they
N    should help you locate incorrectly overwritten memory.  The
N    checking is fairly extensive, and will slow down execution
N    noticeably. Calling malloc_stats or mallinfo with DEBUG set will
N    attempt to check every non-mmapped allocated and free chunk in the
N    course of computing the summmaries. (By nature, mmapped regions
N    cannot be checked very much automatically.)
N
N    Setting DEBUG may also be helpful if you are trying to modify
N    this code. The assertions in the check routines spell out in more
N    detail the assumptions and invariants underlying the algorithms.
N
N*/
N
N/*
N  INTERNAL_SIZE_T is the word-size used for internal bookkeeping
N  of chunk sizes. On a 64-bit machine, you can reduce malloc
N  overhead by defining INTERNAL_SIZE_T to be a 32 bit `unsigned int'
N  at the expense of not being able to handle requests greater than
N  2^31. This limitation is hardly ever a concern; you are encouraged
N  to set this. However, the default version is the same as size_t.
N*/
N
N#ifndef INTERNAL_SIZE_T
N#define INTERNAL_SIZE_T size_t
N#endif
N
N/*
N  REALLOC_ZERO_BYTES_FREES should be set if a call to
N  realloc with zero bytes should be the same as a call to free.
N  Some people think it should. Otherwise, since this malloc
N  returns a unique pointer for malloc(0), so does realloc(p, 0).
N*/
N
N
N/*   #define REALLOC_ZERO_BYTES_FREES */
N
N
N/*
N  WIN32 causes an emulation of sbrk to be compiled in
N  mmap-based options are not currently supported in WIN32.
N*/
N
N/* #define WIN32 */
N#ifdef WIN32
S#define MORECORE wsbrk
S#define HAVE_MMAP 0
S
S#define LACKS_UNISTD_H
S#define LACKS_SYS_PARAM_H
S
S/*
S  Include 'windows.h' to get the necessary declarations for the
S  Microsoft Visual C++ data structures and routines used in the 'sbrk'
S  emulation.
S
S  Define WIN32_LEAN_AND_MEAN so that only the essential Microsoft
S  Visual C++ header files are included.
S*/
S#define WIN32_LEAN_AND_MEAN
S#include <windows.h>
N#endif
N
N
N/*
N  HAVE_MEMCPY should be defined if you are not otherwise using
N  ANSI STD C, but still have memcpy and memset in your C library
N  and want to use them in calloc and realloc. Otherwise simple
N  macro versions are defined here.
N
N  USE_MEMCPY should be defined as 1 if you actually want to
N  have memset and memcpy called. People report that the macro
N  versions are often enough faster than libc versions on many
N  systems that it is better to use them.
N
N*/
N
N#define HAVE_MEMCPY
N
N#ifndef USE_MEMCPY
N#ifdef HAVE_MEMCPY
N#define USE_MEMCPY 1
N#else
S#define USE_MEMCPY 0
N#endif
N#endif
N
N#if (__STD_C || defined(HAVE_MEMCPY))
X#if (1 || 1L)
N
N#if __STD_C
X#if 1
Nvoid* memset(void*, int, size_t);
Nvoid* memcpy(void*, const void*, size_t);
N#else
S#ifdef WIN32
S/* On Win32 platforms, 'memset()' and 'memcpy()' are already declared in */
S/* 'windows.h' */
S#else
SVoid_t* memset();
SVoid_t* memcpy();
S#endif
N#endif
N#endif
N
N#if USE_MEMCPY
X#if 1
N
N/* The following macros are only invoked with (2n+1)-multiples of
N   INTERNAL_SIZE_T units, with a positive integer n. This is exploited
N   for fast inline execution when n is small. */
N
N#define MALLOC_ZERO(charp, nbytes)                                            \
Ndo {                                                                          \
N  INTERNAL_SIZE_T mzsz = (nbytes);                                            \
N  if(mzsz <= 9*sizeof(mzsz)) {                                                \
N    INTERNAL_SIZE_T* mz = (INTERNAL_SIZE_T*) (charp);                         \
N    if(mzsz >= 5*sizeof(mzsz)) {     *mz++ = 0;                               \
N				     *mz++ = 0;                               \
N      if(mzsz >= 7*sizeof(mzsz)) {   *mz++ = 0;                               \
N				     *mz++ = 0;                               \
N	if(mzsz >= 9*sizeof(mzsz)) { *mz++ = 0;                               \
N				     *mz++ = 0; }}}                           \
N				     *mz++ = 0;                               \
N				     *mz++ = 0;                               \
N				     *mz   = 0;                               \
N  } else memset((charp), 0, mzsz);                                            \
N} while(0)
X#define MALLOC_ZERO(charp, nbytes)                                            do {                                                                            INTERNAL_SIZE_T mzsz = (nbytes);                                              if(mzsz <= 9*sizeof(mzsz)) {                                                    INTERNAL_SIZE_T* mz = (INTERNAL_SIZE_T*) (charp);                             if(mzsz >= 5*sizeof(mzsz)) {     *mz++ = 0;                               				     *mz++ = 0;                                     if(mzsz >= 7*sizeof(mzsz)) {   *mz++ = 0;                               				     *mz++ = 0;                               	if(mzsz >= 9*sizeof(mzsz)) { *mz++ = 0;                               				     *mz++ = 0; }}}                           				     *mz++ = 0;                               				     *mz++ = 0;                               				     *mz   = 0;                                 } else memset((charp), 0, mzsz);                                            } while(0)
N
N#define MALLOC_COPY(dest,src,nbytes)                                          \
Ndo {                                                                          \
N  INTERNAL_SIZE_T mcsz = (nbytes);                                            \
N  if(mcsz <= 9*sizeof(mcsz)) {                                                \
N    INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) (src);                        \
N    INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) (dest);                       \
N    if(mcsz >= 5*sizeof(mcsz)) {     *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++;                     \
N      if(mcsz >= 7*sizeof(mcsz)) {   *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++;                     \
N	if(mcsz >= 9*sizeof(mcsz)) { *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++; }}}                 \
N				     *mcdst++ = *mcsrc++;                     \
N				     *mcdst++ = *mcsrc++;                     \
N				     *mcdst   = *mcsrc  ;                     \
N  } else memcpy(dest, src, mcsz);                                             \
N} while(0)
X#define MALLOC_COPY(dest,src,nbytes)                                          do {                                                                            INTERNAL_SIZE_T mcsz = (nbytes);                                              if(mcsz <= 9*sizeof(mcsz)) {                                                    INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) (src);                            INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) (dest);                           if(mcsz >= 5*sizeof(mcsz)) {     *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++;                           if(mcsz >= 7*sizeof(mcsz)) {   *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++;                     	if(mcsz >= 9*sizeof(mcsz)) { *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++; }}}                 				     *mcdst++ = *mcsrc++;                     				     *mcdst++ = *mcsrc++;                     				     *mcdst   = *mcsrc  ;                       } else memcpy(dest, src, mcsz);                                             } while(0)
N
N#else /* !USE_MEMCPY */
S
S/* Use Duff's device for good zeroing/copying performance. */
S
S#define MALLOC_ZERO(charp, nbytes)                                            \
Sdo {                                                                          \
S  INTERNAL_SIZE_T* mzp = (INTERNAL_SIZE_T*)(charp);                           \
S  long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                         \
S  if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }             \
S  switch (mctmp) {                                                            \
S    case 0: for(;;) { *mzp++ = 0;                                             \
S    case 7:           *mzp++ = 0;                                             \
S    case 6:           *mzp++ = 0;                                             \
S    case 5:           *mzp++ = 0;                                             \
S    case 4:           *mzp++ = 0;                                             \
S    case 3:           *mzp++ = 0;                                             \
S    case 2:           *mzp++ = 0;                                             \
S    case 1:           *mzp++ = 0; if(mcn <= 0) break; mcn--; }                \
S  }                                                                           \
S} while(0)
X#define MALLOC_ZERO(charp, nbytes)                                            do {                                                                            INTERNAL_SIZE_T* mzp = (INTERNAL_SIZE_T*)(charp);                             long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                           if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }               switch (mctmp) {                                                                case 0: for(;;) { *mzp++ = 0;                                                 case 7:           *mzp++ = 0;                                                 case 6:           *mzp++ = 0;                                                 case 5:           *mzp++ = 0;                                                 case 4:           *mzp++ = 0;                                                 case 3:           *mzp++ = 0;                                                 case 2:           *mzp++ = 0;                                                 case 1:           *mzp++ = 0; if(mcn <= 0) break; mcn--; }                  }                                                                           } while(0)
S
S#define MALLOC_COPY(dest,src,nbytes)                                          \
Sdo {                                                                          \
S  INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) src;                            \
S  INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) dest;                           \
S  long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                         \
S  if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }             \
S  switch (mctmp) {                                                            \
S    case 0: for(;;) { *mcdst++ = *mcsrc++;                                    \
S    case 7:           *mcdst++ = *mcsrc++;                                    \
S    case 6:           *mcdst++ = *mcsrc++;                                    \
S    case 5:           *mcdst++ = *mcsrc++;                                    \
S    case 4:           *mcdst++ = *mcsrc++;                                    \
S    case 3:           *mcdst++ = *mcsrc++;                                    \
S    case 2:           *mcdst++ = *mcsrc++;                                    \
S    case 1:           *mcdst++ = *mcsrc++; if(mcn <= 0) break; mcn--; }       \
S  }                                                                           \
S} while(0)
X#define MALLOC_COPY(dest,src,nbytes)                                          do {                                                                            INTERNAL_SIZE_T* mcsrc = (INTERNAL_SIZE_T*) src;                              INTERNAL_SIZE_T* mcdst = (INTERNAL_SIZE_T*) dest;                             long mctmp = (nbytes)/sizeof(INTERNAL_SIZE_T), mcn;                           if (mctmp < 8) mcn = 0; else { mcn = (mctmp-1)/8; mctmp %= 8; }               switch (mctmp) {                                                                case 0: for(;;) { *mcdst++ = *mcsrc++;                                        case 7:           *mcdst++ = *mcsrc++;                                        case 6:           *mcdst++ = *mcsrc++;                                        case 5:           *mcdst++ = *mcsrc++;                                        case 4:           *mcdst++ = *mcsrc++;                                        case 3:           *mcdst++ = *mcsrc++;                                        case 2:           *mcdst++ = *mcsrc++;                                        case 1:           *mcdst++ = *mcsrc++; if(mcn <= 0) break; mcn--; }         }                                                                           } while(0)
S
N#endif
N
N
N/*
N  Define HAVE_MMAP to optionally make malloc() use mmap() to
N  allocate very large blocks.  These will be returned to the
N  operating system immediately after a free().
N*/
N
N/***
N#ifndef HAVE_MMAP
N#define HAVE_MMAP 1
N#endif
N***/
N#undef	HAVE_MMAP	/* Not available for U-Boot */
N
N/*
N  Define HAVE_MREMAP to make realloc() use mremap() to re-allocate
N  large blocks.  This is currently only possible on Linux with
N  kernel versions newer than 1.3.77.
N*/
N
N/***
N#ifndef HAVE_MREMAP
N#ifdef INTERNAL_LINUX_C_LIB
N#define HAVE_MREMAP 1
N#else
N#define HAVE_MREMAP 0
N#endif
N#endif
N***/
N#undef	HAVE_MREMAP	/* Not available for U-Boot */
N
N#ifdef HAVE_MMAP
S
S#include <unistd.h>
S#include <fcntl.h>
S#include <sys/mman.h>
S
S#if !defined(MAP_ANONYMOUS) && defined(MAP_ANON)
S#define MAP_ANONYMOUS MAP_ANON
S#endif
S
N#endif /* HAVE_MMAP */
N
N/*
N  Access to system page size. To the extent possible, this malloc
N  manages memory from the system in page-size units.
N
N  The following mechanics for getpagesize were adapted from
N  bsd/gnu getpagesize.h
N*/
N
N#define	LACKS_UNISTD_H	/* Shortcut for U-Boot */
N#define	malloc_getpagesize	4096
N
N#ifndef LACKS_UNISTD_H
S#  include <unistd.h>
N#endif
N
N#ifndef malloc_getpagesize
S#  ifdef _SC_PAGESIZE         /* some SVR4 systems omit an underscore */
S#    ifndef _SC_PAGE_SIZE
S#      define _SC_PAGE_SIZE _SC_PAGESIZE
S#    endif
S#  endif
S#  ifdef _SC_PAGE_SIZE
S#    define malloc_getpagesize sysconf(_SC_PAGE_SIZE)
S#  else
S#    if defined(BSD) || defined(DGUX) || defined(HAVE_GETPAGESIZE)
S       extern size_t getpagesize();
S#      define malloc_getpagesize getpagesize()
S#    else
S#      ifdef WIN32
S#        define malloc_getpagesize (4096) /* TBD: Use 'GetSystemInfo' instead */
S#      else
S#        ifndef LACKS_SYS_PARAM_H
S#          include <sys/param.h>
S#        endif
S#        ifdef EXEC_PAGESIZE
S#          define malloc_getpagesize EXEC_PAGESIZE
S#        else
S#          ifdef NBPG
S#            ifndef CLSIZE
S#              define malloc_getpagesize NBPG
S#            else
S#              define malloc_getpagesize (NBPG * CLSIZE)
S#            endif
S#          else
S#            ifdef NBPC
S#              define malloc_getpagesize NBPC
S#            else
S#              ifdef PAGESIZE
S#                define malloc_getpagesize PAGESIZE
S#              else
S#                define malloc_getpagesize (4096) /* just guess */
S#              endif
S#            endif
S#          endif
S#        endif
S#      endif
S#    endif
S#  endif
N#endif
N
N
N/*
N
N  This version of malloc supports the standard SVID/XPG mallinfo
N  routine that returns a struct containing the same kind of
N  information you can get from malloc_stats. It should work on
N  any SVID/XPG compliant system that has a /usr/include/malloc.h
N  defining struct mallinfo. (If you'd like to install such a thing
N  yourself, cut out the preliminary declarations as described above
N  and below and save them in a malloc.h file. But there's no
N  compelling reason to bother to do this.)
N
N  The main declaration needed is the mallinfo struct that is returned
N  (by-copy) by mallinfo().  The SVID/XPG malloinfo struct contains a
N  bunch of fields, most of which are not even meaningful in this
N  version of malloc. Some of these fields are are instead filled by
N  mallinfo() with other numbers that might possibly be of interest.
N
N  HAVE_USR_INCLUDE_MALLOC_H should be set if you have a
N  /usr/include/malloc.h file that includes a declaration of struct
N  mallinfo.  If so, it is included; else an SVID2/XPG2 compliant
N  version is declared below.  These must be precisely the same for
N  mallinfo() to work.
N
N*/
N
N/* #define HAVE_USR_INCLUDE_MALLOC_H */
N
N#ifdef HAVE_USR_INCLUDE_MALLOC_H
S#include "/usr/include/malloc.h"
N#else
N
N/* SVID2/XPG mallinfo structure */
N
Nstruct mallinfo {
N  int arena;    /* total space allocated from system */
N  int ordblks;  /* number of non-inuse chunks */
N  int smblks;   /* unused -- always zero */
N  int hblks;    /* number of mmapped regions */
N  int hblkhd;   /* total space in mmapped regions */
N  int usmblks;  /* unused -- always zero */
N  int fsmblks;  /* unused -- always zero */
N  int uordblks; /* total allocated space */
N  int fordblks; /* total non-inuse space */
N  int keepcost; /* top-most, releasable (via malloc_trim) space */
N};
N
N/* SVID2/XPG mallopt options */
N
N#define M_MXFAST  1    /* UNUSED in this malloc */
N#define M_NLBLKS  2    /* UNUSED in this malloc */
N#define M_GRAIN   3    /* UNUSED in this malloc */
N#define M_KEEP    4    /* UNUSED in this malloc */
N
N#endif
N
N/* mallopt options that actually do something */
N
N#define M_TRIM_THRESHOLD    -1
N#define M_TOP_PAD           -2
N#define M_MMAP_THRESHOLD    -3
N#define M_MMAP_MAX          -4
N
N
N#ifndef DEFAULT_TRIM_THRESHOLD
N#define DEFAULT_TRIM_THRESHOLD (128 * 1024)
N#endif
N
N/*
N    M_TRIM_THRESHOLD is the maximum amount of unused top-most memory
N      to keep before releasing via malloc_trim in free().
N
N      Automatic trimming is mainly useful in long-lived programs.
N      Because trimming via sbrk can be slow on some systems, and can
N      sometimes be wasteful (in cases where programs immediately
N      afterward allocate more large chunks) the value should be high
N      enough so that your overall system performance would improve by
N      releasing.
N
N      The trim threshold and the mmap control parameters (see below)
N      can be traded off with one another. Trimming and mmapping are
N      two different ways of releasing unused memory back to the
N      system. Between these two, it is often possible to keep
N      system-level demands of a long-lived program down to a bare
N      minimum. For example, in one test suite of sessions measuring
N      the XF86 X server on Linux, using a trim threshold of 128K and a
N      mmap threshold of 192K led to near-minimal long term resource
N      consumption.
N
N      If you are using this malloc in a long-lived program, it should
N      pay to experiment with these values.  As a rough guide, you
N      might set to a value close to the average size of a process
N      (program) running on your system.  Releasing this much memory
N      would allow such a process to run in memory.  Generally, it's
N      worth it to tune for trimming rather tham memory mapping when a
N      program undergoes phases where several large chunks are
N      allocated and released in ways that can reuse each other's
N      storage, perhaps mixed with phases where there are no such
N      chunks at all.  And in well-behaved long-lived programs,
N      controlling release of large blocks via trimming versus mapping
N      is usually faster.
N
N      However, in most programs, these parameters serve mainly as
N      protection against the system-level effects of carrying around
N      massive amounts of unneeded memory. Since frequent calls to
N      sbrk, mmap, and munmap otherwise degrade performance, the default
N      parameters are set to relatively high values that serve only as
N      safeguards.
N
N      The default trim value is high enough to cause trimming only in
N      fairly extreme (by current memory consumption standards) cases.
N      It must be greater than page size to have any useful effect.  To
N      disable trimming completely, you can set to (unsigned long)(-1);
N
N
N*/
N
N
N#ifndef DEFAULT_TOP_PAD
N#define DEFAULT_TOP_PAD        (0)
N#endif
N
N/*
N    M_TOP_PAD is the amount of extra `padding' space to allocate or
N      retain whenever sbrk is called. It is used in two ways internally:
N
N      * When sbrk is called to extend the top of the arena to satisfy
N	a new malloc request, this much padding is added to the sbrk
N	request.
N
N      * When malloc_trim is called automatically from free(),
N	it is used as the `pad' argument.
N
N      In both cases, the actual amount of padding is rounded
N      so that the end of the arena is always a system page boundary.
N
N      The main reason for using padding is to avoid calling sbrk so
N      often. Having even a small pad greatly reduces the likelihood
N      that nearly every malloc request during program start-up (or
N      after trimming) will invoke sbrk, which needlessly wastes
N      time.
N
N      Automatic rounding-up to page-size units is normally sufficient
N      to avoid measurable overhead, so the default is 0.  However, in
N      systems where sbrk is relatively slow, it can pay to increase
N      this value, at the expense of carrying around more memory than
N      the program needs.
N
N*/
N
N
N#ifndef DEFAULT_MMAP_THRESHOLD
N#define DEFAULT_MMAP_THRESHOLD (128 * 1024)
N#endif
N
N/*
N
N    M_MMAP_THRESHOLD is the request size threshold for using mmap()
N      to service a request. Requests of at least this size that cannot
N      be allocated using already-existing space will be serviced via mmap.
N      (If enough normal freed space already exists it is used instead.)
N
N      Using mmap segregates relatively large chunks of memory so that
N      they can be individually obtained and released from the host
N      system. A request serviced through mmap is never reused by any
N      other request (at least not directly; the system may just so
N      happen to remap successive requests to the same locations).
N
N      Segregating space in this way has the benefit that mmapped space
N      can ALWAYS be individually released back to the system, which
N      helps keep the system level memory demands of a long-lived
N      program low. Mapped memory can never become `locked' between
N      other chunks, as can happen with normally allocated chunks, which
N      menas that even trimming via malloc_trim would not release them.
N
N      However, it has the disadvantages that:
N
N	 1. The space cannot be reclaimed, consolidated, and then
N	    used to service later requests, as happens with normal chunks.
N	 2. It can lead to more wastage because of mmap page alignment
N	    requirements
N	 3. It causes malloc performance to be more dependent on host
N	    system memory management support routines which may vary in
N	    implementation quality and may impose arbitrary
N	    limitations. Generally, servicing a request via normal
N	    malloc steps is faster than going through a system's mmap.
N
N      All together, these considerations should lead you to use mmap
N      only for relatively large requests.
N
N
N*/
N
N
N#ifndef DEFAULT_MMAP_MAX
N#ifdef HAVE_MMAP
S#define DEFAULT_MMAP_MAX       (64)
N#else
N#define DEFAULT_MMAP_MAX       (0)
N#endif
N#endif
N
N/*
N    M_MMAP_MAX is the maximum number of requests to simultaneously
N      service using mmap. This parameter exists because:
N
N	 1. Some systems have a limited number of internal tables for
N	    use by mmap.
N	 2. In most systems, overreliance on mmap can degrade overall
N	    performance.
N	 3. If a program allocates many large regions, it is probably
N	    better off using normal sbrk-based allocation routines that
N	    can reclaim and reallocate normal heap memory. Using a
N	    small value allows transition into this mode after the
N	    first few allocations.
N
N      Setting to 0 disables all use of mmap.  If HAVE_MMAP is not set,
N      the default value is 0, and attempts to set it to non-zero values
N      in mallopt will fail.
N*/
N
N
N/*
N    USE_DL_PREFIX will prefix all public routines with the string 'dl'.
N      Useful to quickly avoid procedure declaration conflicts and linker
N      symbol conflicts with existing memory allocation routines.
N
N*/
N
N/* #define USE_DL_PREFIX */
N
N
N/*
N
N  Special defines for linux libc
N
N  Except when compiled using these special defines for Linux libc
N  using weak aliases, this malloc is NOT designed to work in
N  multithreaded applications.  No semaphores or other concurrency
N  control are provided to ensure that multiple malloc or free calls
N  don't run at the same time, which could be disasterous. A single
N  semaphore could be used across malloc, realloc, and free (which is
N  essentially the effect of the linux weak alias approach). It would
N  be hard to obtain finer granularity.
N
N*/
N
N
N#ifdef INTERNAL_LINUX_C_LIB
S
S#if __STD_C
S
SVoid_t * __default_morecore_init (ptrdiff_t);
SVoid_t *(*__morecore)(ptrdiff_t) = __default_morecore_init;
S
S#else
S
SVoid_t * __default_morecore_init ();
SVoid_t *(*__morecore)() = __default_morecore_init;
S
S#endif
S
S#define MORECORE (*__morecore)
S#define MORECORE_FAILURE 0
S#define MORECORE_CLEARS 1
S
N#else /* INTERNAL_LINUX_C_LIB */
N
N#if __STD_C
X#if 1
Nextern Void_t*     sbrk(ptrdiff_t);
Xextern void*     sbrk(ptrdiff_t);
N#else
Sextern Void_t*     sbrk();
N#endif
N
N#ifndef MORECORE
N#define MORECORE sbrk
N#endif
N
N#ifndef MORECORE_FAILURE
N#define MORECORE_FAILURE -1
N#endif
N
N#ifndef MORECORE_CLEARS
N#define MORECORE_CLEARS 1
N#endif
N
N#endif /* INTERNAL_LINUX_C_LIB */
N
N#if defined(INTERNAL_LINUX_C_LIB) && defined(__ELF__)
X#if 0L && 0L
S
S#define cALLOc		__libc_calloc
S#define fREe		__libc_free
S#define mALLOc		__libc_malloc
S#define mEMALIGn	__libc_memalign
S#define rEALLOc		__libc_realloc
S#define vALLOc		__libc_valloc
S#define pvALLOc		__libc_pvalloc
S#define mALLINFo	__libc_mallinfo
S#define mALLOPt		__libc_mallopt
S
S#pragma weak calloc = __libc_calloc
S#pragma weak free = __libc_free
S#pragma weak cfree = __libc_free
S#pragma weak malloc = __libc_malloc
S#pragma weak memalign = __libc_memalign
S#pragma weak realloc = __libc_realloc
S#pragma weak valloc = __libc_valloc
S#pragma weak pvalloc = __libc_pvalloc
S#pragma weak mallinfo = __libc_mallinfo
S#pragma weak mallopt = __libc_mallopt
S
N#else
N
N#ifdef USE_DL_PREFIX
S#define cALLOc		dlcalloc
S#define fREe		dlfree
S#define mALLOc		dlmalloc
S#define mEMALIGn	dlmemalign
S#define rEALLOc		dlrealloc
S#define vALLOc		dlvalloc
S#define pvALLOc		dlpvalloc
S#define mALLINFo	dlmallinfo
S#define mALLOPt		dlmallopt
N#else /* USE_DL_PREFIX */
N#define cALLOc		calloc
N#define fREe		free
N#define mALLOc		malloc
N#define mEMALIGn	memalign
N#define rEALLOc		realloc
N#define vALLOc		valloc
N#define pvALLOc		pvalloc
N#define mALLINFo	mallinfo
N#define mALLOPt		mallopt
N#endif /* USE_DL_PREFIX */
N
N#endif
N
N/* Public routines */
N
N#if __STD_C
X#if 1
N
NVoid_t* mALLOc(size_t);
Xvoid* malloc(size_t);
Nvoid    fREe(Void_t*);
Xvoid    free(void*);
NVoid_t* rEALLOc(Void_t*, size_t);
Xvoid* realloc(void*, size_t);
NVoid_t* mEMALIGn(size_t, size_t);
Xvoid* memalign(size_t, size_t);
NVoid_t* vALLOc(size_t);
Xvoid* valloc(size_t);
NVoid_t* pvALLOc(size_t);
Xvoid* pvalloc(size_t);
NVoid_t* cALLOc(size_t, size_t);
Xvoid* calloc(size_t, size_t);
Nvoid    cfree(Void_t*);
Xvoid    cfree(void*);
Nint     malloc_trim(size_t);
Nsize_t  malloc_usable_size(Void_t*);
Xsize_t  malloc_usable_size(void*);
Nvoid    malloc_stats(void);
Nint     mALLOPt(int, int);
Xint     mallopt(int, int);
Nstruct mallinfo mALLINFo(void);
Xstruct mallinfo mallinfo(void);
N#else
SVoid_t* mALLOc();
Svoid    fREe();
SVoid_t* rEALLOc();
SVoid_t* mEMALIGn();
SVoid_t* vALLOc();
SVoid_t* pvALLOc();
SVoid_t* cALLOc();
Svoid    cfree();
Sint     malloc_trim();
Ssize_t  malloc_usable_size();
Svoid    malloc_stats();
Sint     mALLOPt();
Sstruct mallinfo mALLINFo();
N#endif
N
N/*
N * Begin and End of memory area for malloc(), and current "brk"
N */
Nextern ulong mem_malloc_start;
Nextern ulong mem_malloc_end;
Nextern ulong mem_malloc_brk;
N
Nvoid mem_malloc_init(ulong start, ulong size);
N
N#ifdef __cplusplus
S};  /* end of extern "C" */
N#endif
N
N#endif /* __MALLOC_H__ */
L 14 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N#include "asm\errno.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\asm\errno.h" 1
N/*
N * U-boot - errno.h Error number defines
N *
N * Copyright (c) 2005-2007 Analog Devices Inc.
N *
N * See file CREDITS for list of people who contributed to this
N * project.
N *
N * This program is free software; you can redistribute it and/or
N * modify it under the terms of the GNU General Public License as
N * published by the Free Software Foundation; either version 2 of
N * the License, or (at your option) any later version.
N *
N * This program is distributed in the hope that it will be useful,
N * but WITHOUT ANY WARRANTY; without even the implied warranty of
N * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
N * GNU General Public License for more details.
N *
N * You should have received a copy of the GNU General Public License
N * along with this program; if not, write to the Free Software
N * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
N * MA 02110-1301 USA
N */
N
N#ifndef _GENERIC_ERRNO_H
N#define _GENERIC_ERRNO_H
N
N#define	EPERM		1	/* Operation not permitted */
N#define	ENOENT		2	/* No such file or directory */
N#define	ESRCH		3	/* No such process */
N#define	EINTR		4	/* Interrupted system call */
N#define	EIO		5	/* I/O error */
N#define	ENXIO		6	/* No such device or address */
N#define	E2BIG		7	/* Argument list too long */
N#define	ENOEXEC		8	/* Exec format error */
N#define	EBADF		9	/* Bad file number */
N#define	ECHILD		10	/* No child processes */
N#define	EAGAIN		11	/* Try again */
N#define	ENOMEM		12	/* Out of memory */
N#define	EACCES		13	/* Permission denied */
N#define	EFAULT		14	/* Bad address */
N#define	ENOTBLK		15	/* Block device required */
N#define	EBUSY		16	/* Device or resource busy */
N#define	EEXIST		17	/* File exists */
N#define	EXDEV		18	/* Cross-device link */
N#define	ENODEV		19	/* No such device */
N#define	ENOTDIR		20	/* Not a directory */
N#define	EISDIR		21	/* Is a directory */
N#define	EINVAL		22	/* Invalid argument */
N#define	ENFILE		23	/* File table overflow */
N#define	EMFILE		24	/* Too many open files */
N#define	ENOTTY		25	/* Not a typewriter */
N#define	ETXTBSY		26	/* Text file busy */
N#define	EFBIG		27	/* File too large */
N#define	ENOSPC		28	/* No space left on device */
N#define	ESPIPE		29	/* Illegal seek */
N#define	EROFS		30	/* Read-only file system */
N#define	EMLINK		31	/* Too many links */
N#define	EPIPE		32	/* Broken pipe */
N#define	EDOM		33	/* Math argument out of domain of func */
N#define	ERANGE		34	/* Math result not representable */
N#define	EDEADLK		35	/* Resource deadlock would occur */
N#define	ENAMETOOLONG	36	/* File name too long */
N#define	ENOLCK		37	/* No record locks available */
N#define	ENOSYS		38	/* Function not implemented */
N#define	ENOTEMPTY	39	/* Directory not empty */
N#define	ELOOP		40	/* Too many symbolic links encountered */
N#define	EWOULDBLOCK	EAGAIN	/* Operation would block */
N#define	ENOMSG		42	/* No message of desired type */
N#define	EIDRM		43	/* Identifier removed */
N#define	ECHRNG		44	/* Channel number out of range */
N#define	EL2NSYNC	45	/* Level 2 not synchronized */
N#define	EL3HLT		46	/* Level 3 halted */
N#define	EL3RST		47	/* Level 3 reset */
N#define	ELNRNG		48	/* Link number out of range */
N#define	EUNATCH		49	/* Protocol driver not attached */
N#define	ENOCSI		50	/* No CSI structure available */
N#define	EL2HLT		51	/* Level 2 halted */
N#define	EBADE		52	/* Invalid exchange */
N#define	EBADR		53	/* Invalid request descriptor */
N#define	EXFULL		54	/* Exchange full */
N#define	ENOANO		55	/* No anode */
N#define	EBADRQC		56	/* Invalid request code */
N#define	EBADSLT		57	/* Invalid slot */
N
N#define	EDEADLOCK	EDEADLK
N
N#define	EBFONT		59	/* Bad font file format */
N#define	ENOSTR		60	/* Device not a stream */
N#define	ENODATA		61	/* No data available */
N#define	ETIME		62	/* Timer expired */
N#define	ENOSR		63	/* Out of streams resources */
N#define	ENONET		64	/* Machine is not on the network */
N#define	ENOPKG		65	/* Package not installed */
N#define	EREMOTE		66	/* Object is remote */
N#define	ENOLINK		67	/* Link has been severed */
N#define	EADV		68	/* Advertise error */
N#define	ESRMNT		69	/* Srmount error */
N#define	ECOMM		70	/* Communication error on send */
N#define	EPROTO		71	/* Protocol error */
N#define	EMULTIHOP	72	/* Multihop attempted */
N#define	EDOTDOT		73	/* RFS specific error */
N#define	EBADMSG		74	/* Not a data message */
N#define	EOVERFLOW	75	/* Value too large for defined data type */
N#define	ENOTUNIQ	76	/* Name not unique on network */
N#define	EBADFD		77	/* File descriptor in bad state */
N#define	EREMCHG		78	/* Remote address changed */
N#define	ELIBACC		79	/* Can not access a needed shared library */
N#define	ELIBBAD		80	/* Accessing a corrupted shared library */
N#define	ELIBSCN		81	/* .lib section in a.out corrupted */
N#define	ELIBMAX		82	/* Attempting to link in too many shared libraries */
N#define	ELIBEXEC	83	/* Cannot exec a shared library directly */
N#define	EILSEQ		84	/* Illegal byte sequence */
N#define	ERESTART	85	/* Interrupted system call should be restarted */
N#define	ESTRPIPE	86	/* Streams pipe error */
N#define	EUSERS		87	/* Too many users */
N#define	ENOTSOCK	88	/* Socket operation on non-socket */
N#define	EDESTADDRREQ	89	/* Destination address required */
N#define	EMSGSIZE	90	/* Message too long */
N#define	EPROTOTYPE	91	/* Protocol wrong type for socket */
N#define	ENOPROTOOPT	92	/* Protocol not available */
N#define	EPROTONOSUPPORT	93	/* Protocol not supported */
N#define	ESOCKTNOSUPPORT	94	/* Socket type not supported */
N#define	EOPNOTSUPP	95	/* Operation not supported on transport endpoint */
N#define	EPFNOSUPPORT	96	/* Protocol family not supported */
N#define	EAFNOSUPPORT	97	/* Address family not supported by protocol */
N#define	EADDRINUSE	98	/* Address already in use */
N#define	EADDRNOTAVAIL	99	/* Cannot assign requested address */
N#define	ENETDOWN	100	/* Network is down */
N#define	ENETUNREACH	101	/* Network is unreachable */
N#define	ENETRESET	102	/* Network dropped connection because of reset */
N#define	ECONNABORTED	103	/* Software caused connection abort */
N#define	ECONNRESET	104	/* Connection reset by peer */
N#define	ENOBUFS		105	/* No buffer space available */
N#define	EISCONN		106	/* Transport endpoint is already connected */
N#define	ENOTCONN	107	/* Transport endpoint is not connected */
N#define	ESHUTDOWN	108	/* Cannot send after transport endpoint shutdown */
N#define	ETOOMANYREFS	109	/* Too many references: cannot splice */
N#define	ETIMEDOUT	110	/* Connection timed out */
N#define	ECONNREFUSED	111	/* Connection refused */
N#define	EHOSTDOWN	112	/* Host is down */
N#define	EHOSTUNREACH	113	/* No route to host */
N#define	EALREADY	114	/* Operation already in progress */
N#define	EINPROGRESS	115	/* Operation now in progress */
N#define	ESTALE		116	/* Stale NFS file handle */
N#define	EUCLEAN		117	/* Structure needs cleaning */
N#define	ENOTNAM		118	/* Not a XENIX named type file */
N#define	ENAVAIL		119	/* No XENIX semaphores available */
N#define	EISNAM		120	/* Is a named type file */
N#define	EREMOTEIO	121	/* Remote I/O error */
N#define	EDQUOT		122	/* Quota exceeded */
N#define	ENOMEDIUM	123	/* No medium found */
N#define	EMEDIUMTYPE	124	/* Wrong medium type */
N
N#endif
L 15 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N
N#include "linux\types.h"
N#include "linux\list.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\list.h" 1
N#ifndef _LINUX_LIST_H
N#define _LINUX_LIST_H
N
N/// @cond HIDDEN_SYMBOLS
N
N/*
N * These are non-NULL pointers that will result in page faults
N * under normal circumstances, used to verify that nobody uses
N * non-initialized list entries.
N */
N#define LIST_POISON1  	NULL	// ((void *) 0x00100100 + POISON_POINTER_DELTA)
N#define LIST_POISON2  	NULL	// ((void *) 0x00200200 + POISON_POINTER_DELTA)
N
N
Nstruct list_head {
N	struct list_head *next, *prev;
N};
N
N
N/*
N * Simple doubly linked list implementation.
N *
N * Some of the internal functions ("__xxx") are useful when
N * manipulating whole lists rather than single entries, as
N * sometimes we already know the next/prev entries and we can
N * generate better code by using them directly rather than
N * using the generic single-entry routines.
N */
N
N#define LIST_HEAD_INIT(name) { &(name), &(name) }
N
N#define LIST_HEAD(name) \
N	struct list_head name = LIST_HEAD_INIT(name)
X#define LIST_HEAD(name) 	struct list_head name = LIST_HEAD_INIT(name)
N
Nstatic __inline void INIT_LIST_HEAD(struct list_head *list)
N{
N	list->next = list;
N	list->prev = list;
N}
N
N/*
N * Insert a new entry between two known consecutive entries.
N *
N * This is only for internal list manipulation where we know
N * the prev/next entries already!
N */
N#ifndef CONFIG_DEBUG_LIST
Nstatic __inline void __list_add(struct list_head *new,
N			      struct list_head *prev,
N			      struct list_head *next)
N{
N	next->prev = new;
N	new->next = next;
N	new->prev = prev;
N	prev->next = new;
N}
N#else
Sextern void __list_add(struct list_head *new,
S			      struct list_head *prev,
S			      struct list_head *next);
N#endif
N
N/**
N * list_add - add a new entry
N * @new: new entry to be added
N * @head: list head to add it after
N *
N * Insert a new entry after the specified head.
N * This is good for implementing stacks.
N */
Nstatic __inline void list_add(struct list_head *new, struct list_head *head)
N{
N	__list_add(new, head, head->next);
N}
N
N
N/**
N * list_add_tail - add a new entry
N * @new: new entry to be added
N * @head: list head to add it before
N *
N * Insert a new entry before the specified head.
N * This is useful for implementing queues.
N */
Nstatic __inline void list_add_tail(struct list_head *new, struct list_head *head)
N{
N	__list_add(new, head->prev, head);
N}
N
N/*
N * Delete a list entry by making the prev/next entries
N * point to each other.
N *
N * This is only for internal list manipulation where we know
N * the prev/next entries already!
N */
Nstatic __inline void __list_del(struct list_head * prev, struct list_head * next)
N{
N	next->prev = prev;
N	prev->next = next;
N}
N
N/**
N * list_del - deletes entry from list.
N * @entry: the element to delete from the list.
N * Note: list_empty() on entry does not return true after this, the entry is
N * in an undefined state.
N */
N#ifndef CONFIG_DEBUG_LIST
Nstatic __inline void __list_del_entry(struct list_head *entry)
N{
N	__list_del(entry->prev, entry->next);
N}
N
Nstatic __inline void list_del(struct list_head *entry)
N{
N	__list_del(entry->prev, entry->next);
N	entry->next = LIST_POISON1;
X	entry->next = ((void *)0);
N	entry->prev = LIST_POISON2;
X	entry->prev = ((void *)0);
N}
N#else
Sextern void __list_del_entry(struct list_head *entry);
Sextern void list_del(struct list_head *entry);
N#endif
N
N/**
N * list_replace - replace old entry by new one
N * @old : the element to be replaced
N * @new : the new element to insert
N *
N * If @old was empty, it will be overwritten.
N */
Nstatic __inline void list_replace(struct list_head *old,
N				struct list_head *new)
N{
N	new->next = old->next;
N	new->next->prev = new;
N	new->prev = old->prev;
N	new->prev->next = new;
N}
N
Nstatic __inline void list_replace_init(struct list_head *old,
N					struct list_head *new)
N{
N	list_replace(old, new);
N	INIT_LIST_HEAD(old);
N}
N
N/**
N * list_del_init - deletes entry from list and reinitialize it.
N * @entry: the element to delete from the list.
N */
Nstatic __inline void list_del_init(struct list_head *entry)
N{
N	__list_del_entry(entry);
N	INIT_LIST_HEAD(entry);
N}
N
N/**
N * list_move - delete from one list and add as another's head
N * @list: the entry to move
N * @head: the head that will precede our entry
N */
Nstatic __inline void list_move(struct list_head *list, struct list_head *head)
N{
N	__list_del_entry(list);
N	list_add(list, head);
N}
N
N/**
N * list_move_tail - delete from one list and add as another's tail
N * @list: the entry to move
N * @head: the head that will follow our entry
N */
Nstatic __inline void list_move_tail(struct list_head *list,
N				  struct list_head *head)
N{
N	__list_del_entry(list);
N	list_add_tail(list, head);
N}
N
N/**
N * list_is_last - tests whether @list is the last entry in list @head
N * @list: the entry to test
N * @head: the head of the list
N */
Nstatic __inline int list_is_last(const struct list_head *list,
N				const struct list_head *head)
N{
N	return list->next == head;
N}
N
N/**
N * list_empty - tests whether a list is empty
N * @head: the list to test.
N */
Nstatic __inline int list_empty(const struct list_head *head)
N{
N	return head->next == head;
N}
N
N/**
N * list_empty_careful - tests whether a list is empty and not being modified
N * @head: the list to test
N *
N * Description:
N * tests whether a list is empty _and_ checks that no other CPU might be
N * in the process of modifying either member (next or prev)
N *
N * NOTE: using list_empty_careful() without synchronization
N * can only be safe if the only activity that can happen
N * to the list entry is list_del_init(). Eg. it cannot be used
N * if another CPU could re-list_add() it.
N */
Nstatic __inline int list_empty_careful(const struct list_head *head)
N{
N	struct list_head *next = head->next;
N	return (next == head) && (next == head->prev);
N}
N
N/**
N * list_rotate_left - rotate the list to the left
N * @head: the head of the list
N */
Nstatic __inline void list_rotate_left(struct list_head *head)
N{
N	struct list_head *first;
N
N	if (!list_empty(head)) {
N		first = head->next;
N		list_move_tail(first, head);
N	}
N}
N
N/**
N * list_is_singular - tests whether a list has just one entry.
N * @head: the list to test.
N */
Nstatic __inline int list_is_singular(const struct list_head *head)
N{
N	return !list_empty(head) && (head->next == head->prev);
N}
N
Nstatic __inline void __list_cut_position(struct list_head *list,
N		struct list_head *head, struct list_head *entry)
N{
N	struct list_head *new_first = entry->next;
N	list->next = head->next;
N	list->next->prev = list;
N	list->prev = entry;
N	entry->next = list;
N	head->next = new_first;
N	new_first->prev = head;
N}
N
N/**
N * list_cut_position - cut a list into two
N * @list: a new list to add all removed entries
N * @head: a list with entries
N * @entry: an entry within head, could be the head itself
N *	and if so we won't cut the list
N *
N * This helper moves the initial part of @head, up to and
N * including @entry, from @head to @list. You should
N * pass on @entry an element you know is on @head. @list
N * should be an empty list or a list you do not care about
N * losing its data.
N *
N */
Nstatic __inline void list_cut_position(struct list_head *list,
N		struct list_head *head, struct list_head *entry)
N{
N	if (list_empty(head))
N		return;
N	if (list_is_singular(head) &&
N		(head->next != entry && head != entry))
N		return;
N	if (entry == head)
N		INIT_LIST_HEAD(list);
N	else
N		__list_cut_position(list, head, entry);
N}
N
Nstatic __inline void __list_splice(const struct list_head *list,
N				 struct list_head *prev,
N				 struct list_head *next)
N{
N	struct list_head *first = list->next;
N	struct list_head *last = list->prev;
N
N	first->prev = prev;
N	prev->next = first;
N
N	last->next = next;
N	next->prev = last;
N}
N
N/**
N * list_splice - join two lists, this is designed for stacks
N * @list: the new list to add.
N * @head: the place to add it in the first list.
N */
Nstatic __inline void list_splice(const struct list_head *list,
N				struct list_head *head)
N{
N	if (!list_empty(list))
N		__list_splice(list, head, head->next);
N}
N
N/**
N * list_splice_tail - join two lists, each list being a queue
N * @list: the new list to add.
N * @head: the place to add it in the first list.
N */
Nstatic __inline void list_splice_tail(struct list_head *list,
N				struct list_head *head)
N{
N	if (!list_empty(list))
N		__list_splice(list, head->prev, head);
N}
N
N/**
N * list_splice_init - join two lists and reinitialise the emptied list.
N * @list: the new list to add.
N * @head: the place to add it in the first list.
N *
N * The list at @list is reinitialised
N */
Nstatic __inline void list_splice_init(struct list_head *list,
N				    struct list_head *head)
N{
N	if (!list_empty(list)) {
N		__list_splice(list, head, head->next);
N		INIT_LIST_HEAD(list);
N	}
N}
N
N/**
N * list_splice_tail_init - join two lists and reinitialise the emptied list
N * @list: the new list to add.
N * @head: the place to add it in the first list.
N *
N * Each of the lists is a queue.
N * The list at @list is reinitialised
N */
Nstatic __inline void list_splice_tail_init(struct list_head *list,
N					 struct list_head *head)
N{
N	if (!list_empty(list)) {
N		__list_splice(list, head->prev, head);
N		INIT_LIST_HEAD(list);
N	}
N}
N
N/**
N * list_entry - get the struct for this entry
N * @ptr:	the &struct list_head pointer.
N * @type:	the type of the struct this is embedded in.
N * @member:	the name of the list_struct within the struct.
N */
N#define list_entry(ptr, type, member) \
N	((type *)((char *)(ptr)-(unsigned long)(&((type *)0)->member)))
X#define list_entry(ptr, type, member) 	((type *)((char *)(ptr)-(unsigned long)(&((type *)0)->member)))
N	//container_of(ptr, type, member)
N
N/**
N * list_first_entry - get the first element from a list
N * @ptr:	the list head to take the element from.
N * @type:	the type of the struct this is embedded in.
N * @member:	the name of the list_struct within the struct.
N *
N * Note, that list is expected to be not empty.
N */
N#define list_first_entry(ptr, type, member) \
N	list_entry((ptr)->next, type, member)
X#define list_first_entry(ptr, type, member) 	list_entry((ptr)->next, type, member)
N
N/**
N * list_for_each	-	iterate over a list
N * @pos:	the &struct list_head to use as a loop cursor.
N * @head:	the head for your list.
N */
N#define list_for_each(pos, head) \
N	for (pos = (head)->next; pos != (head); pos = pos->next)
X#define list_for_each(pos, head) 	for (pos = (head)->next; pos != (head); pos = pos->next)
N
N/**
N * __list_for_each	-	iterate over a list
N * @pos:	the &struct list_head to use as a loop cursor.
N * @head:	the head for your list.
N *
N * This variant doesn't differ from list_for_each() any more.
N * We don't do prefetching in either case.
N */
N#define __list_for_each(pos, head) \
N	for (pos = (head)->next; pos != (head); pos = pos->next)
X#define __list_for_each(pos, head) 	for (pos = (head)->next; pos != (head); pos = pos->next)
N
N/**
N * list_for_each_prev	-	iterate over a list backwards
N * @pos:	the &struct list_head to use as a loop cursor.
N * @head:	the head for your list.
N */
N#define list_for_each_prev(pos, head) \
N	for (pos = (head)->prev; pos != (head); pos = pos->prev)
X#define list_for_each_prev(pos, head) 	for (pos = (head)->prev; pos != (head); pos = pos->prev)
N
N/**
N * list_for_each_safe - iterate over a list safe against removal of list entry
N * @pos:	the &struct list_head to use as a loop cursor.
N * @n:		another &struct list_head to use as temporary storage
N * @head:	the head for your list.
N */
N#define list_for_each_safe(pos, n, head) \
N	for (pos = (head)->next, n = pos->next; pos != (head); \
N		pos = n, n = pos->next)
X#define list_for_each_safe(pos, n, head) 	for (pos = (head)->next, n = pos->next; pos != (head); 		pos = n, n = pos->next)
N
N/**
N * list_for_each_prev_safe - iterate over a list backwards safe against removal of list entry
N * @pos:	the &struct list_head to use as a loop cursor.
N * @n:		another &struct list_head to use as temporary storage
N * @head:	the head for your list.
N */
N#define list_for_each_prev_safe(pos, n, head) \
N	for (pos = (head)->prev, n = pos->prev; \
N	     pos != (head); \
N	     pos = n, n = pos->prev)
X#define list_for_each_prev_safe(pos, n, head) 	for (pos = (head)->prev, n = pos->prev; 	     pos != (head); 	     pos = n, n = pos->prev)
N
N/**
N * list_for_each_entry	-	iterate over list of given type
N * @pos:	the type * to use as a loop cursor.
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N */
N#define list_for_each_entry(pos, head, member)				\
N	for (pos = list_entry((head)->next, typeof(*pos), member);	\
N	     &pos->member != (head); 	\
N	     pos = list_entry(pos->member.next, typeof(*pos), member))
X#define list_for_each_entry(pos, head, member)					for (pos = list_entry((head)->next, typeof(*pos), member);		     &pos->member != (head); 		     pos = list_entry(pos->member.next, typeof(*pos), member))
N
N/**
N * list_for_each_entry_reverse - iterate backwards over list of given type.
N * @pos:	the type * to use as a loop cursor.
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N */
N#define list_for_each_entry_reverse(pos, head, member)			\
N	for (pos = list_entry((head)->prev, typeof(*pos), member);	\
N	     &pos->member != (head); 	\
N	     pos = list_entry(pos->member.prev, typeof(*pos), member))
X#define list_for_each_entry_reverse(pos, head, member)				for (pos = list_entry((head)->prev, typeof(*pos), member);		     &pos->member != (head); 		     pos = list_entry(pos->member.prev, typeof(*pos), member))
N
N/**
N * list_prepare_entry - prepare a pos entry for use in list_for_each_entry_continue()
N * @pos:	the type * to use as a start point
N * @head:	the head of the list
N * @member:	the name of the list_struct within the struct.
N *
N * Prepares a pos entry for use as a start point in list_for_each_entry_continue().
N */
N#define list_prepare_entry(pos, head, member) \
N	((pos) ? : list_entry(head, typeof(*pos), member))
X#define list_prepare_entry(pos, head, member) 	((pos) ? : list_entry(head, typeof(*pos), member))
N
N/**
N * list_for_each_entry_continue - continue iteration over list of given type
N * @pos:	the type * to use as a loop cursor.
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N *
N * Continue to iterate over list of given type, continuing after
N * the current position.
N */
N#define list_for_each_entry_continue(pos, head, member) 		\
N	for (pos = list_entry(pos->member.next, typeof(*pos), member);	\
N	     &pos->member != (head);	\
N	     pos = list_entry(pos->member.next, typeof(*pos), member))
X#define list_for_each_entry_continue(pos, head, member) 			for (pos = list_entry(pos->member.next, typeof(*pos), member);		     &pos->member != (head);		     pos = list_entry(pos->member.next, typeof(*pos), member))
N
N/**
N * list_for_each_entry_continue_reverse - iterate backwards from the given point
N * @pos:	the type * to use as a loop cursor.
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N *
N * Start to iterate over list of given type backwards, continuing after
N * the current position.
N */
N#define list_for_each_entry_continue_reverse(pos, head, member)		\
N	for (pos = list_entry(pos->member.prev, typeof(*pos), member);	\
N	     &pos->member != (head);	\
N	     pos = list_entry(pos->member.prev, typeof(*pos), member))
X#define list_for_each_entry_continue_reverse(pos, head, member)			for (pos = list_entry(pos->member.prev, typeof(*pos), member);		     &pos->member != (head);		     pos = list_entry(pos->member.prev, typeof(*pos), member))
N
N/**
N * list_for_each_entry_from - iterate over list of given type from the current point
N * @pos:	the type * to use as a loop cursor.
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N *
N * Iterate over list of given type, continuing from current position.
N */
N#define list_for_each_entry_from(pos, head, member) 			\
N	for (; &pos->member != (head);	\
N	     pos = list_entry(pos->member.next, typeof(*pos), member))
X#define list_for_each_entry_from(pos, head, member) 				for (; &pos->member != (head);		     pos = list_entry(pos->member.next, typeof(*pos), member))
N
N/**
N * list_for_each_entry_safe - iterate over list of given type safe against removal of list entry
N * @pos:	the type * to use as a loop cursor.
N * @n:		another type * to use as temporary storage
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N */
N#define list_for_each_entry_safe(pos, n, head, member)			\
N	for (pos = list_entry((head)->next, typeof(*pos), member),	\
N		n = list_entry(pos->member.next, typeof(*pos), member);	\
N	     &pos->member != (head); 					\
N	     pos = n, n = list_entry(n->member.next, typeof(*n), member))
X#define list_for_each_entry_safe(pos, n, head, member)				for (pos = list_entry((head)->next, typeof(*pos), member),			n = list_entry(pos->member.next, typeof(*pos), member);		     &pos->member != (head); 						     pos = n, n = list_entry(n->member.next, typeof(*n), member))
N
N/**
N * list_for_each_entry_safe_continue - continue list iteration safe against removal
N * @pos:	the type * to use as a loop cursor.
N * @n:		another type * to use as temporary storage
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N *
N * Iterate over list of given type, continuing after current point,
N * safe against removal of list entry.
N */
N#define list_for_each_entry_safe_continue(pos, n, head, member) 		\
N	for (pos = list_entry(pos->member.next, typeof(*pos), member), 		\
N		n = list_entry(pos->member.next, typeof(*pos), member);		\
N	     &pos->member != (head);						\
N	     pos = n, n = list_entry(n->member.next, typeof(*n), member))
X#define list_for_each_entry_safe_continue(pos, n, head, member) 			for (pos = list_entry(pos->member.next, typeof(*pos), member), 				n = list_entry(pos->member.next, typeof(*pos), member);			     &pos->member != (head);							     pos = n, n = list_entry(n->member.next, typeof(*n), member))
N
N/**
N * list_for_each_entry_safe_from - iterate over list from current point safe against removal
N * @pos:	the type * to use as a loop cursor.
N * @n:		another type * to use as temporary storage
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N *
N * Iterate over list of given type from current point, safe against
N * removal of list entry.
N */
N#define list_for_each_entry_safe_from(pos, n, head, member) 			\
N	for (n = list_entry(pos->member.next, typeof(*pos), member);		\
N	     &pos->member != (head);						\
N	     pos = n, n = list_entry(n->member.next, typeof(*n), member))
X#define list_for_each_entry_safe_from(pos, n, head, member) 				for (n = list_entry(pos->member.next, typeof(*pos), member);			     &pos->member != (head);							     pos = n, n = list_entry(n->member.next, typeof(*n), member))
N
N/**
N * list_for_each_entry_safe_reverse - iterate backwards over list safe against removal
N * @pos:	the type * to use as a loop cursor.
N * @n:		another type * to use as temporary storage
N * @head:	the head for your list.
N * @member:	the name of the list_struct within the struct.
N *
N * Iterate backwards over list of given type, safe against removal
N * of list entry.
N */
N#define list_for_each_entry_safe_reverse(pos, n, head, member)		\
N	for (pos = list_entry((head)->prev, typeof(*pos), member),	\
N		n = list_entry(pos->member.prev, typeof(*pos), member);	\
N	     &pos->member != (head); 					\
N	     pos = n, n = list_entry(n->member.prev, typeof(*n), member))
X#define list_for_each_entry_safe_reverse(pos, n, head, member)			for (pos = list_entry((head)->prev, typeof(*pos), member),			n = list_entry(pos->member.prev, typeof(*pos), member);		     &pos->member != (head); 						     pos = n, n = list_entry(n->member.prev, typeof(*n), member))
N
N/**
N * list_safe_reset_next - reset a stale list_for_each_entry_safe loop
N * @pos:	the loop cursor used in the list_for_each_entry_safe loop
N * @n:		temporary storage used in list_for_each_entry_safe
N * @member:	the name of the list_struct within the struct.
N *
N * list_safe_reset_next is not safe to use in general if the list may be
N * modified concurrently (eg. the lock is dropped in the loop body). An
N * exception to this is if the cursor element (pos) is pinned in the list,
N * and list_safe_reset_next is called after re-taking the lock and before
N * completing the current iteration of the loop body.
N */
N#define list_safe_reset_next(pos, n, member)				\
N	n = list_entry(pos->member.next, typeof(*pos), member)
X#define list_safe_reset_next(pos, n, member)					n = list_entry(pos->member.next, typeof(*pos), member)
N
N#if 0	// no hlist
S/*
S * Double linked lists with a single pointer list head.
S * Mostly useful for hash tables where the two pointer list head is
S * too wasteful.
S * You lose the ability to access the tail in O(1).
S */
S
S#define HLIST_HEAD_INIT { .first = NULL }
S#define HLIST_HEAD(name) struct hlist_head name = {  .first = NULL }
S#define INIT_HLIST_HEAD(ptr) ((ptr)->first = NULL)
Sstatic __inline void INIT_HLIST_NODE(struct hlist_node *h)
S{
S	h->next = NULL;
S	h->pprev = NULL;
S}
S
Sstatic __inline int hlist_unhashed(const struct hlist_node *h)
S{
S	return !h->pprev;
S}
S
Sstatic __inline int hlist_empty(const struct hlist_head *h)
S{
S	return !h->first;
S}
S
Sstatic __inline void __hlist_del(struct hlist_node *n)
S{
S	struct hlist_node *next = n->next;
S	struct hlist_node **pprev = n->pprev;
S	*pprev = next;
S	if (next)
S		next->pprev = pprev;
S}
S
Sstatic __inline void hlist_del(struct hlist_node *n)
S{
S	__hlist_del(n);
S	n->next = LIST_POISON1;
S	n->pprev = LIST_POISON2;
S}
S
Sstatic __inline void hlist_del_init(struct hlist_node *n)
S{
S	if (!hlist_unhashed(n)) {
S		__hlist_del(n);
S		INIT_HLIST_NODE(n);
S	}
S}
S
Sstatic __inline void hlist_add_head(struct hlist_node *n, struct hlist_head *h)
S{
S	struct hlist_node *first = h->first;
S	n->next = first;
S	if (first)
S		first->pprev = &n->next;
S	h->first = n;
S	n->pprev = &h->first;
S}
S
S/* next must be != NULL */
Sstatic __inline void hlist_add_before(struct hlist_node *n,
S					struct hlist_node *next)
S{
S	n->pprev = next->pprev;
S	n->next = next;
S	next->pprev = &n->next;
S	*(n->pprev) = n;
S}
S
Sstatic __inline void hlist_add_after(struct hlist_node *n,
S					struct hlist_node *next)
S{
S	next->next = n->next;
S	n->next = next;
S	next->pprev = &n->next;
S
S	if(next->next)
S		next->next->pprev  = &next->next;
S}
S
S/* after that we'll appear to be on some hlist and hlist_del will work */
Sstatic __inline void hlist_add_fake(struct hlist_node *n)
S{
S	n->pprev = &n->next;
S}
S
S/*
S * Move a list from one list head to another. Fixup the pprev
S * reference of the first entry if it exists.
S */
Sstatic __inline void hlist_move_list(struct hlist_head *old,
S				   struct hlist_head *new)
S{
S	new->first = old->first;
S	if (new->first)
S		new->first->pprev = &new->first;
S	old->first = NULL;
S}
S
S#define hlist_entry(ptr, type, member) container_of(ptr,type,member)
S
S#define hlist_for_each(pos, head) \
S	for (pos = (head)->first; pos ; pos = pos->next)
X#define hlist_for_each(pos, head) 	for (pos = (head)->first; pos ; pos = pos->next)
S
S#define hlist_for_each_safe(pos, n, head) \
S	for (pos = (head)->first; pos && ({ n = pos->next; 1; }); \
S	     pos = n)
X#define hlist_for_each_safe(pos, n, head) 	for (pos = (head)->first; pos && ({ n = pos->next; 1; }); 	     pos = n)
S
S/**
S * hlist_for_each_entry	- iterate over list of given type
S * @tpos:	the type * to use as a loop cursor.
S * @pos:	the &struct hlist_node to use as a loop cursor.
S * @head:	the head for your list.
S * @member:	the name of the hlist_node within the struct.
S */
S#define hlist_for_each_entry(tpos, pos, head, member)			 \
S	for (pos = (head)->first;					 \
S	     pos &&							 \
S		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
S	     pos = pos->next)
X#define hlist_for_each_entry(tpos, pos, head, member)			 	for (pos = (head)->first;					 	     pos &&							 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); 	     pos = pos->next)
S
S/**
S * hlist_for_each_entry_continue - iterate over a hlist continuing after current point
S * @tpos:	the type * to use as a loop cursor.
S * @pos:	the &struct hlist_node to use as a loop cursor.
S * @member:	the name of the hlist_node within the struct.
S */
S#define hlist_for_each_entry_continue(tpos, pos, member)		 \
S	for (pos = (pos)->next;						 \
S	     pos &&							 \
S		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
S	     pos = pos->next)
X#define hlist_for_each_entry_continue(tpos, pos, member)		 	for (pos = (pos)->next;						 	     pos &&							 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); 	     pos = pos->next)
S
S/**
S * hlist_for_each_entry_from - iterate over a hlist continuing from current point
S * @tpos:	the type * to use as a loop cursor.
S * @pos:	the &struct hlist_node to use as a loop cursor.
S * @member:	the name of the hlist_node within the struct.
S */
S#define hlist_for_each_entry_from(tpos, pos, member)			 \
S	for (; pos &&							 \
S		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
S	     pos = pos->next)
X#define hlist_for_each_entry_from(tpos, pos, member)			 	for (; pos &&							 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); 	     pos = pos->next)
S
S/**
S * hlist_for_each_entry_safe - iterate over list of given type safe against removal of list entry
S * @tpos:	the type * to use as a loop cursor.
S * @pos:	the &struct hlist_node to use as a loop cursor.
S * @n:		another &struct hlist_node to use as temporary storage
S * @head:	the head for your list.
S * @member:	the name of the hlist_node within the struct.
S */
S#define hlist_for_each_entry_safe(tpos, pos, n, head, member) 		 \
S	for (pos = (head)->first;					 \
S	     pos && ({ n = pos->next; 1; }) && 				 \
S		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
S	     pos = n)
X#define hlist_for_each_entry_safe(tpos, pos, n, head, member) 		 	for (pos = (head)->first;					 	     pos && ({ n = pos->next; 1; }) && 				 		({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); 	     pos = n)
S
N#endif
N
N/// @endcond HIDDEN_SYMBOLS
N
N#endif  // no hlist
L 18 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N#include "linux\mtd.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd.h" 1
N/*
N * Copyright (C) 1999-2003 David Woodhouse <dwmw2@infradead.org> et al.
N *
N * Released under GPL
N */
N
N#ifndef __MTD_MTD_H__
N#define __MTD_MTD_H__
N
N#include "linux\types.h"
N#include "div64.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\div64.h" 1
N#ifndef _ASM_GENERIC_DIV64_H
N#define _ASM_GENERIC_DIV64_H
N/*
N * Copyright (C) 2003 Bernardo Innocenti <bernie@develer.com>
N * Based on former asm-ppc/div64.h and asm-m68knommu/div64.h
N *
N * The semantics of do_div() are:
N *
N * uint32_t do_div(uint64_t *n, uint32_t base)
N * {
N *	uint32_t remainder = *n % base;
N *	*n = *n / base;
N *	return remainder;
N * }
N *
N * NOTE: macro parameter n is evaluated multiple times,
N *       beware of side effects!
N */
N#include <stdint.h>
L 1 "C:\Keil\ARM\ARMCC\bin\..\include\stdint.h" 1
N/* Copyright (C) ARM Ltd., 1999 */
N/* All rights reserved */
N
N/*
N * RCS $Revision: 178085 $
N * Checkin $Date: 2012-12-11 14:54:17 +0000 (Tue, 11 Dec 2012) $
N * Revising $Author: agrant $
N */
N
N#ifndef __stdint_h
N#define __stdint_h
N#define __ARMCLIB_VERSION 5030076
N
N  #ifndef __STDINT_DECLS
N  #define __STDINT_DECLS
N
N    #undef __CLIBNS
N
N    #ifdef __cplusplus
S      namespace std {
S          #define __CLIBNS std::
S          extern "C" {
N    #else
N      #define __CLIBNS
N    #endif  /* __cplusplus */
N
N
N/*
N * 'signed' is redundant below, except for 'signed char' and if
N * the typedef is used to declare a bitfield.
N * '__int64' is used instead of 'long long' so that this header
N * can be used in --strict mode.
N */
N
N    /* 7.18.1.1 */
N
N    /* exact-width signed integer types */
Ntypedef   signed          char int8_t;
Ntypedef   signed short     int int16_t;
Ntypedef   signed           int int32_t;
Ntypedef   signed       __int64 int64_t;
N
N    /* exact-width unsigned integer types */
Ntypedef unsigned          char uint8_t;
Ntypedef unsigned short     int uint16_t;
Ntypedef unsigned           int uint32_t;
Ntypedef unsigned       __int64 uint64_t;
N
N    /* 7.18.1.2 */
N
N    /* smallest type of at least n bits */
N    /* minimum-width signed integer types */
Ntypedef   signed          char int_least8_t;
Ntypedef   signed short     int int_least16_t;
Ntypedef   signed           int int_least32_t;
Ntypedef   signed       __int64 int_least64_t;
N
N    /* minimum-width unsigned integer types */
Ntypedef unsigned          char uint_least8_t;
Ntypedef unsigned short     int uint_least16_t;
Ntypedef unsigned           int uint_least32_t;
Ntypedef unsigned       __int64 uint_least64_t;
N
N    /* 7.18.1.3 */
N
N    /* fastest minimum-width signed integer types */
Ntypedef   signed           int int_fast8_t;
Ntypedef   signed           int int_fast16_t;
Ntypedef   signed           int int_fast32_t;
Ntypedef   signed       __int64 int_fast64_t;
N
N    /* fastest minimum-width unsigned integer types */
Ntypedef unsigned           int uint_fast8_t;
Ntypedef unsigned           int uint_fast16_t;
Ntypedef unsigned           int uint_fast32_t;
Ntypedef unsigned       __int64 uint_fast64_t;
N
N    /* 7.18.1.4 integer types capable of holding object pointers */
Ntypedef   signed           int intptr_t;
Ntypedef unsigned           int uintptr_t;
N
N    /* 7.18.1.5 greatest-width integer types */
Ntypedef   signed       __int64 intmax_t;
Ntypedef unsigned       __int64 uintmax_t;
N
N
N#if !defined(__cplusplus) || defined(__STDC_LIMIT_MACROS)
X#if !0L || 0L
N
N    /* 7.18.2.1 */
N
N    /* minimum values of exact-width signed integer types */
N#define INT8_MIN                   -128
N#define INT16_MIN                -32768
N#define INT32_MIN          (~0x7fffffff)   /* -2147483648 is unsigned */
N#define INT64_MIN  __ESCAPE__(~0x7fffffffffffffffll) /* -9223372036854775808 is unsigned */
N
N    /* maximum values of exact-width signed integer types */
N#define INT8_MAX                    127
N#define INT16_MAX                 32767
N#define INT32_MAX            2147483647
N#define INT64_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum values of exact-width unsigned integer types */
N#define UINT8_MAX                   255
N#define UINT16_MAX                65535
N#define UINT32_MAX           4294967295u
N#define UINT64_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.2.2 */
N
N    /* minimum values of minimum-width signed integer types */
N#define INT_LEAST8_MIN                   -128
N#define INT_LEAST16_MIN                -32768
N#define INT_LEAST32_MIN          (~0x7fffffff)
N#define INT_LEAST64_MIN  __ESCAPE__(~0x7fffffffffffffffll)
N
N    /* maximum values of minimum-width signed integer types */
N#define INT_LEAST8_MAX                    127
N#define INT_LEAST16_MAX                 32767
N#define INT_LEAST32_MAX            2147483647
N#define INT_LEAST64_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum values of minimum-width unsigned integer types */
N#define UINT_LEAST8_MAX                   255
N#define UINT_LEAST16_MAX                65535
N#define UINT_LEAST32_MAX           4294967295u
N#define UINT_LEAST64_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.2.3 */
N
N    /* minimum values of fastest minimum-width signed integer types */
N#define INT_FAST8_MIN           (~0x7fffffff)
N#define INT_FAST16_MIN          (~0x7fffffff)
N#define INT_FAST32_MIN          (~0x7fffffff)
N#define INT_FAST64_MIN  __ESCAPE__(~0x7fffffffffffffffll)
N
N    /* maximum values of fastest minimum-width signed integer types */
N#define INT_FAST8_MAX             2147483647
N#define INT_FAST16_MAX            2147483647
N#define INT_FAST32_MAX            2147483647
N#define INT_FAST64_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum values of fastest minimum-width unsigned integer types */
N#define UINT_FAST8_MAX            4294967295u
N#define UINT_FAST16_MAX           4294967295u
N#define UINT_FAST32_MAX           4294967295u
N#define UINT_FAST64_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.2.4 */
N
N    /* minimum value of pointer-holding signed integer type */
N#define INTPTR_MIN (~0x7fffffff)
N
N    /* maximum value of pointer-holding signed integer type */
N#define INTPTR_MAX   2147483647
N
N    /* maximum value of pointer-holding unsigned integer type */
N#define UINTPTR_MAX  4294967295u
N
N    /* 7.18.2.5 */
N
N    /* minimum value of greatest-width signed integer type */
N#define INTMAX_MIN  __ESCAPE__(~0x7fffffffffffffffll)
N
N    /* maximum value of greatest-width signed integer type */
N#define INTMAX_MAX  __ESCAPE__(9223372036854775807ll)
N
N    /* maximum value of greatest-width unsigned integer type */
N#define UINTMAX_MAX __ESCAPE__(18446744073709551615ull)
N
N    /* 7.18.3 */
N
N    /* limits of ptrdiff_t */
N#define PTRDIFF_MIN (~0x7fffffff)
N#define PTRDIFF_MAX   2147483647
N
N    /* limits of sig_atomic_t */
N#define SIG_ATOMIC_MIN (~0x7fffffff)
N#define SIG_ATOMIC_MAX   2147483647
N
N    /* limit of size_t */
N#define SIZE_MAX 4294967295u
N
N    /* limits of wchar_t */
N    /* NB we have to undef and redef because they're defined in both
N     * stdint.h and wchar.h */
N#undef WCHAR_MIN
N#undef WCHAR_MAX
N
N#if defined(__WCHAR32)
X#if 0L
S  #define WCHAR_MIN   0
S  #define WCHAR_MAX   0xffffffffU
N#else
N  #define WCHAR_MIN   0
N  #define WCHAR_MAX   65535
N#endif
N
N    /* limits of wint_t */
N#define WINT_MIN (~0x7fffffff)
N#define WINT_MAX 2147483647
N
N#endif /* __STDC_LIMIT_MACROS */
N
N#if !defined(__cplusplus) || defined(__STDC_CONSTANT_MACROS)
X#if !0L || 0L
N
N    /* 7.18.4.1 macros for minimum-width integer constants */
N#define INT8_C(x)   (x)
N#define INT16_C(x)  (x)
N#define INT32_C(x)  (x)
N#define INT64_C(x)  __ESCAPE__(x ## ll)
N
N#define UINT8_C(x)  (x ## u)
N#define UINT16_C(x) (x ## u)
N#define UINT32_C(x) (x ## u)
N#define UINT64_C(x) __ESCAPE__(x ## ull)
N
N    /* 7.18.4.2 macros for greatest-width integer constants */
N#define INTMAX_C(x)  __ESCAPE__(x ## ll)
N#define UINTMAX_C(x) __ESCAPE__(x ## ull)
N
N#endif /* __STDC_CONSTANT_MACROS */
N
N    #ifdef __cplusplus
S         }  /* extern "C" */
S      }  /* namespace std */
N    #endif /* __cplusplus */
N  #endif /* __STDINT_DECLS */
N
N  #ifdef __cplusplus
S    #ifndef __STDINT_NO_EXPORTS
S      using ::std::int8_t;
S      using ::std::int16_t;
S      using ::std::int32_t;
S      using ::std::int64_t;
S      using ::std::uint8_t;
S      using ::std::uint16_t;
S      using ::std::uint32_t;
S      using ::std::uint64_t;
S      using ::std::int_least8_t;
S      using ::std::int_least16_t;
S      using ::std::int_least32_t;
S      using ::std::int_least64_t;
S      using ::std::uint_least8_t;
S      using ::std::uint_least16_t;
S      using ::std::uint_least32_t;
S      using ::std::uint_least64_t;
S      using ::std::int_fast8_t;
S      using ::std::int_fast16_t;
S      using ::std::int_fast32_t;
S      using ::std::int_fast64_t;
S      using ::std::uint_fast8_t;
S      using ::std::uint_fast16_t;
S      using ::std::uint_fast32_t;
S      using ::std::uint_fast64_t;
S      using ::std::intptr_t;
S      using ::std::uintptr_t;
S      using ::std::intmax_t;
S      using ::std::uintmax_t;
S    #endif 
N  #endif /* __cplusplus */
N
N#endif /* __stdint_h */
N
N/* end of stdint.h */
N
N
N
L 20 "..\..\common\src\BSP\ThirdParty\yaffs2\include\div64.h" 2
N#include "linux\types.h"
N
Nextern uint32_t __div64_32(uint64_t *dividend, uint32_t divisor);
N
N/* The unnecessary pointer compare is there
N * to check for type safety (n must be 64bit)
N */
N#define do_div(n,base) (n = n/base)
N
N#if 0
S#define do_div(n,base) ({   \
S	uint32_t __base = (base);   \
S	uint32_t __rem; \
S	(void)(((typeof((n)) *)0) == ((uint64_t *)0));  \
S	if (((n) >> 32) == 0) { \
S		__rem = (uint32_t)(n) % __base; \
S		(n) = (uint32_t)(n) / __base;   \
S	} else  \
S		__rem = __div64_32(&(n), __base);   \
S	__rem;  \
S})
X#define do_div(n,base) ({   	uint32_t __base = (base);   	uint32_t __rem; 	(void)(((typeof((n)) *)0) == ((uint64_t *)0));  	if (((n) >> 32) == 0) { 		__rem = (uint32_t)(n) % __base; 		(n) = (uint32_t)(n) / __base;   	} else  		__rem = __div64_32(&(n), __base);   	__rem;  })
S
S/* Wrapper for do_div(). Doesn't modify dividend and returns
S * the result, not reminder.
S */
Sstatic __inline uint64_t lldiv(uint64_t dividend, uint32_t divisor)
S{
S	uint64_t __res = dividend;
S	do_div(__res, divisor);
S	return(__res);
S}
N#endif
N#endif /* _ASM_GENERIC_DIV64_H */
L 12 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd.h" 2
N#include "linux\mtd-abi.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd-abi.h" 1
N/*
N * $Id: mtd-abi.h,v 1.13 2005/11/07 11:14:56 gleixner Exp $
N *
N * Portions of MTD ABI definition which are shared by kernel and user space
N */
N
N#ifndef __MTD_ABI_H__
N#define __MTD_ABI_H__
N
N#include <stdint.h>
N
N#include <linux/compiler.h>
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux/compiler.h" 1
N#ifndef __LINUX_COMPILER_H
N#define __LINUX_COMPILER_H
N
N#ifndef __ASSEMBLY__
N
N#ifdef __CHECKER__
S# define __user		__attribute__((noderef, address_space(1)))
S# define __kernel	/* default address space */
S# define __safe		__attribute__((safe))
S# define __force	__attribute__((force))
S# define __nocast	__attribute__((nocast))
S# define __iomem	__attribute__((noderef, address_space(2)))
S# define __acquires(x)	__attribute__((context(x,0,1)))
S# define __releases(x)	__attribute__((context(x,1,0)))
S# define __acquire(x)	__context__(x,1)
S# define __release(x)	__context__(x,-1)
S# define __cond_lock(x,c)	((c) ? ({ __acquire(x); 1; }) : 0)
Sextern void __chk_user_ptr(const volatile void __user *);
Sextern void __chk_io_ptr(const volatile void __iomem *);
N#else
N# define __user
N# define __kernel
N# define __safe
N# define __force
N# define __nocast
N# define __iomem
N# define __chk_user_ptr(x) (void)0
N# define __chk_io_ptr(x) (void)0
N# define __builtin_warning(x, y...) (1)
N# define __acquires(x)
N# define __releases(x)
N# define __acquire(x) (void)0
N# define __release(x) (void)0
N# define __cond_lock(x,c) (c)
N#endif
N
N#ifdef __KERNEL__
S
S#ifdef __GNUC__
S#include <linux/compiler-gcc.h>
S#endif
S
S#define notrace __attribute__((no_instrument_function))
S
S/* Intel compiler defines __GNUC__. So we will overwrite implementations
S * coming from above header files here
S */
S#ifdef __INTEL_COMPILER
S# include <linux/compiler-intel.h>
S#endif
S
S/*
S * Generic compiler-dependent macros required for kernel
S * build go below this comment. Actual compiler/compiler version
S * specific implementations come from the above header files
S */
S
Sstruct ftrace_branch_data {
S	const char *func;
S	const char *file;
S	unsigned line;
S	union {
S		struct {
S			unsigned long correct;
S			unsigned long incorrect;
S		};
S		struct {
S			unsigned long miss;
S			unsigned long hit;
S		};
S		unsigned long miss_hit[2];
S	};
S};
S
S/*
S * Note: DISABLE_BRANCH_PROFILING can be used by special lowlevel code
S * to disable branch tracing on a per file basis.
S */
S#if defined(CONFIG_TRACE_BRANCH_PROFILING) \
S    && !defined(DISABLE_BRANCH_PROFILING) && !defined(__CHECKER__)
X#if defined(CONFIG_TRACE_BRANCH_PROFILING)     && !defined(DISABLE_BRANCH_PROFILING) && !defined(__CHECKER__)
Svoid ftrace_likely_update(struct ftrace_branch_data *f, int val, int expect);
S
S#define likely_notrace(x)	__builtin_expect(!!(x), 1)
S#define unlikely_notrace(x)	__builtin_expect(!!(x), 0)
S
S#define __branch_check__(x, expect) ({					\
S			int ______r;					\
S			static struct ftrace_branch_data		\
S				__attribute__((__aligned__(4)))		\
S				__attribute__((section("_ftrace_annotated_branch"))) \
S				______f = {				\
S				.func = __func__,			\
S				.file = __FILE__,			\
S				.line = __LINE__,			\
S			};						\
S			______r = likely_notrace(x);			\
S			ftrace_likely_update(&______f, ______r, expect); \
S			______r;					\
S		})
X#define __branch_check__(x, expect) ({								int ______r;								static struct ftrace_branch_data						__attribute__((__aligned__(4)))						__attribute__((section("_ftrace_annotated_branch"))) 				______f = {								.func = __func__,							.file = __FILE__,							.line = __LINE__,						};									______r = likely_notrace(x);						ftrace_likely_update(&______f, ______r, expect); 			______r;							})
S
S/*
S * Using __builtin_constant_p(x) to ignore cases where the return
S * value is always the same.  This idea is taken from a similar patch
S * written by Daniel Walker.
S */
S# ifndef likely
S#  define likely(x)	(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 1))
S# endif
S# ifndef unlikely
S#  define unlikely(x)	(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 0))
S# endif
S
S#ifdef CONFIG_PROFILE_ALL_BRANCHES
S/*
S * "Define 'is'", Bill Clinton
S * "Define 'if'", Steven Rostedt
S */
S#define if(cond, ...) __trace_if( (cond , ## __VA_ARGS__) )
S#define __trace_if(cond) \
S	if (__builtin_constant_p((cond)) ? !!(cond) :			\
S	({								\
S		int ______r;						\
S		static struct ftrace_branch_data			\
S			__attribute__((__aligned__(4)))			\
S			__attribute__((section("_ftrace_branch")))	\
S			______f = {					\
S				.func = __func__,			\
S				.file = __FILE__,			\
S				.line = __LINE__,			\
S			};						\
S		______r = !!(cond);					\
S		______f.miss_hit[______r]++;					\
S		______r;						\
S	}))
X#define __trace_if(cond) 	if (__builtin_constant_p((cond)) ? !!(cond) :				({										int ______r;								static struct ftrace_branch_data						__attribute__((__aligned__(4)))						__attribute__((section("_ftrace_branch")))				______f = {									.func = __func__,							.file = __FILE__,							.line = __LINE__,						};								______r = !!(cond);							______f.miss_hit[______r]++;							______r;							}))
S#endif /* CONFIG_PROFILE_ALL_BRANCHES */
S
S#else
S# define likely(x)	__builtin_expect(!!(x), 1)
S# define unlikely(x)	__builtin_expect(!!(x), 0)
S#endif
S
S/* Optimization barrier */
S#ifndef barrier
S# define barrier() __memory_barrier()
S#endif
S
S/* Unreachable code */
S#ifndef unreachable
S# define unreachable() do { } while (1)
S#endif
S
S#ifndef RELOC_HIDE
S# define RELOC_HIDE(ptr, off)					\
S  ({ unsigned long __ptr;					\
S     __ptr = (unsigned long) (ptr);				\
S    (typeof(ptr)) (__ptr + (off)); })
X# define RELOC_HIDE(ptr, off)					  ({ unsigned long __ptr;					     __ptr = (unsigned long) (ptr);				    (typeof(ptr)) (__ptr + (off)); })
S#endif
S
N#endif /* __KERNEL__ */
N
N#endif /* __ASSEMBLY__ */
N
N#ifdef __KERNEL__
S/*
S * Allow us to mark functions as 'deprecated' and have gcc emit a nice
S * warning for each use, in hopes of speeding the functions removal.
S * Usage is:
S * 		int __deprecated foo(void)
S */
S#ifndef __deprecated
S# define __deprecated		/* unimplemented */
S#endif
S
S#ifdef MODULE
S#define __deprecated_for_modules __deprecated
S#else
S#define __deprecated_for_modules
S#endif
S
S#ifndef __must_check
S#define __must_check
S#endif
S
S#ifndef CONFIG_ENABLE_MUST_CHECK
S#undef __must_check
S#define __must_check
S#endif
S#ifndef CONFIG_ENABLE_WARN_DEPRECATED
S#undef __deprecated
S#undef __deprecated_for_modules
S#define __deprecated
S#define __deprecated_for_modules
S#endif
S
S/*
S * Allow us to avoid 'defined but not used' warnings on functions and data,
S * as well as force them to be emitted to the assembly file.
S *
S * As of gcc 3.4, static functions that are not marked with attribute((used))
S * may be elided from the assembly file.  As of gcc 3.4, static data not so
S * marked will not be elided, but this may change in a future gcc version.
S *
S * NOTE: Because distributions shipped with a backported unit-at-a-time
S * compiler in gcc 3.3, we must define __used to be __attribute__((used))
S * for gcc >=3.3 instead of 3.4.
S *
S * In prior versions of gcc, such functions and data would be emitted, but
S * would be warned about except with attribute((unused)).
S *
S * Mark functions that are referenced only in inline assembly as __used so
S * the code is emitted even though it appears to be unreferenced.
S */
S#ifndef __used
S# define __used			/* unimplemented */
S#endif
S
S#ifndef __maybe_unused
S# define __maybe_unused		/* unimplemented */
S#endif
S
S#ifndef __always_unused
S# define __always_unused	/* unimplemented */
S#endif
S
S#ifndef noinline
S#define noinline
S#endif
S
S/*
S * Rather then using noinline to prevent stack consumption, use
S * noinline_for_stack instead.  For documentaiton reasons.
S */
S#define noinline_for_stack noinline
S
S#ifndef __always_inline
S#define __always_inline inline
S#endif
S
N#endif /* __KERNEL__ */
N
N/*
N * From the GCC manual:
N *
N * Many functions do not examine any values except their arguments,
N * and have no effects except the return value.  Basically this is
N * just slightly more strict class than the `pure' attribute above,
N * since function is not allowed to read global memory.
N *
N * Note that a function that has pointer arguments and examines the
N * data pointed to must _not_ be declared `const'.  Likewise, a
N * function that calls a non-`const' function usually must not be
N * `const'.  It does not make sense for a `const' function to return
N * `void'.
N */
N#ifndef __attribute_const__
N# define __attribute_const__	/* unimplemented */
N#endif
N
N/*
N * Tell gcc if a function is cold. The compiler will assume any path
N * directly leading to the call is unlikely.
N */
N
N#ifndef __cold
N#define __cold
N#endif
N
N/* Simple shorthand for a section definition */
N#ifndef __section
N# define __section(S) __attribute__ ((__section__(#S)))
N#endif
N
N/* Are two types/vars the same type (ignoring qualifiers)? */
N#ifndef __same_type
N# define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
N#endif
N
N/* Compile time object size, -1 for unknown */
N#ifndef __compiletime_object_size
N# define __compiletime_object_size(obj) -1
N#endif
N#ifndef __compiletime_warning
N# define __compiletime_warning(message)
N#endif
N#ifndef __compiletime_error
N# define __compiletime_error(message)
N#endif
N
N/*
N * Prevent the compiler from merging or refetching accesses.  The compiler
N * is also forbidden from reordering successive instances of ACCESS_ONCE(),
N * but only when the compiler is aware of some particular ordering.  One way
N * to make the compiler aware of ordering is to put the two invocations of
N * ACCESS_ONCE() in different C statements.
N *
N * This macro does absolutely -nothing- to prevent the CPU from reordering,
N * merging, or refetching absolutely anything at any time.  Its main intended
N * use is to mediate communication between process-level code and irq/NMI
N * handlers, all running on the same CPU.
N */
N#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
N
N#endif /* __LINUX_COMPILER_H */
L 13 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd-abi.h" 2
N
Nstruct erase_info_user {
N	uint32_t start;
N	uint32_t length;
N};
N
Nstruct mtd_oob_buf {
N	uint32_t start;
N	uint32_t length;
N	unsigned char __user *ptr;
X	unsigned char  *ptr;
N};
N
N#define MTD_ABSENT		0
N#define MTD_RAM			1
N#define MTD_ROM			2
N#define MTD_NORFLASH		3
N#define MTD_NANDFLASH		4
N#define MTD_DATAFLASH		6
N#define MTD_UBIVOLUME		7
N
N#define MTD_WRITEABLE		0x400	/* Device is writeable */
N#define MTD_BIT_WRITEABLE	0x800	/* Single bits can be flipped */
N#define MTD_NO_ERASE		0x1000	/* No erase necessary */
N#define MTD_STUPID_LOCK		0x2000	/* Always locked after reset */
N
N/* Some common devices / combinations of capabilities */
N#define MTD_CAP_ROM		0
N#define MTD_CAP_RAM		(MTD_WRITEABLE | MTD_BIT_WRITEABLE | MTD_NO_ERASE)
N#define MTD_CAP_NORFLASH	(MTD_WRITEABLE | MTD_BIT_WRITEABLE)
N#define MTD_CAP_NANDFLASH	(MTD_WRITEABLE)
N
N/* ECC byte placement */
N#define MTD_NANDECC_OFF		0	/* Switch off ECC (Not recommended) */
N#define MTD_NANDECC_PLACE	1	/* Use the given placement in the structure (YAFFS1 legacy mode) */
N#define MTD_NANDECC_AUTOPLACE	2	/* Use the default placement scheme */
N#define MTD_NANDECC_PLACEONLY	3	/* Use the given placement in the structure (Do not store ecc result on read) */
N#define MTD_NANDECC_AUTOPL_USR	4	/* Use the given autoplacement scheme rather than using the default */
N
N/* OTP mode selection */
N#define MTD_OTP_OFF		0
N#define MTD_OTP_FACTORY		1
N#define MTD_OTP_USER		2
N
Nstruct mtd_info_user {
N	uint8_t type;
N	uint32_t flags;
N	uint32_t size;			/* Total size of the MTD */
N	uint32_t erasesize;
N	uint32_t writesize;
N	uint32_t oobsize;		/* Amount of OOB data per block (e.g. 16) */
N	/* The below two fields are obsolete and broken, do not use them
N	 * (TODO: remove at some point) */
N	uint32_t ecctype;
N	uint32_t eccsize;
N};
N
Nstruct region_info_user {
N	uint32_t offset;		/* At which this region starts,
N					 * from the beginning of the MTD */
N	uint32_t erasesize;		/* For this region */
N	uint32_t numblocks;		/* Number of blocks in this region */
N	uint32_t regionindex;
N};
N
Nstruct otp_info {
N	uint32_t start;
N	uint32_t length;
N	uint32_t locked;
N};
N
N#define MEMGETINFO		_IOR('M', 1, struct mtd_info_user)
N#define MEMERASE		_IOW('M', 2, struct erase_info_user)
N#define MEMWRITEOOB		_IOWR('M', 3, struct mtd_oob_buf)
N#define MEMREADOOB		_IOWR('M', 4, struct mtd_oob_buf)
N#define MEMLOCK			_IOW('M', 5, struct erase_info_user)
N#define MEMUNLOCK		_IOW('M', 6, struct erase_info_user)
N#define MEMGETREGIONCOUNT	_IOR('M', 7, int)
N#define MEMGETREGIONINFO	_IOWR('M', 8, struct region_info_user)
N#define MEMSETOOBSEL		_IOW('M', 9, struct nand_oobinfo)
N#define MEMGETOOBSEL		_IOR('M', 10, struct nand_oobinfo)
N#define MEMGETBADBLOCK		_IOW('M', 11, loff_t)
N#define MEMSETBADBLOCK		_IOW('M', 12, loff_t)
N#define OTPSELECT		_IOR('M', 13, int)
N#define OTPGETREGIONCOUNT	_IOW('M', 14, int)
N#define OTPGETREGIONINFO	_IOW('M', 15, struct otp_info)
N#define OTPLOCK			_IOR('M', 16, struct otp_info)
N#define ECCGETLAYOUT		_IOR('M', 17, struct nand_ecclayout)
N#define ECCGETSTATS		_IOR('M', 18, struct mtd_ecc_stats)
N#define MTDFILEMODE		_IO('M', 19)
N
N/*
N * Obsolete legacy interface. Keep it in order not to break userspace
N * interfaces
N */
Nstruct nand_oobinfo {
N	uint32_t useecc;
N	uint32_t eccbytes;
N	uint32_t oobfree[8][2];
N	uint32_t eccpos[48];
N};
N
Nstruct nand_oobfree {
N	uint32_t offset;
N	uint32_t length;
N};
N
N#define MTD_MAX_OOBFREE_ENTRIES	8
N/*
N * ECC layout control structure. Exported to userspace for
N * diagnosis and to allow creation of raw images
N */
Nstruct nand_ecclayout {
N	uint32_t eccbytes;
N	uint32_t eccpos[128];
N	uint32_t oobavail;
N	struct nand_oobfree oobfree[MTD_MAX_OOBFREE_ENTRIES];
X	struct nand_oobfree oobfree[8];
N};
N
N/**
N * struct mtd_ecc_stats - error correction stats
N *
N * @corrected:	number of corrected bits
N * @failed:	number of uncorrectable errors
N * @badblocks:	number of bad blocks in this partition
N * @bbtblocks:	number of blocks reserved for bad block tables
N */
Nstruct mtd_ecc_stats {
N	uint32_t corrected;
N	uint32_t failed;
N	uint32_t badblocks;
N	uint32_t bbtblocks;
N};
N
N/*
N * Read/write file modes for access to MTD
N */
Nenum mtd_file_modes {
N	MTD_MODE_NORMAL = MTD_OTP_OFF,
X	MTD_MODE_NORMAL = 0,
N	MTD_MODE_OTP_FACTORY = MTD_OTP_FACTORY,
X	MTD_MODE_OTP_FACTORY = 1,
N	MTD_MODE_OTP_USER = MTD_OTP_USER,
X	MTD_MODE_OTP_USER = 2,
N	MTD_MODE_RAW,
N};
N
N#endif /* __MTD_ABI_H__ */
L 13 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\mtd.h" 2
N
N#define MTD_CHAR_MAJOR 90
N#define MTD_BLOCK_MAJOR 31
N#define MAX_MTD_DEVICES 32
N
N#define MTD_ERASE_PENDING	0x01
N#define MTD_ERASING		0x02
N#define MTD_ERASE_SUSPEND	0x04
N#define MTD_ERASE_DONE          0x08
N#define MTD_ERASE_FAILED        0x10
N
N#define MTD_FAIL_ADDR_UNKNOWN	-1LL
N
N/*
N * Enumeration for NAND/OneNAND flash chip state
N */
Nenum {
N	FL_READY,
N	FL_READING,
N	FL_WRITING,
N	FL_ERASING,
N	FL_SYNCING,
N	FL_CACHEDPRG,
N	FL_RESETING,
N	FL_UNLOCKING,
N	FL_LOCKING,
N	FL_PM_SUSPENDED,
N};
N
N/* If the erase fails, fail_addr might indicate exactly which block failed.  If
N   fail_addr = MTD_FAIL_ADDR_UNKNOWN, the failure was not at the device level or was not
N   specific to any particular block. */
Nstruct erase_info {
N	struct mtd_info *mtd;
N	uint64_t addr;
N	uint64_t len;
N	uint64_t fail_addr;
N	u_long time;
N	u_long retries;
N	u_int dev;
N	u_int cell;
N	void (*callback) (struct erase_info *self);
N	u_long priv;
N	u_char state;
N	struct erase_info *next;
N	int scrub;
N};
N
Nstruct mtd_erase_region_info {
N	uint64_t offset;			/* At which this region starts, from the beginning of the MTD */
N	u_int32_t erasesize;		/* For this region */
N	u_int32_t numblocks;		/* Number of blocks of erasesize in this region */
N	unsigned long *lockmap;		/* If keeping bitmap of locks */
N};
N
N/*
N * oob operation modes
N *
N * MTD_OOB_PLACE:	oob data are placed at the given offset
N * MTD_OOB_AUTO:	oob data are automatically placed at the free areas
N *			which are defined by the ecclayout
N * MTD_OOB_RAW:		mode to read raw data+oob in one chunk. The oob data
N *			is inserted into the data. Thats a raw image of the
N *			flash contents.
N */
Ntypedef enum {
N	MTD_OOB_PLACE,
N	MTD_OOB_AUTO,
N	MTD_OOB_RAW,
N} mtd_oob_mode_t;
N
N/**
N * struct mtd_oob_ops - oob operation operands
N * @mode:	operation mode
N *
N * @len:	number of data bytes to write/read
N *
N * @retlen:	number of data bytes written/read
N *
N * @ooblen:	number of oob bytes to write/read
N * @oobretlen:	number of oob bytes written/read
N * @ooboffs:	offset of oob data in the oob area (only relevant when
N *		mode = MTD_OOB_PLACE)
N * @datbuf:	data buffer - if NULL only oob data are read/written
N * @oobbuf:	oob data buffer
N *
N * Note, it is allowed to read more then one OOB area at one go, but not write.
N * The interface assumes that the OOB write requests program only one page's
N * OOB area.
N */
Nstruct mtd_oob_ops {
N	mtd_oob_mode_t	mode;
N	size_t		len;
N	size_t		retlen;
N	size_t		ooblen;
N	size_t		oobretlen;
N	uint32_t	ooboffs;
N	uint8_t		*datbuf;
N	uint8_t		*oobbuf;
N};
N
Nstruct mtd_info {
N	u_char type;
N	u_int32_t flags;
N	uint64_t size;	 /* Total size of the MTD */
N
N	/* "Major" erase size for the device. Naïve users may take this
N	 * to be the only erase size available, or may use the more detailed
N	 * information below if they desire
N	 */
N	u_int32_t erasesize;
N	/* Minimal writable flash unit size. In case of NOR flash it is 1 (even
N	 * though individual bits can be cleared), in case of NAND flash it is
N	 * one NAND page (or half, or one-fourths of it), in case of ECC-ed NOR
N	 * it is of ECC block size, etc. It is illegal to have writesize = 0.
N	 * Any driver registering a struct mtd_info must ensure a writesize of
N	 * 1 or larger.
N	 */
N	u_int32_t writesize;
N
N	u_int32_t oobsize;   /* Amount of OOB data per block (e.g. 16) */
N	u_int32_t oobavail;  /* Available OOB bytes per block */
N
N	/* Kernel-only stuff starts here. */
N	const char *name;
N	int index;
N
N	/* ecc layout structure pointer - read only ! */
N	struct nand_ecclayout *ecclayout;
N
N	/* Data for variable erase regions. If numeraseregions is zero,
N	 * it means that the whole device has erasesize as given above.
N	 */
N	int numeraseregions;
N	struct mtd_erase_region_info *eraseregions;
N
N	/*
N	 * Erase is an asynchronous operation.  Device drivers are supposed
N	 * to call instr->callback() whenever the operation completes, even
N	 * if it completes with a failure.
N	 * Callers are supposed to pass a callback function and wait for it
N	 * to be called before writing to the block.
N	 */
N	int (*erase) (struct mtd_info *mtd, struct erase_info *instr);
N
N	/* This stuff for eXecute-In-Place */
N	/* phys is optional and may be set to NULL */
N	int (*point) (struct mtd_info *mtd, loff_t from, size_t len,
N			size_t *retlen, void **virt, phys_addr_t *phys);
N
N	/* We probably shouldn't allow XIP if the unpoint isn't a NULL */
N	void (*unpoint) (struct mtd_info *mtd, loff_t from, size_t len);
N
N
N	int (*read) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*write) (struct mtd_info *mtd, loff_t to, size_t len, size_t *retlen, const u_char *buf);
N
N	/* In blackbox flight recorder like scenarios we want to make successful
N	   writes in interrupt context. panic_write() is only intended to be
N	   called when its known the kernel is about to panic and we need the
N	   write to succeed. Since the kernel is not going to be running for much
N	   longer, this function can break locks and delay to ensure the write
N	   succeeds (but not sleep). */
N
N	int (*panic_write) (struct mtd_info *mtd, loff_t to, size_t len, size_t *retlen, const u_char *buf);
N
N	int (*read_oob) (struct mtd_info *mtd, loff_t from,
N			 struct mtd_oob_ops *ops);
N	int (*write_oob) (struct mtd_info *mtd, loff_t to,
N			 struct mtd_oob_ops *ops);
N
N	/*
N	 * Methods to access the protection register area, present in some
N	 * flash devices. The user data is one time programmable but the
N	 * factory data is read only.
N	 */
N	int (*get_fact_prot_info) (struct mtd_info *mtd, struct otp_info *buf, size_t len);
N	int (*read_fact_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*get_user_prot_info) (struct mtd_info *mtd, struct otp_info *buf, size_t len);
N	int (*read_user_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*write_user_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf);
N	int (*lock_user_prot_reg) (struct mtd_info *mtd, loff_t from, size_t len);
N
N	/* Sync */
N	void (*sync) (struct mtd_info *mtd);
N
N	/* Chip-supported device locking */
N	int (*lock) (struct mtd_info *mtd, loff_t ofs, uint64_t len);
N	int (*unlock) (struct mtd_info *mtd, loff_t ofs, uint64_t len);
N
N	/* Bad block management functions */
N	int (*block_isbad) (struct mtd_info *mtd, loff_t ofs);
N	int (*block_markbad) (struct mtd_info *mtd, loff_t ofs);
N
N	/* ECC status information */
N	struct mtd_ecc_stats ecc_stats;
N	/* Subpage shift (NAND) */
N	int subpage_sft;
N
N	void *priv;
N
N	struct module *owner;
N	int usecount;
N
N	/* If the driver is something smart, like UBI, it may need to maintain
N	 * its own reference counting. The below functions are only for driver.
N	 * The driver may register its callbacks. These callbacks are not
N	 * supposed to be called by MTD users */
N	int (*get_device) (struct mtd_info *mtd);
N	void (*put_device) (struct mtd_info *mtd);
N	u_char rw_oob;
N	u_char skipfirstblk;
N};
N
Nstatic __inline uint32_t mtd_div_by_eb(uint64_t sz, struct mtd_info *mtd)
N{
N	do_div(sz, mtd->erasesize);
X	(sz = sz/mtd->erasesize);
N	return sz;
N}
N
Nstatic __inline uint32_t mtd_mod_by_eb(uint64_t sz, struct mtd_info *mtd)
N{
N	return do_div(sz, mtd->erasesize);
X	return (sz = sz/mtd->erasesize);
N}
N
N	/* Kernel-side ioctl definitions */
N
Nextern int add_mtd_device(struct mtd_info *mtd);
Nextern int del_mtd_device (struct mtd_info *mtd);
N
Nextern struct mtd_info *get_mtd_device(struct mtd_info *mtd, int num);
Nextern struct mtd_info *get_mtd_device_nm(const char *name);
N
Nextern void put_mtd_device(struct mtd_info *mtd);
Nextern void mtd_get_len_incl_bad(struct mtd_info *mtd, uint64_t offset,
N				 const uint64_t length, uint64_t *len_incl_bad,
N				 int *truncated);
N
Nvoid mtd_erase_callback(struct erase_info *instr);
N
N/*
N * Debugging macro and defines
N */
N#define MTD_DEBUG_LEVEL0	(0)	/* Quiet   */
N#define MTD_DEBUG_LEVEL1	(1)	/* Audible */
N#define MTD_DEBUG_LEVEL2	(2)	/* Loud    */
N#define MTD_DEBUG_LEVEL3	(3)	/* Noisy   */
N
N#ifdef CONFIG_MTD_DEBUG
S#define MTDDEBUG(n, args...)				\
S	do {						\
S		if (n <= CONFIG_MTD_DEBUG_VERBOSE)	\
S			sysprintf(KERN_INFO args);		\
S	} while(0)
X#define MTDDEBUG(n, args...)					do {								if (n <= CONFIG_MTD_DEBUG_VERBOSE)				sysprintf(KERN_INFO args);			} while(0)
N#else /* CONFIG_MTD_DEBUG */
N#define MTDDEBUG(n, args...)				\
N	do {						\
N		if (0)					\
N			sysprintf(args);		\
N	} while(0)
X#define MTDDEBUG(n, args...)					do {								if (0)								sysprintf(args);			} while(0)
N#endif /* CONFIG_MTD_DEBUG */
N
N#endif /* __MTD_MTD_H__ */
L 19 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N#include "linux\partitions.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\partitions.h" 1
N/*
N * MTD partitioning layer definitions
N *
N * (C) 2000 Nicolas Pitre <nico@cam.org>
N *
N * This code is GPL
N *
N * $Id: partitions.h,v 1.17 2005/11/07 11:14:55 gleixner Exp $
N */
N
N#ifndef MTD_PARTITIONS_H
N#define MTD_PARTITIONS_H
N
N#include "linux\types.h"
N
N
N/*
N * Partition definition structure:
N *
N * An array of struct partition is passed along with a MTD object to
N * add_mtd_partitions() to create them.
N *
N * For each partition, these fields are available:
N * name: string that will be used to label the partition's MTD device.
N * size: the partition size; if defined as MTDPART_SIZ_FULL, the partition
N * 	will extend to the end of the master MTD device.
N * offset: absolute starting position within the master MTD device; if
N * 	defined as MTDPART_OFS_APPEND, the partition will start where the
N * 	previous one ended; if MTDPART_OFS_NXTBLK, at the next erase block.
N * mask_flags: contains flags that have to be masked (removed) from the
N * 	master MTD flag set for the corresponding MTD partition.
N * 	For example, to force a read-only partition, simply adding
N * 	MTD_WRITEABLE to the mask_flags will do the trick.
N *
N * Note: writeable partitions require their size and offset be
N * erasesize aligned (e.g. use MTDPART_OFS_NEXTBLK).
N */
N
Nstruct mtd_partition {
N	char *name;			/* identifier string */
N	uint64_t size;			/* partition size */
N	uint64_t offset;		/* offset within the master MTD space */
N	u_int32_t mask_flags;		/* master MTD flags to mask out for this partition */
N	struct nand_ecclayout *ecclayout;	/* out of band layout for this partition (NAND only)*/
N	struct mtd_info **mtdp;		/* pointer to store the MTD object */
N};
N
N#define MTDPART_OFS_NXTBLK	(-2)
N#define MTDPART_OFS_APPEND	(-1)
N#define MTDPART_SIZ_FULL	(0)
N
N
Nint add_mtd_partitions(struct mtd_info *, const struct mtd_partition *, int);
Nint del_mtd_partitions(struct mtd_info *);
N
N#if 0
S/*
S * Functions dealing with the various ways of partitioning the space
S */
S
Sstruct mtd_part_parser {
S	struct list_head list;
S	struct module *owner;
S	const char *name;
S	int (*parse_fn)(struct mtd_info *, struct mtd_partition **, unsigned long);
S};
S
Sextern int register_mtd_parser(struct mtd_part_parser *parser);
Sextern int deregister_mtd_parser(struct mtd_part_parser *parser);
Sextern int parse_mtd_partitions(struct mtd_info *master, const char **types,
S				struct mtd_partition **pparts, unsigned long origin);
S
S#define put_partition_parser(p) do { module_put((p)->owner); } while(0)
S
Sstruct device;
Sstruct device_node;
S
Sint __devinit of_mtd_parse_partitions(struct device *dev,
S				      struct mtd_info *mtd,
S				      struct device_node *node,
S				      struct mtd_partition **pparts);
N#endif
N
N#endif
L 20 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N#include "linux\compat.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 1
N#ifndef _LINUX_COMPAT_H_
N#define _LINUX_COMPAT_H_
N
N/* Scheduler includes. */
N#include "FreeRTOS.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef INC_FREERTOS_H
N#define INC_FREERTOS_H
N
N/*
N * Include the generic headers required for the FreeRTOS port being used.
N */
N#include <stddef.h>
L 1 "C:\Keil\ARM\ARMCC\bin\..\include\stddef.h" 1
N/* stddef.h: ANSI 'C' (X3J11 Oct 88) library header, section 4.1.4 */
N
N/* Copyright (C) ARM Ltd., 1999
N * All rights reserved
N * RCS $Revision: 178085 $
N * Checkin $Date: 2012-12-11 14:54:17 +0000 (Tue, 11 Dec 2012) $
N * Revising $Author: agrant $
N */
N
N/* Copyright (C) Codemist Ltd., 1988                            */
N/* Copyright 1991 ARM Limited. All rights reserved.             */
N/* version 0.05 */
N
N/*
N * The following types and macros are defined in several headers referred to in
N * the descriptions of the functions declared in that header. They are also
N * defined in this header file.
N */
N
N#ifndef __stddef_h
N#define __stddef_h
N#define __ARMCLIB_VERSION 5030076
N
N  #ifndef __STDDEF_DECLS
N  #define __STDDEF_DECLS
N    #undef __CLIBNS
N    #ifdef __cplusplus
S        namespace std {
S        #define __CLIBNS ::std::
S        extern "C" {
N    #else
N      #define __CLIBNS
N    #endif  /* __cplusplus */
N
Ntypedef signed int ptrdiff_t;
N
N#if defined(__cplusplus) || !defined(__STRICT_ANSI__)
X#if 0L || !0L
N /* unconditional in C++ and non-strict C for consistency of debug info */
N  typedef unsigned int size_t;
N#elif !defined(__size_t)
S  #define __size_t 1
S  typedef unsigned int size_t;   /* others (e.g. <stdio.h>) also define */
S   /* the unsigned integral type of the result of the sizeof operator. */
N#endif
N
N#ifndef __cplusplus  /* wchar_t is a builtin type for C++ */
N  #if !defined(__STRICT_ANSI__)
X  #if !0L
N  /* unconditional in non-strict C for consistency of debug info */
N    #if defined(__WCHAR32)
X    #if 0L
S      typedef unsigned int wchar_t; /* also in <stdlib.h> and <inttypes.h> */
N    #else
N      typedef unsigned short wchar_t; /* also in <stdlib.h> and <inttypes.h> */
N    #endif
N  #elif !defined(__wchar_t)
S    #define __wchar_t 1
S    #if defined(__WCHAR32)
S      typedef unsigned int wchar_t; /* also in <stdlib.h> and <inttypes.h> */
S    #else
S      typedef unsigned short wchar_t; /* also in <stdlib.h> and <inttypes.h> */
S    #endif
S   /*
S    * An integral type whose range of values can represent distinct codes for
S    * all members of the largest extended character set specified among the
S    * supported locales; the null character shall have the code value zero and
S    * each member of the basic character set shall have a code value when used
S    * as the lone character in an integer character constant.
S    */
N  #endif
N#endif
N
N#undef NULL  /* others (e.g. <stdio.h>) also define */
N#define NULL 0
N   /* null pointer constant. */
N
N  /* EDG uses __INTADDR__ to avoid errors when strict */
N  #define offsetof(t, memb) ((__CLIBNS size_t)__INTADDR__(&(((t *)0)->memb)))
N
N    #ifdef __cplusplus
S         }  /* extern "C" */
S      }  /* namespace std */
N    #endif /* __cplusplus */
N  #endif /* __STDDEF_DECLS */
N
N
N  #ifdef __cplusplus
S    #ifndef __STDDEF_NO_EXPORTS
S      using ::std::size_t;
S      using ::std::ptrdiff_t;
S    #endif 
N  #endif /* __cplusplus */
N
N#endif
N
N/* end of stddef.h */
N
L 77 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/*
N * If stdint.h cannot be located then:
N *   + If using GCC ensure the -nostdint options is *not* being used.
N *   + Ensure the project's include path includes the directory in which your
N *     compiler stores stdint.h.
N *   + Set any compiler options necessary for it to support C99, as technically
N *     stdint.h is only mandatory with C99 (FreeRTOS does not require C99 in any
N *     other way).
N *   + The FreeRTOS download includes a simple stdint.h definition that can be
N *     used in cases where none is provided by the compiler.  The files only
N *     contains the typedefs required to build FreeRTOS.  Read the instructions
N *     in FreeRTOS/source/stdint.readme for more information.
N */
N#include <stdint.h> /* READ COMMENT ABOVE. */
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N/* Application specific configuration options. */
N#include "FreeRTOSConfig.h"
L 1 "..\..\common\src\FreeRTOS\FreeRTOSConfig.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef FREERTOS_CONFIG_H
N#define FREERTOS_CONFIG_H
N
N/*-----------------------------------------------------------
N * Application specific definitions.
N *
N * These definitions should be adjusted for your particular hardware and
N * application requirements.
N *
N * THESE PARAMETERS ARE DESCRIBED WITHIN THE 'CONFIGURATION' SECTION OF THE
N * FreeRTOS API DOCUMENTATION AVAILABLE ON THE FreeRTOS.org WEB SITE.
N *
N * See http://www.freertos.org/a00110.html.
N *----------------------------------------------------------*/
N#define configUSE_PREEMPTION			1
N#define configUSE_IDLE_HOOK				1
N#define configUSE_TICK_HOOK				1
N#define configCPU_CLOCK_HZ				( ( unsigned long ) 300000000 )
N//#define configTICK_RATE_HZ				( ( TickType_t ) 1000 )
N#define configTICK_RATE_HZ				( ( TickType_t ) 100 )
N#define configMAX_PRIORITIES			( 16 )
N#define configMINIMAL_STACK_SIZE		( ( unsigned short ) 1024 )
N#define configTOTAL_HEAP_SIZE			( ( size_t ) 1024*1024*16 )
N#define configMAX_TASK_NAME_LEN			( 16 )
N#define configUSE_TRACE_FACILITY		1
N#define configUSE_16_BIT_TICKS			0
N#define configIDLE_SHOULD_YIELD			1
N#define configUSE_MUTEXES				1
N#define configCHECK_FOR_STACK_OVERFLOW  1
N#define configUSE_MALLOC_FAILED_HOOK    1
N
N#define configSUPPORT_DYNAMIC_ALLOCATION 1
N#define configUSE_COUNTING_SEMAPHORES   1
N
N/* Co-routine definitions. */
N#define configUSE_CO_ROUTINES 			0
N#define configMAX_CO_ROUTINE_PRIORITIES ( 2 )
N
N/* Set the following definitions to 1 to include the API function, or zero
Nto exclude the API function. */
N
N#define INCLUDE_vTaskPrioritySet				0//1
N#define INCLUDE_uxTaskPriorityGet				1
N#define INCLUDE_vTaskDelete						1
N#define INCLUDE_vTaskCleanUpResources			0
N#define INCLUDE_vTaskSuspend					1
N#define INCLUDE_vTaskDelayUntil					1
N#define INCLUDE_vTaskDelay						1
N#define INCLUDE_xTaskGetCurrentTaskHandle 		1
N#define INCLUDE_uxTaskGetStackHighWaterMark     1
N
N/* This demo makes use of one or more example stats formatting functions.  These
Nformat the raw data provided by the uxTaskGetSystemState() function in to human
Nreadable ASCII form.  See the notes in the implementation of vTaskList() within 
NFreeRTOS/Source/tasks.c for limitations. */
N#define configUSE_STATS_FORMATTING_FUNCTIONS	1
N
N#endif /* FREERTOS_CONFIG_H */
L 99 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/* Basic FreeRTOS definitions. */
N#include "projdefs.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\projdefs.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef PROJDEFS_H
N#define PROJDEFS_H
N
N/*
N * Defines the prototype to which task functions must conform.  Defined in this
N * file to ensure the type is known before portable.h is included.
N */
Ntypedef void (*TaskFunction_t)( void * );
N
N/* Converts a time in milliseconds to a time in ticks.  This macro can be
Noverridden by a macro of the same name defined in FreeRTOSConfig.h in case the
Ndefinition here is not suitable for your application. */
N#ifndef pdMS_TO_TICKS
N	#define pdMS_TO_TICKS( xTimeInMs ) ( ( TickType_t ) ( ( ( TickType_t ) ( xTimeInMs ) * ( TickType_t ) configTICK_RATE_HZ ) / ( TickType_t ) 1000 ) )
N#endif
N
N#define pdFALSE			( ( BaseType_t ) 0 )
N#define pdTRUE			( ( BaseType_t ) 1 )
N
N#define pdPASS			( pdTRUE )
N#define pdFAIL			( pdFALSE )
N#define errQUEUE_EMPTY	( ( BaseType_t ) 0 )
N#define errQUEUE_FULL	( ( BaseType_t ) 0 )
N
N/* FreeRTOS error definitions. */
N#define errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY	( -1 )
N#define errQUEUE_BLOCKED						( -4 )
N#define errQUEUE_YIELD							( -5 )
N
N/* Macros used for basic data corruption checks. */
N#ifndef configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES
N	#define configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES 0
N#endif
N
N#if( configUSE_16_BIT_TICKS == 1 )
X#if( 0 == 1 )
S	#define pdINTEGRITY_CHECK_VALUE 0x5a5a
N#else
N	#define pdINTEGRITY_CHECK_VALUE 0x5a5a5a5aUL
N#endif
N
N/* The following errno values are used by FreeRTOS+ components, not FreeRTOS
Nitself. */
N#define pdFREERTOS_ERRNO_NONE			0	/* No errors */
N#define	pdFREERTOS_ERRNO_ENOENT			2	/* No such file or directory */
N#define	pdFREERTOS_ERRNO_EINTR			4	/* Interrupted system call */
N#define	pdFREERTOS_ERRNO_EIO			5	/* I/O error */
N#define	pdFREERTOS_ERRNO_ENXIO			6	/* No such device or address */
N#define	pdFREERTOS_ERRNO_EBADF			9	/* Bad file number */
N#define	pdFREERTOS_ERRNO_EAGAIN			11	/* No more processes */
N#define	pdFREERTOS_ERRNO_EWOULDBLOCK	11	/* Operation would block */
N#define	pdFREERTOS_ERRNO_ENOMEM			12	/* Not enough memory */
N#define	pdFREERTOS_ERRNO_EACCES			13	/* Permission denied */
N#define	pdFREERTOS_ERRNO_EFAULT			14	/* Bad address */
N#define	pdFREERTOS_ERRNO_EBUSY			16	/* Mount device busy */
N#define	pdFREERTOS_ERRNO_EEXIST			17	/* File exists */
N#define	pdFREERTOS_ERRNO_EXDEV			18	/* Cross-device link */
N#define	pdFREERTOS_ERRNO_ENODEV			19	/* No such device */
N#define	pdFREERTOS_ERRNO_ENOTDIR		20	/* Not a directory */
N#define	pdFREERTOS_ERRNO_EISDIR			21	/* Is a directory */
N#define	pdFREERTOS_ERRNO_EINVAL			22	/* Invalid argument */
N#define	pdFREERTOS_ERRNO_ENOSPC			28	/* No space left on device */
N#define	pdFREERTOS_ERRNO_ESPIPE			29	/* Illegal seek */
N#define	pdFREERTOS_ERRNO_EROFS			30	/* Read only file system */
N#define	pdFREERTOS_ERRNO_EUNATCH		42	/* Protocol driver not attached */
N#define	pdFREERTOS_ERRNO_EBADE			50	/* Invalid exchange */
N#define	pdFREERTOS_ERRNO_EFTYPE			79	/* Inappropriate file type or format */
N#define	pdFREERTOS_ERRNO_ENMFILE		89	/* No more files */
N#define	pdFREERTOS_ERRNO_ENOTEMPTY		90	/* Directory not empty */
N#define	pdFREERTOS_ERRNO_ENAMETOOLONG 	91	/* File or path name too long */
N#define	pdFREERTOS_ERRNO_EOPNOTSUPP		95	/* Operation not supported on transport endpoint */
N#define	pdFREERTOS_ERRNO_ENOBUFS		105	/* No buffer space available */
N#define	pdFREERTOS_ERRNO_ENOPROTOOPT	109	/* Protocol not available */
N#define	pdFREERTOS_ERRNO_EADDRINUSE		112	/* Address already in use */
N#define	pdFREERTOS_ERRNO_ETIMEDOUT		116	/* Connection timed out */
N#define	pdFREERTOS_ERRNO_EINPROGRESS	119	/* Connection already in progress */
N#define	pdFREERTOS_ERRNO_EALREADY		120	/* Socket already connected */
N#define	pdFREERTOS_ERRNO_EADDRNOTAVAIL 	125	/* Address not available */
N#define	pdFREERTOS_ERRNO_EISCONN		127	/* Socket is already connected */
N#define	pdFREERTOS_ERRNO_ENOTCONN		128	/* Socket is not connected */
N#define	pdFREERTOS_ERRNO_ENOMEDIUM		135	/* No medium inserted */
N#define	pdFREERTOS_ERRNO_EILSEQ			138	/* An invalid UTF-16 sequence was encountered. */
N#define	pdFREERTOS_ERRNO_ECANCELED		140	/* Operation canceled. */
N
N/* The following endian values are used by FreeRTOS+ components, not FreeRTOS
Nitself. */
N#define pdFREERTOS_LITTLE_ENDIAN	0
N#define pdFREERTOS_BIG_ENDIAN		1
N
N#endif /* PROJDEFS_H */
N
N
N
L 102 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/* Definitions specific to the port being used. */
N#include "portable.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\portable.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N/*-----------------------------------------------------------
N * Portable layer API.  Each function must be defined for each port.
N *----------------------------------------------------------*/
N
N#ifndef PORTABLE_H
N#define PORTABLE_H
N
N/* Each FreeRTOS port has a unique portmacro.h header file.  Originally a
Npre-processor definition was used to ensure the pre-processor found the correct
Nportmacro.h file for the port being used.  That scheme was deprecated in favour
Nof setting the compiler's include path such that it found the correct
Nportmacro.h file - removing the need for the constant and allowing the
Nportmacro.h file to be located anywhere in relation to the port being used.
NPurely for reasons of backward compatibility the old method is still valid, but
Nto make it clear that new projects should not use it, support for the port
Nspecific constants has been moved into the deprecated_definitions.h header
Nfile. */
N#include "deprecated_definitions.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\deprecated_definitions.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef DEPRECATED_DEFINITIONS_H
N#define DEPRECATED_DEFINITIONS_H
N
N
N/* Each FreeRTOS port has a unique portmacro.h header file.  Originally a
Npre-processor definition was used to ensure the pre-processor found the correct
Nportmacro.h file for the port being used.  That scheme was deprecated in favour
Nof setting the compiler's include path such that it found the correct
Nportmacro.h file - removing the need for the constant and allowing the
Nportmacro.h file to be located anywhere in relation to the port being used.  The
Ndefinitions below remain in the code for backward compatibility only.  New
Nprojects should not use them. */
N
N#ifdef OPEN_WATCOM_INDUSTRIAL_PC_PORT
S	#include "..\..\Source\portable\owatcom\16bitdos\pc\portmacro.h"
S	typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef OPEN_WATCOM_FLASH_LITE_186_PORT
S	#include "..\..\Source\portable\owatcom\16bitdos\flsh186\portmacro.h"
S	typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef GCC_MEGA_AVR
S	#include "../portable/GCC/ATMega323/portmacro.h"
N#endif
N
N#ifdef IAR_MEGA_AVR
S	#include "../portable/IAR/ATMega323/portmacro.h"
N#endif
N
N#ifdef MPLAB_PIC24_PORT
S	#include "../../Source/portable/MPLAB/PIC24_dsPIC/portmacro.h"
N#endif
N
N#ifdef MPLAB_DSPIC_PORT
S	#include "../../Source/portable/MPLAB/PIC24_dsPIC/portmacro.h"
N#endif
N
N#ifdef MPLAB_PIC18F_PORT
S	#include "../../Source/portable/MPLAB/PIC18F/portmacro.h"
N#endif
N
N#ifdef MPLAB_PIC32MX_PORT
S	#include "../../Source/portable/MPLAB/PIC32MX/portmacro.h"
N#endif
N
N#ifdef _FEDPICC
S	#include "libFreeRTOS/Include/portmacro.h"
N#endif
N
N#ifdef SDCC_CYGNAL
S	#include "../../Source/portable/SDCC/Cygnal/portmacro.h"
N#endif
N
N#ifdef GCC_ARM7
S	#include "../../Source/portable/GCC/ARM7_LPC2000/portmacro.h"
N#endif
N
N#ifdef GCC_ARM7_ECLIPSE
S	#include "portmacro.h"
N#endif
N
N#ifdef ROWLEY_LPC23xx
S	#include "../../Source/portable/GCC/ARM7_LPC23xx/portmacro.h"
N#endif
N
N#ifdef IAR_MSP430
S	#include "..\..\Source\portable\IAR\MSP430\portmacro.h"
N#endif
N
N#ifdef GCC_MSP430
S	#include "../../Source/portable/GCC/MSP430F449/portmacro.h"
N#endif
N
N#ifdef ROWLEY_MSP430
S	#include "../../Source/portable/Rowley/MSP430F449/portmacro.h"
N#endif
N
N#ifdef ARM7_LPC21xx_KEIL_RVDS
S	#include "..\..\Source\portable\RVDS\ARM7_LPC21xx\portmacro.h"
N#endif
N
N#ifdef SAM7_GCC
S	#include "../../Source/portable/GCC/ARM7_AT91SAM7S/portmacro.h"
N#endif
N
N#ifdef SAM7_IAR
S	#include "..\..\Source\portable\IAR\AtmelSAM7S64\portmacro.h"
N#endif
N
N#ifdef SAM9XE_IAR
S	#include "..\..\Source\portable\IAR\AtmelSAM9XE\portmacro.h"
N#endif
N
N#ifdef LPC2000_IAR
S	#include "..\..\Source\portable\IAR\LPC2000\portmacro.h"
N#endif
N
N#ifdef STR71X_IAR
S	#include "..\..\Source\portable\IAR\STR71x\portmacro.h"
N#endif
N
N#ifdef STR75X_IAR
S	#include "..\..\Source\portable\IAR\STR75x\portmacro.h"
N#endif
N
N#ifdef STR75X_GCC
S	#include "..\..\Source\portable\GCC\STR75x\portmacro.h"
N#endif
N
N#ifdef STR91X_IAR
S	#include "..\..\Source\portable\IAR\STR91x\portmacro.h"
N#endif
N
N#ifdef GCC_H8S
S	#include "../../Source/portable/GCC/H8S2329/portmacro.h"
N#endif
N
N#ifdef GCC_AT91FR40008
S	#include "../../Source/portable/GCC/ARM7_AT91FR40008/portmacro.h"
N#endif
N
N#ifdef RVDS_ARMCM3_LM3S102
S	#include "../../Source/portable/RVDS/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef GCC_ARMCM3_LM3S102
S	#include "../../Source/portable/GCC/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef GCC_ARMCM3
S	#include "../../Source/portable/GCC/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef IAR_ARM_CM3
S	#include "../../Source/portable/IAR/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef IAR_ARMCM3_LM
S	#include "../../Source/portable/IAR/ARM_CM3/portmacro.h"
N#endif
N
N#ifdef HCS12_CODE_WARRIOR
S	#include "../../Source/portable/CodeWarrior/HCS12/portmacro.h"
N#endif
N
N#ifdef MICROBLAZE_GCC
S	#include "../../Source/portable/GCC/MicroBlaze/portmacro.h"
N#endif
N
N#ifdef TERN_EE
S	#include "..\..\Source\portable\Paradigm\Tern_EE\small\portmacro.h"
N#endif
N
N#ifdef GCC_HCS12
S	#include "../../Source/portable/GCC/HCS12/portmacro.h"
N#endif
N
N#ifdef GCC_MCF5235
S    #include "../../Source/portable/GCC/MCF5235/portmacro.h"
N#endif
N
N#ifdef COLDFIRE_V2_GCC
S	#include "../../../Source/portable/GCC/ColdFire_V2/portmacro.h"
N#endif
N
N#ifdef COLDFIRE_V2_CODEWARRIOR
S	#include "../../Source/portable/CodeWarrior/ColdFire_V2/portmacro.h"
N#endif
N
N#ifdef GCC_PPC405
S	#include "../../Source/portable/GCC/PPC405_Xilinx/portmacro.h"
N#endif
N
N#ifdef GCC_PPC440
S	#include "../../Source/portable/GCC/PPC440_Xilinx/portmacro.h"
N#endif
N
N#ifdef _16FX_SOFTUNE
S	#include "..\..\Source\portable\Softune\MB96340\portmacro.h"
N#endif
N
N#ifdef BCC_INDUSTRIAL_PC_PORT
S	/* A short file name has to be used in place of the normal
S	FreeRTOSConfig.h when using the Borland compiler. */
S	#include "frconfig.h"
S	#include "..\portable\BCC\16BitDOS\PC\prtmacro.h"
S    typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef BCC_FLASH_LITE_186_PORT
S	/* A short file name has to be used in place of the normal
S	FreeRTOSConfig.h when using the Borland compiler. */
S	#include "frconfig.h"
S	#include "..\portable\BCC\16BitDOS\flsh186\prtmacro.h"
S    typedef void ( __interrupt __far *pxISR )();
N#endif
N
N#ifdef __GNUC__
S   #ifdef __AVR32_AVR32A__
S	   #include "portmacro.h"
S   #endif
N#endif
N
N#ifdef __ICCAVR32__
S   #ifdef __CORE__
S      #if __CORE__ == __AVR32A__
S	      #include "portmacro.h"
S      #endif
S   #endif
N#endif
N
N#ifdef __91467D
S	#include "portmacro.h"
N#endif
N
N#ifdef __96340
S	#include "portmacro.h"
N#endif
N
N
N#ifdef __IAR_V850ES_Fx3__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Jx3__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Jx3_L__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Jx2__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_V850ES_Hx2__
S	#include "../../Source/portable/IAR/V850ES/portmacro.h"
N#endif
N
N#ifdef __IAR_78K0R_Kx3__
S	#include "../../Source/portable/IAR/78K0R/portmacro.h"
N#endif
N
N#ifdef __IAR_78K0R_Kx3L__
S	#include "../../Source/portable/IAR/78K0R/portmacro.h"
N#endif
N
N#endif /* DEPRECATED_DEFINITIONS_H */
N
L 88 "..\..\common\src\FreeRTOS\Source\include\portable.h" 2
N
N/* If portENTER_CRITICAL is not defined then including deprecated_definitions.h
Ndid not result in a portmacro.h header file being included - and it should be
Nincluded here.  In this case the path to the correct portmacro.h header file
Nmust be set in the compiler's include path. */
N#ifndef portENTER_CRITICAL
N	#include "portmacro.h"
L 1 "..\..\common\src\FreeRTOS\Source\portable\RVDS\ARM926EJ-S\portmacro.h" 1
N/*
N * It turns out that portmacro.h from the officially supported
N * GCC/ARM7_LPC2000 port can be reused at ARM926EJ-S too.
N * Although the file could remain unmodified, it was slightly modified
N * so interrupt enabling macros do not enable FIQ exceptions that is
N * currently not supported.
N * Additionally all "annoying" tabs have been replaced by spaces.
N *
N * The original file is available under the following license:
N */
N
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N
N#ifndef PORTMACRO_H
N#define PORTMACRO_H
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N    /*-----------------------------------------------------------
N     * Port specific definitions.
N     *
N     * The settings in this file configure FreeRTOS correctly for the
N     * given hardware and compiler.
N     *
N     * These settings should not be altered.
N     *-----------------------------------------------------------
N     */
N#define portCHAR        char
N#define portFLOAT        float
N#define portDOUBLE        double
N#define portLONG        long
N#define portSHORT        short
N#define portSTACK_TYPE    unsigned portLONG
N#define portBASE_TYPE    portLONG
N
N//add by sam
Ntypedef portSTACK_TYPE StackType_t;
Xtypedef unsigned long StackType_t;
Ntypedef long BaseType_t;
Ntypedef unsigned long UBaseType_t;
N
N
N
N#if( configUSE_16_BIT_TICKS == 1 )
X#if( 0 == 1 )
S    typedef unsigned portSHORT portTickType;
S#define portMAX_DELAY ( portTickType ) 0xffff
N#else
N    typedef unsigned portLONG portTickType;
X    typedef unsigned long portTickType;
N#define portMAX_DELAY ( portTickType ) 0xffffffff
N#endif
N
N//add by sam
Ntypedef portTickType TickType_t;
N
N    /*-----------------------------------------------------------*/
N
N    /* Hardware specifics. */
N//#define portSTACK_GROWTH            ( -1 )
N//#define portTICK_RATE_MS            ( ( portTickType ) 1000 / configTICK_RATE_HZ )
N//#define portBYTE_ALIGNMENT            8
N//by sam
N/* Hardware specifics. */
N#define portSTACK_GROWTH			( -1 )
N#define portTICK_PERIOD_MS			( ( TickType_t ) 1000 / configTICK_RATE_HZ )
N#define portBYTE_ALIGNMENT			8
N    /*-----------------------------------------------------------*/
N
N
N#define portEXIT_SWITCHING_ISR(SwitchRequired)                 \
N                        {                                                             \
N                        extern void vTaskSwitchContext(void);                         \
N                                                                                     \
N                                if(SwitchRequired)                                     \
N                                {                                                     \
N                                    vTaskSwitchContext();                             \
N                                }                                                     \
N                        }                                                             \
N
X#define portEXIT_SWITCHING_ISR(SwitchRequired)                                         {                                                                                     extern void vTaskSwitchContext(void);                                                                                                                                              if(SwitchRequired)                                                                     {                                                                                         vTaskSwitchContext();                                                             }                                                                             }                                                             
Nextern void vPortYield2( void );
N#define portYIELD() vPortYield2()
N
N
N    /* Critical section management. */
N
N#define portDISABLE_INTERRUPTS()    __disable_irq()
N#define portENABLE_INTERRUPTS()        __enable_irq()
N
N    extern void vPortEnterCritical( void );
N    extern void vPortExitCritical( void );
N
N#define portENTER_CRITICAL()        vPortEnterCritical();
N#define portEXIT_CRITICAL()            vPortExitCritical();
N    /*-----------------------------------------------------------*/
N
N    /* Compiler specifics. */
N#define inline
N#define register
N#define portNOP()                   __asm{ NOP }
N//#define portYIELD()					__asm{ SWI 0 }//asm ( "SWI 0" )
N    /*-----------------------------------------------------------*/
N
N    /* Task function macros as described on the FreeRTOS.org WEB site. */
N#define portTASK_FUNCTION_PROTO( vFunction, pvParameters )    void vFunction( void *pvParameters )
N#define portTASK_FUNCTION( vFunction, pvParameters )    void vFunction( void *pvParameters )
N
N    //代码中大部分都是声明了一些函数，以及定义了数据类型
N    //真正重要有三个地方
N    //#define portYIELD() vPortYield() ///这个宏告诉os， task如何放弃CPU. vPortYield会在portasm.s 中实现。
N    //#define portDISABLE_INTERRUPTS()    __disable_irq()                     ////实现了关中断 __disable_irq() 和 __enable_irq() 支持的库函数
N    //#define portENABLE_INTERRUPTS()        __enable_irq()           ////实现了开中断
N    //#define portNOP()    __asm{ NOP }                             ////实现了nop
N
N    //以上都是跟硬件相关的。
N
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* PORTMACRO_H */
L 95 "..\..\common\src\FreeRTOS\Source\include\portable.h" 2
N#endif
N
N#if portBYTE_ALIGNMENT == 32
X#if 8 == 32
S	#define portBYTE_ALIGNMENT_MASK ( 0x001f )
N#endif
N
N#if portBYTE_ALIGNMENT == 16
X#if 8 == 16
S	#define portBYTE_ALIGNMENT_MASK ( 0x000f )
N#endif
N
N#if portBYTE_ALIGNMENT == 8
X#if 8 == 8
N	#define portBYTE_ALIGNMENT_MASK ( 0x0007 )
N#endif
N
N#if portBYTE_ALIGNMENT == 4
X#if 8 == 4
S	#define portBYTE_ALIGNMENT_MASK	( 0x0003 )
N#endif
N
N#if portBYTE_ALIGNMENT == 2
X#if 8 == 2
S	#define portBYTE_ALIGNMENT_MASK	( 0x0001 )
N#endif
N
N#if portBYTE_ALIGNMENT == 1
X#if 8 == 1
S	#define portBYTE_ALIGNMENT_MASK	( 0x0000 )
N#endif
N
N#ifndef portBYTE_ALIGNMENT_MASK
S	#error "Invalid portBYTE_ALIGNMENT definition"
N#endif
N
N#ifndef portNUM_CONFIGURABLE_REGIONS
N	#define portNUM_CONFIGURABLE_REGIONS 1
N#endif
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N#include "mpu_wrappers.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\mpu_wrappers.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef MPU_WRAPPERS_H
N#define MPU_WRAPPERS_H
N
N/* This file redefines API functions to be called through a wrapper macro, but
Nonly for ports that are using the MPU. */
N#ifdef portUSING_MPU_WRAPPERS
S
S	/* MPU_WRAPPERS_INCLUDED_FROM_API_FILE will be defined when this file is
S	included from queue.c or task.c to prevent it from having an effect within
S	those files. */
S	#ifndef MPU_WRAPPERS_INCLUDED_FROM_API_FILE
S
S		/*
S		 * Map standard (non MPU) API functions to equivalents that start
S		 * "MPU_".  This will cause the application code to call the MPU_
S		 * version, which wraps the non-MPU version with privilege promoting
S		 * then demoting code, so the kernel code always runs will full
S		 * privileges.
S		 */
S
S		/* Map standard tasks.h API functions to the MPU equivalents. */
S		#define xTaskCreate								MPU_xTaskCreate
S		#define xTaskCreateStatic						MPU_xTaskCreateStatic
S		#define xTaskCreateRestricted					MPU_xTaskCreateRestricted
S		#define vTaskAllocateMPURegions					MPU_vTaskAllocateMPURegions
S		#define vTaskDelete								MPU_vTaskDelete
S		#define vTaskDelay								MPU_vTaskDelay
S		#define vTaskDelayUntil							MPU_vTaskDelayUntil
S		#define xTaskAbortDelay							MPU_xTaskAbortDelay
S		#define uxTaskPriorityGet						MPU_uxTaskPriorityGet
S		#define eTaskGetState							MPU_eTaskGetState
S		#define vTaskGetInfo							MPU_vTaskGetInfo
S		#define vTaskPrioritySet						MPU_vTaskPrioritySet
S		#define vTaskSuspend							MPU_vTaskSuspend
S		#define vTaskResume								MPU_vTaskResume
S		#define vTaskSuspendAll							MPU_vTaskSuspendAll
S		#define xTaskResumeAll							MPU_xTaskResumeAll
S		#define xTaskGetTickCount						MPU_xTaskGetTickCount
S		#define uxTaskGetNumberOfTasks					MPU_uxTaskGetNumberOfTasks
S		#define pcTaskGetName							MPU_pcTaskGetName
S		#define xTaskGetHandle							MPU_xTaskGetHandle
S		#define uxTaskGetStackHighWaterMark				MPU_uxTaskGetStackHighWaterMark
S		#define vTaskSetApplicationTaskTag				MPU_vTaskSetApplicationTaskTag
S		#define xTaskGetApplicationTaskTag				MPU_xTaskGetApplicationTaskTag
S		#define vTaskSetThreadLocalStoragePointer		MPU_vTaskSetThreadLocalStoragePointer
S		#define pvTaskGetThreadLocalStoragePointer		MPU_pvTaskGetThreadLocalStoragePointer
S		#define xTaskCallApplicationTaskHook			MPU_xTaskCallApplicationTaskHook
S		#define xTaskGetIdleTaskHandle					MPU_xTaskGetIdleTaskHandle
S		#define uxTaskGetSystemState					MPU_uxTaskGetSystemState
S		#define vTaskList								MPU_vTaskList
S		#define vTaskGetRunTimeStats					MPU_vTaskGetRunTimeStats
S		#define xTaskGenericNotify						MPU_xTaskGenericNotify
S		#define xTaskNotifyWait							MPU_xTaskNotifyWait
S		#define ulTaskNotifyTake						MPU_ulTaskNotifyTake
S		#define xTaskNotifyStateClear					MPU_xTaskNotifyStateClear
S
S		#define xTaskGetCurrentTaskHandle				MPU_xTaskGetCurrentTaskHandle
S		#define vTaskSetTimeOutState					MPU_vTaskSetTimeOutState
S		#define xTaskCheckForTimeOut					MPU_xTaskCheckForTimeOut
S		#define xTaskGetSchedulerState					MPU_xTaskGetSchedulerState
S
S		/* Map standard queue.h API functions to the MPU equivalents. */
S		#define xQueueGenericSend						MPU_xQueueGenericSend
S		#define xQueueGenericReceive					MPU_xQueueGenericReceive
S		#define uxQueueMessagesWaiting					MPU_uxQueueMessagesWaiting
S		#define uxQueueSpacesAvailable					MPU_uxQueueSpacesAvailable
S		#define vQueueDelete							MPU_vQueueDelete
S		#define xQueueCreateMutex						MPU_xQueueCreateMutex
S		#define xQueueCreateMutexStatic					MPU_xQueueCreateMutexStatic
S		#define xQueueCreateCountingSemaphore			MPU_xQueueCreateCountingSemaphore
S		#define xQueueCreateCountingSemaphoreStatic		MPU_xQueueCreateCountingSemaphoreStatic
S		#define xQueueGetMutexHolder					MPU_xQueueGetMutexHolder
S		#define xQueueTakeMutexRecursive				MPU_xQueueTakeMutexRecursive
S		#define xQueueGiveMutexRecursive				MPU_xQueueGiveMutexRecursive
S		#define xQueueGenericCreate						MPU_xQueueGenericCreate
S		#define xQueueGenericCreateStatic				MPU_xQueueGenericCreateStatic
S		#define xQueueCreateSet							MPU_xQueueCreateSet
S		#define xQueueAddToSet							MPU_xQueueAddToSet
S		#define xQueueRemoveFromSet						MPU_xQueueRemoveFromSet
S		#define xQueueSelectFromSet						MPU_xQueueSelectFromSet
S		#define xQueueGenericReset						MPU_xQueueGenericReset
S
S		#if( configQUEUE_REGISTRY_SIZE > 0 )
S			#define vQueueAddToRegistry						MPU_vQueueAddToRegistry
S			#define vQueueUnregisterQueue					MPU_vQueueUnregisterQueue
S			#define pcQueueGetName							MPU_pcQueueGetName
S		#endif
S
S		/* Map standard timer.h API functions to the MPU equivalents. */
S		#define xTimerCreate							MPU_xTimerCreate
S		#define xTimerCreateStatic						MPU_xTimerCreateStatic
S		#define pvTimerGetTimerID						MPU_pvTimerGetTimerID
S		#define vTimerSetTimerID						MPU_vTimerSetTimerID
S		#define xTimerIsTimerActive						MPU_xTimerIsTimerActive
S		#define xTimerGetTimerDaemonTaskHandle			MPU_xTimerGetTimerDaemonTaskHandle
S		#define xTimerPendFunctionCall					MPU_xTimerPendFunctionCall
S		#define pcTimerGetName							MPU_pcTimerGetName
S		#define xTimerGetPeriod							MPU_xTimerGetPeriod
S		#define xTimerGetExpiryTime						MPU_xTimerGetExpiryTime
S		#define xTimerGenericCommand					MPU_xTimerGenericCommand
S
S		/* Map standard event_group.h API functions to the MPU equivalents. */
S		#define xEventGroupCreate						MPU_xEventGroupCreate
S		#define xEventGroupCreateStatic					MPU_xEventGroupCreateStatic
S		#define xEventGroupWaitBits						MPU_xEventGroupWaitBits
S		#define xEventGroupClearBits					MPU_xEventGroupClearBits
S		#define xEventGroupSetBits						MPU_xEventGroupSetBits
S		#define xEventGroupSync							MPU_xEventGroupSync
S		#define vEventGroupDelete						MPU_vEventGroupDelete
S
S		/* Remove the privileged function macro. */
S		#define PRIVILEGED_FUNCTION
S
S	#else /* MPU_WRAPPERS_INCLUDED_FROM_API_FILE */
S
S		/* Ensure API functions go in the privileged execution section. */
S		#define PRIVILEGED_FUNCTION __attribute__((section("privileged_functions")))
S		#define PRIVILEGED_DATA __attribute__((section("privileged_data")))
S
S	#endif /* MPU_WRAPPERS_INCLUDED_FROM_API_FILE */
S
N#else /* portUSING_MPU_WRAPPERS */
N
N	#define PRIVILEGED_FUNCTION
N	#define PRIVILEGED_DATA
N	#define portUSING_MPU_WRAPPERS 0
N
N#endif /* portUSING_MPU_WRAPPERS */
N
N
N#endif /* MPU_WRAPPERS_H */
N
L 134 "..\..\common\src\FreeRTOS\Source\include\portable.h" 2
N
N/*
N * Setup the stack of a new task so it is ready to be placed under the
N * scheduler control.  The registers have to be placed on the stack in
N * the order that the port expects to find them.
N *
N */
N#if( portUSING_MPU_WRAPPERS == 1 )
X#if( 0 == 1 )
S	StackType_t *pxPortInitialiseStack( StackType_t *pxTopOfStack, TaskFunction_t pxCode, void *pvParameters, BaseType_t xRunPrivileged ) PRIVILEGED_FUNCTION;
N#else
N	StackType_t *pxPortInitialiseStack( StackType_t *pxTopOfStack, TaskFunction_t pxCode, void *pvParameters ) PRIVILEGED_FUNCTION;
X	StackType_t *pxPortInitialiseStack( StackType_t *pxTopOfStack, TaskFunction_t pxCode, void *pvParameters ) ;
N#endif
N
N/* Used by heap_5.c. */
Ntypedef struct HeapRegion
N{
N	uint8_t *pucStartAddress;
N	size_t xSizeInBytes;
N} HeapRegion_t;
N
N/*
N * Used to define multiple heap regions for use by heap_5.c.  This function
N * must be called before any calls to pvPortMalloc() - not creating a task,
N * queue, semaphore, mutex, software timer, event group, etc. will result in
N * pvPortMalloc being called.
N *
N * pxHeapRegions passes in an array of HeapRegion_t structures - each of which
N * defines a region of memory that can be used as the heap.  The array is
N * terminated by a HeapRegions_t structure that has a size of 0.  The region
N * with the lowest start address must appear first in the array.
N */
Nvoid vPortDefineHeapRegions( const HeapRegion_t * const pxHeapRegions ) PRIVILEGED_FUNCTION;
Xvoid vPortDefineHeapRegions( const HeapRegion_t * const pxHeapRegions ) ;
N
N
N/*
N * Map to the memory management routines required for the port.
N */
Nvoid *pvPortMalloc( size_t xSize ) PRIVILEGED_FUNCTION;
Xvoid *pvPortMalloc( size_t xSize ) ;
Nvoid vPortFree( void *pv ) PRIVILEGED_FUNCTION;
Xvoid vPortFree( void *pv ) ;
Nvoid vPortInitialiseBlocks( void ) PRIVILEGED_FUNCTION;
Xvoid vPortInitialiseBlocks( void ) ;
Nsize_t xPortGetFreeHeapSize( void ) PRIVILEGED_FUNCTION;
Xsize_t xPortGetFreeHeapSize( void ) ;
Nsize_t xPortGetMinimumEverFreeHeapSize( void ) PRIVILEGED_FUNCTION;
Xsize_t xPortGetMinimumEverFreeHeapSize( void ) ;
N
N/*
N * Setup the hardware ready for the scheduler to take control.  This generally
N * sets up a tick interrupt and sets timers for the correct tick frequency.
N */
NBaseType_t xPortStartScheduler( void ) PRIVILEGED_FUNCTION;
XBaseType_t xPortStartScheduler( void ) ;
N
N/*
N * Undo any hardware/ISR setup that was performed by xPortStartScheduler() so
N * the hardware is left in its original condition after the scheduler stops
N * executing.
N */
Nvoid vPortEndScheduler( void ) PRIVILEGED_FUNCTION;
Xvoid vPortEndScheduler( void ) ;
N
N/*
N * The structures and methods of manipulating the MPU are contained within the
N * port layer.
N *
N * Fills the xMPUSettings structure with the memory region information
N * contained in xRegions.
N */
N#if( portUSING_MPU_WRAPPERS == 1 )
X#if( 0 == 1 )
S	struct xMEMORY_REGION;
S	void vPortStoreTaskMPUSettings( xMPU_SETTINGS *xMPUSettings, const struct xMEMORY_REGION * const xRegions, StackType_t *pxBottomOfStack, uint32_t ulStackDepth ) PRIVILEGED_FUNCTION;
N#endif
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* PORTABLE_H */
N
L 105 "..\..\common\src\FreeRTOS\Source\include\FreeRTOS.h" 2
N
N/* Must be defaulted before configUSE_NEWLIB_REENTRANT is used below. */
N#ifndef configUSE_NEWLIB_REENTRANT
N	#define configUSE_NEWLIB_REENTRANT 0
N#endif
N
N/* Required if struct _reent is used. */
N#if ( configUSE_NEWLIB_REENTRANT == 1 )
X#if ( 0 == 1 )
S	#include <reent.h>
N#endif
N/*
N * Check all the required application specific macros have been defined.
N * These macros are application specific and (as downloaded) are defined
N * within FreeRTOSConfig.h.
N */
N
N#ifndef configMINIMAL_STACK_SIZE
S	#error Missing definition:  configMINIMAL_STACK_SIZE must be defined in FreeRTOSConfig.h.  configMINIMAL_STACK_SIZE defines the size (in words) of the stack allocated to the idle task.  Refer to the demo project provided for your port for a suitable value.
N#endif
N
N#ifndef configMAX_PRIORITIES
S	#error Missing definition:  configMAX_PRIORITIES must be defined in FreeRTOSConfig.h.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#if configMAX_PRIORITIES < 1
X#if ( 16 ) < 1
S	#error configMAX_PRIORITIES must be defined to be greater than or equal to 1.
N#endif
N
N#ifndef configUSE_PREEMPTION
S	#error Missing definition:  configUSE_PREEMPTION must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_IDLE_HOOK
S	#error Missing definition:  configUSE_IDLE_HOOK must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_TICK_HOOK
S	#error Missing definition:  configUSE_TICK_HOOK must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_16_BIT_TICKS
S	#error Missing definition:  configUSE_16_BIT_TICKS must be defined in FreeRTOSConfig.h as either 1 or 0.  See the Configuration section of the FreeRTOS API documentation for details.
N#endif
N
N#ifndef configUSE_CO_ROUTINES
S	#define configUSE_CO_ROUTINES 0
N#endif
N
N#ifndef INCLUDE_vTaskPrioritySet
S	#define INCLUDE_vTaskPrioritySet 0
N#endif
N
N#ifndef INCLUDE_uxTaskPriorityGet
S	#define INCLUDE_uxTaskPriorityGet 0
N#endif
N
N#ifndef INCLUDE_vTaskDelete
S	#define INCLUDE_vTaskDelete 0
N#endif
N
N#ifndef INCLUDE_vTaskSuspend
S	#define INCLUDE_vTaskSuspend 0
N#endif
N
N#ifndef INCLUDE_vTaskDelayUntil
S	#define INCLUDE_vTaskDelayUntil 0
N#endif
N
N#ifndef INCLUDE_vTaskDelay
S	#define INCLUDE_vTaskDelay 0
N#endif
N
N#ifndef INCLUDE_xTaskGetIdleTaskHandle
N	#define INCLUDE_xTaskGetIdleTaskHandle 0
N#endif
N
N#ifndef INCLUDE_xTaskAbortDelay
N	#define INCLUDE_xTaskAbortDelay 0
N#endif
N
N#ifndef INCLUDE_xQueueGetMutexHolder
N	#define INCLUDE_xQueueGetMutexHolder 0
N#endif
N
N#ifndef INCLUDE_xSemaphoreGetMutexHolder
N	#define INCLUDE_xSemaphoreGetMutexHolder INCLUDE_xQueueGetMutexHolder
N#endif
N
N#ifndef INCLUDE_xTaskGetHandle
N	#define INCLUDE_xTaskGetHandle 0
N#endif
N
N#ifndef INCLUDE_uxTaskGetStackHighWaterMark
S	#define INCLUDE_uxTaskGetStackHighWaterMark 0
N#endif
N
N#ifndef INCLUDE_eTaskGetState
N	#define INCLUDE_eTaskGetState 0
N#endif
N
N#ifndef INCLUDE_xTaskResumeFromISR
N	#define INCLUDE_xTaskResumeFromISR 1
N#endif
N
N#ifndef INCLUDE_xTimerPendFunctionCall
N	#define INCLUDE_xTimerPendFunctionCall 0
N#endif
N
N#ifndef INCLUDE_xTaskGetSchedulerState
N	#define INCLUDE_xTaskGetSchedulerState 0
N#endif
N
N#ifndef INCLUDE_xTaskGetCurrentTaskHandle
S	#define INCLUDE_xTaskGetCurrentTaskHandle 0
N#endif
N
N#if configUSE_CO_ROUTINES != 0
X#if 0 != 0
S	#ifndef configMAX_CO_ROUTINE_PRIORITIES
S		#error configMAX_CO_ROUTINE_PRIORITIES must be greater than or equal to 1.
S	#endif
N#endif
N
N#ifndef configUSE_DAEMON_TASK_STARTUP_HOOK
N	#define configUSE_DAEMON_TASK_STARTUP_HOOK 0
N#endif
N
N#ifndef configUSE_APPLICATION_TASK_TAG
N	#define configUSE_APPLICATION_TASK_TAG 0
N#endif
N
N#ifndef configNUM_THREAD_LOCAL_STORAGE_POINTERS
N	#define configNUM_THREAD_LOCAL_STORAGE_POINTERS 0
N#endif
N
N#ifndef configUSE_RECURSIVE_MUTEXES
N	#define configUSE_RECURSIVE_MUTEXES 0
N#endif
N
N#ifndef configUSE_MUTEXES
S	#define configUSE_MUTEXES 0
N#endif
N
N#ifndef configUSE_TIMERS
N	#define configUSE_TIMERS 0
N#endif
N
N#ifndef configUSE_COUNTING_SEMAPHORES
S	#define configUSE_COUNTING_SEMAPHORES 0
N#endif
N
N#ifndef configUSE_ALTERNATIVE_API
N	#define configUSE_ALTERNATIVE_API 0
N#endif
N
N#ifndef portCRITICAL_NESTING_IN_TCB
N	#define portCRITICAL_NESTING_IN_TCB 0
N#endif
N
N#ifndef configMAX_TASK_NAME_LEN
S	#define configMAX_TASK_NAME_LEN 16
N#endif
N
N#ifndef configIDLE_SHOULD_YIELD
S	#define configIDLE_SHOULD_YIELD		1
N#endif
N
N#if configMAX_TASK_NAME_LEN < 1
X#if ( 16 ) < 1
S	#error configMAX_TASK_NAME_LEN must be set to a minimum of 1 in FreeRTOSConfig.h
N#endif
N
N#ifndef configASSERT
N	#define configASSERT( x )
N	#define configASSERT_DEFINED 0
N#else
S	#define configASSERT_DEFINED 1
N#endif
N
N/* The timers module relies on xTaskGetSchedulerState(). */
N#if configUSE_TIMERS == 1
X#if 0 == 1
S
S	#ifndef configTIMER_TASK_PRIORITY
S		#error If configUSE_TIMERS is set to 1 then configTIMER_TASK_PRIORITY must also be defined.
S	#endif /* configTIMER_TASK_PRIORITY */
S
S	#ifndef configTIMER_QUEUE_LENGTH
S		#error If configUSE_TIMERS is set to 1 then configTIMER_QUEUE_LENGTH must also be defined.
S	#endif /* configTIMER_QUEUE_LENGTH */
S
S	#ifndef configTIMER_TASK_STACK_DEPTH
S		#error If configUSE_TIMERS is set to 1 then configTIMER_TASK_STACK_DEPTH must also be defined.
S	#endif /* configTIMER_TASK_STACK_DEPTH */
S
N#endif /* configUSE_TIMERS */
N
N#ifndef portSET_INTERRUPT_MASK_FROM_ISR
N	#define portSET_INTERRUPT_MASK_FROM_ISR() 0
N#endif
N
N#ifndef portCLEAR_INTERRUPT_MASK_FROM_ISR
N	#define portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedStatusValue ) ( void ) uxSavedStatusValue
N#endif
N
N#ifndef portCLEAN_UP_TCB
N	#define portCLEAN_UP_TCB( pxTCB ) ( void ) pxTCB
N#endif
N
N#ifndef portPRE_TASK_DELETE_HOOK
N	#define portPRE_TASK_DELETE_HOOK( pvTaskToDelete, pxYieldPending )
N#endif
N
N#ifndef portSETUP_TCB
N	#define portSETUP_TCB( pxTCB ) ( void ) pxTCB
N#endif
N
N#ifndef configQUEUE_REGISTRY_SIZE
N	#define configQUEUE_REGISTRY_SIZE 0U
N#endif
N
N#if ( configQUEUE_REGISTRY_SIZE < 1 )
X#if ( 0U < 1 )
N	#define vQueueAddToRegistry( xQueue, pcName )
N	#define vQueueUnregisterQueue( xQueue )
N	#define pcQueueGetName( xQueue )
N#endif
N
N#ifndef portPOINTER_SIZE_TYPE
N	#define portPOINTER_SIZE_TYPE uint32_t
N#endif
N
N/* Remove any unused trace macros. */
N#ifndef traceSTART
N	/* Used to perform any necessary initialisation - for example, open a file
N	into which trace is to be written. */
N	#define traceSTART()
N#endif
N
N#ifndef traceEND
N	/* Use to close a trace, for example close a file into which trace has been
N	written. */
N	#define traceEND()
N#endif
N
N#ifndef traceTASK_SWITCHED_IN
N	/* Called after a task has been selected to run.  pxCurrentTCB holds a pointer
N	to the task control block of the selected task. */
N	#define traceTASK_SWITCHED_IN()
N#endif
N
N#ifndef traceINCREASE_TICK_COUNT
N	/* Called before stepping the tick count after waking from tickless idle
N	sleep. */
N	#define traceINCREASE_TICK_COUNT( x )
N#endif
N
N#ifndef traceLOW_POWER_IDLE_BEGIN
N	/* Called immediately before entering tickless idle. */
N	#define traceLOW_POWER_IDLE_BEGIN()
N#endif
N
N#ifndef	traceLOW_POWER_IDLE_END
N	/* Called when returning to the Idle task after a tickless idle. */
N	#define traceLOW_POWER_IDLE_END()
N#endif
N
N#ifndef traceTASK_SWITCHED_OUT
N	/* Called before a task has been selected to run.  pxCurrentTCB holds a pointer
N	to the task control block of the task being switched out. */
N	#define traceTASK_SWITCHED_OUT()
N#endif
N
N#ifndef traceTASK_PRIORITY_INHERIT
N	/* Called when a task attempts to take a mutex that is already held by a
N	lower priority task.  pxTCBOfMutexHolder is a pointer to the TCB of the task
N	that holds the mutex.  uxInheritedPriority is the priority the mutex holder
N	will inherit (the priority of the task that is attempting to obtain the
N	muted. */
N	#define traceTASK_PRIORITY_INHERIT( pxTCBOfMutexHolder, uxInheritedPriority )
N#endif
N
N#ifndef traceTASK_PRIORITY_DISINHERIT
N	/* Called when a task releases a mutex, the holding of which had resulted in
N	the task inheriting the priority of a higher priority task.
N	pxTCBOfMutexHolder is a pointer to the TCB of the task that is releasing the
N	mutex.  uxOriginalPriority is the task's configured (base) priority. */
N	#define traceTASK_PRIORITY_DISINHERIT( pxTCBOfMutexHolder, uxOriginalPriority )
N#endif
N
N#ifndef traceBLOCKING_ON_QUEUE_RECEIVE
N	/* Task is about to block because it cannot read from a
N	queue/mutex/semaphore.  pxQueue is a pointer to the queue/mutex/semaphore
N	upon which the read was attempted.  pxCurrentTCB points to the TCB of the
N	task that attempted the read. */
N	#define traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue )
N#endif
N
N#ifndef traceBLOCKING_ON_QUEUE_SEND
N	/* Task is about to block because it cannot write to a
N	queue/mutex/semaphore.  pxQueue is a pointer to the queue/mutex/semaphore
N	upon which the write was attempted.  pxCurrentTCB points to the TCB of the
N	task that attempted the write. */
N	#define traceBLOCKING_ON_QUEUE_SEND( pxQueue )
N#endif
N
N#ifndef configCHECK_FOR_STACK_OVERFLOW
S	#define configCHECK_FOR_STACK_OVERFLOW 0
N#endif
N
N/* The following event macros are embedded in the kernel API calls. */
N
N#ifndef traceMOVED_TASK_TO_READY_STATE
N	#define traceMOVED_TASK_TO_READY_STATE( pxTCB )
N#endif
N
N#ifndef tracePOST_MOVED_TASK_TO_READY_STATE
N	#define tracePOST_MOVED_TASK_TO_READY_STATE( pxTCB )
N#endif
N
N#ifndef traceQUEUE_CREATE
N	#define traceQUEUE_CREATE( pxNewQueue )
N#endif
N
N#ifndef traceQUEUE_CREATE_FAILED
N	#define traceQUEUE_CREATE_FAILED( ucQueueType )
N#endif
N
N#ifndef traceCREATE_MUTEX
N	#define traceCREATE_MUTEX( pxNewQueue )
N#endif
N
N#ifndef traceCREATE_MUTEX_FAILED
N	#define traceCREATE_MUTEX_FAILED()
N#endif
N
N#ifndef traceGIVE_MUTEX_RECURSIVE
N	#define traceGIVE_MUTEX_RECURSIVE( pxMutex )
N#endif
N
N#ifndef traceGIVE_MUTEX_RECURSIVE_FAILED
N	#define traceGIVE_MUTEX_RECURSIVE_FAILED( pxMutex )
N#endif
N
N#ifndef traceTAKE_MUTEX_RECURSIVE
N	#define traceTAKE_MUTEX_RECURSIVE( pxMutex )
N#endif
N
N#ifndef traceTAKE_MUTEX_RECURSIVE_FAILED
N	#define traceTAKE_MUTEX_RECURSIVE_FAILED( pxMutex )
N#endif
N
N#ifndef traceCREATE_COUNTING_SEMAPHORE
N	#define traceCREATE_COUNTING_SEMAPHORE()
N#endif
N
N#ifndef traceCREATE_COUNTING_SEMAPHORE_FAILED
N	#define traceCREATE_COUNTING_SEMAPHORE_FAILED()
N#endif
N
N#ifndef traceQUEUE_SEND
N	#define traceQUEUE_SEND( pxQueue )
N#endif
N
N#ifndef traceQUEUE_SEND_FAILED
N	#define traceQUEUE_SEND_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE
N	#define traceQUEUE_RECEIVE( pxQueue )
N#endif
N
N#ifndef traceQUEUE_PEEK
N	#define traceQUEUE_PEEK( pxQueue )
N#endif
N
N#ifndef traceQUEUE_PEEK_FROM_ISR
N	#define traceQUEUE_PEEK_FROM_ISR( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE_FAILED
N	#define traceQUEUE_RECEIVE_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_SEND_FROM_ISR
N	#define traceQUEUE_SEND_FROM_ISR( pxQueue )
N#endif
N
N#ifndef traceQUEUE_SEND_FROM_ISR_FAILED
N	#define traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE_FROM_ISR
N	#define traceQUEUE_RECEIVE_FROM_ISR( pxQueue )
N#endif
N
N#ifndef traceQUEUE_RECEIVE_FROM_ISR_FAILED
N	#define traceQUEUE_RECEIVE_FROM_ISR_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_PEEK_FROM_ISR_FAILED
N	#define traceQUEUE_PEEK_FROM_ISR_FAILED( pxQueue )
N#endif
N
N#ifndef traceQUEUE_DELETE
N	#define traceQUEUE_DELETE( pxQueue )
N#endif
N
N#ifndef traceTASK_CREATE
N	#define traceTASK_CREATE( pxNewTCB )
N#endif
N
N#ifndef traceTASK_CREATE_FAILED
N	#define traceTASK_CREATE_FAILED()
N#endif
N
N#ifndef traceTASK_DELETE
N	#define traceTASK_DELETE( pxTaskToDelete )
N#endif
N
N#ifndef traceTASK_DELAY_UNTIL
N	#define traceTASK_DELAY_UNTIL( x )
N#endif
N
N#ifndef traceTASK_DELAY
N	#define traceTASK_DELAY()
N#endif
N
N#ifndef traceTASK_PRIORITY_SET
N	#define traceTASK_PRIORITY_SET( pxTask, uxNewPriority )
N#endif
N
N#ifndef traceTASK_SUSPEND
N	#define traceTASK_SUSPEND( pxTaskToSuspend )
N#endif
N
N#ifndef traceTASK_RESUME
N	#define traceTASK_RESUME( pxTaskToResume )
N#endif
N
N#ifndef traceTASK_RESUME_FROM_ISR
N	#define traceTASK_RESUME_FROM_ISR( pxTaskToResume )
N#endif
N
N#ifndef traceTASK_INCREMENT_TICK
N	#define traceTASK_INCREMENT_TICK( xTickCount )
N#endif
N
N#ifndef traceTIMER_CREATE
N	#define traceTIMER_CREATE( pxNewTimer )
N#endif
N
N#ifndef traceTIMER_CREATE_FAILED
N	#define traceTIMER_CREATE_FAILED()
N#endif
N
N#ifndef traceTIMER_COMMAND_SEND
N	#define traceTIMER_COMMAND_SEND( xTimer, xMessageID, xMessageValueValue, xReturn )
N#endif
N
N#ifndef traceTIMER_EXPIRED
N	#define traceTIMER_EXPIRED( pxTimer )
N#endif
N
N#ifndef traceTIMER_COMMAND_RECEIVED
N	#define traceTIMER_COMMAND_RECEIVED( pxTimer, xMessageID, xMessageValue )
N#endif
N
N#ifndef traceMALLOC
N    #define traceMALLOC( pvAddress, uiSize )
N#endif
N
N#ifndef traceFREE
N    #define traceFREE( pvAddress, uiSize )
N#endif
N
N#ifndef traceEVENT_GROUP_CREATE
N	#define traceEVENT_GROUP_CREATE( xEventGroup )
N#endif
N
N#ifndef traceEVENT_GROUP_CREATE_FAILED
N	#define traceEVENT_GROUP_CREATE_FAILED()
N#endif
N
N#ifndef traceEVENT_GROUP_SYNC_BLOCK
N	#define traceEVENT_GROUP_SYNC_BLOCK( xEventGroup, uxBitsToSet, uxBitsToWaitFor )
N#endif
N
N#ifndef traceEVENT_GROUP_SYNC_END
N	#define traceEVENT_GROUP_SYNC_END( xEventGroup, uxBitsToSet, uxBitsToWaitFor, xTimeoutOccurred ) ( void ) xTimeoutOccurred
N#endif
N
N#ifndef traceEVENT_GROUP_WAIT_BITS_BLOCK
N	#define traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor )
N#endif
N
N#ifndef traceEVENT_GROUP_WAIT_BITS_END
N	#define traceEVENT_GROUP_WAIT_BITS_END( xEventGroup, uxBitsToWaitFor, xTimeoutOccurred ) ( void ) xTimeoutOccurred
N#endif
N
N#ifndef traceEVENT_GROUP_CLEAR_BITS
N	#define traceEVENT_GROUP_CLEAR_BITS( xEventGroup, uxBitsToClear )
N#endif
N
N#ifndef traceEVENT_GROUP_CLEAR_BITS_FROM_ISR
N	#define traceEVENT_GROUP_CLEAR_BITS_FROM_ISR( xEventGroup, uxBitsToClear )
N#endif
N
N#ifndef traceEVENT_GROUP_SET_BITS
N	#define traceEVENT_GROUP_SET_BITS( xEventGroup, uxBitsToSet )
N#endif
N
N#ifndef traceEVENT_GROUP_SET_BITS_FROM_ISR
N	#define traceEVENT_GROUP_SET_BITS_FROM_ISR( xEventGroup, uxBitsToSet )
N#endif
N
N#ifndef traceEVENT_GROUP_DELETE
N	#define traceEVENT_GROUP_DELETE( xEventGroup )
N#endif
N
N#ifndef tracePEND_FUNC_CALL
N	#define tracePEND_FUNC_CALL(xFunctionToPend, pvParameter1, ulParameter2, ret)
N#endif
N
N#ifndef tracePEND_FUNC_CALL_FROM_ISR
N	#define tracePEND_FUNC_CALL_FROM_ISR(xFunctionToPend, pvParameter1, ulParameter2, ret)
N#endif
N
N#ifndef traceQUEUE_REGISTRY_ADD
N	#define traceQUEUE_REGISTRY_ADD(xQueue, pcQueueName)
N#endif
N
N#ifndef traceTASK_NOTIFY_TAKE_BLOCK
N	#define traceTASK_NOTIFY_TAKE_BLOCK()
N#endif
N
N#ifndef traceTASK_NOTIFY_TAKE
N	#define traceTASK_NOTIFY_TAKE()
N#endif
N
N#ifndef traceTASK_NOTIFY_WAIT_BLOCK
N	#define traceTASK_NOTIFY_WAIT_BLOCK()
N#endif
N
N#ifndef traceTASK_NOTIFY_WAIT
N	#define traceTASK_NOTIFY_WAIT()
N#endif
N
N#ifndef traceTASK_NOTIFY
N	#define traceTASK_NOTIFY()
N#endif
N
N#ifndef traceTASK_NOTIFY_FROM_ISR
N	#define traceTASK_NOTIFY_FROM_ISR()
N#endif
N
N#ifndef traceTASK_NOTIFY_GIVE_FROM_ISR
N	#define traceTASK_NOTIFY_GIVE_FROM_ISR()
N#endif
N
N#ifndef configGENERATE_RUN_TIME_STATS
N	#define configGENERATE_RUN_TIME_STATS 0
N#endif
N
N#if ( configGENERATE_RUN_TIME_STATS == 1 )
X#if ( 0 == 1 )
S
S	#ifndef portCONFIGURE_TIMER_FOR_RUN_TIME_STATS
S		#error If configGENERATE_RUN_TIME_STATS is defined then portCONFIGURE_TIMER_FOR_RUN_TIME_STATS must also be defined.  portCONFIGURE_TIMER_FOR_RUN_TIME_STATS should call a port layer function to setup a peripheral timer/counter that can then be used as the run time counter time base.
S	#endif /* portCONFIGURE_TIMER_FOR_RUN_TIME_STATS */
S
S	#ifndef portGET_RUN_TIME_COUNTER_VALUE
S		#ifndef portALT_GET_RUN_TIME_COUNTER_VALUE
S			#error If configGENERATE_RUN_TIME_STATS is defined then either portGET_RUN_TIME_COUNTER_VALUE or portALT_GET_RUN_TIME_COUNTER_VALUE must also be defined.  See the examples provided and the FreeRTOS web site for more information.
S		#endif /* portALT_GET_RUN_TIME_COUNTER_VALUE */
S	#endif /* portGET_RUN_TIME_COUNTER_VALUE */
S
N#endif /* configGENERATE_RUN_TIME_STATS */
N
N#ifndef portCONFIGURE_TIMER_FOR_RUN_TIME_STATS
N	#define portCONFIGURE_TIMER_FOR_RUN_TIME_STATS()
N#endif
N
N#ifndef configUSE_MALLOC_FAILED_HOOK
S	#define configUSE_MALLOC_FAILED_HOOK 0
N#endif
N
N#ifndef portPRIVILEGE_BIT
N	#define portPRIVILEGE_BIT ( ( UBaseType_t ) 0x00 )
N#endif
N
N#ifndef portYIELD_WITHIN_API
N	#define portYIELD_WITHIN_API portYIELD
N#endif
N
N#ifndef portSUPPRESS_TICKS_AND_SLEEP
N	#define portSUPPRESS_TICKS_AND_SLEEP( xExpectedIdleTime )
N#endif
N
N#ifndef configEXPECTED_IDLE_TIME_BEFORE_SLEEP
N	#define configEXPECTED_IDLE_TIME_BEFORE_SLEEP 2
N#endif
N
N#if configEXPECTED_IDLE_TIME_BEFORE_SLEEP < 2
X#if 2 < 2
S	#error configEXPECTED_IDLE_TIME_BEFORE_SLEEP must not be less than 2
N#endif
N
N#ifndef configUSE_TICKLESS_IDLE
N	#define configUSE_TICKLESS_IDLE 0
N#endif
N
N#ifndef configPRE_SLEEP_PROCESSING
N	#define configPRE_SLEEP_PROCESSING( x )
N#endif
N
N#ifndef configPOST_SLEEP_PROCESSING
N	#define configPOST_SLEEP_PROCESSING( x )
N#endif
N
N#ifndef configUSE_QUEUE_SETS
N	#define configUSE_QUEUE_SETS 0
N#endif
N
N#ifndef portTASK_USES_FLOATING_POINT
N	#define portTASK_USES_FLOATING_POINT()
N#endif
N
N#ifndef configUSE_TIME_SLICING
N	#define configUSE_TIME_SLICING 1
N#endif
N
N#ifndef configINCLUDE_APPLICATION_DEFINED_PRIVILEGED_FUNCTIONS
N	#define configINCLUDE_APPLICATION_DEFINED_PRIVILEGED_FUNCTIONS 0
N#endif
N
N#ifndef configUSE_STATS_FORMATTING_FUNCTIONS
S	#define configUSE_STATS_FORMATTING_FUNCTIONS 0
N#endif
N
N#ifndef portASSERT_IF_INTERRUPT_PRIORITY_INVALID
N	#define portASSERT_IF_INTERRUPT_PRIORITY_INVALID()
N#endif
N
N#ifndef configUSE_TRACE_FACILITY
S	#define configUSE_TRACE_FACILITY 0
N#endif
N
N#ifndef mtCOVERAGE_TEST_MARKER
N	#define mtCOVERAGE_TEST_MARKER()
N#endif
N
N#ifndef mtCOVERAGE_TEST_DELAY
N	#define mtCOVERAGE_TEST_DELAY()
N#endif
N
N#ifndef portASSERT_IF_IN_ISR
N	#define portASSERT_IF_IN_ISR()
N#endif
N
N#ifndef configUSE_PORT_OPTIMISED_TASK_SELECTION
N	#define configUSE_PORT_OPTIMISED_TASK_SELECTION 0
N#endif
N
N#ifndef configAPPLICATION_ALLOCATED_HEAP
N	#define configAPPLICATION_ALLOCATED_HEAP 0
N#endif
N
N#ifndef configUSE_TASK_NOTIFICATIONS
N	#define configUSE_TASK_NOTIFICATIONS 1
N#endif
N
N#ifndef portTICK_TYPE_IS_ATOMIC
N	#define portTICK_TYPE_IS_ATOMIC 0
N#endif
N
N#ifndef configSUPPORT_STATIC_ALLOCATION
N	/* Defaults to 0 for backward compatibility. */
N	#define configSUPPORT_STATIC_ALLOCATION 0
N#endif
N
N#ifndef configSUPPORT_DYNAMIC_ALLOCATION
S	/* Defaults to 1 for backward compatibility. */
S	#define configSUPPORT_DYNAMIC_ALLOCATION 1
N#endif
N
N/* Sanity check the configuration. */
N#if( configUSE_TICKLESS_IDLE != 0 )
X#if( 0 != 0 )
S	#if( INCLUDE_vTaskSuspend != 1 )
S		#error INCLUDE_vTaskSuspend must be set to 1 if configUSE_TICKLESS_IDLE is not set to 0
S	#endif /* INCLUDE_vTaskSuspend */
N#endif /* configUSE_TICKLESS_IDLE */
N
N#if( ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 0 ) )
X#if( ( 0 == 0 ) && ( 1 == 0 ) )
S	#error configSUPPORT_STATIC_ALLOCATION and configSUPPORT_DYNAMIC_ALLOCATION cannot both be 0, but can both be 1.
N#endif
N
N#if( ( configUSE_RECURSIVE_MUTEXES == 1 ) && ( configUSE_MUTEXES != 1 ) )
X#if( ( 0 == 1 ) && ( 1 != 1 ) )
S	#error configUSE_MUTEXES must be set to 1 to use recursive mutexes
N#endif
N
N#if( portTICK_TYPE_IS_ATOMIC == 0 )
X#if( 0 == 0 )
N	/* Either variables of tick type cannot be read atomically, or
N	portTICK_TYPE_IS_ATOMIC was not set - map the critical sections used when
N	the tick count is returned to the standard critical section macros. */
N	#define portTICK_TYPE_ENTER_CRITICAL() portENTER_CRITICAL()
N	#define portTICK_TYPE_EXIT_CRITICAL() portEXIT_CRITICAL()
N	#define portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR() portSET_INTERRUPT_MASK_FROM_ISR()
N	#define portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( x ) portCLEAR_INTERRUPT_MASK_FROM_ISR( ( x ) )
N#else
S	/* The tick type can be read atomically, so critical sections used when the
S	tick count is returned can be defined away. */
S	#define portTICK_TYPE_ENTER_CRITICAL()
S	#define portTICK_TYPE_EXIT_CRITICAL()
S	#define portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR() 0
S	#define portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( x ) ( void ) x
N#endif
N
N/* Definitions to allow backward compatibility with FreeRTOS versions prior to
NV8 if desired. */
N#ifndef configENABLE_BACKWARD_COMPATIBILITY
N	#define configENABLE_BACKWARD_COMPATIBILITY 1
N#endif
N
N#if configENABLE_BACKWARD_COMPATIBILITY == 1
X#if 1 == 1
N	#define eTaskStateGet eTaskGetState
N	#define portTickType TickType_t
N	#define xTaskHandle TaskHandle_t
N	#define xQueueHandle QueueHandle_t
N	#define xSemaphoreHandle SemaphoreHandle_t
N	#define xQueueSetHandle QueueSetHandle_t
N	#define xQueueSetMemberHandle QueueSetMemberHandle_t
N	#define xTimeOutType TimeOut_t
N	#define xMemoryRegion MemoryRegion_t
N	#define xTaskParameters TaskParameters_t
N	#define xTaskStatusType	TaskStatus_t
N	#define xTimerHandle TimerHandle_t
N	#define xCoRoutineHandle CoRoutineHandle_t
N	#define pdTASK_HOOK_CODE TaskHookFunction_t
N	#define portTICK_RATE_MS portTICK_PERIOD_MS
N	#define pcTaskGetTaskName pcTaskGetName
N	#define pcTimerGetTimerName pcTimerGetName
N	#define pcQueueGetQueueName pcQueueGetName
N	#define vTaskGetTaskInfo vTaskGetInfo
N
N	/* Backward compatibility within the scheduler code only - these definitions
N	are not really required but are included for completeness. */
N	#define tmrTIMER_CALLBACK TimerCallbackFunction_t
N	#define pdTASK_CODE TaskFunction_t
N	#define xListItem ListItem_t
N	#define xList List_t
N#endif /* configENABLE_BACKWARD_COMPATIBILITY */
N
N#if( configUSE_ALTERNATIVE_API != 0 )
X#if( 0 != 0 )
S	#error The alternative API was deprecated some time ago, and was removed in FreeRTOS V9.0 0
N#endif
N
N/* Set configUSE_TASK_FPU_SUPPORT to 0 to omit floating point support even
Nif floating point hardware is otherwise supported by the FreeRTOS port in use.
NThis constant is not supported by all FreeRTOS ports that include floating
Npoint support. */
N#ifndef configUSE_TASK_FPU_SUPPORT
N	#define configUSE_TASK_FPU_SUPPORT 1
N#endif
N
N/*
N * In line with software engineering best practice, FreeRTOS implements a strict
N * data hiding policy, so the real structures used by FreeRTOS to maintain the
N * state of tasks, queues, semaphores, etc. are not accessible to the application
N * code.  However, if the application writer wants to statically allocate such
N * an object then the size of the object needs to be know.  Dummy structures
N * that are guaranteed to have the same size and alignment requirements of the
N * real objects are used for this purpose.  The dummy list and list item
N * structures below are used for inclusion in such a dummy structure.
N */
Nstruct xSTATIC_LIST_ITEM
N{
N	TickType_t xDummy1;
N	void *pvDummy2[ 4 ];
N};
Ntypedef struct xSTATIC_LIST_ITEM StaticListItem_t;
N
N/* See the comments above the struct xSTATIC_LIST_ITEM definition. */
Nstruct xSTATIC_MINI_LIST_ITEM
N{
N	TickType_t xDummy1;
N	void *pvDummy2[ 2 ];
N};
Ntypedef struct xSTATIC_MINI_LIST_ITEM StaticMiniListItem_t;
N
N/* See the comments above the struct xSTATIC_LIST_ITEM definition. */
Ntypedef struct xSTATIC_LIST
N{
N	UBaseType_t uxDummy1;
N	void *pvDummy2;
N	StaticMiniListItem_t xDummy3;
N} StaticList_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the Task structure used internally by
N * FreeRTOS is not accessible to application code.  However, if the application
N * writer wants to statically allocate the memory required to create a task then
N * the size of the task object needs to be know.  The StaticTask_t structure
N * below is provided for this purpose.  Its sizes and alignment requirements are
N * guaranteed to match those of the genuine structure, no matter which
N * architecture is being used, and no matter how the values in FreeRTOSConfig.h
N * are set.  Its contents are somewhat obfuscated in the hope users will
N * recognise that it would be unwise to make direct use of the structure members.
N */
Ntypedef struct xSTATIC_TCB
N{
N	void				*pxDummy1;
N	#if ( portUSING_MPU_WRAPPERS == 1 )
X	#if ( 0 == 1 )
S		xMPU_SETTINGS	xDummy2;
N	#endif
N	StaticListItem_t	xDummy3[ 2 ];
N	UBaseType_t			uxDummy5;
N	void				*pxDummy6;
N	uint8_t				ucDummy7[ configMAX_TASK_NAME_LEN ];
X	uint8_t				ucDummy7[ ( 16 ) ];
N	#if ( portSTACK_GROWTH > 0 )
X	#if ( ( -1 ) > 0 )
S		void			*pxDummy8;
N	#endif
N	#if ( portCRITICAL_NESTING_IN_TCB == 1 )
X	#if ( 0 == 1 )
S		UBaseType_t		uxDummy9;
N	#endif
N	#if ( configUSE_TRACE_FACILITY == 1 )
X	#if ( 1 == 1 )
N		UBaseType_t		uxDummy10[ 2 ];
N	#endif
N	#if ( configUSE_MUTEXES == 1 )
X	#if ( 1 == 1 )
N		UBaseType_t		uxDummy12[ 2 ];
N	#endif
N	#if ( configUSE_APPLICATION_TASK_TAG == 1 )
X	#if ( 0 == 1 )
S		void			*pxDummy14;
N	#endif
N	#if( configNUM_THREAD_LOCAL_STORAGE_POINTERS > 0 )
X	#if( 0 > 0 )
S		void			*pvDummy15[ configNUM_THREAD_LOCAL_STORAGE_POINTERS ];
N	#endif
N	#if ( configGENERATE_RUN_TIME_STATS == 1 )
X	#if ( 0 == 1 )
S		uint32_t		ulDummy16;
N	#endif
N	#if ( configUSE_NEWLIB_REENTRANT == 1 )
X	#if ( 0 == 1 )
S		struct	_reent	xDummy17;
N	#endif
N	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
X	#if ( 1 == 1 )
N		uint32_t 		ulDummy18;
N		uint8_t 		ucDummy19;
N	#endif
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S		uint8_t			uxDummy20;
N	#endif
N
N} StaticTask_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the Queue structure used internally by
N * FreeRTOS is not accessible to application code.  However, if the application
N * writer wants to statically allocate the memory required to create a queue
N * then the size of the queue object needs to be know.  The StaticQueue_t
N * structure below is provided for this purpose.  Its sizes and alignment
N * requirements are guaranteed to match those of the genuine structure, no
N * matter which architecture is being used, and no matter how the values in
N * FreeRTOSConfig.h are set.  Its contents are somewhat obfuscated in the hope
N * users will recognise that it would be unwise to make direct use of the
N * structure members.
N */
Ntypedef struct xSTATIC_QUEUE
N{
N	void *pvDummy1[ 3 ];
N
N	union
N	{
N		void *pvDummy2;
N		UBaseType_t uxDummy2;
N	} u;
N
N	StaticList_t xDummy3[ 2 ];
N	UBaseType_t uxDummy4[ 3 ];
N	uint8_t ucDummy5[ 2 ];
N
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S		uint8_t ucDummy6;
N	#endif
N
N	#if ( configUSE_QUEUE_SETS == 1 )
X	#if ( 0 == 1 )
S		void *pvDummy7;
N	#endif
N
N	#if ( configUSE_TRACE_FACILITY == 1 )
X	#if ( 1 == 1 )
N		UBaseType_t uxDummy8;
N		uint8_t ucDummy9;
N	#endif
N
N} StaticQueue_t;
Ntypedef StaticQueue_t StaticSemaphore_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the event group structure used
N * internally by FreeRTOS is not accessible to application code.  However, if
N * the application writer wants to statically allocate the memory required to
N * create an event group then the size of the event group object needs to be
N * know.  The StaticEventGroup_t structure below is provided for this purpose.
N * Its sizes and alignment requirements are guaranteed to match those of the
N * genuine structure, no matter which architecture is being used, and no matter
N * how the values in FreeRTOSConfig.h are set.  Its contents are somewhat
N * obfuscated in the hope users will recognise that it would be unwise to make
N * direct use of the structure members.
N */
Ntypedef struct xSTATIC_EVENT_GROUP
N{
N	TickType_t xDummy1;
N	StaticList_t xDummy2;
N
N	#if( configUSE_TRACE_FACILITY == 1 )
X	#if( 1 == 1 )
N		UBaseType_t uxDummy3;
N	#endif
N
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S			uint8_t ucDummy4;
N	#endif
N
N} StaticEventGroup_t;
N
N/*
N * In line with software engineering best practice, especially when supplying a
N * library that is likely to change in future versions, FreeRTOS implements a
N * strict data hiding policy.  This means the software timer structure used
N * internally by FreeRTOS is not accessible to application code.  However, if
N * the application writer wants to statically allocate the memory required to
N * create a software timer then the size of the queue object needs to be know.
N * The StaticTimer_t structure below is provided for this purpose.  Its sizes
N * and alignment requirements are guaranteed to match those of the genuine
N * structure, no matter which architecture is being used, and no matter how the
N * values in FreeRTOSConfig.h are set.  Its contents are somewhat obfuscated in
N * the hope users will recognise that it would be unwise to make direct use of
N * the structure members.
N */
Ntypedef struct xSTATIC_TIMER
N{
N	void				*pvDummy1;
N	StaticListItem_t	xDummy2;
N	TickType_t			xDummy3;
N	UBaseType_t			uxDummy4;
N	void 				*pvDummy5[ 2 ];
N	#if( configUSE_TRACE_FACILITY == 1 )
X	#if( 1 == 1 )
N		UBaseType_t		uxDummy6;
N	#endif
N
N	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
X	#if( ( 0 == 1 ) && ( 1 == 1 ) )
S		uint8_t 		ucDummy7;
N	#endif
N
N} StaticTimer_t;
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* INC_FREERTOS_H */
N
L 6 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N#include "task.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\task.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N
N#ifndef INC_TASK_H
N#define INC_TASK_H
N
N#ifndef INC_FREERTOS_H
S	#error "include FreeRTOS.h must appear in source files before include task.h"
N#endif
N
N#include "list.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\list.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N/*
N * This is the list implementation used by the scheduler.  While it is tailored
N * heavily for the schedulers needs, it is also available for use by
N * application code.
N *
N * list_ts can only store pointers to list_item_ts.  Each ListItem_t contains a
N * numeric value (xItemValue).  Most of the time the lists are sorted in
N * descending item value order.
N *
N * Lists are created already containing one list item.  The value of this
N * item is the maximum possible that can be stored, it is therefore always at
N * the end of the list and acts as a marker.  The list member pxHead always
N * points to this marker - even though it is at the tail of the list.  This
N * is because the tail contains a wrap back pointer to the true head of
N * the list.
N *
N * In addition to it's value, each list item contains a pointer to the next
N * item in the list (pxNext), a pointer to the list it is in (pxContainer)
N * and a pointer to back to the object that contains it.  These later two
N * pointers are included for efficiency of list manipulation.  There is
N * effectively a two way link between the object containing the list item and
N * the list item itself.
N *
N *
N * \page ListIntroduction List Implementation
N * \ingroup FreeRTOSIntro
N */
N
N#ifndef INC_FREERTOS_H
S	#error FreeRTOS.h must be included before list.h
N#endif
N
N#ifndef LIST_H
N#define LIST_H
N
N/*
N * The list structure members are modified from within interrupts, and therefore
N * by rights should be declared volatile.  However, they are only modified in a
N * functionally atomic way (within critical sections of with the scheduler
N * suspended) and are either passed by reference into a function or indexed via
N * a volatile variable.  Therefore, in all use cases tested so far, the volatile
N * qualifier can be omitted in order to provide a moderate performance
N * improvement without adversely affecting functional behaviour.  The assembly
N * instructions generated by the IAR, ARM and GCC compilers when the respective
N * compiler's options were set for maximum optimisation has been inspected and
N * deemed to be as intended.  That said, as compiler technology advances, and
N * especially if aggressive cross module optimisation is used (a use case that
N * has not been exercised to any great extend) then it is feasible that the
N * volatile qualifier will be needed for correct optimisation.  It is expected
N * that a compiler removing essential code because, without the volatile
N * qualifier on the list structure members and with aggressive cross module
N * optimisation, the compiler deemed the code unnecessary will result in
N * complete and obvious failure of the scheduler.  If this is ever experienced
N * then the volatile qualifier can be inserted in the relevant places within the
N * list structures by simply defining configLIST_VOLATILE to volatile in
N * FreeRTOSConfig.h (as per the example at the bottom of this comment block).
N * If configLIST_VOLATILE is not defined then the preprocessor directives below
N * will simply #define configLIST_VOLATILE away completely.
N *
N * To use volatile list structure members then add the following line to
N * FreeRTOSConfig.h (without the quotes):
N * "#define configLIST_VOLATILE volatile"
N */
N#ifndef configLIST_VOLATILE
N	#define configLIST_VOLATILE
N#endif /* configSUPPORT_CROSS_MODULE_OPTIMISATION */
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N/* Macros that can be used to place known values within the list structures,
Nthen check that the known values do not get corrupted during the execution of
Nthe application.   These may catch the list data structures being overwritten in
Nmemory.  They will not catch data errors caused by incorrect configuration or
Nuse of FreeRTOS.*/
N#if( configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES == 0 )
X#if( 0 == 0 )
N	/* Define the macros to do nothing. */
N	#define listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE
N	#define listSECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE
N	#define listFIRST_LIST_INTEGRITY_CHECK_VALUE
N	#define listSECOND_LIST_INTEGRITY_CHECK_VALUE
N	#define listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )
N	#define listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )
N	#define listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList )
N	#define listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList )
N	#define listTEST_LIST_ITEM_INTEGRITY( pxItem )
N	#define listTEST_LIST_INTEGRITY( pxList )
N#else
S	/* Define macros that add new members into the list structures. */
S	#define listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE				TickType_t xListItemIntegrityValue1;
S	#define listSECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE				TickType_t xListItemIntegrityValue2;
S	#define listFIRST_LIST_INTEGRITY_CHECK_VALUE					TickType_t xListIntegrityValue1;
S	#define listSECOND_LIST_INTEGRITY_CHECK_VALUE					TickType_t xListIntegrityValue2;
S
S	/* Define macros that set the new structure members to known values. */
S	#define listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )		( pxItem )->xListItemIntegrityValue1 = pdINTEGRITY_CHECK_VALUE
S	#define listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem )	( pxItem )->xListItemIntegrityValue2 = pdINTEGRITY_CHECK_VALUE
S	#define listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList )		( pxList )->xListIntegrityValue1 = pdINTEGRITY_CHECK_VALUE
S	#define listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList )		( pxList )->xListIntegrityValue2 = pdINTEGRITY_CHECK_VALUE
S
S	/* Define macros that will assert if one of the structure members does not
S	contain its expected value. */
S	#define listTEST_LIST_ITEM_INTEGRITY( pxItem )		configASSERT( ( ( pxItem )->xListItemIntegrityValue1 == pdINTEGRITY_CHECK_VALUE ) && ( ( pxItem )->xListItemIntegrityValue2 == pdINTEGRITY_CHECK_VALUE ) )
S	#define listTEST_LIST_INTEGRITY( pxList )			configASSERT( ( ( pxList )->xListIntegrityValue1 == pdINTEGRITY_CHECK_VALUE ) && ( ( pxList )->xListIntegrityValue2 == pdINTEGRITY_CHECK_VALUE ) )
N#endif /* configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES */
N
N
N/*
N * Definition of the only type of object that a list can contain.
N */
Nstruct xLIST_ITEM
N{
N	listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE			/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X				 
N	configLIST_VOLATILE TickType_t xItemValue;			/*< The value being listed.  In most cases this is used to sort the list in descending order. */
X	 TickType_t xItemValue;			 
N	struct xLIST_ITEM * configLIST_VOLATILE pxNext;		/*< Pointer to the next ListItem_t in the list. */
X	struct xLIST_ITEM *  pxNext;		 
N	struct xLIST_ITEM * configLIST_VOLATILE pxPrevious;	/*< Pointer to the previous ListItem_t in the list. */
X	struct xLIST_ITEM *  pxPrevious;	 
N	void * pvOwner;										/*< Pointer to the object (normally a TCB) that contains the list item.  There is therefore a two way link between the object containing the list item and the list item itself. */
N	void * configLIST_VOLATILE pvContainer;				/*< Pointer to the list in which this list item is placed (if any). */
X	void *  pvContainer;				 
N	listSECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE			/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X				 
N};
Ntypedef struct xLIST_ITEM ListItem_t;					/* For some reason lint wants this as two separate definitions. */
N
Nstruct xMINI_LIST_ITEM
N{
N	listFIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE			/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X				 
N	configLIST_VOLATILE TickType_t xItemValue;
X	 TickType_t xItemValue;
N	struct xLIST_ITEM * configLIST_VOLATILE pxNext;
X	struct xLIST_ITEM *  pxNext;
N	struct xLIST_ITEM * configLIST_VOLATILE pxPrevious;
X	struct xLIST_ITEM *  pxPrevious;
N};
Ntypedef struct xMINI_LIST_ITEM MiniListItem_t;
N
N/*
N * Definition of the type of queue used by the scheduler.
N */
Ntypedef struct xLIST
N{
N	listFIRST_LIST_INTEGRITY_CHECK_VALUE				/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X					 
N	configLIST_VOLATILE UBaseType_t uxNumberOfItems;
X	 UBaseType_t uxNumberOfItems;
N	ListItem_t * configLIST_VOLATILE pxIndex;			/*< Used to walk through the list.  Points to the last item returned by a call to listGET_OWNER_OF_NEXT_ENTRY (). */
X	ListItem_t *  pxIndex;			 
N	MiniListItem_t xListEnd;							/*< List item that contains the maximum possible item value meaning it is always at the end of the list and is therefore used as a marker. */
N	listSECOND_LIST_INTEGRITY_CHECK_VALUE				/*< Set to a known value if configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
X					 
N} List_t;
N
N/*
N * Access macro to set the owner of a list item.  The owner of a list item
N * is the object (usually a TCB) that contains the list item.
N *
N * \page listSET_LIST_ITEM_OWNER listSET_LIST_ITEM_OWNER
N * \ingroup LinkedList
N */
N#define listSET_LIST_ITEM_OWNER( pxListItem, pxOwner )		( ( pxListItem )->pvOwner = ( void * ) ( pxOwner ) )
N
N/*
N * Access macro to get the owner of a list item.  The owner of a list item
N * is the object (usually a TCB) that contains the list item.
N *
N * \page listSET_LIST_ITEM_OWNER listSET_LIST_ITEM_OWNER
N * \ingroup LinkedList
N */
N#define listGET_LIST_ITEM_OWNER( pxListItem )	( ( pxListItem )->pvOwner )
N
N/*
N * Access macro to set the value of the list item.  In most cases the value is
N * used to sort the list in descending order.
N *
N * \page listSET_LIST_ITEM_VALUE listSET_LIST_ITEM_VALUE
N * \ingroup LinkedList
N */
N#define listSET_LIST_ITEM_VALUE( pxListItem, xValue )	( ( pxListItem )->xItemValue = ( xValue ) )
N
N/*
N * Access macro to retrieve the value of the list item.  The value can
N * represent anything - for example the priority of a task, or the time at
N * which a task should be unblocked.
N *
N * \page listGET_LIST_ITEM_VALUE listGET_LIST_ITEM_VALUE
N * \ingroup LinkedList
N */
N#define listGET_LIST_ITEM_VALUE( pxListItem )	( ( pxListItem )->xItemValue )
N
N/*
N * Access macro to retrieve the value of the list item at the head of a given
N * list.
N *
N * \page listGET_LIST_ITEM_VALUE listGET_LIST_ITEM_VALUE
N * \ingroup LinkedList
N */
N#define listGET_ITEM_VALUE_OF_HEAD_ENTRY( pxList )	( ( ( pxList )->xListEnd ).pxNext->xItemValue )
N
N/*
N * Return the list item at the head of the list.
N *
N * \page listGET_HEAD_ENTRY listGET_HEAD_ENTRY
N * \ingroup LinkedList
N */
N#define listGET_HEAD_ENTRY( pxList )	( ( ( pxList )->xListEnd ).pxNext )
N
N/*
N * Return the list item at the head of the list.
N *
N * \page listGET_NEXT listGET_NEXT
N * \ingroup LinkedList
N */
N#define listGET_NEXT( pxListItem )	( ( pxListItem )->pxNext )
N
N/*
N * Return the list item that marks the end of the list
N *
N * \page listGET_END_MARKER listGET_END_MARKER
N * \ingroup LinkedList
N */
N#define listGET_END_MARKER( pxList )	( ( ListItem_t const * ) ( &( ( pxList )->xListEnd ) ) )
N
N/*
N * Access macro to determine if a list contains any items.  The macro will
N * only have the value true if the list is empty.
N *
N * \page listLIST_IS_EMPTY listLIST_IS_EMPTY
N * \ingroup LinkedList
N */
N#define listLIST_IS_EMPTY( pxList )	( ( BaseType_t ) ( ( pxList )->uxNumberOfItems == ( UBaseType_t ) 0 ) )
N
N/*
N * Access macro to return the number of items in the list.
N */
N#define listCURRENT_LIST_LENGTH( pxList )	( ( pxList )->uxNumberOfItems )
N
N/*
N * Access function to obtain the owner of the next entry in a list.
N *
N * The list member pxIndex is used to walk through a list.  Calling
N * listGET_OWNER_OF_NEXT_ENTRY increments pxIndex to the next item in the list
N * and returns that entry's pxOwner parameter.  Using multiple calls to this
N * function it is therefore possible to move through every item contained in
N * a list.
N *
N * The pxOwner parameter of a list item is a pointer to the object that owns
N * the list item.  In the scheduler this is normally a task control block.
N * The pxOwner parameter effectively creates a two way link between the list
N * item and its owner.
N *
N * @param pxTCB pxTCB is set to the address of the owner of the next list item.
N * @param pxList The list from which the next item owner is to be returned.
N *
N * \page listGET_OWNER_OF_NEXT_ENTRY listGET_OWNER_OF_NEXT_ENTRY
N * \ingroup LinkedList
N */
N#define listGET_OWNER_OF_NEXT_ENTRY( pxTCB, pxList )										\
N{																							\
NList_t * const pxConstList = ( pxList );													\
N	/* Increment the index to the next item and return the item, ensuring */				\
N	/* we don't return the marker used at the end of the list.  */							\
N	( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;							\
N	if( ( void * ) ( pxConstList )->pxIndex == ( void * ) &( ( pxConstList )->xListEnd ) )	\
N	{																						\
N		( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;						\
N	}																						\
N	( pxTCB ) = ( pxConstList )->pxIndex->pvOwner;											\
N}
X#define listGET_OWNER_OF_NEXT_ENTRY( pxTCB, pxList )										{																							List_t * const pxConstList = ( pxList );														 					 								( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;								if( ( void * ) ( pxConstList )->pxIndex == ( void * ) &( ( pxConstList )->xListEnd ) )		{																								( pxConstList )->pxIndex = ( pxConstList )->pxIndex->pxNext;							}																							( pxTCB ) = ( pxConstList )->pxIndex->pvOwner;											}
N
N
N/*
N * Access function to obtain the owner of the first entry in a list.  Lists
N * are normally sorted in ascending item value order.
N *
N * This function returns the pxOwner member of the first item in the list.
N * The pxOwner parameter of a list item is a pointer to the object that owns
N * the list item.  In the scheduler this is normally a task control block.
N * The pxOwner parameter effectively creates a two way link between the list
N * item and its owner.
N *
N * @param pxList The list from which the owner of the head item is to be
N * returned.
N *
N * \page listGET_OWNER_OF_HEAD_ENTRY listGET_OWNER_OF_HEAD_ENTRY
N * \ingroup LinkedList
N */
N#define listGET_OWNER_OF_HEAD_ENTRY( pxList )  ( (&( ( pxList )->xListEnd ))->pxNext->pvOwner )
N
N/*
N * Check to see if a list item is within a list.  The list item maintains a
N * "container" pointer that points to the list it is in.  All this macro does
N * is check to see if the container and the list match.
N *
N * @param pxList The list we want to know if the list item is within.
N * @param pxListItem The list item we want to know if is in the list.
N * @return pdTRUE if the list item is in the list, otherwise pdFALSE.
N */
N#define listIS_CONTAINED_WITHIN( pxList, pxListItem ) ( ( BaseType_t ) ( ( pxListItem )->pvContainer == ( void * ) ( pxList ) ) )
N
N/*
N * Return the list a list item is contained within (referenced from).
N *
N * @param pxListItem The list item being queried.
N * @return A pointer to the List_t object that references the pxListItem
N */
N#define listLIST_ITEM_CONTAINER( pxListItem ) ( ( pxListItem )->pvContainer )
N
N/*
N * This provides a crude means of knowing if a list has been initialised, as
N * pxList->xListEnd.xItemValue is set to portMAX_DELAY by the vListInitialise()
N * function.
N */
N#define listLIST_IS_INITIALISED( pxList ) ( ( pxList )->xListEnd.xItemValue == portMAX_DELAY )
N
N/*
N * Must be called before a list is used!  This initialises all the members
N * of the list structure and inserts the xListEnd item into the list as a
N * marker to the back of the list.
N *
N * @param pxList Pointer to the list being initialised.
N *
N * \page vListInitialise vListInitialise
N * \ingroup LinkedList
N */
Nvoid vListInitialise( List_t * const pxList ) PRIVILEGED_FUNCTION;
Xvoid vListInitialise( List_t * const pxList ) ;
N
N/*
N * Must be called before a list item is used.  This sets the list container to
N * null so the item does not think that it is already contained in a list.
N *
N * @param pxItem Pointer to the list item being initialised.
N *
N * \page vListInitialiseItem vListInitialiseItem
N * \ingroup LinkedList
N */
Nvoid vListInitialiseItem( ListItem_t * const pxItem ) PRIVILEGED_FUNCTION;
Xvoid vListInitialiseItem( ListItem_t * const pxItem ) ;
N
N/*
N * Insert a list item into a list.  The item will be inserted into the list in
N * a position determined by its item value (descending item value order).
N *
N * @param pxList The list into which the item is to be inserted.
N *
N * @param pxNewListItem The item that is to be placed in the list.
N *
N * \page vListInsert vListInsert
N * \ingroup LinkedList
N */
Nvoid vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem ) PRIVILEGED_FUNCTION;
Xvoid vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem ) ;
N
N/*
N * Insert a list item into a list.  The item will be inserted in a position
N * such that it will be the last item within the list returned by multiple
N * calls to listGET_OWNER_OF_NEXT_ENTRY.
N *
N * The list member pxIndex is used to walk through a list.  Calling
N * listGET_OWNER_OF_NEXT_ENTRY increments pxIndex to the next item in the list.
N * Placing an item in a list using vListInsertEnd effectively places the item
N * in the list position pointed to by pxIndex.  This means that every other
N * item within the list will be returned by listGET_OWNER_OF_NEXT_ENTRY before
N * the pxIndex parameter again points to the item being inserted.
N *
N * @param pxList The list into which the item is to be inserted.
N *
N * @param pxNewListItem The list item to be inserted into the list.
N *
N * \page vListInsertEnd vListInsertEnd
N * \ingroup LinkedList
N */
Nvoid vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem ) PRIVILEGED_FUNCTION;
Xvoid vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem ) ;
N
N/*
N * Remove an item from a list.  The list item has a pointer to the list that
N * it is in, so only the list item need be passed into the function.
N *
N * @param uxListRemove The item to be removed.  The item will remove itself from
N * the list pointed to by it's pxContainer parameter.
N *
N * @return The number of items that remain in the list after the list item has
N * been removed.
N *
N * \page uxListRemove uxListRemove
N * \ingroup LinkedList
N */
NUBaseType_t uxListRemove( ListItem_t * const pxItemToRemove ) PRIVILEGED_FUNCTION;
XUBaseType_t uxListRemove( ListItem_t * const pxItemToRemove ) ;
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif
N
L 79 "..\..\common\src\FreeRTOS\Source\include\task.h" 2
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N/*-----------------------------------------------------------
N * MACROS AND DEFINITIONS
N *----------------------------------------------------------*/
N
N#define tskKERNEL_VERSION_NUMBER "V9.0.0"
N#define tskKERNEL_VERSION_MAJOR 9
N#define tskKERNEL_VERSION_MINOR 0
N#define tskKERNEL_VERSION_BUILD 0
N
N/**
N * task. h
N *
N * Type by which tasks are referenced.  For example, a call to xTaskCreate
N * returns (via a pointer parameter) an TaskHandle_t variable that can then
N * be used as a parameter to vTaskDelete to delete the task.
N *
N * \defgroup TaskHandle_t TaskHandle_t
N * \ingroup Tasks
N */
Ntypedef void * TaskHandle_t;
N
N/*
N * Defines the prototype to which the application task hook function must
N * conform.
N */
Ntypedef BaseType_t (*TaskHookFunction_t)( void * );
N
N/* Task states returned by eTaskGetState. */
Ntypedef enum
N{
N	eRunning = 0,	/* A task is querying the state of itself, so must be running. */
N	eReady,			/* The task being queried is in a read or pending ready list. */
N	eBlocked,		/* The task being queried is in the Blocked state. */
N	eSuspended,		/* The task being queried is in the Suspended state, or is in the Blocked state with an infinite time out. */
N	eDeleted,		/* The task being queried has been deleted, but its TCB has not yet been freed. */
N	eInvalid			/* Used as an 'invalid state' value. */
N} eTaskState;
N
N/* Actions that can be performed when vTaskNotify() is called. */
Ntypedef enum
N{
N	eNoAction = 0,				/* Notify the task without updating its notify value. */
N	eSetBits,					/* Set bits in the task's notification value. */
N	eIncrement,					/* Increment the task's notification value. */
N	eSetValueWithOverwrite,		/* Set the task's notification value to a specific value even if the previous value has not yet been read by the task. */
N	eSetValueWithoutOverwrite	/* Set the task's notification value if the previous value has been read by the task. */
N} eNotifyAction;
N
N/*
N * Used internally only.
N */
Ntypedef struct xTIME_OUT
N{
N	BaseType_t xOverflowCount;
N	TickType_t xTimeOnEntering;
N} TimeOut_t;
N
N/*
N * Defines the memory ranges allocated to the task when an MPU is used.
N */
Ntypedef struct xMEMORY_REGION
N{
N	void *pvBaseAddress;
N	uint32_t ulLengthInBytes;
N	uint32_t ulParameters;
N} MemoryRegion_t;
N
N/*
N * Parameters required to create an MPU protected task.
N */
Ntypedef struct xTASK_PARAMETERS
N{
N	TaskFunction_t pvTaskCode;
N	const char * const pcName;	/*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N	uint16_t usStackDepth;
N	void *pvParameters;
N	UBaseType_t uxPriority;
N	StackType_t *puxStackBuffer;
N	MemoryRegion_t xRegions[ portNUM_CONFIGURABLE_REGIONS ];
X	MemoryRegion_t xRegions[ 1 ];
N} TaskParameters_t;
N
N/* Used with the uxTaskGetSystemState() function to return the state of each task
Nin the system. */
Ntypedef struct xTASK_STATUS
N{
N	TaskHandle_t xHandle;			/* The handle of the task to which the rest of the information in the structure relates. */
N	const char *pcTaskName;			/* A pointer to the task's name.  This value will be invalid if the task was deleted since the structure was populated! */ /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N	UBaseType_t xTaskNumber;		/* A number unique to the task. */
N	eTaskState eCurrentState;		/* The state in which the task existed when the structure was populated. */
N	UBaseType_t uxCurrentPriority;	/* The priority at which the task was running (may be inherited) when the structure was populated. */
N	UBaseType_t uxBasePriority;		/* The priority to which the task will return if the task's current priority has been inherited to avoid unbounded priority inversion when obtaining a mutex.  Only valid if configUSE_MUTEXES is defined as 1 in FreeRTOSConfig.h. */
N	uint32_t ulRunTimeCounter;		/* The total run time allocated to the task so far, as defined by the run time stats clock.  See http://www.freertos.org/rtos-run-time-stats.html.  Only valid when configGENERATE_RUN_TIME_STATS is defined as 1 in FreeRTOSConfig.h. */
N	StackType_t *pxStackBase;		/* Points to the lowest address of the task's stack area. */
N	uint16_t usStackHighWaterMark;	/* The minimum amount of stack space that has remained for the task since the task was created.  The closer this value is to zero the closer the task has come to overflowing its stack. */
N} TaskStatus_t;
N
N/* Possible return values for eTaskConfirmSleepModeStatus(). */
Ntypedef enum
N{
N	eAbortSleep = 0,		/* A task has been made ready or a context switch pended since portSUPPORESS_TICKS_AND_SLEEP() was called - abort entering a sleep mode. */
N	eStandardSleep,			/* Enter a sleep mode that will not last any longer than the expected idle time. */
N	eNoTasksWaitingTimeout	/* No tasks are waiting for a timeout so it is safe to enter a sleep mode that can only be exited by an external interrupt. */
N} eSleepModeStatus;
N
N/**
N * Defines the priority used by the idle task.  This must not be modified.
N *
N * \ingroup TaskUtils
N */
N#define tskIDLE_PRIORITY			( ( UBaseType_t ) 0U )
N
N/**
N * task. h
N *
N * Macro for forcing a context switch.
N *
N * \defgroup taskYIELD taskYIELD
N * \ingroup SchedulerControl
N */
N#define taskYIELD()					portYIELD()
N
N/**
N * task. h
N *
N * Macro to mark the start of a critical code region.  Preemptive context
N * switches cannot occur when in a critical region.
N *
N * NOTE: This may alter the stack (depending on the portable implementation)
N * so must be used with care!
N *
N * \defgroup taskENTER_CRITICAL taskENTER_CRITICAL
N * \ingroup SchedulerControl
N */
N#define taskENTER_CRITICAL()		portENTER_CRITICAL()
N#define taskENTER_CRITICAL_FROM_ISR() portSET_INTERRUPT_MASK_FROM_ISR()
N
N/**
N * task. h
N *
N * Macro to mark the end of a critical code region.  Preemptive context
N * switches cannot occur when in a critical region.
N *
N * NOTE: This may alter the stack (depending on the portable implementation)
N * so must be used with care!
N *
N * \defgroup taskEXIT_CRITICAL taskEXIT_CRITICAL
N * \ingroup SchedulerControl
N */
N#define taskEXIT_CRITICAL()			portEXIT_CRITICAL()
N#define taskEXIT_CRITICAL_FROM_ISR( x ) portCLEAR_INTERRUPT_MASK_FROM_ISR( x )
N/**
N * task. h
N *
N * Macro to disable all maskable interrupts.
N *
N * \defgroup taskDISABLE_INTERRUPTS taskDISABLE_INTERRUPTS
N * \ingroup SchedulerControl
N */
N#define taskDISABLE_INTERRUPTS()	portDISABLE_INTERRUPTS()
N
N/**
N * task. h
N *
N * Macro to enable microcontroller interrupts.
N *
N * \defgroup taskENABLE_INTERRUPTS taskENABLE_INTERRUPTS
N * \ingroup SchedulerControl
N */
N#define taskENABLE_INTERRUPTS()		portENABLE_INTERRUPTS()
N
N/* Definitions returned by xTaskGetSchedulerState().  taskSCHEDULER_SUSPENDED is
N0 to generate more optimal code when configASSERT() is defined as the constant
Nis used in assert() statements. */
N#define taskSCHEDULER_SUSPENDED		( ( BaseType_t ) 0 )
N#define taskSCHEDULER_NOT_STARTED	( ( BaseType_t ) 1 )
N#define taskSCHEDULER_RUNNING		( ( BaseType_t ) 2 )
N
N
N/*-----------------------------------------------------------
N * TASK CREATION API
N *----------------------------------------------------------*/
N
N/**
N * task. h
N *<pre>
N BaseType_t xTaskCreate(
N							  TaskFunction_t pvTaskCode,
N							  const char * const pcName,
N							  uint16_t usStackDepth,
N							  void *pvParameters,
N							  UBaseType_t uxPriority,
N							  TaskHandle_t *pvCreatedTask
N						  );</pre>
N *
N * Create a new task and add it to the list of tasks that are ready to run.
N *
N * Internally, within the FreeRTOS implementation, tasks use two blocks of
N * memory.  The first block is used to hold the task's data structures.  The
N * second block is used by the task as its stack.  If a task is created using
N * xTaskCreate() then both blocks of memory are automatically dynamically
N * allocated inside the xTaskCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a task is created using
N * xTaskCreateStatic() then the application writer must provide the required
N * memory.  xTaskCreateStatic() therefore allows a task to be created without
N * using any dynamic memory allocation.
N *
N * See xTaskCreateStatic() for a version that does not use any dynamic memory
N * allocation.
N *
N * xTaskCreate() can only be used to create a task that has unrestricted
N * access to the entire microcontroller memory map.  Systems that include MPU
N * support can alternatively create an MPU constrained task using
N * xTaskCreateRestricted().
N *
N * @param pvTaskCode Pointer to the task entry function.  Tasks
N * must be implemented to never return (i.e. continuous loop).
N *
N * @param pcName A descriptive name for the task.  This is mainly used to
N * facilitate debugging.  Max length defined by configMAX_TASK_NAME_LEN - default
N * is 16.
N *
N * @param usStackDepth The size of the task stack specified as the number of
N * variables the stack can hold - not the number of bytes.  For example, if
N * the stack is 16 bits wide and usStackDepth is defined as 100, 200 bytes
N * will be allocated for stack storage.
N *
N * @param pvParameters Pointer that will be used as the parameter for the task
N * being created.
N *
N * @param uxPriority The priority at which the task should run.  Systems that
N * include MPU support can optionally create tasks in a privileged (system)
N * mode by setting bit portPRIVILEGE_BIT of the priority parameter.  For
N * example, to create a privileged task at priority 2 the uxPriority parameter
N * should be set to ( 2 | portPRIVILEGE_BIT ).
N *
N * @param pvCreatedTask Used to pass back a handle by which the created task
N * can be referenced.
N *
N * @return pdPASS if the task was successfully created and added to a ready
N * list, otherwise an error code defined in the file projdefs.h
N *
N * Example usage:
N   <pre>
N // Task to be created.
N void vTaskCode( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N	 }
N }
N
N // Function that creates a task.
N void vOtherFunction( void )
N {
N static uint8_t ucParameterToPass;
N TaskHandle_t xHandle = NULL;
N
N	 // Create the task, storing the handle.  Note that the passed parameter ucParameterToPass
N	 // must exist for the lifetime of the task, so in this case is declared static.  If it was just an
N	 // an automatic stack variable it might no longer exist, or at least have been corrupted, by the time
N	 // the new task attempts to access it.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, &ucParameterToPass, tskIDLE_PRIORITY, &xHandle );
N     configASSERT( xHandle );
N
N	 // Use the handle to delete the task.
N     if( xHandle != NULL )
N     {
N	     vTaskDelete( xHandle );
N     }
N }
N   </pre>
N * \defgroup xTaskCreate xTaskCreate
N * \ingroup Tasks
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
N							const char * const pcName,	/*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N							const uint16_t usStackDepth,
N							void * const pvParameters,
N							UBaseType_t uxPriority,
N							TaskHandle_t * const pxCreatedTask ) PRIVILEGED_FUNCTION;
X							TaskHandle_t * const pxCreatedTask ) ;
N#endif
N
N/**
N * task. h
N *<pre>
N TaskHandle_t xTaskCreateStatic( TaskFunction_t pvTaskCode,
N								 const char * const pcName,
N								 uint32_t ulStackDepth,
N								 void *pvParameters,
N								 UBaseType_t uxPriority,
N								 StackType_t *pxStackBuffer,
N								 StaticTask_t *pxTaskBuffer );</pre>
N *
N * Create a new task and add it to the list of tasks that are ready to run.
N *
N * Internally, within the FreeRTOS implementation, tasks use two blocks of
N * memory.  The first block is used to hold the task's data structures.  The
N * second block is used by the task as its stack.  If a task is created using
N * xTaskCreate() then both blocks of memory are automatically dynamically
N * allocated inside the xTaskCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a task is created using
N * xTaskCreateStatic() then the application writer must provide the required
N * memory.  xTaskCreateStatic() therefore allows a task to be created without
N * using any dynamic memory allocation.
N *
N * @param pvTaskCode Pointer to the task entry function.  Tasks
N * must be implemented to never return (i.e. continuous loop).
N *
N * @param pcName A descriptive name for the task.  This is mainly used to
N * facilitate debugging.  The maximum length of the string is defined by
N * configMAX_TASK_NAME_LEN in FreeRTOSConfig.h.
N *
N * @param ulStackDepth The size of the task stack specified as the number of
N * variables the stack can hold - not the number of bytes.  For example, if
N * the stack is 32-bits wide and ulStackDepth is defined as 100 then 400 bytes
N * will be allocated for stack storage.
N *
N * @param pvParameters Pointer that will be used as the parameter for the task
N * being created.
N *
N * @param uxPriority The priority at which the task will run.
N *
N * @param pxStackBuffer Must point to a StackType_t array that has at least
N * ulStackDepth indexes - the array will then be used as the task's stack,
N * removing the need for the stack to be allocated dynamically.
N *
N * @param pxTaskBuffer Must point to a variable of type StaticTask_t, which will
N * then be used to hold the task's data structures, removing the need for the
N * memory to be allocated dynamically.
N *
N * @return If neither pxStackBuffer or pxTaskBuffer are NULL, then the task will
N * be created and pdPASS is returned.  If either pxStackBuffer or pxTaskBuffer
N * are NULL then the task will not be created and
N * errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY is returned.
N *
N * Example usage:
N   <pre>
N
N    // Dimensions the buffer that the task being created will use as its stack.
N    // NOTE:  This is the number of words the stack will hold, not the number of
N    // bytes.  For example, if each stack item is 32-bits, and this is set to 100,
N    // then 400 bytes (100 * 32-bits) will be allocated.
N    #define STACK_SIZE 200
N
N    // Structure that will hold the TCB of the task being created.
N    StaticTask_t xTaskBuffer;
N
N    // Buffer that the task being created will use as its stack.  Note this is
N    // an array of StackType_t variables.  The size of StackType_t is dependent on
N    // the RTOS port.
N    StackType_t xStack[ STACK_SIZE ];
N
N    // Function that implements the task being created.
N    void vTaskCode( void * pvParameters )
N    {
N        // The parameter value is expected to be 1 as 1 is passed in the
N        // pvParameters value in the call to xTaskCreateStatic().
N        configASSERT( ( uint32_t ) pvParameters == 1UL );
N
N        for( ;; )
N        {
N            // Task code goes here.
N        }
N    }
N
N    // Function that creates a task.
N    void vOtherFunction( void )
N    {
N        TaskHandle_t xHandle = NULL;
N
N        // Create the task without using any dynamic memory allocation.
N        xHandle = xTaskCreateStatic(
N                      vTaskCode,       // Function that implements the task.
N                      "NAME",          // Text name for the task.
N                      STACK_SIZE,      // Stack size in words, not bytes.
N                      ( void * ) 1,    // Parameter passed into the task.
N                      tskIDLE_PRIORITY,// Priority at which the task is created.
N                      xStack,          // Array to use as the task's stack.
N                      &xTaskBuffer );  // Variable to hold the task's data structure.
N
N        // puxStackBuffer and pxTaskBuffer were not NULL, so the task will have
N        // been created, and xHandle will be the task's handle.  Use the handle
N        // to suspend the task.
N        vTaskSuspend( xHandle );
N    }
N   </pre>
N * \defgroup xTaskCreateStatic xTaskCreateStatic
N * \ingroup Tasks
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	TaskHandle_t xTaskCreateStatic(	TaskFunction_t pxTaskCode,
S									const char * const pcName, /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
S									const uint32_t ulStackDepth,
S									void * const pvParameters,
S									UBaseType_t uxPriority,
S									StackType_t * const puxStackBuffer,
S									StaticTask_t * const pxTaskBuffer ) PRIVILEGED_FUNCTION;
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * task. h
N *<pre>
N BaseType_t xTaskCreateRestricted( TaskParameters_t *pxTaskDefinition, TaskHandle_t *pxCreatedTask );</pre>
N *
N * xTaskCreateRestricted() should only be used in systems that include an MPU
N * implementation.
N *
N * Create a new task and add it to the list of tasks that are ready to run.
N * The function parameters define the memory regions and associated access
N * permissions allocated to the task.
N *
N * @param pxTaskDefinition Pointer to a structure that contains a member
N * for each of the normal xTaskCreate() parameters (see the xTaskCreate() API
N * documentation) plus an optional stack buffer and the memory region
N * definitions.
N *
N * @param pxCreatedTask Used to pass back a handle by which the created task
N * can be referenced.
N *
N * @return pdPASS if the task was successfully created and added to a ready
N * list, otherwise an error code defined in the file projdefs.h
N *
N * Example usage:
N   <pre>
N// Create an TaskParameters_t structure that defines the task to be created.
Nstatic const TaskParameters_t xCheckTaskParameters =
N{
N	vATask,		// pvTaskCode - the function that implements the task.
N	"ATask",	// pcName - just a text name for the task to assist debugging.
N	100,		// usStackDepth	- the stack size DEFINED IN WORDS.
N	NULL,		// pvParameters - passed into the task function as the function parameters.
N	( 1UL | portPRIVILEGE_BIT ),// uxPriority - task priority, set the portPRIVILEGE_BIT if the task should run in a privileged state.
N	cStackBuffer,// puxStackBuffer - the buffer to be used as the task stack.
N
N	// xRegions - Allocate up to three separate memory regions for access by
N	// the task, with appropriate access permissions.  Different processors have
N	// different memory alignment requirements - refer to the FreeRTOS documentation
N	// for full information.
N	{
N		// Base address					Length	Parameters
N        { cReadWriteArray,				32,		portMPU_REGION_READ_WRITE },
N        { cReadOnlyArray,				32,		portMPU_REGION_READ_ONLY },
N        { cPrivilegedOnlyAccessArray,	128,	portMPU_REGION_PRIVILEGED_READ_WRITE }
N	}
N};
N
Nint main( void )
N{
NTaskHandle_t xHandle;
N
N	// Create a task from the const structure defined above.  The task handle
N	// is requested (the second parameter is not NULL) but in this case just for
N	// demonstration purposes as its not actually used.
N	xTaskCreateRestricted( &xRegTest1Parameters, &xHandle );
N
N	// Start the scheduler.
N	vTaskStartScheduler();
N
N	// Will only get here if there was insufficient memory to create the idle
N	// and/or timer task.
N	for( ;; );
N}
N   </pre>
N * \defgroup xTaskCreateRestricted xTaskCreateRestricted
N * \ingroup Tasks
N */
N#if( portUSING_MPU_WRAPPERS == 1 )
X#if( 0 == 1 )
S	BaseType_t xTaskCreateRestricted( const TaskParameters_t * const pxTaskDefinition, TaskHandle_t *pxCreatedTask ) PRIVILEGED_FUNCTION;
N#endif
N
N/**
N * task. h
N *<pre>
N void vTaskAllocateMPURegions( TaskHandle_t xTask, const MemoryRegion_t * const pxRegions );</pre>
N *
N * Memory regions are assigned to a restricted task when the task is created by
N * a call to xTaskCreateRestricted().  These regions can be redefined using
N * vTaskAllocateMPURegions().
N *
N * @param xTask The handle of the task being updated.
N *
N * @param xRegions A pointer to an MemoryRegion_t structure that contains the
N * new memory region definitions.
N *
N * Example usage:
N   <pre>
N// Define an array of MemoryRegion_t structures that configures an MPU region
N// allowing read/write access for 1024 bytes starting at the beginning of the
N// ucOneKByte array.  The other two of the maximum 3 definable regions are
N// unused so set to zero.
Nstatic const MemoryRegion_t xAltRegions[ portNUM_CONFIGURABLE_REGIONS ] =
N{
N	// Base address		Length		Parameters
N	{ ucOneKByte,		1024,		portMPU_REGION_READ_WRITE },
N	{ 0,				0,			0 },
N	{ 0,				0,			0 }
N};
N
Nvoid vATask( void *pvParameters )
N{
N	// This task was created such that it has access to certain regions of
N	// memory as defined by the MPU configuration.  At some point it is
N	// desired that these MPU regions are replaced with that defined in the
N	// xAltRegions const struct above.  Use a call to vTaskAllocateMPURegions()
N	// for this purpose.  NULL is used as the task handle to indicate that this
N	// function should modify the MPU regions of the calling task.
N	vTaskAllocateMPURegions( NULL, xAltRegions );
N
N	// Now the task can continue its function, but from this point on can only
N	// access its stack and the ucOneKByte array (unless any other statically
N	// defined or shared regions have been declared elsewhere).
N}
N   </pre>
N * \defgroup xTaskCreateRestricted xTaskCreateRestricted
N * \ingroup Tasks
N */
Nvoid vTaskAllocateMPURegions( TaskHandle_t xTask, const MemoryRegion_t * const pxRegions ) PRIVILEGED_FUNCTION;
Xvoid vTaskAllocateMPURegions( TaskHandle_t xTask, const MemoryRegion_t * const pxRegions ) ;
N
N/**
N * task. h
N * <pre>void vTaskDelete( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_vTaskDelete must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Remove a task from the RTOS real time kernel's management.  The task being
N * deleted will be removed from all ready, blocked, suspended and event lists.
N *
N * NOTE:  The idle task is responsible for freeing the kernel allocated
N * memory from tasks that have been deleted.  It is therefore important that
N * the idle task is not starved of microcontroller processing time if your
N * application makes any calls to vTaskDelete ().  Memory allocated by the
N * task code is not automatically freed, and should be freed before the task
N * is deleted.
N *
N * See the demo application file death.c for sample code that utilises
N * vTaskDelete ().
N *
N * @param xTask The handle of the task to be deleted.  Passing NULL will
N * cause the calling task to be deleted.
N *
N * Example usage:
N   <pre>
N void vOtherFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create the task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // Use the handle to delete the task.
N	 vTaskDelete( xHandle );
N }
N   </pre>
N * \defgroup vTaskDelete vTaskDelete
N * \ingroup Tasks
N */
Nvoid vTaskDelete( TaskHandle_t xTaskToDelete ) PRIVILEGED_FUNCTION;
Xvoid vTaskDelete( TaskHandle_t xTaskToDelete ) ;
N
N/*-----------------------------------------------------------
N * TASK CONTROL API
N *----------------------------------------------------------*/
N
N/**
N * task. h
N * <pre>void vTaskDelay( const TickType_t xTicksToDelay );</pre>
N *
N * Delay a task for a given number of ticks.  The actual time that the
N * task remains blocked depends on the tick rate.  The constant
N * portTICK_PERIOD_MS can be used to calculate real time from the tick
N * rate - with the resolution of one tick period.
N *
N * INCLUDE_vTaskDelay must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N *
N * vTaskDelay() specifies a time at which the task wishes to unblock relative to
N * the time at which vTaskDelay() is called.  For example, specifying a block
N * period of 100 ticks will cause the task to unblock 100 ticks after
N * vTaskDelay() is called.  vTaskDelay() does not therefore provide a good method
N * of controlling the frequency of a periodic task as the path taken through the
N * code, as well as other task and interrupt activity, will effect the frequency
N * at which vTaskDelay() gets called and therefore the time at which the task
N * next executes.  See vTaskDelayUntil() for an alternative API function designed
N * to facilitate fixed frequency execution.  It does this by specifying an
N * absolute time (rather than a relative time) at which the calling task should
N * unblock.
N *
N * @param xTicksToDelay The amount of time, in tick periods, that
N * the calling task should block.
N *
N * Example usage:
N
N void vTaskFunction( void * pvParameters )
N {
N // Block for 500ms.
N const TickType_t xDelay = 500 / portTICK_PERIOD_MS;
N
N	 for( ;; )
N	 {
N		 // Simply toggle the LED every 500ms, blocking between each toggle.
N		 vToggleLED();
N		 vTaskDelay( xDelay );
N	 }
N }
N
N * \defgroup vTaskDelay vTaskDelay
N * \ingroup TaskCtrl
N */
Nvoid vTaskDelay( const TickType_t xTicksToDelay ) PRIVILEGED_FUNCTION;
Xvoid vTaskDelay( const TickType_t xTicksToDelay ) ;
N
N/**
N * task. h
N * <pre>void vTaskDelayUntil( TickType_t *pxPreviousWakeTime, const TickType_t xTimeIncrement );</pre>
N *
N * INCLUDE_vTaskDelayUntil must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Delay a task until a specified time.  This function can be used by periodic
N * tasks to ensure a constant execution frequency.
N *
N * This function differs from vTaskDelay () in one important aspect:  vTaskDelay () will
N * cause a task to block for the specified number of ticks from the time vTaskDelay () is
N * called.  It is therefore difficult to use vTaskDelay () by itself to generate a fixed
N * execution frequency as the time between a task starting to execute and that task
N * calling vTaskDelay () may not be fixed [the task may take a different path though the
N * code between calls, or may get interrupted or preempted a different number of times
N * each time it executes].
N *
N * Whereas vTaskDelay () specifies a wake time relative to the time at which the function
N * is called, vTaskDelayUntil () specifies the absolute (exact) time at which it wishes to
N * unblock.
N *
N * The constant portTICK_PERIOD_MS can be used to calculate real time from the tick
N * rate - with the resolution of one tick period.
N *
N * @param pxPreviousWakeTime Pointer to a variable that holds the time at which the
N * task was last unblocked.  The variable must be initialised with the current time
N * prior to its first use (see the example below).  Following this the variable is
N * automatically updated within vTaskDelayUntil ().
N *
N * @param xTimeIncrement The cycle time period.  The task will be unblocked at
N * time *pxPreviousWakeTime + xTimeIncrement.  Calling vTaskDelayUntil with the
N * same xTimeIncrement parameter value will cause the task to execute with
N * a fixed interface period.
N *
N * Example usage:
N   <pre>
N // Perform an action every 10 ticks.
N void vTaskFunction( void * pvParameters )
N {
N TickType_t xLastWakeTime;
N const TickType_t xFrequency = 10;
N
N	 // Initialise the xLastWakeTime variable with the current time.
N	 xLastWakeTime = xTaskGetTickCount ();
N	 for( ;; )
N	 {
N		 // Wait for the next cycle.
N		 vTaskDelayUntil( &xLastWakeTime, xFrequency );
N
N		 // Perform action here.
N	 }
N }
N   </pre>
N * \defgroup vTaskDelayUntil vTaskDelayUntil
N * \ingroup TaskCtrl
N */
Nvoid vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement ) PRIVILEGED_FUNCTION;
Xvoid vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement ) ;
N
N/**
N * task. h
N * <pre>BaseType_t xTaskAbortDelay( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_xTaskAbortDelay must be defined as 1 in FreeRTOSConfig.h for this
N * function to be available.
N *
N * A task will enter the Blocked state when it is waiting for an event.  The
N * event it is waiting for can be a temporal event (waiting for a time), such
N * as when vTaskDelay() is called, or an event on an object, such as when
N * xQueueReceive() or ulTaskNotifyTake() is called.  If the handle of a task
N * that is in the Blocked state is used in a call to xTaskAbortDelay() then the
N * task will leave the Blocked state, and return from whichever function call
N * placed the task into the Blocked state.
N *
N * @param xTask The handle of the task to remove from the Blocked state.
N *
N * @return If the task referenced by xTask was not in the Blocked state then
N * pdFAIL is returned.  Otherwise pdPASS is returned.
N *
N * \defgroup xTaskAbortDelay xTaskAbortDelay
N * \ingroup TaskCtrl
N */
NBaseType_t xTaskAbortDelay( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskAbortDelay( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>UBaseType_t uxTaskPriorityGet( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_uxTaskPriorityGet must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Obtain the priority of any task.
N *
N * @param xTask Handle of the task to be queried.  Passing a NULL
N * handle results in the priority of the calling task being returned.
N *
N * @return The priority of xTask.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to obtain the priority of the created task.
N	 // It was created with tskIDLE_PRIORITY, but may have changed
N	 // it itself.
N	 if( uxTaskPriorityGet( xHandle ) != tskIDLE_PRIORITY )
N	 {
N		 // The task has changed it's priority.
N	 }
N
N	 // ...
N
N	 // Is our priority higher than the created task?
N	 if( uxTaskPriorityGet( xHandle ) < uxTaskPriorityGet( NULL ) )
N	 {
N		 // Our priority (obtained using NULL handle) is higher.
N	 }
N }
N   </pre>
N * \defgroup uxTaskPriorityGet uxTaskPriorityGet
N * \ingroup TaskCtrl
N */
NUBaseType_t uxTaskPriorityGet( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskPriorityGet( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>UBaseType_t uxTaskPriorityGetFromISR( TaskHandle_t xTask );</pre>
N *
N * A version of uxTaskPriorityGet() that can be used from an ISR.
N */
NUBaseType_t uxTaskPriorityGetFromISR( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskPriorityGetFromISR( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>eTaskState eTaskGetState( TaskHandle_t xTask );</pre>
N *
N * INCLUDE_eTaskGetState must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Obtain the state of any task.  States are encoded by the eTaskState
N * enumerated type.
N *
N * @param xTask Handle of the task to be queried.
N *
N * @return The state of xTask at the time the function was called.  Note the
N * state of the task might change between the function being called, and the
N * functions return value being tested by the calling task.
N */
NeTaskState eTaskGetState( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XeTaskState eTaskGetState( TaskHandle_t xTask ) ;
N
N/**
N * task. h
N * <pre>void vTaskGetInfo( TaskHandle_t xTask, TaskStatus_t *pxTaskStatus, BaseType_t xGetFreeStackSpace, eTaskState eState );</pre>
N *
N * configUSE_TRACE_FACILITY must be defined as 1 for this function to be
N * available.  See the configuration section for more information.
N *
N * Populates a TaskStatus_t structure with information about a task.
N *
N * @param xTask Handle of the task being queried.  If xTask is NULL then
N * information will be returned about the calling task.
N *
N * @param pxTaskStatus A pointer to the TaskStatus_t structure that will be
N * filled with information about the task referenced by the handle passed using
N * the xTask parameter.
N *
N * @xGetFreeStackSpace The TaskStatus_t structure contains a member to report
N * the stack high water mark of the task being queried.  Calculating the stack
N * high water mark takes a relatively long time, and can make the system
N * temporarily unresponsive - so the xGetFreeStackSpace parameter is provided to
N * allow the high water mark checking to be skipped.  The high watermark value
N * will only be written to the TaskStatus_t structure if xGetFreeStackSpace is
N * not set to pdFALSE;
N *
N * @param eState The TaskStatus_t structure contains a member to report the
N * state of the task being queried.  Obtaining the task state is not as fast as
N * a simple assignment - so the eState parameter is provided to allow the state
N * information to be omitted from the TaskStatus_t structure.  To obtain state
N * information then set eState to eInvalid - otherwise the value passed in
N * eState will be reported as the task state in the TaskStatus_t structure.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N TaskStatus_t xTaskDetails;
N
N    // Obtain the handle of a task from its name.
N    xHandle = xTaskGetHandle( "Task_Name" );
N
N    // Check the handle is not NULL.
N    configASSERT( xHandle );
N
N    // Use the handle to obtain further information about the task.
N    vTaskGetInfo( xHandle,
N                  &xTaskDetails,
N                  pdTRUE, // Include the high water mark in xTaskDetails.
N                  eInvalid ); // Include the task state in xTaskDetails.
N }
N   </pre>
N * \defgroup vTaskGetInfo vTaskGetInfo
N * \ingroup TaskCtrl
N */
Nvoid vTaskGetInfo( TaskHandle_t xTask, TaskStatus_t *pxTaskStatus, BaseType_t xGetFreeStackSpace, eTaskState eState ) PRIVILEGED_FUNCTION;
Xvoid vTaskGetInfo( TaskHandle_t xTask, TaskStatus_t *pxTaskStatus, BaseType_t xGetFreeStackSpace, eTaskState eState ) ;
N
N/**
N * task. h
N * <pre>void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority );</pre>
N *
N * INCLUDE_vTaskPrioritySet must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Set the priority of any task.
N *
N * A context switch will occur before the function returns if the priority
N * being set is higher than the currently executing task.
N *
N * @param xTask Handle to the task for which the priority is being set.
N * Passing a NULL handle results in the priority of the calling task being set.
N *
N * @param uxNewPriority The priority to which the task will be set.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to raise the priority of the created task.
N	 vTaskPrioritySet( xHandle, tskIDLE_PRIORITY + 1 );
N
N	 // ...
N
N	 // Use a NULL handle to raise our priority to the same value.
N	 vTaskPrioritySet( NULL, tskIDLE_PRIORITY + 1 );
N }
N   </pre>
N * \defgroup vTaskPrioritySet vTaskPrioritySet
N * \ingroup TaskCtrl
N */
Nvoid vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority ) PRIVILEGED_FUNCTION;
Xvoid vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority ) ;
N
N/**
N * task. h
N * <pre>void vTaskSuspend( TaskHandle_t xTaskToSuspend );</pre>
N *
N * INCLUDE_vTaskSuspend must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Suspend any task.  When suspended a task will never get any microcontroller
N * processing time, no matter what its priority.
N *
N * Calls to vTaskSuspend are not accumulative -
N * i.e. calling vTaskSuspend () twice on the same task still only requires one
N * call to vTaskResume () to ready the suspended task.
N *
N * @param xTaskToSuspend Handle to the task being suspended.  Passing a NULL
N * handle will cause the calling task to be suspended.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to suspend the created task.
N	 vTaskSuspend( xHandle );
N
N	 // ...
N
N	 // The created task will not run during this period, unless
N	 // another task calls vTaskResume( xHandle ).
N
N	 //...
N
N
N	 // Suspend ourselves.
N	 vTaskSuspend( NULL );
N
N	 // We cannot get here unless another task calls vTaskResume
N	 // with our handle as the parameter.
N }
N   </pre>
N * \defgroup vTaskSuspend vTaskSuspend
N * \ingroup TaskCtrl
N */
Nvoid vTaskSuspend( TaskHandle_t xTaskToSuspend ) PRIVILEGED_FUNCTION;
Xvoid vTaskSuspend( TaskHandle_t xTaskToSuspend ) ;
N
N/**
N * task. h
N * <pre>void vTaskResume( TaskHandle_t xTaskToResume );</pre>
N *
N * INCLUDE_vTaskSuspend must be defined as 1 for this function to be available.
N * See the configuration section for more information.
N *
N * Resumes a suspended task.
N *
N * A task that has been suspended by one or more calls to vTaskSuspend ()
N * will be made available for running again by a single call to
N * vTaskResume ().
N *
N * @param xTaskToResume Handle to the task being readied.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N TaskHandle_t xHandle;
N
N	 // Create a task, storing the handle.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, &xHandle );
N
N	 // ...
N
N	 // Use the handle to suspend the created task.
N	 vTaskSuspend( xHandle );
N
N	 // ...
N
N	 // The created task will not run during this period, unless
N	 // another task calls vTaskResume( xHandle ).
N
N	 //...
N
N
N	 // Resume the suspended task ourselves.
N	 vTaskResume( xHandle );
N
N	 // The created task will once again get microcontroller processing
N	 // time in accordance with its priority within the system.
N }
N   </pre>
N * \defgroup vTaskResume vTaskResume
N * \ingroup TaskCtrl
N */
Nvoid vTaskResume( TaskHandle_t xTaskToResume ) PRIVILEGED_FUNCTION;
Xvoid vTaskResume( TaskHandle_t xTaskToResume ) ;
N
N/**
N * task. h
N * <pre>void xTaskResumeFromISR( TaskHandle_t xTaskToResume );</pre>
N *
N * INCLUDE_xTaskResumeFromISR must be defined as 1 for this function to be
N * available.  See the configuration section for more information.
N *
N * An implementation of vTaskResume() that can be called from within an ISR.
N *
N * A task that has been suspended by one or more calls to vTaskSuspend ()
N * will be made available for running again by a single call to
N * xTaskResumeFromISR ().
N *
N * xTaskResumeFromISR() should not be used to synchronise a task with an
N * interrupt if there is a chance that the interrupt could arrive prior to the
N * task being suspended - as this can lead to interrupts being missed. Use of a
N * semaphore as a synchronisation mechanism would avoid this eventuality.
N *
N * @param xTaskToResume Handle to the task being readied.
N *
N * @return pdTRUE if resuming the task should result in a context switch,
N * otherwise pdFALSE. This is used by the ISR to determine if a context switch
N * may be required following the ISR.
N *
N * \defgroup vTaskResumeFromISR vTaskResumeFromISR
N * \ingroup TaskCtrl
N */
NBaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume ) ;
N
N/*-----------------------------------------------------------
N * SCHEDULER CONTROL
N *----------------------------------------------------------*/
N
N/**
N * task. h
N * <pre>void vTaskStartScheduler( void );</pre>
N *
N * Starts the real time kernel tick processing.  After calling the kernel
N * has control over which tasks are executed and when.
N *
N * See the demo application file main.c for an example of creating
N * tasks and starting the kernel.
N *
N * Example usage:
N   <pre>
N void vAFunction( void )
N {
N	 // Create at least one task before starting the kernel.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, NULL );
N
N	 // Start the real time kernel with preemption.
N	 vTaskStartScheduler ();
N
N	 // Will not get here unless a task calls vTaskEndScheduler ()
N }
N   </pre>
N *
N * \defgroup vTaskStartScheduler vTaskStartScheduler
N * \ingroup SchedulerControl
N */
Nvoid vTaskStartScheduler( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskStartScheduler( void ) ;
N
N/**
N * task. h
N * <pre>void vTaskEndScheduler( void );</pre>
N *
N * NOTE:  At the time of writing only the x86 real mode port, which runs on a PC
N * in place of DOS, implements this function.
N *
N * Stops the real time kernel tick.  All created tasks will be automatically
N * deleted and multitasking (either preemptive or cooperative) will
N * stop.  Execution then resumes from the point where vTaskStartScheduler ()
N * was called, as if vTaskStartScheduler () had just returned.
N *
N * See the demo application file main. c in the demo/PC directory for an
N * example that uses vTaskEndScheduler ().
N *
N * vTaskEndScheduler () requires an exit function to be defined within the
N * portable layer (see vPortEndScheduler () in port. c for the PC port).  This
N * performs hardware specific operations such as stopping the kernel tick.
N *
N * vTaskEndScheduler () will cause all of the resources allocated by the
N * kernel to be freed - but will not free resources allocated by application
N * tasks.
N *
N * Example usage:
N   <pre>
N void vTaskCode( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N
N		 // At some point we want to end the real time kernel processing
N		 // so call ...
N		 vTaskEndScheduler ();
N	 }
N }
N
N void vAFunction( void )
N {
N	 // Create at least one task before starting the kernel.
N	 xTaskCreate( vTaskCode, "NAME", STACK_SIZE, NULL, tskIDLE_PRIORITY, NULL );
N
N	 // Start the real time kernel with preemption.
N	 vTaskStartScheduler ();
N
N	 // Will only get here when the vTaskCode () task has called
N	 // vTaskEndScheduler ().  When we get here we are back to single task
N	 // execution.
N }
N   </pre>
N *
N * \defgroup vTaskEndScheduler vTaskEndScheduler
N * \ingroup SchedulerControl
N */
Nvoid vTaskEndScheduler( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskEndScheduler( void ) ;
N
N/**
N * task. h
N * <pre>void vTaskSuspendAll( void );</pre>
N *
N * Suspends the scheduler without disabling interrupts.  Context switches will
N * not occur while the scheduler is suspended.
N *
N * After calling vTaskSuspendAll () the calling task will continue to execute
N * without risk of being swapped out until a call to xTaskResumeAll () has been
N * made.
N *
N * API functions that have the potential to cause a context switch (for example,
N * vTaskDelayUntil(), xQueueSend(), etc.) must not be called while the scheduler
N * is suspended.
N *
N * Example usage:
N   <pre>
N void vTask1( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N
N		 // ...
N
N		 // At some point the task wants to perform a long operation during
N		 // which it does not want to get swapped out.  It cannot use
N		 // taskENTER_CRITICAL ()/taskEXIT_CRITICAL () as the length of the
N		 // operation may cause interrupts to be missed - including the
N		 // ticks.
N
N		 // Prevent the real time kernel swapping out the task.
N		 vTaskSuspendAll ();
N
N		 // Perform the operation here.  There is no need to use critical
N		 // sections as we have all the microcontroller processing time.
N		 // During this time interrupts will still operate and the kernel
N		 // tick count will be maintained.
N
N		 // ...
N
N		 // The operation is complete.  Restart the kernel.
N		 xTaskResumeAll ();
N	 }
N }
N   </pre>
N * \defgroup vTaskSuspendAll vTaskSuspendAll
N * \ingroup SchedulerControl
N */
Nvoid vTaskSuspendAll( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskSuspendAll( void ) ;
N
N/**
N * task. h
N * <pre>BaseType_t xTaskResumeAll( void );</pre>
N *
N * Resumes scheduler activity after it was suspended by a call to
N * vTaskSuspendAll().
N *
N * xTaskResumeAll() only resumes the scheduler.  It does not unsuspend tasks
N * that were previously suspended by a call to vTaskSuspend().
N *
N * @return If resuming the scheduler caused a context switch then pdTRUE is
N *		  returned, otherwise pdFALSE is returned.
N *
N * Example usage:
N   <pre>
N void vTask1( void * pvParameters )
N {
N	 for( ;; )
N	 {
N		 // Task code goes here.
N
N		 // ...
N
N		 // At some point the task wants to perform a long operation during
N		 // which it does not want to get swapped out.  It cannot use
N		 // taskENTER_CRITICAL ()/taskEXIT_CRITICAL () as the length of the
N		 // operation may cause interrupts to be missed - including the
N		 // ticks.
N
N		 // Prevent the real time kernel swapping out the task.
N		 vTaskSuspendAll ();
N
N		 // Perform the operation here.  There is no need to use critical
N		 // sections as we have all the microcontroller processing time.
N		 // During this time interrupts will still operate and the real
N		 // time kernel tick count will be maintained.
N
N		 // ...
N
N		 // The operation is complete.  Restart the kernel.  We want to force
N		 // a context switch - but there is no point if resuming the scheduler
N		 // caused a context switch already.
N		 if( !xTaskResumeAll () )
N		 {
N			  taskYIELD ();
N		 }
N	 }
N }
N   </pre>
N * \defgroup xTaskResumeAll xTaskResumeAll
N * \ingroup SchedulerControl
N */
NBaseType_t xTaskResumeAll( void ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskResumeAll( void ) ;
N
N/*-----------------------------------------------------------
N * TASK UTILITIES
N *----------------------------------------------------------*/
N
N/**
N * task. h
N * <PRE>TickType_t xTaskGetTickCount( void );</PRE>
N *
N * @return The count of ticks since vTaskStartScheduler was called.
N *
N * \defgroup xTaskGetTickCount xTaskGetTickCount
N * \ingroup TaskUtils
N */
NTickType_t xTaskGetTickCount( void ) PRIVILEGED_FUNCTION;
XTickType_t xTaskGetTickCount( void ) ;
N
N/**
N * task. h
N * <PRE>TickType_t xTaskGetTickCountFromISR( void );</PRE>
N *
N * @return The count of ticks since vTaskStartScheduler was called.
N *
N * This is a version of xTaskGetTickCount() that is safe to be called from an
N * ISR - provided that TickType_t is the natural word size of the
N * microcontroller being used or interrupt nesting is either not supported or
N * not being used.
N *
N * \defgroup xTaskGetTickCountFromISR xTaskGetTickCountFromISR
N * \ingroup TaskUtils
N */
NTickType_t xTaskGetTickCountFromISR( void ) PRIVILEGED_FUNCTION;
XTickType_t xTaskGetTickCountFromISR( void ) ;
N
N/**
N * task. h
N * <PRE>uint16_t uxTaskGetNumberOfTasks( void );</PRE>
N *
N * @return The number of tasks that the real time kernel is currently managing.
N * This includes all ready, blocked and suspended tasks.  A task that
N * has been deleted but not yet freed by the idle task will also be
N * included in the count.
N *
N * \defgroup uxTaskGetNumberOfTasks uxTaskGetNumberOfTasks
N * \ingroup TaskUtils
N */
NUBaseType_t uxTaskGetNumberOfTasks( void ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetNumberOfTasks( void ) ;
N
N/**
N * task. h
N * <PRE>char *pcTaskGetName( TaskHandle_t xTaskToQuery );</PRE>
N *
N * @return The text (human readable) name of the task referenced by the handle
N * xTaskToQuery.  A task can query its own name by either passing in its own
N * handle, or by setting xTaskToQuery to NULL.
N *
N * \defgroup pcTaskGetName pcTaskGetName
N * \ingroup TaskUtils
N */
Nchar *pcTaskGetName( TaskHandle_t xTaskToQuery ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
Xchar *pcTaskGetName( TaskHandle_t xTaskToQuery ) ;  
N
N/**
N * task. h
N * <PRE>TaskHandle_t xTaskGetHandle( const char *pcNameToQuery );</PRE>
N *
N * NOTE:  This function takes a relatively long time to complete and should be
N * used sparingly.
N *
N * @return The handle of the task that has the human readable name pcNameToQuery.
N * NULL is returned if no matching name is found.  INCLUDE_xTaskGetHandle
N * must be set to 1 in FreeRTOSConfig.h for pcTaskGetHandle() to be available.
N *
N * \defgroup pcTaskGetHandle pcTaskGetHandle
N * \ingroup TaskUtils
N */
NTaskHandle_t xTaskGetHandle( const char *pcNameToQuery ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
XTaskHandle_t xTaskGetHandle( const char *pcNameToQuery ) ;  
N
N/**
N * task.h
N * <PRE>UBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask );</PRE>
N *
N * INCLUDE_uxTaskGetStackHighWaterMark must be set to 1 in FreeRTOSConfig.h for
N * this function to be available.
N *
N * Returns the high water mark of the stack associated with xTask.  That is,
N * the minimum free stack space there has been (in words, so on a 32 bit machine
N * a value of 1 means 4 bytes) since the task started.  The smaller the returned
N * number the closer the task has come to overflowing its stack.
N *
N * @param xTask Handle of the task associated with the stack to be checked.
N * Set xTask to NULL to check the stack of the calling task.
N *
N * @return The smallest amount of free stack space there has been (in words, so
N * actual spaces on the stack rather than bytes) since the task referenced by
N * xTask was created.
N */
NUBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask ) ;
N
N/* When using trace macros it is sometimes necessary to include task.h before
NFreeRTOS.h.  When this is done TaskHookFunction_t will not yet have been defined,
Nso the following two prototypes will cause a compilation error.  This can be
Nfixed by simply guarding against the inclusion of these two prototypes unless
Nthey are explicitly required by the configUSE_APPLICATION_TASK_TAG configuration
Nconstant. */
N#ifdef configUSE_APPLICATION_TASK_TAG
N	#if configUSE_APPLICATION_TASK_TAG == 1
X	#if 0 == 1
S		/**
S		 * task.h
S		 * <pre>void vTaskSetApplicationTaskTag( TaskHandle_t xTask, TaskHookFunction_t pxHookFunction );</pre>
S		 *
S		 * Sets pxHookFunction to be the task hook function used by the task xTask.
S		 * Passing xTask as NULL has the effect of setting the calling tasks hook
S		 * function.
S		 */
S		void vTaskSetApplicationTaskTag( TaskHandle_t xTask, TaskHookFunction_t pxHookFunction ) PRIVILEGED_FUNCTION;
S
S		/**
S		 * task.h
S		 * <pre>void xTaskGetApplicationTaskTag( TaskHandle_t xTask );</pre>
S		 *
S		 * Returns the pxHookFunction value assigned to the task xTask.
S		 */
S		TaskHookFunction_t xTaskGetApplicationTaskTag( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
N	#endif /* configUSE_APPLICATION_TASK_TAG ==1 */
N#endif /* ifdef configUSE_APPLICATION_TASK_TAG */
N
N#if( configNUM_THREAD_LOCAL_STORAGE_POINTERS > 0 )
X#if( 0 > 0 )
S
S	/* Each task contains an array of pointers that is dimensioned by the
S	configNUM_THREAD_LOCAL_STORAGE_POINTERS setting in FreeRTOSConfig.h.  The
S	kernel does not use the pointers itself, so the application writer can use
S	the pointers for any purpose they wish.  The following two functions are
S	used to set and query a pointer respectively. */
S	void vTaskSetThreadLocalStoragePointer( TaskHandle_t xTaskToSet, BaseType_t xIndex, void *pvValue ) PRIVILEGED_FUNCTION;
S	void *pvTaskGetThreadLocalStoragePointer( TaskHandle_t xTaskToQuery, BaseType_t xIndex ) PRIVILEGED_FUNCTION;
S
N#endif
N
N/**
N * task.h
N * <pre>BaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask, void *pvParameter );</pre>
N *
N * Calls the hook function associated with xTask.  Passing xTask as NULL has
N * the effect of calling the Running tasks (the calling task) hook function.
N *
N * pvParameter is passed to the hook function for the task to interpret as it
N * wants.  The return value is the value returned by the task hook function
N * registered by the user.
N */
NBaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask, void *pvParameter ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask, void *pvParameter ) ;
N
N/**
N * xTaskGetIdleTaskHandle() is only available if
N * INCLUDE_xTaskGetIdleTaskHandle is set to 1 in FreeRTOSConfig.h.
N *
N * Simply returns the handle of the idle task.  It is not valid to call
N * xTaskGetIdleTaskHandle() before the scheduler has been started.
N */
NTaskHandle_t xTaskGetIdleTaskHandle( void ) PRIVILEGED_FUNCTION;
XTaskHandle_t xTaskGetIdleTaskHandle( void ) ;
N
N/**
N * configUSE_TRACE_FACILITY must be defined as 1 in FreeRTOSConfig.h for
N * uxTaskGetSystemState() to be available.
N *
N * uxTaskGetSystemState() populates an TaskStatus_t structure for each task in
N * the system.  TaskStatus_t structures contain, among other things, members
N * for the task handle, task name, task priority, task state, and total amount
N * of run time consumed by the task.  See the TaskStatus_t structure
N * definition in this file for the full member list.
N *
N * NOTE:  This function is intended for debugging use only as its use results in
N * the scheduler remaining suspended for an extended period.
N *
N * @param pxTaskStatusArray A pointer to an array of TaskStatus_t structures.
N * The array must contain at least one TaskStatus_t structure for each task
N * that is under the control of the RTOS.  The number of tasks under the control
N * of the RTOS can be determined using the uxTaskGetNumberOfTasks() API function.
N *
N * @param uxArraySize The size of the array pointed to by the pxTaskStatusArray
N * parameter.  The size is specified as the number of indexes in the array, or
N * the number of TaskStatus_t structures contained in the array, not by the
N * number of bytes in the array.
N *
N * @param pulTotalRunTime If configGENERATE_RUN_TIME_STATS is set to 1 in
N * FreeRTOSConfig.h then *pulTotalRunTime is set by uxTaskGetSystemState() to the
N * total run time (as defined by the run time stats clock, see
N * http://www.freertos.org/rtos-run-time-stats.html) since the target booted.
N * pulTotalRunTime can be set to NULL to omit the total run time information.
N *
N * @return The number of TaskStatus_t structures that were populated by
N * uxTaskGetSystemState().  This should equal the number returned by the
N * uxTaskGetNumberOfTasks() API function, but will be zero if the value passed
N * in the uxArraySize parameter was too small.
N *
N * Example usage:
N   <pre>
N    // This example demonstrates how a human readable table of run time stats
N	// information is generated from raw data provided by uxTaskGetSystemState().
N	// The human readable table is written to pcWriteBuffer
N	void vTaskGetRunTimeStats( char *pcWriteBuffer )
N	{
N	TaskStatus_t *pxTaskStatusArray;
N	volatile UBaseType_t uxArraySize, x;
N	uint32_t ulTotalRunTime, ulStatsAsPercentage;
N
N		// Make sure the write buffer does not contain a string.
N		*pcWriteBuffer = 0x00;
N
N		// Take a snapshot of the number of tasks in case it changes while this
N		// function is executing.
N		uxArraySize = uxTaskGetNumberOfTasks();
N
N		// Allocate a TaskStatus_t structure for each task.  An array could be
N		// allocated statically at compile time.
N		pxTaskStatusArray = pvPortMalloc( uxArraySize * sizeof( TaskStatus_t ) );
N
N		if( pxTaskStatusArray != NULL )
N		{
N			// Generate raw status information about each task.
N			uxArraySize = uxTaskGetSystemState( pxTaskStatusArray, uxArraySize, &ulTotalRunTime );
N
N			// For percentage calculations.
N			ulTotalRunTime /= 100UL;
N
N			// Avoid divide by zero errors.
N			if( ulTotalRunTime > 0 )
N			{
N				// For each populated position in the pxTaskStatusArray array,
N				// format the raw data as human readable ASCII data
N				for( x = 0; x < uxArraySize; x++ )
N				{
N					// What percentage of the total run time has the task used?
N					// This will always be rounded down to the nearest integer.
N					// ulTotalRunTimeDiv100 has already been divided by 100.
N					ulStatsAsPercentage = pxTaskStatusArray[ x ].ulRunTimeCounter / ulTotalRunTime;
N
N					if( ulStatsAsPercentage > 0UL )
N					{
N						sprintf( pcWriteBuffer, "%s\t\t%lu\t\t%lu%%\r\n", pxTaskStatusArray[ x ].pcTaskName, pxTaskStatusArray[ x ].ulRunTimeCounter, ulStatsAsPercentage );
N					}
N					else
N					{
N						// If the percentage is zero here then the task has
N						// consumed less than 1% of the total run time.
N						sprintf( pcWriteBuffer, "%s\t\t%lu\t\t<1%%\r\n", pxTaskStatusArray[ x ].pcTaskName, pxTaskStatusArray[ x ].ulRunTimeCounter );
N					}
N
N					pcWriteBuffer += strlen( ( char * ) pcWriteBuffer );
N				}
N			}
N
N			// The array is no longer needed, free the memory it consumes.
N			vPortFree( pxTaskStatusArray );
N		}
N	}
N	</pre>
N */
NUBaseType_t uxTaskGetSystemState( TaskStatus_t * const pxTaskStatusArray, const UBaseType_t uxArraySize, uint32_t * const pulTotalRunTime ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetSystemState( TaskStatus_t * const pxTaskStatusArray, const UBaseType_t uxArraySize, uint32_t * const pulTotalRunTime ) ;
N
N/**
N * task. h
N * <PRE>void vTaskList( char *pcWriteBuffer );</PRE>
N *
N * configUSE_TRACE_FACILITY and configUSE_STATS_FORMATTING_FUNCTIONS must
N * both be defined as 1 for this function to be available.  See the
N * configuration section of the FreeRTOS.org website for more information.
N *
N * NOTE 1: This function will disable interrupts for its duration.  It is
N * not intended for normal application runtime use but as a debug aid.
N *
N * Lists all the current tasks, along with their current state and stack
N * usage high water mark.
N *
N * Tasks are reported as blocked ('B'), ready ('R'), deleted ('D') or
N * suspended ('S').
N *
N * PLEASE NOTE:
N *
N * This function is provided for convenience only, and is used by many of the
N * demo applications.  Do not consider it to be part of the scheduler.
N *
N * vTaskList() calls uxTaskGetSystemState(), then formats part of the
N * uxTaskGetSystemState() output into a human readable table that displays task
N * names, states and stack usage.
N *
N * vTaskList() has a dependency on the sprintf() C library function that might
N * bloat the code size, use a lot of stack, and provide different results on
N * different platforms.  An alternative, tiny, third party, and limited
N * functionality implementation of sprintf() is provided in many of the
N * FreeRTOS/Demo sub-directories in a file called printf-stdarg.c (note
N * printf-stdarg.c does not provide a full snprintf() implementation!).
N *
N * It is recommended that production systems call uxTaskGetSystemState()
N * directly to get access to raw stats data, rather than indirectly through a
N * call to vTaskList().
N *
N * @param pcWriteBuffer A buffer into which the above mentioned details
N * will be written, in ASCII form.  This buffer is assumed to be large
N * enough to contain the generated report.  Approximately 40 bytes per
N * task should be sufficient.
N *
N * \defgroup vTaskList vTaskList
N * \ingroup TaskUtils
N */
Nvoid vTaskList( char * pcWriteBuffer ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
Xvoid vTaskList( char * pcWriteBuffer ) ;  
N
N/**
N * task. h
N * <PRE>void vTaskGetRunTimeStats( char *pcWriteBuffer );</PRE>
N *
N * configGENERATE_RUN_TIME_STATS and configUSE_STATS_FORMATTING_FUNCTIONS
N * must both be defined as 1 for this function to be available.  The application
N * must also then provide definitions for
N * portCONFIGURE_TIMER_FOR_RUN_TIME_STATS() and portGET_RUN_TIME_COUNTER_VALUE()
N * to configure a peripheral timer/counter and return the timers current count
N * value respectively.  The counter should be at least 10 times the frequency of
N * the tick count.
N *
N * NOTE 1: This function will disable interrupts for its duration.  It is
N * not intended for normal application runtime use but as a debug aid.
N *
N * Setting configGENERATE_RUN_TIME_STATS to 1 will result in a total
N * accumulated execution time being stored for each task.  The resolution
N * of the accumulated time value depends on the frequency of the timer
N * configured by the portCONFIGURE_TIMER_FOR_RUN_TIME_STATS() macro.
N * Calling vTaskGetRunTimeStats() writes the total execution time of each
N * task into a buffer, both as an absolute count value and as a percentage
N * of the total system execution time.
N *
N * NOTE 2:
N *
N * This function is provided for convenience only, and is used by many of the
N * demo applications.  Do not consider it to be part of the scheduler.
N *
N * vTaskGetRunTimeStats() calls uxTaskGetSystemState(), then formats part of the
N * uxTaskGetSystemState() output into a human readable table that displays the
N * amount of time each task has spent in the Running state in both absolute and
N * percentage terms.
N *
N * vTaskGetRunTimeStats() has a dependency on the sprintf() C library function
N * that might bloat the code size, use a lot of stack, and provide different
N * results on different platforms.  An alternative, tiny, third party, and
N * limited functionality implementation of sprintf() is provided in many of the
N * FreeRTOS/Demo sub-directories in a file called printf-stdarg.c (note
N * printf-stdarg.c does not provide a full snprintf() implementation!).
N *
N * It is recommended that production systems call uxTaskGetSystemState() directly
N * to get access to raw stats data, rather than indirectly through a call to
N * vTaskGetRunTimeStats().
N *
N * @param pcWriteBuffer A buffer into which the execution times will be
N * written, in ASCII form.  This buffer is assumed to be large enough to
N * contain the generated report.  Approximately 40 bytes per task should
N * be sufficient.
N *
N * \defgroup vTaskGetRunTimeStats vTaskGetRunTimeStats
N * \ingroup TaskUtils
N */
Nvoid vTaskGetRunTimeStats( char *pcWriteBuffer ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
Xvoid vTaskGetRunTimeStats( char *pcWriteBuffer ) ;  
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction );</PRE>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * A notification sent to a task will remain pending until it is cleared by the
N * task calling xTaskNotifyWait() or ulTaskNotifyTake().  If the task was
N * already in the Blocked state to wait for a notification when the notification
N * arrives then the task will automatically be removed from the Blocked state
N * (unblocked) and the notification cleared.
N *
N * A task can use xTaskNotifyWait() to [optionally] block to wait for a
N * notification to be pending, or ulTaskNotifyTake() to [optionally] block
N * to wait for its notification value to have a non-zero value.  The task does
N * not consume any CPU time while it is in the Blocked state.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @param ulValue Data that can be sent with the notification.  How the data is
N * used depends on the value of the eAction parameter.
N *
N * @param eAction Specifies how the notification updates the task's notification
N * value, if at all.  Valid values for eAction are as follows:
N *
N * eSetBits -
N * The task's notification value is bitwise ORed with ulValue.  xTaskNofify()
N * always returns pdPASS in this case.
N *
N * eIncrement -
N * The task's notification value is incremented.  ulValue is not used and
N * xTaskNotify() always returns pdPASS in this case.
N *
N * eSetValueWithOverwrite -
N * The task's notification value is set to the value of ulValue, even if the
N * task being notified had not yet processed the previous notification (the
N * task already had a notification pending).  xTaskNotify() always returns
N * pdPASS in this case.
N *
N * eSetValueWithoutOverwrite -
N * If the task being notified did not already have a notification pending then
N * the task's notification value is set to ulValue and xTaskNotify() will
N * return pdPASS.  If the task being notified already had a notification
N * pending then no action is performed and pdFAIL is returned.
N *
N * eNoAction -
N * The task receives a notification without its notification value being
N * updated.  ulValue is not used and xTaskNotify() always returns pdPASS in
N * this case.
N *
N *  pulPreviousNotificationValue -
N *  Can be used to pass out the subject task's notification value before any
N *  bits are modified by the notify function.
N *
N * @return Dependent on the value of eAction.  See the description of the
N * eAction parameter.
N *
N * \defgroup xTaskNotify xTaskNotify
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue ) ;
N#define xTaskNotify( xTaskToNotify, ulValue, eAction ) xTaskGenericNotify( ( xTaskToNotify ), ( ulValue ), ( eAction ), NULL )
N#define xTaskNotifyAndQuery( xTaskToNotify, ulValue, eAction, pulPreviousNotifyValue ) xTaskGenericNotify( ( xTaskToNotify ), ( ulValue ), ( eAction ), ( pulPreviousNotifyValue ) )
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, BaseType_t *pxHigherPriorityTaskWoken );</PRE>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * A version of xTaskNotify() that can be used from an interrupt service routine
N * (ISR).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * A notification sent to a task will remain pending until it is cleared by the
N * task calling xTaskNotifyWait() or ulTaskNotifyTake().  If the task was
N * already in the Blocked state to wait for a notification when the notification
N * arrives then the task will automatically be removed from the Blocked state
N * (unblocked) and the notification cleared.
N *
N * A task can use xTaskNotifyWait() to [optionally] block to wait for a
N * notification to be pending, or ulTaskNotifyTake() to [optionally] block
N * to wait for its notification value to have a non-zero value.  The task does
N * not consume any CPU time while it is in the Blocked state.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @param ulValue Data that can be sent with the notification.  How the data is
N * used depends on the value of the eAction parameter.
N *
N * @param eAction Specifies how the notification updates the task's notification
N * value, if at all.  Valid values for eAction are as follows:
N *
N * eSetBits -
N * The task's notification value is bitwise ORed with ulValue.  xTaskNofify()
N * always returns pdPASS in this case.
N *
N * eIncrement -
N * The task's notification value is incremented.  ulValue is not used and
N * xTaskNotify() always returns pdPASS in this case.
N *
N * eSetValueWithOverwrite -
N * The task's notification value is set to the value of ulValue, even if the
N * task being notified had not yet processed the previous notification (the
N * task already had a notification pending).  xTaskNotify() always returns
N * pdPASS in this case.
N *
N * eSetValueWithoutOverwrite -
N * If the task being notified did not already have a notification pending then
N * the task's notification value is set to ulValue and xTaskNotify() will
N * return pdPASS.  If the task being notified already had a notification
N * pending then no action is performed and pdFAIL is returned.
N *
N * eNoAction -
N * The task receives a notification without its notification value being
N * updated.  ulValue is not used and xTaskNotify() always returns pdPASS in
N * this case.
N *
N * @param pxHigherPriorityTaskWoken  xTaskNotifyFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending the notification caused the
N * task to which the notification was sent to leave the Blocked state, and the
N * unblocked task has a priority higher than the currently running task.  If
N * xTaskNotifyFromISR() sets this value to pdTRUE then a context switch should
N * be requested before the interrupt is exited.  How a context switch is
N * requested from an ISR is dependent on the port - see the documentation page
N * for the port in use.
N *
N * @return Dependent on the value of eAction.  See the description of the
N * eAction parameter.
N *
N * \defgroup xTaskNotify xTaskNotify
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken ) ;
N#define xTaskNotifyFromISR( xTaskToNotify, ulValue, eAction, pxHigherPriorityTaskWoken ) xTaskGenericNotifyFromISR( ( xTaskToNotify ), ( ulValue ), ( eAction ), NULL, ( pxHigherPriorityTaskWoken ) )
N#define xTaskNotifyAndQueryFromISR( xTaskToNotify, ulValue, eAction, pulPreviousNotificationValue, pxHigherPriorityTaskWoken ) xTaskGenericNotifyFromISR( ( xTaskToNotify ), ( ulValue ), ( eAction ), ( pulPreviousNotificationValue ), ( pxHigherPriorityTaskWoken ) )
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait );</pre>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * A notification sent to a task will remain pending until it is cleared by the
N * task calling xTaskNotifyWait() or ulTaskNotifyTake().  If the task was
N * already in the Blocked state to wait for a notification when the notification
N * arrives then the task will automatically be removed from the Blocked state
N * (unblocked) and the notification cleared.
N *
N * A task can use xTaskNotifyWait() to [optionally] block to wait for a
N * notification to be pending, or ulTaskNotifyTake() to [optionally] block
N * to wait for its notification value to have a non-zero value.  The task does
N * not consume any CPU time while it is in the Blocked state.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param ulBitsToClearOnEntry Bits that are set in ulBitsToClearOnEntry value
N * will be cleared in the calling task's notification value before the task
N * checks to see if any notifications are pending, and optionally blocks if no
N * notifications are pending.  Setting ulBitsToClearOnEntry to ULONG_MAX (if
N * limits.h is included) or 0xffffffffUL (if limits.h is not included) will have
N * the effect of resetting the task's notification value to 0.  Setting
N * ulBitsToClearOnEntry to 0 will leave the task's notification value unchanged.
N *
N * @param ulBitsToClearOnExit If a notification is pending or received before
N * the calling task exits the xTaskNotifyWait() function then the task's
N * notification value (see the xTaskNotify() API function) is passed out using
N * the pulNotificationValue parameter.  Then any bits that are set in
N * ulBitsToClearOnExit will be cleared in the task's notification value (note
N * *pulNotificationValue is set before any bits are cleared).  Setting
N * ulBitsToClearOnExit to ULONG_MAX (if limits.h is included) or 0xffffffffUL
N * (if limits.h is not included) will have the effect of resetting the task's
N * notification value to 0 before the function exits.  Setting
N * ulBitsToClearOnExit to 0 will leave the task's notification value unchanged
N * when the function exits (in which case the value passed out in
N * pulNotificationValue will match the task's notification value).
N *
N * @param pulNotificationValue Used to pass the task's notification value out
N * of the function.  Note the value passed out will not be effected by the
N * clearing of any bits caused by ulBitsToClearOnExit being non-zero.
N *
N * @param xTicksToWait The maximum amount of time that the task should wait in
N * the Blocked state for a notification to be received, should a notification
N * not already be pending when xTaskNotifyWait() was called.  The task
N * will not consume any processing time while it is in the Blocked state.  This
N * is specified in kernel ticks, the macro pdMS_TO_TICSK( value_in_ms ) can be
N * used to convert a time specified in milliseconds to a time specified in
N * ticks.
N *
N * @return If a notification was received (including notifications that were
N * already pending when xTaskNotifyWait was called) then pdPASS is
N * returned.  Otherwise pdFAIL is returned.
N *
N * \defgroup xTaskNotifyWait xTaskNotifyWait
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait ) ;
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyGive( TaskHandle_t xTaskToNotify );</PRE>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this macro
N * to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * xTaskNotifyGive() is a helper macro intended for use when task notifications
N * are used as light weight and faster binary or counting semaphore equivalents.
N * Actual FreeRTOS semaphores are given using the xSemaphoreGive() API function,
N * the equivalent action that instead uses a task notification is
N * xTaskNotifyGive().
N *
N * When task notifications are being used as a binary or counting semaphore
N * equivalent then the task being notified should wait for the notification
N * using the ulTaskNotificationTake() API function rather than the
N * xTaskNotifyWait() API function.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for more details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @return xTaskNotifyGive() is a macro that calls xTaskNotify() with the
N * eAction parameter set to eIncrement - so pdPASS is always returned.
N *
N * \defgroup xTaskNotifyGive xTaskNotifyGive
N * \ingroup TaskNotifications
N */
N#define xTaskNotifyGive( xTaskToNotify ) xTaskGenericNotify( ( xTaskToNotify ), ( 0 ), eIncrement, NULL )
N
N/**
N * task. h
N * <PRE>void vTaskNotifyGiveFromISR( TaskHandle_t xTaskHandle, BaseType_t *pxHigherPriorityTaskWoken );
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this macro
N * to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * A version of xTaskNotifyGive() that can be called from an interrupt service
N * routine (ISR).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * vTaskNotifyGiveFromISR() is intended for use when task notifications are
N * used as light weight and faster binary or counting semaphore equivalents.
N * Actual FreeRTOS semaphores are given from an ISR using the
N * xSemaphoreGiveFromISR() API function, the equivalent action that instead uses
N * a task notification is vTaskNotifyGiveFromISR().
N *
N * When task notifications are being used as a binary or counting semaphore
N * equivalent then the task being notified should wait for the notification
N * using the ulTaskNotificationTake() API function rather than the
N * xTaskNotifyWait() API function.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for more details.
N *
N * @param xTaskToNotify The handle of the task being notified.  The handle to a
N * task can be returned from the xTaskCreate() API function used to create the
N * task, and the handle of the currently running task can be obtained by calling
N * xTaskGetCurrentTaskHandle().
N *
N * @param pxHigherPriorityTaskWoken  vTaskNotifyGiveFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending the notification caused the
N * task to which the notification was sent to leave the Blocked state, and the
N * unblocked task has a priority higher than the currently running task.  If
N * vTaskNotifyGiveFromISR() sets this value to pdTRUE then a context switch
N * should be requested before the interrupt is exited.  How a context switch is
N * requested from an ISR is dependent on the port - see the documentation page
N * for the port in use.
N *
N * \defgroup xTaskNotifyWait xTaskNotifyWait
N * \ingroup TaskNotifications
N */
Nvoid vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
Xvoid vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken ) ;
N
N/**
N * task. h
N * <PRE>uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait );</pre>
N *
N * configUSE_TASK_NOTIFICATIONS must be undefined or defined as 1 for this
N * function to be available.
N *
N * When configUSE_TASK_NOTIFICATIONS is set to one each task has its own private
N * "notification value", which is a 32-bit unsigned integer (uint32_t).
N *
N * Events can be sent to a task using an intermediary object.  Examples of such
N * objects are queues, semaphores, mutexes and event groups.  Task notifications
N * are a method of sending an event directly to a task without the need for such
N * an intermediary object.
N *
N * A notification sent to a task can optionally perform an action, such as
N * update, overwrite or increment the task's notification value.  In that way
N * task notifications can be used to send data to a task, or be used as light
N * weight and fast binary or counting semaphores.
N *
N * ulTaskNotifyTake() is intended for use when a task notification is used as a
N * faster and lighter weight binary or counting semaphore alternative.  Actual
N * FreeRTOS semaphores are taken using the xSemaphoreTake() API function, the
N * equivalent action that instead uses a task notification is
N * ulTaskNotifyTake().
N *
N * When a task is using its notification value as a binary or counting semaphore
N * other tasks should send notifications to it using the xTaskNotifyGive()
N * macro, or xTaskNotify() function with the eAction parameter set to
N * eIncrement.
N *
N * ulTaskNotifyTake() can either clear the task's notification value to
N * zero on exit, in which case the notification value acts like a binary
N * semaphore, or decrement the task's notification value on exit, in which case
N * the notification value acts like a counting semaphore.
N *
N * A task can use ulTaskNotifyTake() to [optionally] block to wait for a
N * the task's notification value to be non-zero.  The task does not consume any
N * CPU time while it is in the Blocked state.
N *
N * Where as xTaskNotifyWait() will return when a notification is pending,
N * ulTaskNotifyTake() will return when the task's notification value is
N * not zero.
N *
N * See http://www.FreeRTOS.org/RTOS-task-notifications.html for details.
N *
N * @param xClearCountOnExit if xClearCountOnExit is pdFALSE then the task's
N * notification value is decremented when the function exits.  In this way the
N * notification value acts like a counting semaphore.  If xClearCountOnExit is
N * not pdFALSE then the task's notification value is cleared to zero when the
N * function exits.  In this way the notification value acts like a binary
N * semaphore.
N *
N * @param xTicksToWait The maximum amount of time that the task should wait in
N * the Blocked state for the task's notification value to be greater than zero,
N * should the count not already be greater than zero when
N * ulTaskNotifyTake() was called.  The task will not consume any processing
N * time while it is in the Blocked state.  This is specified in kernel ticks,
N * the macro pdMS_TO_TICSK( value_in_ms ) can be used to convert a time
N * specified in milliseconds to a time specified in ticks.
N *
N * @return The task's notification count before it is either cleared to zero or
N * decremented (see the xClearCountOnExit parameter).
N *
N * \defgroup ulTaskNotifyTake ulTaskNotifyTake
N * \ingroup TaskNotifications
N */
Nuint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
Xuint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait ) ;
N
N/**
N * task. h
N * <PRE>BaseType_t xTaskNotifyStateClear( TaskHandle_t xTask );</pre>
N *
N * If the notification state of the task referenced by the handle xTask is
N * eNotified, then set the task's notification state to eNotWaitingNotification.
N * The task's notification value is not altered.  Set xTask to NULL to clear the
N * notification state of the calling task.
N *
N * @return pdTRUE if the task's notification state was set to
N * eNotWaitingNotification, otherwise pdFALSE.
N * \defgroup xTaskNotifyStateClear xTaskNotifyStateClear
N * \ingroup TaskNotifications
N */
NBaseType_t xTaskNotifyStateClear( TaskHandle_t xTask );
N
N/*-----------------------------------------------------------
N * SCHEDULER INTERNALS AVAILABLE FOR PORTING PURPOSES
N *----------------------------------------------------------*/
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS ONLY
N * INTENDED FOR USE WHEN IMPLEMENTING A PORT OF THE SCHEDULER AND IS
N * AN INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * Called from the real time kernel tick (either preemptive or cooperative),
N * this increments the tick count and checks if any tasks that are blocked
N * for a finite period required removing from a blocked list and placing on
N * a ready list.  If a non-zero value is returned then a context switch is
N * required because either:
N *   + A task was removed from a blocked list because its timeout had expired,
N *     or
N *   + Time slicing is in use and there is a task of equal priority to the
N *     currently running task.
N */
NBaseType_t xTaskIncrementTick( void ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskIncrementTick( void ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS AN
N * INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * THIS FUNCTION MUST BE CALLED WITH INTERRUPTS DISABLED.
N *
N * Removes the calling task from the ready list and places it both
N * on the list of tasks waiting for a particular event, and the
N * list of delayed tasks.  The task will be removed from both lists
N * and replaced on the ready list should either the event occur (and
N * there be no higher priority tasks waiting on the same event) or
N * the delay period expires.
N *
N * The 'unordered' version replaces the event list item value with the
N * xItemValue value, and inserts the list item at the end of the list.
N *
N * The 'ordered' version uses the existing event list item value (which is the
N * owning tasks priority) to insert the list item into the event list is task
N * priority order.
N *
N * @param pxEventList The list containing tasks that are blocked waiting
N * for the event to occur.
N *
N * @param xItemValue The item value to use for the event list item when the
N * event list is not ordered by task priority.
N *
N * @param xTicksToWait The maximum amount of time that the task should wait
N * for the event to occur.  This is specified in kernel ticks,the constant
N * portTICK_PERIOD_MS can be used to convert kernel ticks into a real time
N * period.
N */
Nvoid vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
Xvoid vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait ) ;
Nvoid vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
Xvoid vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS AN
N * INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * THIS FUNCTION MUST BE CALLED WITH INTERRUPTS DISABLED.
N *
N * This function performs nearly the same function as vTaskPlaceOnEventList().
N * The difference being that this function does not permit tasks to block
N * indefinitely, whereas vTaskPlaceOnEventList() does.
N *
N */
Nvoid vTaskPlaceOnEventListRestricted( List_t * const pxEventList, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) PRIVILEGED_FUNCTION;
Xvoid vTaskPlaceOnEventListRestricted( List_t * const pxEventList, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS AN
N * INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * THIS FUNCTION MUST BE CALLED WITH INTERRUPTS DISABLED.
N *
N * Removes a task from both the specified event list and the list of blocked
N * tasks, and places it on a ready queue.
N *
N * xTaskRemoveFromEventList()/vTaskRemoveFromUnorderedEventList() will be called
N * if either an event occurs to unblock a task, or the block timeout period
N * expires.
N *
N * xTaskRemoveFromEventList() is used when the event list is in task priority
N * order.  It removes the list item from the head of the event list as that will
N * have the highest priority owning task of all the tasks on the event list.
N * vTaskRemoveFromUnorderedEventList() is used when the event list is not
N * ordered and the event list items hold something other than the owning tasks
N * priority.  In this case the event list item value is updated to the value
N * passed in the xItemValue parameter.
N *
N * @return pdTRUE if the task being removed has a higher priority than the task
N * making the call, otherwise pdFALSE.
N */
NBaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList ) ;
Nvoid vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue ) PRIVILEGED_FUNCTION;
Xvoid vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue ) ;
N
N/*
N * THIS FUNCTION MUST NOT BE USED FROM APPLICATION CODE.  IT IS ONLY
N * INTENDED FOR USE WHEN IMPLEMENTING A PORT OF THE SCHEDULER AND IS
N * AN INTERFACE WHICH IS FOR THE EXCLUSIVE USE OF THE SCHEDULER.
N *
N * Sets the pointer to the current TCB to the TCB of the highest priority task
N * that is ready to run.
N */
Nvoid vTaskSwitchContext( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskSwitchContext( void ) ;
N
N/*
N * THESE FUNCTIONS MUST NOT BE USED FROM APPLICATION CODE.  THEY ARE USED BY
N * THE EVENT BITS MODULE.
N */
NTickType_t uxTaskResetEventItemValue( void ) PRIVILEGED_FUNCTION;
XTickType_t uxTaskResetEventItemValue( void ) ;
N
N/*
N * Return the handle of the calling task.
N */
NTaskHandle_t xTaskGetCurrentTaskHandle( void ) PRIVILEGED_FUNCTION;
XTaskHandle_t xTaskGetCurrentTaskHandle( void ) ;
N
N/*
N * Capture the current time status for future reference.
N */
Nvoid vTaskSetTimeOutState( TimeOut_t * const pxTimeOut ) PRIVILEGED_FUNCTION;
Xvoid vTaskSetTimeOutState( TimeOut_t * const pxTimeOut ) ;
N
N/*
N * Compare the time status now with that previously captured to see if the
N * timeout has expired.
N */
NBaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait ) ;
N
N/*
N * Shortcut used by the queue implementation to prevent unnecessary call to
N * taskYIELD();
N */
Nvoid vTaskMissedYield( void ) PRIVILEGED_FUNCTION;
Xvoid vTaskMissedYield( void ) ;
N
N/*
N * Returns the scheduler state as taskSCHEDULER_RUNNING,
N * taskSCHEDULER_NOT_STARTED or taskSCHEDULER_SUSPENDED.
N */
NBaseType_t xTaskGetSchedulerState( void ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskGetSchedulerState( void ) ;
N
N/*
N * Raises the priority of the mutex holder to that of the calling task should
N * the mutex holder have a priority less than the calling task.
N */
Nvoid vTaskPriorityInherit( TaskHandle_t const pxMutexHolder ) PRIVILEGED_FUNCTION;
Xvoid vTaskPriorityInherit( TaskHandle_t const pxMutexHolder ) ;
N
N/*
N * Set the priority of a task back to its proper priority in the case that it
N * inherited a higher priority while it was holding a semaphore.
N */
NBaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder ) PRIVILEGED_FUNCTION;
XBaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder ) ;
N
N/*
N * Get the uxTCBNumber assigned to the task referenced by the xTask parameter.
N */
NUBaseType_t uxTaskGetTaskNumber( TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
XUBaseType_t uxTaskGetTaskNumber( TaskHandle_t xTask ) ;
N
N/*
N * Set the uxTaskNumber of the task referenced by the xTask parameter to
N * uxHandle.
N */
Nvoid vTaskSetTaskNumber( TaskHandle_t xTask, const UBaseType_t uxHandle ) PRIVILEGED_FUNCTION;
Xvoid vTaskSetTaskNumber( TaskHandle_t xTask, const UBaseType_t uxHandle ) ;
N
N/*
N * Only available when configUSE_TICKLESS_IDLE is set to 1.
N * If tickless mode is being used, or a low power mode is implemented, then
N * the tick interrupt will not execute during idle periods.  When this is the
N * case, the tick count value maintained by the scheduler needs to be kept up
N * to date with the actual execution time by being skipped forward by a time
N * equal to the idle period.
N */
Nvoid vTaskStepTick( const TickType_t xTicksToJump ) PRIVILEGED_FUNCTION;
Xvoid vTaskStepTick( const TickType_t xTicksToJump ) ;
N
N/*
N * Only avilable when configUSE_TICKLESS_IDLE is set to 1.
N * Provided for use within portSUPPRESS_TICKS_AND_SLEEP() to allow the port
N * specific sleep function to determine if it is ok to proceed with the sleep,
N * and if it is ok to proceed, if it is ok to sleep indefinitely.
N *
N * This function is necessary because portSUPPRESS_TICKS_AND_SLEEP() is only
N * called with the scheduler suspended, not from within a critical section.  It
N * is therefore possible for an interrupt to request a context switch between
N * portSUPPRESS_TICKS_AND_SLEEP() and the low power mode actually being
N * entered.  eTaskConfirmSleepModeStatus() should be called from a short
N * critical section between the timer being stopped and the sleep mode being
N * entered to ensure it is ok to proceed into the sleep mode.
N */
NeSleepModeStatus eTaskConfirmSleepModeStatus( void ) PRIVILEGED_FUNCTION;
XeSleepModeStatus eTaskConfirmSleepModeStatus( void ) ;
N
N/*
N * For internal use only.  Increment the mutex held count when a mutex is
N * taken and return the handle of the task that has taken the mutex.
N */
Nvoid *pvTaskIncrementMutexHeldCount( void ) PRIVILEGED_FUNCTION;
Xvoid *pvTaskIncrementMutexHeldCount( void ) ;
N
N#ifdef __cplusplus
S}
N#endif
N#endif /* INC_TASK_H */
N
N
N
L 7 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N#include "queue.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\queue.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N
N#ifndef QUEUE_H
N#define QUEUE_H
N
N#ifndef INC_FREERTOS_H
S	#error "include FreeRTOS.h" must appear in source files before "include queue.h"
N#endif
N
N#ifdef __cplusplus
Sextern "C" {
N#endif
N
N
N/**
N * Type by which queues are referenced.  For example, a call to xQueueCreate()
N * returns an QueueHandle_t variable that can then be used as a parameter to
N * xQueueSend(), xQueueReceive(), etc.
N */
Ntypedef void * QueueHandle_t;
N
N/**
N * Type by which queue sets are referenced.  For example, a call to
N * xQueueCreateSet() returns an xQueueSet variable that can then be used as a
N * parameter to xQueueSelectFromSet(), xQueueAddToSet(), etc.
N */
Ntypedef void * QueueSetHandle_t;
N
N/**
N * Queue sets can contain both queues and semaphores, so the
N * QueueSetMemberHandle_t is defined as a type to be used where a parameter or
N * return value can be either an QueueHandle_t or an SemaphoreHandle_t.
N */
Ntypedef void * QueueSetMemberHandle_t;
N
N/* For internal use only. */
N#define	queueSEND_TO_BACK		( ( BaseType_t ) 0 )
N#define	queueSEND_TO_FRONT		( ( BaseType_t ) 1 )
N#define queueOVERWRITE			( ( BaseType_t ) 2 )
N
N/* For internal use only.  These definitions *must* match those in queue.c. */
N#define queueQUEUE_TYPE_BASE				( ( uint8_t ) 0U )
N#define queueQUEUE_TYPE_SET					( ( uint8_t ) 0U )
N#define queueQUEUE_TYPE_MUTEX 				( ( uint8_t ) 1U )
N#define queueQUEUE_TYPE_COUNTING_SEMAPHORE	( ( uint8_t ) 2U )
N#define queueQUEUE_TYPE_BINARY_SEMAPHORE	( ( uint8_t ) 3U )
N#define queueQUEUE_TYPE_RECURSIVE_MUTEX		( ( uint8_t ) 4U )
N
N/**
N * queue. h
N * <pre>
N QueueHandle_t xQueueCreate(
N							  UBaseType_t uxQueueLength,
N							  UBaseType_t uxItemSize
N						  );
N * </pre>
N *
N * Creates a new queue instance, and returns a handle by which the new queue
N * can be referenced.
N *
N * Internally, within the FreeRTOS implementation, queues use two blocks of
N * memory.  The first block is used to hold the queue's data structures.  The
N * second block is used to hold items placed into the queue.  If a queue is
N * created using xQueueCreate() then both blocks of memory are automatically
N * dynamically allocated inside the xQueueCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a queue is created using
N * xQueueCreateStatic() then the application writer must provide the memory that
N * will get used by the queue.  xQueueCreateStatic() therefore allows a queue to
N * be created without using any dynamic memory allocation.
N *
N * http://www.FreeRTOS.org/Embedded-RTOS-Queues.html
N *
N * @param uxQueueLength The maximum number of items that the queue can contain.
N *
N * @param uxItemSize The number of bytes each item in the queue will require.
N * Items are queued by copy, not by reference, so this is the number of bytes
N * that will be copied for each posted item.  Each item on the queue must be
N * the same size.
N *
N * @return If the queue is successfully create then a handle to the newly
N * created queue is returned.  If the queue cannot be created then 0 is
N * returned.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N };
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N	if( xQueue1 == 0 )
N	{
N		// Queue was not created and must not be used.
N	}
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue2 == 0 )
N	{
N		// Queue was not created and must not be used.
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueCreate xQueueCreate
N * \ingroup QueueManagement
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xQueueCreate( uxQueueLength, uxItemSize ) xQueueGenericCreate( ( uxQueueLength ), ( uxItemSize ), ( queueQUEUE_TYPE_BASE ) )
N#endif
N
N/**
N * queue. h
N * <pre>
N QueueHandle_t xQueueCreateStatic(
N							  UBaseType_t uxQueueLength,
N							  UBaseType_t uxItemSize,
N							  uint8_t *pucQueueStorageBuffer,
N							  StaticQueue_t *pxQueueBuffer
N						  );
N * </pre>
N *
N * Creates a new queue instance, and returns a handle by which the new queue
N * can be referenced.
N *
N * Internally, within the FreeRTOS implementation, queues use two blocks of
N * memory.  The first block is used to hold the queue's data structures.  The
N * second block is used to hold items placed into the queue.  If a queue is
N * created using xQueueCreate() then both blocks of memory are automatically
N * dynamically allocated inside the xQueueCreate() function.  (see
N * http://www.freertos.org/a00111.html).  If a queue is created using
N * xQueueCreateStatic() then the application writer must provide the memory that
N * will get used by the queue.  xQueueCreateStatic() therefore allows a queue to
N * be created without using any dynamic memory allocation.
N *
N * http://www.FreeRTOS.org/Embedded-RTOS-Queues.html
N *
N * @param uxQueueLength The maximum number of items that the queue can contain.
N *
N * @param uxItemSize The number of bytes each item in the queue will require.
N * Items are queued by copy, not by reference, so this is the number of bytes
N * that will be copied for each posted item.  Each item on the queue must be
N * the same size.
N *
N * @param pucQueueStorageBuffer If uxItemSize is not zero then
N * pucQueueStorageBuffer must point to a uint8_t array that is at least large
N * enough to hold the maximum number of items that can be in the queue at any
N * one time - which is ( uxQueueLength * uxItemsSize ) bytes.  If uxItemSize is
N * zero then pucQueueStorageBuffer can be NULL.
N *
N * @param pxQueueBuffer Must point to a variable of type StaticQueue_t, which
N * will be used to hold the queue's data structure.
N *
N * @return If the queue is created then a handle to the created queue is
N * returned.  If pxQueueBuffer is NULL then NULL is returned.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N };
N
N #define QUEUE_LENGTH 10
N #define ITEM_SIZE sizeof( uint32_t )
N
N // xQueueBuffer will hold the queue structure.
N StaticQueue_t xQueueBuffer;
N
N // ucQueueStorage will hold the items posted to the queue.  Must be at least
N // [(queue length) * ( queue item size)] bytes long.
N uint8_t ucQueueStorage[ QUEUE_LENGTH * ITEM_SIZE ];
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( QUEUE_LENGTH, // The number of items the queue can hold.
N							ITEM_SIZE	  // The size of each item in the queue
N							&( ucQueueStorage[ 0 ] ), // The buffer that will hold the items in the queue.
N							&xQueueBuffer ); // The buffer that will hold the queue structure.
N
N	// The queue is guaranteed to be created successfully as no dynamic memory
N	// allocation is used.  Therefore xQueue1 is now a handle to a valid queue.
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueCreateStatic xQueueCreateStatic
N * \ingroup QueueManagement
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	#define xQueueCreateStatic( uxQueueLength, uxItemSize, pucQueueStorage, pxQueueBuffer ) xQueueGenericCreateStatic( ( uxQueueLength ), ( uxItemSize ), ( pucQueueStorage ), ( pxQueueBuffer ), ( queueQUEUE_TYPE_BASE ) )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToToFront(
N								   QueueHandle_t	xQueue,
N								   const void		*pvItemToQueue,
N								   TickType_t		xTicksToWait
N							   );
N * </pre>
N *
N * This is a macro that calls xQueueGenericSend().
N *
N * Post an item to the front of a queue.  The item is queued by copy, not by
N * reference.  This function must not be called from an interrupt service
N * routine.  See xQueueSendFromISR () for an alternative which may be used
N * in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the
N * queue is full.  The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueSendToFront( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10 ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueSendToFront( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0 );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
N#define xQueueSendToFront( xQueue, pvItemToQueue, xTicksToWait ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), ( xTicksToWait ), queueSEND_TO_FRONT )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToBack(
N								   QueueHandle_t	xQueue,
N								   const void		*pvItemToQueue,
N								   TickType_t		xTicksToWait
N							   );
N * </pre>
N *
N * This is a macro that calls xQueueGenericSend().
N *
N * Post an item to the back of a queue.  The item is queued by copy, not by
N * reference.  This function must not be called from an interrupt service
N * routine.  See xQueueSendFromISR () for an alternative which may be used
N * in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the queue
N * is full.  The  time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueSendToBack( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10 ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueSendToBack( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0 );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
N#define xQueueSendToBack( xQueue, pvItemToQueue, xTicksToWait ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), ( xTicksToWait ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSend(
N							  QueueHandle_t xQueue,
N							  const void * pvItemToQueue,
N							  TickType_t xTicksToWait
N						 );
N * </pre>
N *
N * This is a macro that calls xQueueGenericSend().  It is included for
N * backward compatibility with versions of FreeRTOS.org that did not
N * include the xQueueSendToFront() and xQueueSendToBack() macros.  It is
N * equivalent to xQueueSendToBack().
N *
N * Post an item on a queue.  The item is queued by copy, not by reference.
N * This function must not be called from an interrupt service routine.
N * See xQueueSendFromISR () for an alternative which may be used in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the
N * queue is full.  The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueSend( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10 ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueSend( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0 );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
N#define xQueueSend( xQueue, pvItemToQueue, xTicksToWait ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), ( xTicksToWait ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueOverwrite(
N							  QueueHandle_t xQueue,
N							  const void * pvItemToQueue
N						 );
N * </pre>
N *
N * Only for use with queues that have a length of one - so the queue is either
N * empty or full.
N *
N * Post an item on a queue.  If the queue is already full then overwrite the
N * value held in the queue.  The item is queued by copy, not by reference.
N *
N * This function must not be called from an interrupt service routine.
N * See xQueueOverwriteFromISR () for an alternative which may be used in an ISR.
N *
N * @param xQueue The handle of the queue to which the data is being sent.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @return xQueueOverwrite() is a macro that calls xQueueGenericSend(), and
N * therefore has the same return values as xQueueSendToFront().  However, pdPASS
N * is the only value that can be returned because xQueueOverwrite() will write
N * to the queue even when the queue is already full.
N *
N * Example usage:
N   <pre>
N
N void vFunction( void *pvParameters )
N {
N QueueHandle_t xQueue;
N uint32_t ulVarToSend, ulValReceived;
N
N	// Create a queue to hold one uint32_t value.  It is strongly
N	// recommended *not* to use xQueueOverwrite() on queues that can
N	// contain more than one value, and doing so will trigger an assertion
N	// if configASSERT() is defined.
N	xQueue = xQueueCreate( 1, sizeof( uint32_t ) );
N
N	// Write the value 10 to the queue using xQueueOverwrite().
N	ulVarToSend = 10;
N	xQueueOverwrite( xQueue, &ulVarToSend );
N
N	// Peeking the queue should now return 10, but leave the value 10 in
N	// the queue.  A block time of zero is used as it is known that the
N	// queue holds a value.
N	ulValReceived = 0;
N	xQueuePeek( xQueue, &ulValReceived, 0 );
N
N	if( ulValReceived != 10 )
N	{
N		// Error unless the item was removed by a different task.
N	}
N
N	// The queue is still full.  Use xQueueOverwrite() to overwrite the
N	// value held in the queue with 100.
N	ulVarToSend = 100;
N	xQueueOverwrite( xQueue, &ulVarToSend );
N
N	// This time read from the queue, leaving the queue empty once more.
N	// A block time of 0 is used again.
N	xQueueReceive( xQueue, &ulValReceived, 0 );
N
N	// The value read should be the last value written, even though the
N	// queue was already full when the value was written.
N	if( ulValReceived != 100 )
N	{
N		// Error!
N	}
N
N	// ...
N}
N </pre>
N * \defgroup xQueueOverwrite xQueueOverwrite
N * \ingroup QueueManagement
N */
N#define xQueueOverwrite( xQueue, pvItemToQueue ) xQueueGenericSend( ( xQueue ), ( pvItemToQueue ), 0, queueOVERWRITE )
N
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueGenericSend(
N									QueueHandle_t xQueue,
N									const void * pvItemToQueue,
N									TickType_t xTicksToWait
N									BaseType_t xCopyPosition
N								);
N * </pre>
N *
N * It is preferred that the macros xQueueSend(), xQueueSendToFront() and
N * xQueueSendToBack() are used in place of calling this function directly.
N *
N * Post an item on a queue.  The item is queued by copy, not by reference.
N * This function must not be called from an interrupt service routine.
N * See xQueueSendFromISR () for an alternative which may be used in an ISR.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for space to become available on the queue, should it already
N * be full.  The call will return immediately if this is set to 0 and the
N * queue is full.  The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N *
N * @param xCopyPosition Can take the value queueSEND_TO_BACK to place the
N * item at the back of the queue, or queueSEND_TO_FRONT to place the item
N * at the front of the queue (for high priority messages).
N *
N * @return pdTRUE if the item was successfully posted, otherwise errQUEUE_FULL.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N uint32_t ulVar = 10UL;
N
N void vATask( void *pvParameters )
N {
N QueueHandle_t xQueue1, xQueue2;
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 uint32_t values.
N	xQueue1 = xQueueCreate( 10, sizeof( uint32_t ) );
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue2 = xQueueCreate( 10, sizeof( struct AMessage * ) );
N
N	// ...
N
N	if( xQueue1 != 0 )
N	{
N		// Send an uint32_t.  Wait for 10 ticks for space to become
N		// available if necessary.
N		if( xQueueGenericSend( xQueue1, ( void * ) &ulVar, ( TickType_t ) 10, queueSEND_TO_BACK ) != pdPASS )
N		{
N			// Failed to post the message, even after 10 ticks.
N		}
N	}
N
N	if( xQueue2 != 0 )
N	{
N		// Send a pointer to a struct AMessage object.  Don't block if the
N		// queue is already full.
N		pxMessage = & xMessage;
N		xQueueGenericSend( xQueue2, ( void * ) &pxMessage, ( TickType_t ) 0, queueSEND_TO_BACK );
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueSend xQueueSend
N * \ingroup QueueManagement
N */
NBaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueuePeek(
N							 QueueHandle_t xQueue,
N							 void *pvBuffer,
N							 TickType_t xTicksToWait
N						 );</pre>
N *
N * This is a macro that calls the xQueueGenericReceive() function.
N *
N * Receive an item from a queue without removing the item from the queue.
N * The item is received by copy so a buffer of adequate size must be
N * provided.  The number of bytes copied into the buffer was defined when
N * the queue was created.
N *
N * Successfully received items remain on the queue so will be returned again
N * by the next call, or a call to xQueueReceive().
N *
N * This macro must not be used in an interrupt service routine.  See
N * xQueuePeekFromISR() for an alternative that can be called from an interrupt
N * service routine.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for an item to receive should the queue be empty at the time
N * of the call.	 The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N * xQueuePeek() will return immediately if xTicksToWait is 0 and the queue
N * is empty.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N QueueHandle_t xQueue;
N
N // Task to create a queue and post a value.
N void vATask( void *pvParameters )
N {
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Send a pointer to a struct AMessage object.  Don't block if the
N	// queue is already full.
N	pxMessage = & xMessage;
N	xQueueSend( xQueue, ( void * ) &pxMessage, ( TickType_t ) 0 );
N
N	// ... Rest of task code.
N }
N
N // Task to peek the data from the queue.
N void vADifferentTask( void *pvParameters )
N {
N struct AMessage *pxRxedMessage;
N
N	if( xQueue != 0 )
N	{
N		// Peek a message on the created queue.  Block for 10 ticks if a
N		// message is not immediately available.
N		if( xQueuePeek( xQueue, &( pxRxedMessage ), ( TickType_t ) 10 ) )
N		{
N			// pcRxedMessage now points to the struct AMessage variable posted
N			// by vATask, but the item still remains on the queue.
N		}
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueReceive xQueueReceive
N * \ingroup QueueManagement
N */
N#define xQueuePeek( xQueue, pvBuffer, xTicksToWait ) xQueueGenericReceive( ( xQueue ), ( pvBuffer ), ( xTicksToWait ), pdTRUE )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueuePeekFromISR(
N									QueueHandle_t xQueue,
N									void *pvBuffer,
N								);</pre>
N *
N * A version of xQueuePeek() that can be called from an interrupt service
N * routine (ISR).
N *
N * Receive an item from a queue without removing the item from the queue.
N * The item is received by copy so a buffer of adequate size must be
N * provided.  The number of bytes copied into the buffer was defined when
N * the queue was created.
N *
N * Successfully received items remain on the queue so will be returned again
N * by the next call, or a call to xQueueReceive().
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * \defgroup xQueuePeekFromISR xQueuePeekFromISR
N * \ingroup QueueManagement
N */
NBaseType_t xQueuePeekFromISR( QueueHandle_t xQueue, void * const pvBuffer ) PRIVILEGED_FUNCTION;
XBaseType_t xQueuePeekFromISR( QueueHandle_t xQueue, void * const pvBuffer ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueReceive(
N								 QueueHandle_t xQueue,
N								 void *pvBuffer,
N								 TickType_t xTicksToWait
N							);</pre>
N *
N * This is a macro that calls the xQueueGenericReceive() function.
N *
N * Receive an item from a queue.  The item is received by copy so a buffer of
N * adequate size must be provided.  The number of bytes copied into the buffer
N * was defined when the queue was created.
N *
N * Successfully received items are removed from the queue.
N *
N * This function must not be used in an interrupt service routine.  See
N * xQueueReceiveFromISR for an alternative that can.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for an item to receive should the queue be empty at the time
N * of the call.	 xQueueReceive() will return immediately if xTicksToWait
N * is zero and the queue is empty.  The time is defined in tick periods so the
N * constant portTICK_PERIOD_MS should be used to convert to real time if this is
N * required.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N QueueHandle_t xQueue;
N
N // Task to create a queue and post a value.
N void vATask( void *pvParameters )
N {
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Send a pointer to a struct AMessage object.  Don't block if the
N	// queue is already full.
N	pxMessage = & xMessage;
N	xQueueSend( xQueue, ( void * ) &pxMessage, ( TickType_t ) 0 );
N
N	// ... Rest of task code.
N }
N
N // Task to receive from the queue.
N void vADifferentTask( void *pvParameters )
N {
N struct AMessage *pxRxedMessage;
N
N	if( xQueue != 0 )
N	{
N		// Receive a message on the created queue.  Block for 10 ticks if a
N		// message is not immediately available.
N		if( xQueueReceive( xQueue, &( pxRxedMessage ), ( TickType_t ) 10 ) )
N		{
N			// pcRxedMessage now points to the struct AMessage variable posted
N			// by vATask.
N		}
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueReceive xQueueReceive
N * \ingroup QueueManagement
N */
N#define xQueueReceive( xQueue, pvBuffer, xTicksToWait ) xQueueGenericReceive( ( xQueue ), ( pvBuffer ), ( xTicksToWait ), pdFALSE )
N
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueGenericReceive(
N									   QueueHandle_t	xQueue,
N									   void	*pvBuffer,
N									   TickType_t	xTicksToWait
N									   BaseType_t	xJustPeek
N									);</pre>
N *
N * It is preferred that the macro xQueueReceive() be used rather than calling
N * this function directly.
N *
N * Receive an item from a queue.  The item is received by copy so a buffer of
N * adequate size must be provided.  The number of bytes copied into the buffer
N * was defined when the queue was created.
N *
N * This function must not be used in an interrupt service routine.  See
N * xQueueReceiveFromISR for an alternative that can.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param xTicksToWait The maximum amount of time the task should block
N * waiting for an item to receive should the queue be empty at the time
N * of the call.	 The time is defined in tick periods so the constant
N * portTICK_PERIOD_MS should be used to convert to real time if this is required.
N * xQueueGenericReceive() will return immediately if the queue is empty and
N * xTicksToWait is 0.
N *
N * @param xJustPeek When set to true, the item received from the queue is not
N * actually removed from the queue - meaning a subsequent call to
N * xQueueReceive() will return the same item.  When set to false, the item
N * being received from the queue is also removed from the queue.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N struct AMessage
N {
N	char ucMessageID;
N	char ucData[ 20 ];
N } xMessage;
N
N QueueHandle_t xQueue;
N
N // Task to create a queue and post a value.
N void vATask( void *pvParameters )
N {
N struct AMessage *pxMessage;
N
N	// Create a queue capable of containing 10 pointers to AMessage structures.
N	// These should be passed by pointer as they contain a lot of data.
N	xQueue = xQueueCreate( 10, sizeof( struct AMessage * ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Send a pointer to a struct AMessage object.  Don't block if the
N	// queue is already full.
N	pxMessage = & xMessage;
N	xQueueSend( xQueue, ( void * ) &pxMessage, ( TickType_t ) 0 );
N
N	// ... Rest of task code.
N }
N
N // Task to receive from the queue.
N void vADifferentTask( void *pvParameters )
N {
N struct AMessage *pxRxedMessage;
N
N	if( xQueue != 0 )
N	{
N		// Receive a message on the created queue.  Block for 10 ticks if a
N		// message is not immediately available.
N		if( xQueueGenericReceive( xQueue, &( pxRxedMessage ), ( TickType_t ) 10 ) )
N		{
N			// pcRxedMessage now points to the struct AMessage variable posted
N			// by vATask.
N		}
N	}
N
N	// ... Rest of task code.
N }
N </pre>
N * \defgroup xQueueReceive xQueueReceive
N * \ingroup QueueManagement
N */
NBaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeek ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait, const BaseType_t xJustPeek ) ;
N
N/**
N * queue. h
N * <pre>UBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue );</pre>
N *
N * Return the number of messages stored in a queue.
N *
N * @param xQueue A handle to the queue being queried.
N *
N * @return The number of messages available in the queue.
N *
N * \defgroup uxQueueMessagesWaiting uxQueueMessagesWaiting
N * \ingroup QueueManagement
N */
NUBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue ) ;
N
N/**
N * queue. h
N * <pre>UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue );</pre>
N *
N * Return the number of free spaces available in a queue.  This is equal to the
N * number of items that can be sent to the queue before the queue becomes full
N * if no items are removed.
N *
N * @param xQueue A handle to the queue being queried.
N *
N * @return The number of spaces available in the queue.
N *
N * \defgroup uxQueueMessagesWaiting uxQueueMessagesWaiting
N * \ingroup QueueManagement
N */
NUBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue ) ;
N
N/**
N * queue. h
N * <pre>void vQueueDelete( QueueHandle_t xQueue );</pre>
N *
N * Delete a queue - freeing all the memory allocated for storing of items
N * placed on the queue.
N *
N * @param xQueue A handle to the queue to be deleted.
N *
N * \defgroup vQueueDelete vQueueDelete
N * \ingroup QueueManagement
N */
Nvoid vQueueDelete( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
Xvoid vQueueDelete( QueueHandle_t xQueue ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToFrontFromISR(
N										 QueueHandle_t xQueue,
N										 const void *pvItemToQueue,
N										 BaseType_t *pxHigherPriorityTaskWoken
N									  );
N </pre>
N *
N * This is a macro that calls xQueueGenericSendFromISR().
N *
N * Post an item to the front of a queue.  It is safe to use this macro from
N * within an interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueSendToFrontFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueSendToFromFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPrioritTaskWoken;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWoken = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post the byte.
N		xQueueSendToFrontFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWoken );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.
N	if( xHigherPriorityTaskWoken )
N	{
N		taskYIELD ();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
N#define xQueueSendToFrontFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueSEND_TO_FRONT )
N
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendToBackFromISR(
N										 QueueHandle_t xQueue,
N										 const void *pvItemToQueue,
N										 BaseType_t *pxHigherPriorityTaskWoken
N									  );
N </pre>
N *
N * This is a macro that calls xQueueGenericSendFromISR().
N *
N * Post an item to the back of a queue.  It is safe to use this macro from
N * within an interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueSendToBackFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueSendToBackFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPriorityTaskWoken;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWoken = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post the byte.
N		xQueueSendToBackFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWoken );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.
N	if( xHigherPriorityTaskWoken )
N	{
N		taskYIELD ();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
N#define xQueueSendToBackFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueOverwriteFromISR(
N							  QueueHandle_t xQueue,
N							  const void * pvItemToQueue,
N							  BaseType_t *pxHigherPriorityTaskWoken
N						 );
N * </pre>
N *
N * A version of xQueueOverwrite() that can be used in an interrupt service
N * routine (ISR).
N *
N * Only for use with queues that can hold a single item - so the queue is either
N * empty or full.
N *
N * Post an item on a queue.  If the queue is already full then overwrite the
N * value held in the queue.  The item is queued by copy, not by reference.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueOverwriteFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueOverwriteFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return xQueueOverwriteFromISR() is a macro that calls
N * xQueueGenericSendFromISR(), and therefore has the same return values as
N * xQueueSendToFrontFromISR().  However, pdPASS is the only value that can be
N * returned because xQueueOverwriteFromISR() will write to the queue even when
N * the queue is already full.
N *
N * Example usage:
N   <pre>
N
N QueueHandle_t xQueue;
N
N void vFunction( void *pvParameters )
N {
N 	// Create a queue to hold one uint32_t value.  It is strongly
N	// recommended *not* to use xQueueOverwriteFromISR() on queues that can
N	// contain more than one value, and doing so will trigger an assertion
N	// if configASSERT() is defined.
N	xQueue = xQueueCreate( 1, sizeof( uint32_t ) );
N}
N
Nvoid vAnInterruptHandler( void )
N{
N// xHigherPriorityTaskWoken must be set to pdFALSE before it is used.
NBaseType_t xHigherPriorityTaskWoken = pdFALSE;
Nuint32_t ulVarToSend, ulValReceived;
N
N	// Write the value 10 to the queue using xQueueOverwriteFromISR().
N	ulVarToSend = 10;
N	xQueueOverwriteFromISR( xQueue, &ulVarToSend, &xHigherPriorityTaskWoken );
N
N	// The queue is full, but calling xQueueOverwriteFromISR() again will still
N	// pass because the value held in the queue will be overwritten with the
N	// new value.
N	ulVarToSend = 100;
N	xQueueOverwriteFromISR( xQueue, &ulVarToSend, &xHigherPriorityTaskWoken );
N
N	// Reading from the queue will now return 100.
N
N	// ...
N
N	if( xHigherPrioritytaskWoken == pdTRUE )
N	{
N		// Writing to the queue caused a task to unblock and the unblocked task
N		// has a priority higher than or equal to the priority of the currently
N		// executing task (the task this interrupt interrupted).  Perform a context
N		// switch so this interrupt returns directly to the unblocked task.
N		portYIELD_FROM_ISR(); // or portEND_SWITCHING_ISR() depending on the port.
N	}
N}
N </pre>
N * \defgroup xQueueOverwriteFromISR xQueueOverwriteFromISR
N * \ingroup QueueManagement
N */
N#define xQueueOverwriteFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueOVERWRITE )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueSendFromISR(
N									 QueueHandle_t xQueue,
N									 const void *pvItemToQueue,
N									 BaseType_t *pxHigherPriorityTaskWoken
N								);
N </pre>
N *
N * This is a macro that calls xQueueGenericSendFromISR().  It is included
N * for backward compatibility with versions of FreeRTOS.org that did not
N * include the xQueueSendToBackFromISR() and xQueueSendToFrontFromISR()
N * macros.
N *
N * Post an item to the back of a queue.  It is safe to use this function from
N * within an interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueSendFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueSendFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPriorityTaskWoken;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWoken = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post the byte.
N		xQueueSendFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWoken );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.
N	if( xHigherPriorityTaskWoken )
N	{
N		// Actual macro used here is port specific.
N		portYIELD_FROM_ISR ();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
N#define xQueueSendFromISR( xQueue, pvItemToQueue, pxHigherPriorityTaskWoken ) xQueueGenericSendFromISR( ( xQueue ), ( pvItemToQueue ), ( pxHigherPriorityTaskWoken ), queueSEND_TO_BACK )
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueGenericSendFromISR(
N										   QueueHandle_t		xQueue,
N										   const	void	*pvItemToQueue,
N										   BaseType_t	*pxHigherPriorityTaskWoken,
N										   BaseType_t	xCopyPosition
N									   );
N </pre>
N *
N * It is preferred that the macros xQueueSendFromISR(),
N * xQueueSendToFrontFromISR() and xQueueSendToBackFromISR() be used in place
N * of calling this function directly.  xQueueGiveFromISR() is an
N * equivalent for use by semaphores that don't actually copy any data.
N *
N * Post an item on a queue.  It is safe to use this function from within an
N * interrupt service routine.
N *
N * Items are queued by copy not reference so it is preferable to only
N * queue small items, especially when called from an ISR.  In most cases
N * it would be preferable to store a pointer to the item being queued.
N *
N * @param xQueue The handle to the queue on which the item is to be posted.
N *
N * @param pvItemToQueue A pointer to the item that is to be placed on the
N * queue.  The size of the items the queue will hold was defined when the
N * queue was created, so this many bytes will be copied from pvItemToQueue
N * into the queue storage area.
N *
N * @param pxHigherPriorityTaskWoken xQueueGenericSendFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if sending to the queue caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xQueueGenericSendFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @param xCopyPosition Can take the value queueSEND_TO_BACK to place the
N * item at the back of the queue, or queueSEND_TO_FRONT to place the item
N * at the front of the queue (for high priority messages).
N *
N * @return pdTRUE if the data was successfully sent to the queue, otherwise
N * errQUEUE_FULL.
N *
N * Example usage for buffered IO (where the ISR can obtain more than one value
N * per call):
N   <pre>
N void vBufferISR( void )
N {
N char cIn;
N BaseType_t xHigherPriorityTaskWokenByPost;
N
N	// We have not woken a task at the start of the ISR.
N	xHigherPriorityTaskWokenByPost = pdFALSE;
N
N	// Loop until the buffer is empty.
N	do
N	{
N		// Obtain a byte from the buffer.
N		cIn = portINPUT_BYTE( RX_REGISTER_ADDRESS );
N
N		// Post each byte.
N		xQueueGenericSendFromISR( xRxQueue, &cIn, &xHigherPriorityTaskWokenByPost, queueSEND_TO_BACK );
N
N	} while( portINPUT_BYTE( BUFFER_COUNT ) );
N
N	// Now the buffer is empty we can switch context if necessary.  Note that the
N	// name of the yield function required is port specific.
N	if( xHigherPriorityTaskWokenByPost )
N	{
N		taskYIELD_YIELD_FROM_ISR();
N	}
N }
N </pre>
N *
N * \defgroup xQueueSendFromISR xQueueSendFromISR
N * \ingroup QueueManagement
N */
NBaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition ) ;
NBaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken ) ;
N
N/**
N * queue. h
N * <pre>
N BaseType_t xQueueReceiveFromISR(
N									   QueueHandle_t	xQueue,
N									   void	*pvBuffer,
N									   BaseType_t *pxTaskWoken
N								   );
N * </pre>
N *
N * Receive an item from a queue.  It is safe to use this function from within an
N * interrupt service routine.
N *
N * @param xQueue The handle to the queue from which the item is to be
N * received.
N *
N * @param pvBuffer Pointer to the buffer into which the received item will
N * be copied.
N *
N * @param pxTaskWoken A task may be blocked waiting for space to become
N * available on the queue.  If xQueueReceiveFromISR causes such a task to
N * unblock *pxTaskWoken will get set to pdTRUE, otherwise *pxTaskWoken will
N * remain unchanged.
N *
N * @return pdTRUE if an item was successfully received from the queue,
N * otherwise pdFALSE.
N *
N * Example usage:
N   <pre>
N
N QueueHandle_t xQueue;
N
N // Function to create a queue and post some values.
N void vAFunction( void *pvParameters )
N {
N char cValueToPost;
N const TickType_t xTicksToWait = ( TickType_t )0xff;
N
N	// Create a queue capable of containing 10 characters.
N	xQueue = xQueueCreate( 10, sizeof( char ) );
N	if( xQueue == 0 )
N	{
N		// Failed to create the queue.
N	}
N
N	// ...
N
N	// Post some characters that will be used within an ISR.  If the queue
N	// is full then this task will block for xTicksToWait ticks.
N	cValueToPost = 'a';
N	xQueueSend( xQueue, ( void * ) &cValueToPost, xTicksToWait );
N	cValueToPost = 'b';
N	xQueueSend( xQueue, ( void * ) &cValueToPost, xTicksToWait );
N
N	// ... keep posting characters ... this task may block when the queue
N	// becomes full.
N
N	cValueToPost = 'c';
N	xQueueSend( xQueue, ( void * ) &cValueToPost, xTicksToWait );
N }
N
N // ISR that outputs all the characters received on the queue.
N void vISR_Routine( void )
N {
N BaseType_t xTaskWokenByReceive = pdFALSE;
N char cRxedChar;
N
N	while( xQueueReceiveFromISR( xQueue, ( void * ) &cRxedChar, &xTaskWokenByReceive) )
N	{
N		// A character was received.  Output the character now.
N		vOutputCharacter( cRxedChar );
N
N		// If removing the character from the queue woke the task that was
N		// posting onto the queue cTaskWokenByReceive will have been set to
N		// pdTRUE.  No matter how many times this loop iterates only one
N		// task will be woken.
N	}
N
N	if( cTaskWokenByPost != ( char ) pdFALSE;
N	{
N		taskYIELD ();
N	}
N }
N </pre>
N * \defgroup xQueueReceiveFromISR xQueueReceiveFromISR
N * \ingroup QueueManagement
N */
NBaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken ) ;
N
N/*
N * Utilities to query queues that are safe to use from an ISR.  These utilities
N * should be used only from witin an ISR, or within a critical section.
N */
NBaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue ) ;
NBaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue ) ;
NUBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue ) ;
N
N/*
N * The functions defined above are for passing data to and from tasks.  The
N * functions below are the equivalents for passing data to and from
N * co-routines.
N *
N * These functions are called from the co-routine macro implementation and
N * should not be called directly from application code.  Instead use the macro
N * wrappers defined within croutine.h.
N */
NBaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken );
NBaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue, void *pvBuffer, BaseType_t *pxTaskWoken );
NBaseType_t xQueueCRSend( QueueHandle_t xQueue, const void *pvItemToQueue, TickType_t xTicksToWait );
NBaseType_t xQueueCRReceive( QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait );
N
N/*
N * For internal use only.  Use xSemaphoreCreateMutex(),
N * xSemaphoreCreateCounting() or xSemaphoreGetMutexHolder() instead of calling
N * these functions directly.
N */
NQueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType ) ;
NQueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType, StaticQueue_t *pxStaticQueue ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType, StaticQueue_t *pxStaticQueue ) ;
NQueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount ) ;
NQueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount, StaticQueue_t *pxStaticQueue ) PRIVILEGED_FUNCTION;
XQueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount, StaticQueue_t *pxStaticQueue ) ;
Nvoid* xQueueGetMutexHolder( QueueHandle_t xSemaphore ) PRIVILEGED_FUNCTION;
Xvoid* xQueueGetMutexHolder( QueueHandle_t xSemaphore ) ;
Nvoid* xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore ) PRIVILEGED_FUNCTION;
Xvoid* xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore ) ;
N
N/*
N * For internal use only.  Use xSemaphoreTakeMutexRecursive() or
N * xSemaphoreGiveMutexRecursive() instead of calling these functions directly.
N */
NBaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex, TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex, TickType_t xTicksToWait ) ;
NBaseType_t xQueueGiveMutexRecursive( QueueHandle_t pxMutex ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGiveMutexRecursive( QueueHandle_t pxMutex ) ;
N
N/*
N * Reset a queue back to its original empty state.  The return value is now
N * obsolete and is always set to pdPASS.
N */
N#define xQueueReset( xQueue ) xQueueGenericReset( xQueue, pdFALSE )
N
N/*
N * The registry is provided as a means for kernel aware debuggers to
N * locate queues, semaphores and mutexes.  Call vQueueAddToRegistry() add
N * a queue, semaphore or mutex handle to the registry if you want the handle
N * to be available to a kernel aware debugger.  If you are not using a kernel
N * aware debugger then this function can be ignored.
N *
N * configQUEUE_REGISTRY_SIZE defines the maximum number of handles the
N * registry can hold.  configQUEUE_REGISTRY_SIZE must be greater than 0
N * within FreeRTOSConfig.h for the registry to be available.  Its value
N * does not effect the number of queues, semaphores and mutexes that can be
N * created - just the number that the registry can hold.
N *
N * @param xQueue The handle of the queue being added to the registry.  This
N * is the handle returned by a call to xQueueCreate().  Semaphore and mutex
N * handles can also be passed in here.
N *
N * @param pcName The name to be associated with the handle.  This is the
N * name that the kernel aware debugger will display.  The queue registry only
N * stores a pointer to the string - so the string must be persistent (global or
N * preferably in ROM/Flash), not on the stack.
N */
N#if( configQUEUE_REGISTRY_SIZE > 0 )
X#if( 0U > 0 )
S	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcName ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N#endif
N
N/*
N * The registry is provided as a means for kernel aware debuggers to
N * locate queues, semaphores and mutexes.  Call vQueueAddToRegistry() add
N * a queue, semaphore or mutex handle to the registry if you want the handle
N * to be available to a kernel aware debugger, and vQueueUnregisterQueue() to
N * remove the queue, semaphore or mutex from the register.  If you are not using
N * a kernel aware debugger then this function can be ignored.
N *
N * @param xQueue The handle of the queue being removed from the registry.
N */
N#if( configQUEUE_REGISTRY_SIZE > 0 )
X#if( 0U > 0 )
S	void vQueueUnregisterQueue( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
N#endif
N
N/*
N * The queue registry is provided as a means for kernel aware debuggers to
N * locate queues, semaphores and mutexes.  Call pcQueueGetName() to look
N * up and return the name of a queue in the queue registry from the queue's
N * handle.
N *
N * @param xQueue The handle of the queue the name of which will be returned.
N * @return If the queue is in the registry then a pointer to the name of the
N * queue is returned.  If the queue is not in the registry then NULL is
N * returned.
N */
N#if( configQUEUE_REGISTRY_SIZE > 0 )
X#if( 0U > 0 )
S	const char *pcQueueGetName( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION; /*lint !e971 Unqualified char types are allowed for strings and single characters only. */
N#endif
N
N/*
N * Generic version of the function used to creaet a queue using dynamic memory
N * allocation.  This is called by other functions and macros that create other
N * RTOS objects that use the queue structure as their base.
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType ) PRIVILEGED_FUNCTION;
X	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType ) ;
N#endif
N
N/*
N * Generic version of the function used to creaet a queue using dynamic memory
N * allocation.  This is called by other functions and macros that create other
N * RTOS objects that use the queue structure as their base.
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	QueueHandle_t xQueueGenericCreateStatic( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, StaticQueue_t *pxStaticQueue, const uint8_t ucQueueType ) PRIVILEGED_FUNCTION;
N#endif
N
N/*
N * Queue sets provide a mechanism to allow a task to block (pend) on a read
N * operation from multiple queues or semaphores simultaneously.
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * A queue set must be explicitly created using a call to xQueueCreateSet()
N * before it can be used.  Once created, standard FreeRTOS queues and semaphores
N * can be added to the set using calls to xQueueAddToSet().
N * xQueueSelectFromSet() is then used to determine which, if any, of the queues
N * or semaphores contained in the set is in a state where a queue read or
N * semaphore take operation would be successful.
N *
N * Note 1:  See the documentation on http://wwwFreeRTOS.org/RTOS-queue-sets.html
N * for reasons why queue sets are very rarely needed in practice as there are
N * simpler methods of blocking on multiple objects.
N *
N * Note 2:  Blocking on a queue set that contains a mutex will not cause the
N * mutex holder to inherit the priority of the blocked task.
N *
N * Note 3:  An additional 4 bytes of RAM is required for each space in a every
N * queue added to a queue set.  Therefore counting semaphores that have a high
N * maximum count value should not be added to a queue set.
N *
N * Note 4:  A receive (in the case of a queue) or take (in the case of a
N * semaphore) operation must not be performed on a member of a queue set unless
N * a call to xQueueSelectFromSet() has first returned a handle to that set member.
N *
N * @param uxEventQueueLength Queue sets store events that occur on
N * the queues and semaphores contained in the set.  uxEventQueueLength specifies
N * the maximum number of events that can be queued at once.  To be absolutely
N * certain that events are not lost uxEventQueueLength should be set to the
N * total sum of the length of the queues added to the set, where binary
N * semaphores and mutexes have a length of 1, and counting semaphores have a
N * length set by their maximum count value.  Examples:
N *  + If a queue set is to hold a queue of length 5, another queue of length 12,
N *    and a binary semaphore, then uxEventQueueLength should be set to
N *    (5 + 12 + 1), or 18.
N *  + If a queue set is to hold three binary semaphores then uxEventQueueLength
N *    should be set to (1 + 1 + 1 ), or 3.
N *  + If a queue set is to hold a counting semaphore that has a maximum count of
N *    5, and a counting semaphore that has a maximum count of 3, then
N *    uxEventQueueLength should be set to (5 + 3), or 8.
N *
N * @return If the queue set is created successfully then a handle to the created
N * queue set is returned.  Otherwise NULL is returned.
N */
NQueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength ) PRIVILEGED_FUNCTION;
XQueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength ) ;
N
N/*
N * Adds a queue or semaphore to a queue set that was previously created by a
N * call to xQueueCreateSet().
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * Note 1:  A receive (in the case of a queue) or take (in the case of a
N * semaphore) operation must not be performed on a member of a queue set unless
N * a call to xQueueSelectFromSet() has first returned a handle to that set member.
N *
N * @param xQueueOrSemaphore The handle of the queue or semaphore being added to
N * the queue set (cast to an QueueSetMemberHandle_t type).
N *
N * @param xQueueSet The handle of the queue set to which the queue or semaphore
N * is being added.
N *
N * @return If the queue or semaphore was successfully added to the queue set
N * then pdPASS is returned.  If the queue could not be successfully added to the
N * queue set because it is already a member of a different queue set then pdFAIL
N * is returned.
N */
NBaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) ;
N
N/*
N * Removes a queue or semaphore from a queue set.  A queue or semaphore can only
N * be removed from a set if the queue or semaphore is empty.
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * @param xQueueOrSemaphore The handle of the queue or semaphore being removed
N * from the queue set (cast to an QueueSetMemberHandle_t type).
N *
N * @param xQueueSet The handle of the queue set in which the queue or semaphore
N * is included.
N *
N * @return If the queue or semaphore was successfully removed from the queue set
N * then pdPASS is returned.  If the queue was not in the queue set, or the
N * queue (or semaphore) was not empty, then pdFAIL is returned.
N */
NBaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet ) ;
N
N/*
N * xQueueSelectFromSet() selects from the members of a queue set a queue or
N * semaphore that either contains data (in the case of a queue) or is available
N * to take (in the case of a semaphore).  xQueueSelectFromSet() effectively
N * allows a task to block (pend) on a read operation on all the queues and
N * semaphores in a queue set simultaneously.
N *
N * See FreeRTOS/Source/Demo/Common/Minimal/QueueSet.c for an example using this
N * function.
N *
N * Note 1:  See the documentation on http://wwwFreeRTOS.org/RTOS-queue-sets.html
N * for reasons why queue sets are very rarely needed in practice as there are
N * simpler methods of blocking on multiple objects.
N *
N * Note 2:  Blocking on a queue set that contains a mutex will not cause the
N * mutex holder to inherit the priority of the blocked task.
N *
N * Note 3:  A receive (in the case of a queue) or take (in the case of a
N * semaphore) operation must not be performed on a member of a queue set unless
N * a call to xQueueSelectFromSet() has first returned a handle to that set member.
N *
N * @param xQueueSet The queue set on which the task will (potentially) block.
N *
N * @param xTicksToWait The maximum time, in ticks, that the calling task will
N * remain in the Blocked state (with other tasks executing) to wait for a member
N * of the queue set to be ready for a successful queue read or semaphore take
N * operation.
N *
N * @return xQueueSelectFromSet() will return the handle of a queue (cast to
N * a QueueSetMemberHandle_t type) contained in the queue set that contains data,
N * or the handle of a semaphore (cast to a QueueSetMemberHandle_t type) contained
N * in the queue set that is available, or NULL if no such queue or semaphore
N * exists before before the specified block time expires.
N */
NQueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet, const TickType_t xTicksToWait ) PRIVILEGED_FUNCTION;
XQueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet, const TickType_t xTicksToWait ) ;
N
N/*
N * A version of xQueueSelectFromSet() that can be used from an ISR.
N */
NQueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet ) PRIVILEGED_FUNCTION;
XQueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet ) ;
N
N/* Not public API functions. */
Nvoid vQueueWaitForMessageRestricted( QueueHandle_t xQueue, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) PRIVILEGED_FUNCTION;
Xvoid vQueueWaitForMessageRestricted( QueueHandle_t xQueue, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely ) ;
NBaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue ) PRIVILEGED_FUNCTION;
XBaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue ) ;
Nvoid vQueueSetQueueNumber( QueueHandle_t xQueue, UBaseType_t uxQueueNumber ) PRIVILEGED_FUNCTION;
Xvoid vQueueSetQueueNumber( QueueHandle_t xQueue, UBaseType_t uxQueueNumber ) ;
NUBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
XUBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue ) ;
Nuint8_t ucQueueGetQueueType( QueueHandle_t xQueue ) PRIVILEGED_FUNCTION;
Xuint8_t ucQueueGetQueueType( QueueHandle_t xQueue ) ;
N
N
N#ifdef __cplusplus
S}
N#endif
N
N#endif /* QUEUE_H */
N
L 8 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N#include "semphr.h"
L 1 "..\..\common\src\FreeRTOS\Source\include\semphr.h" 1
N/*
N    FreeRTOS V9.0.0 - Copyright (C) 2016 Real Time Engineers Ltd.
N    All rights reserved
N
N    VISIT http://www.FreeRTOS.org TO ENSURE YOU ARE USING THE LATEST VERSION.
N
N    This file is part of the FreeRTOS distribution.
N
N    FreeRTOS is free software; you can redistribute it and/or modify it under
N    the terms of the GNU General Public License (version 2) as published by the
N    Free Software Foundation >>>> AND MODIFIED BY <<<< the FreeRTOS exception.
N
N    ***************************************************************************
N    >>!   NOTE: The modification to the GPL is included to allow you to     !<<
N    >>!   distribute a combined work that includes FreeRTOS without being   !<<
N    >>!   obliged to provide the source code for proprietary components     !<<
N    >>!   outside of the FreeRTOS kernel.                                   !<<
N    ***************************************************************************
N
N    FreeRTOS is distributed in the hope that it will be useful, but WITHOUT ANY
N    WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
N    FOR A PARTICULAR PURPOSE.  Full license text is available on the following
N    link: http://www.freertos.org/a00114.html
N
N    ***************************************************************************
N     *                                                                       *
N     *    FreeRTOS provides completely free yet professionally developed,    *
N     *    robust, strictly quality controlled, supported, and cross          *
N     *    platform software that is more than just the market leader, it     *
N     *    is the industry's de facto standard.                               *
N     *                                                                       *
N     *    Help yourself get started quickly while simultaneously helping     *
N     *    to support the FreeRTOS project by purchasing a FreeRTOS           *
N     *    tutorial book, reference manual, or both:                          *
N     *    http://www.FreeRTOS.org/Documentation                              *
N     *                                                                       *
N    ***************************************************************************
N
N    http://www.FreeRTOS.org/FAQHelp.html - Having a problem?  Start by reading
N    the FAQ page "My application does not run, what could be wrong?".  Have you
N    defined configASSERT()?
N
N    http://www.FreeRTOS.org/support - In return for receiving this top quality
N    embedded software for free we request you assist our global community by
N    participating in the support forum.
N
N    http://www.FreeRTOS.org/training - Investing in training allows your team to
N    be as productive as possible as early as possible.  Now you can receive
N    FreeRTOS training directly from Richard Barry, CEO of Real Time Engineers
N    Ltd, and the world's leading authority on the world's leading RTOS.
N
N    http://www.FreeRTOS.org/plus - A selection of FreeRTOS ecosystem products,
N    including FreeRTOS+Trace - an indispensable productivity tool, a DOS
N    compatible FAT file system, and our tiny thread aware UDP/IP stack.
N
N    http://www.FreeRTOS.org/labs - Where new FreeRTOS products go to incubate.
N    Come and try FreeRTOS+TCP, our new open source TCP/IP stack for FreeRTOS.
N
N    http://www.OpenRTOS.com - Real Time Engineers ltd. license FreeRTOS to High
N    Integrity Systems ltd. to sell under the OpenRTOS brand.  Low cost OpenRTOS
N    licenses offer ticketed support, indemnification and commercial middleware.
N
N    http://www.SafeRTOS.com - High Integrity Systems also provide a safety
N    engineered and independently SIL3 certified version for use in safety and
N    mission critical applications that require provable dependability.
N
N    1 tab == 4 spaces!
N*/
N
N#ifndef SEMAPHORE_H
N#define SEMAPHORE_H
N
N#ifndef INC_FREERTOS_H
S	#error "include FreeRTOS.h" must appear in source files before "include semphr.h"
N#endif
N
N#include "queue.h"
N
Ntypedef QueueHandle_t SemaphoreHandle_t;
N
N#define semBINARY_SEMAPHORE_QUEUE_LENGTH	( ( uint8_t ) 1U )
N#define semSEMAPHORE_QUEUE_ITEM_LENGTH		( ( uint8_t ) 0U )
N#define semGIVE_BLOCK_TIME					( ( TickType_t ) 0U )
N
N
N/**
N * semphr. h
N * <pre>vSemaphoreCreateBinary( SemaphoreHandle_t xSemaphore )</pre>
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a binary semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * This old vSemaphoreCreateBinary() macro is now deprecated in favour of the
N * xSemaphoreCreateBinary() function.  Note that binary semaphores created using
N * the vSemaphoreCreateBinary() macro are created in a state such that the
N * first call to 'take' the semaphore would pass, whereas binary semaphores
N * created using xSemaphoreCreateBinary() are created in a state such that the
N * the semaphore must first be 'given' before it can be 'taken'.
N *
N * <i>Macro</i> that implements a semaphore by using the existing queue mechanism.
N * The queue length is 1 as this is a binary semaphore.  The data size is 0
N * as we don't want to actually store any data - we just want to know if the
N * queue is empty or full.
N *
N * This type of semaphore can be used for pure synchronisation between tasks or
N * between an interrupt and a task.  The semaphore need not be given back once
N * obtained, so one task/interrupt can continuously 'give' the semaphore while
N * another continuously 'takes' the semaphore.  For this reason this type of
N * semaphore does not use a priority inheritance mechanism.  For an alternative
N * that does use priority inheritance see xSemaphoreCreateMutex().
N *
N * @param xSemaphore Handle to the created semaphore.  Should be of type SemaphoreHandle_t.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to vSemaphoreCreateBinary ().
N    // This is a macro so pass the variable in directly.
N    vSemaphoreCreateBinary( xSemaphore );
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup vSemaphoreCreateBinary vSemaphoreCreateBinary
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define vSemaphoreCreateBinary( xSemaphore )																							\
N		{																																	\
N			( xSemaphore ) = xQueueGenericCreate( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_BINARY_SEMAPHORE );	\
N			if( ( xSemaphore ) != NULL )																									\
N			{																																\
N				( void ) xSemaphoreGive( ( xSemaphore ) );																					\
N			}																																\
N		}
X	#define vSemaphoreCreateBinary( xSemaphore )																									{																																				( xSemaphore ) = xQueueGenericCreate( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_BINARY_SEMAPHORE );				if( ( xSemaphore ) != NULL )																												{																																				( void ) xSemaphoreGive( ( xSemaphore ) );																								}																																		}
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateBinary( void )</pre>
N *
N * Creates a new binary semaphore instance, and returns a handle by which the
N * new semaphore can be referenced.
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a binary semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, binary semaphores use a block
N * of memory, in which the semaphore structure is stored.  If a binary semaphore
N * is created using xSemaphoreCreateBinary() then the required memory is
N * automatically dynamically allocated inside the xSemaphoreCreateBinary()
N * function.  (see http://www.freertos.org/a00111.html).  If a binary semaphore
N * is created using xSemaphoreCreateBinaryStatic() then the application writer
N * must provide the memory.  xSemaphoreCreateBinaryStatic() therefore allows a
N * binary semaphore to be created without using any dynamic memory allocation.
N *
N * The old vSemaphoreCreateBinary() macro is now deprecated in favour of this
N * xSemaphoreCreateBinary() function.  Note that binary semaphores created using
N * the vSemaphoreCreateBinary() macro are created in a state such that the
N * first call to 'take' the semaphore would pass, whereas binary semaphores
N * created using xSemaphoreCreateBinary() are created in a state such that the
N * the semaphore must first be 'given' before it can be 'taken'.
N *
N * This type of semaphore can be used for pure synchronisation between tasks or
N * between an interrupt and a task.  The semaphore need not be given back once
N * obtained, so one task/interrupt can continuously 'give' the semaphore while
N * another continuously 'takes' the semaphore.  For this reason this type of
N * semaphore does not use a priority inheritance mechanism.  For an alternative
N * that does use priority inheritance see xSemaphoreCreateMutex().
N *
N * @return Handle to the created semaphore, or NULL if the memory required to
N * hold the semaphore's data structures could not be allocated.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateBinary().
N    // This is a macro so pass the variable in directly.
N    xSemaphore = xSemaphoreCreateBinary();
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateBinary xSemaphoreCreateBinary
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xSemaphoreCreateBinary() xQueueGenericCreate( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_BINARY_SEMAPHORE )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateBinaryStatic( StaticSemaphore_t *pxSemaphoreBuffer )</pre>
N *
N * Creates a new binary semaphore instance, and returns a handle by which the
N * new semaphore can be referenced.
N *
N * NOTE: In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a binary semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, binary semaphores use a block
N * of memory, in which the semaphore structure is stored.  If a binary semaphore
N * is created using xSemaphoreCreateBinary() then the required memory is
N * automatically dynamically allocated inside the xSemaphoreCreateBinary()
N * function.  (see http://www.freertos.org/a00111.html).  If a binary semaphore
N * is created using xSemaphoreCreateBinaryStatic() then the application writer
N * must provide the memory.  xSemaphoreCreateBinaryStatic() therefore allows a
N * binary semaphore to be created without using any dynamic memory allocation.
N *
N * This type of semaphore can be used for pure synchronisation between tasks or
N * between an interrupt and a task.  The semaphore need not be given back once
N * obtained, so one task/interrupt can continuously 'give' the semaphore while
N * another continuously 'takes' the semaphore.  For this reason this type of
N * semaphore does not use a priority inheritance mechanism.  For an alternative
N * that does use priority inheritance see xSemaphoreCreateMutex().
N *
N * @param pxSemaphoreBuffer Must point to a variable of type StaticSemaphore_t,
N * which will then be used to hold the semaphore's data structure, removing the
N * need for the memory to be allocated dynamically.
N *
N * @return If the semaphore is created then a handle to the created semaphore is
N * returned.  If pxSemaphoreBuffer is NULL then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N StaticSemaphore_t xSemaphoreBuffer;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateBinary().
N    // The semaphore's data structures will be placed in the xSemaphoreBuffer
N    // variable, the address of which is passed into the function.  The
N    // function's parameter is not NULL, so the function will not attempt any
N    // dynamic memory allocation, and therefore the function will not return
N    // return NULL.
N    xSemaphore = xSemaphoreCreateBinary( &xSemaphoreBuffer );
N
N    // Rest of task code goes here.
N }
N </pre>
N * \defgroup xSemaphoreCreateBinaryStatic xSemaphoreCreateBinaryStatic
N * \ingroup Semaphores
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreCreateBinaryStatic( pxStaticSemaphore ) xQueueGenericCreateStatic( ( UBaseType_t ) 1, semSEMAPHORE_QUEUE_ITEM_LENGTH, NULL, pxStaticSemaphore, queueQUEUE_TYPE_BINARY_SEMAPHORE )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * semphr. h
N * <pre>xSemaphoreTake(
N *                   SemaphoreHandle_t xSemaphore,
N *                   TickType_t xBlockTime
N *               )</pre>
N *
N * <i>Macro</i> to obtain a semaphore.  The semaphore must have previously been
N * created with a call to xSemaphoreCreateBinary(), xSemaphoreCreateMutex() or
N * xSemaphoreCreateCounting().
N *
N * @param xSemaphore A handle to the semaphore being taken - obtained when
N * the semaphore was created.
N *
N * @param xBlockTime The time in ticks to wait for the semaphore to become
N * available.  The macro portTICK_PERIOD_MS can be used to convert this to a
N * real time.  A block time of zero can be used to poll the semaphore.  A block
N * time of portMAX_DELAY can be used to block indefinitely (provided
N * INCLUDE_vTaskSuspend is set to 1 in FreeRTOSConfig.h).
N *
N * @return pdTRUE if the semaphore was obtained.  pdFALSE
N * if xBlockTime expired without the semaphore becoming available.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N // A task that creates a semaphore.
N void vATask( void * pvParameters )
N {
N    // Create the semaphore to guard a shared resource.
N    xSemaphore = xSemaphoreCreateBinary();
N }
N
N // A task that uses the semaphore.
N void vAnotherTask( void * pvParameters )
N {
N    // ... Do other things.
N
N    if( xSemaphore != NULL )
N    {
N        // See if we can obtain the semaphore.  If the semaphore is not available
N        // wait 10 ticks to see if it becomes free.
N        if( xSemaphoreTake( xSemaphore, ( TickType_t ) 10 ) == pdTRUE )
N        {
N            // We were able to obtain the semaphore and can now access the
N            // shared resource.
N
N            // ...
N
N            // We have finished accessing the shared resource.  Release the
N            // semaphore.
N            xSemaphoreGive( xSemaphore );
N        }
N        else
N        {
N            // We could not obtain the semaphore and can therefore not access
N            // the shared resource safely.
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreTake xSemaphoreTake
N * \ingroup Semaphores
N */
N#define xSemaphoreTake( xSemaphore, xBlockTime )		xQueueGenericReceive( ( QueueHandle_t ) ( xSemaphore ), NULL, ( xBlockTime ), pdFALSE )
N
N/**
N * semphr. h
N * xSemaphoreTakeRecursive(
N *                          SemaphoreHandle_t xMutex,
N *                          TickType_t xBlockTime
N *                        )
N *
N * <i>Macro</i> to recursively obtain, or 'take', a mutex type semaphore.
N * The mutex must have previously been created using a call to
N * xSemaphoreCreateRecursiveMutex();
N *
N * configUSE_RECURSIVE_MUTEXES must be set to 1 in FreeRTOSConfig.h for this
N * macro to be available.
N *
N * This macro must not be used on mutexes created using xSemaphoreCreateMutex().
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * @param xMutex A handle to the mutex being obtained.  This is the
N * handle returned by xSemaphoreCreateRecursiveMutex();
N *
N * @param xBlockTime The time in ticks to wait for the semaphore to become
N * available.  The macro portTICK_PERIOD_MS can be used to convert this to a
N * real time.  A block time of zero can be used to poll the semaphore.  If
N * the task already owns the semaphore then xSemaphoreTakeRecursive() will
N * return immediately no matter what the value of xBlockTime.
N *
N * @return pdTRUE if the semaphore was obtained.  pdFALSE if xBlockTime
N * expired without the semaphore becoming available.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xMutex = NULL;
N
N // A task that creates a mutex.
N void vATask( void * pvParameters )
N {
N    // Create the mutex to guard a shared resource.
N    xMutex = xSemaphoreCreateRecursiveMutex();
N }
N
N // A task that uses the mutex.
N void vAnotherTask( void * pvParameters )
N {
N    // ... Do other things.
N
N    if( xMutex != NULL )
N    {
N        // See if we can obtain the mutex.  If the mutex is not available
N        // wait 10 ticks to see if it becomes free.
N        if( xSemaphoreTakeRecursive( xSemaphore, ( TickType_t ) 10 ) == pdTRUE )
N        {
N            // We were able to obtain the mutex and can now access the
N            // shared resource.
N
N            // ...
N            // For some reason due to the nature of the code further calls to
N			// xSemaphoreTakeRecursive() are made on the same mutex.  In real
N			// code these would not be just sequential calls as this would make
N			// no sense.  Instead the calls are likely to be buried inside
N			// a more complex call structure.
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N
N            // The mutex has now been 'taken' three times, so will not be
N			// available to another task until it has also been given back
N			// three times.  Again it is unlikely that real code would have
N			// these calls sequentially, but instead buried in a more complex
N			// call structure.  This is just for illustrative purposes.
N            xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N
N			// Now the mutex can be taken by other tasks.
N        }
N        else
N        {
N            // We could not obtain the mutex and can therefore not access
N            // the shared resource safely.
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreTakeRecursive xSemaphoreTakeRecursive
N * \ingroup Semaphores
N */
N#if( configUSE_RECURSIVE_MUTEXES == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreTakeRecursive( xMutex, xBlockTime )	xQueueTakeMutexRecursive( ( xMutex ), ( xBlockTime ) )
N#endif
N
N/**
N * semphr. h
N * <pre>xSemaphoreGive( SemaphoreHandle_t xSemaphore )</pre>
N *
N * <i>Macro</i> to release a semaphore.  The semaphore must have previously been
N * created with a call to xSemaphoreCreateBinary(), xSemaphoreCreateMutex() or
N * xSemaphoreCreateCounting(). and obtained using sSemaphoreTake().
N *
N * This macro must not be used from an ISR.  See xSemaphoreGiveFromISR () for
N * an alternative which can be used from an ISR.
N *
N * This macro must also not be used on semaphores created using
N * xSemaphoreCreateRecursiveMutex().
N *
N * @param xSemaphore A handle to the semaphore being released.  This is the
N * handle returned when the semaphore was created.
N *
N * @return pdTRUE if the semaphore was released.  pdFALSE if an error occurred.
N * Semaphores are implemented using queues.  An error can occur if there is
N * no space on the queue to post a message - indicating that the
N * semaphore was not first obtained correctly.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore = NULL;
N
N void vATask( void * pvParameters )
N {
N    // Create the semaphore to guard a shared resource.
N    xSemaphore = vSemaphoreCreateBinary();
N
N    if( xSemaphore != NULL )
N    {
N        if( xSemaphoreGive( xSemaphore ) != pdTRUE )
N        {
N            // We would expect this call to fail because we cannot give
N            // a semaphore without first "taking" it!
N        }
N
N        // Obtain the semaphore - don't block if the semaphore is not
N        // immediately available.
N        if( xSemaphoreTake( xSemaphore, ( TickType_t ) 0 ) )
N        {
N            // We now have the semaphore and can access the shared resource.
N
N            // ...
N
N            // We have finished accessing the shared resource so can free the
N            // semaphore.
N            if( xSemaphoreGive( xSemaphore ) != pdTRUE )
N            {
N                // We would not expect this call to fail because we must have
N                // obtained the semaphore to get here.
N            }
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreGive xSemaphoreGive
N * \ingroup Semaphores
N */
N#define xSemaphoreGive( xSemaphore )		xQueueGenericSend( ( QueueHandle_t ) ( xSemaphore ), NULL, semGIVE_BLOCK_TIME, queueSEND_TO_BACK )
N
N/**
N * semphr. h
N * <pre>xSemaphoreGiveRecursive( SemaphoreHandle_t xMutex )</pre>
N *
N * <i>Macro</i> to recursively release, or 'give', a mutex type semaphore.
N * The mutex must have previously been created using a call to
N * xSemaphoreCreateRecursiveMutex();
N *
N * configUSE_RECURSIVE_MUTEXES must be set to 1 in FreeRTOSConfig.h for this
N * macro to be available.
N *
N * This macro must not be used on mutexes created using xSemaphoreCreateMutex().
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * @param xMutex A handle to the mutex being released, or 'given'.  This is the
N * handle returned by xSemaphoreCreateMutex();
N *
N * @return pdTRUE if the semaphore was given.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xMutex = NULL;
N
N // A task that creates a mutex.
N void vATask( void * pvParameters )
N {
N    // Create the mutex to guard a shared resource.
N    xMutex = xSemaphoreCreateRecursiveMutex();
N }
N
N // A task that uses the mutex.
N void vAnotherTask( void * pvParameters )
N {
N    // ... Do other things.
N
N    if( xMutex != NULL )
N    {
N        // See if we can obtain the mutex.  If the mutex is not available
N        // wait 10 ticks to see if it becomes free.
N        if( xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 ) == pdTRUE )
N        {
N            // We were able to obtain the mutex and can now access the
N            // shared resource.
N
N            // ...
N            // For some reason due to the nature of the code further calls to
N			// xSemaphoreTakeRecursive() are made on the same mutex.  In real
N			// code these would not be just sequential calls as this would make
N			// no sense.  Instead the calls are likely to be buried inside
N			// a more complex call structure.
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N            xSemaphoreTakeRecursive( xMutex, ( TickType_t ) 10 );
N
N            // The mutex has now been 'taken' three times, so will not be
N			// available to another task until it has also been given back
N			// three times.  Again it is unlikely that real code would have
N			// these calls sequentially, it would be more likely that the calls
N			// to xSemaphoreGiveRecursive() would be called as a call stack
N			// unwound.  This is just for demonstrative purposes.
N            xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N			xSemaphoreGiveRecursive( xMutex );
N
N			// Now the mutex can be taken by other tasks.
N        }
N        else
N        {
N            // We could not obtain the mutex and can therefore not access
N            // the shared resource safely.
N        }
N    }
N }
N </pre>
N * \defgroup xSemaphoreGiveRecursive xSemaphoreGiveRecursive
N * \ingroup Semaphores
N */
N#if( configUSE_RECURSIVE_MUTEXES == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreGiveRecursive( xMutex )	xQueueGiveMutexRecursive( ( xMutex ) )
N#endif
N
N/**
N * semphr. h
N * <pre>
N xSemaphoreGiveFromISR(
N                          SemaphoreHandle_t xSemaphore,
N                          BaseType_t *pxHigherPriorityTaskWoken
N                      )</pre>
N *
N * <i>Macro</i> to  release a semaphore.  The semaphore must have previously been
N * created with a call to xSemaphoreCreateBinary() or xSemaphoreCreateCounting().
N *
N * Mutex type semaphores (those created using a call to xSemaphoreCreateMutex())
N * must not be used with this macro.
N *
N * This macro can be used from an ISR.
N *
N * @param xSemaphore A handle to the semaphore being released.  This is the
N * handle returned when the semaphore was created.
N *
N * @param pxHigherPriorityTaskWoken xSemaphoreGiveFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if giving the semaphore caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xSemaphoreGiveFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the semaphore was successfully given, otherwise errQUEUE_FULL.
N *
N * Example usage:
N <pre>
N \#define LONG_TIME 0xffff
N \#define TICKS_TO_WAIT	10
N SemaphoreHandle_t xSemaphore = NULL;
N
N // Repetitive task.
N void vATask( void * pvParameters )
N {
N    for( ;; )
N    {
N        // We want this task to run every 10 ticks of a timer.  The semaphore
N        // was created before this task was started.
N
N        // Block waiting for the semaphore to become available.
N        if( xSemaphoreTake( xSemaphore, LONG_TIME ) == pdTRUE )
N        {
N            // It is time to execute.
N
N            // ...
N
N            // We have finished our task.  Return to the top of the loop where
N            // we will block on the semaphore until it is time to execute
N            // again.  Note when using the semaphore for synchronisation with an
N			// ISR in this manner there is no need to 'give' the semaphore back.
N        }
N    }
N }
N
N // Timer ISR
N void vTimerISR( void * pvParameters )
N {
N static uint8_t ucLocalTickCount = 0;
N static BaseType_t xHigherPriorityTaskWoken;
N
N    // A timer tick has occurred.
N
N    // ... Do other time functions.
N
N    // Is it time for vATask () to run?
N	xHigherPriorityTaskWoken = pdFALSE;
N    ucLocalTickCount++;
N    if( ucLocalTickCount >= TICKS_TO_WAIT )
N    {
N        // Unblock the task by releasing the semaphore.
N        xSemaphoreGiveFromISR( xSemaphore, &xHigherPriorityTaskWoken );
N
N        // Reset the count so we release the semaphore again in 10 ticks time.
N        ucLocalTickCount = 0;
N    }
N
N    if( xHigherPriorityTaskWoken != pdFALSE )
N    {
N        // We can force a context switch here.  Context switching from an
N        // ISR uses port specific syntax.  Check the demo task for your port
N        // to find the syntax required.
N    }
N }
N </pre>
N * \defgroup xSemaphoreGiveFromISR xSemaphoreGiveFromISR
N * \ingroup Semaphores
N */
N#define xSemaphoreGiveFromISR( xSemaphore, pxHigherPriorityTaskWoken )	xQueueGiveFromISR( ( QueueHandle_t ) ( xSemaphore ), ( pxHigherPriorityTaskWoken ) )
N
N/**
N * semphr. h
N * <pre>
N xSemaphoreTakeFromISR(
N                          SemaphoreHandle_t xSemaphore,
N                          BaseType_t *pxHigherPriorityTaskWoken
N                      )</pre>
N *
N * <i>Macro</i> to  take a semaphore from an ISR.  The semaphore must have
N * previously been created with a call to xSemaphoreCreateBinary() or
N * xSemaphoreCreateCounting().
N *
N * Mutex type semaphores (those created using a call to xSemaphoreCreateMutex())
N * must not be used with this macro.
N *
N * This macro can be used from an ISR, however taking a semaphore from an ISR
N * is not a common operation.  It is likely to only be useful when taking a
N * counting semaphore when an interrupt is obtaining an object from a resource
N * pool (when the semaphore count indicates the number of resources available).
N *
N * @param xSemaphore A handle to the semaphore being taken.  This is the
N * handle returned when the semaphore was created.
N *
N * @param pxHigherPriorityTaskWoken xSemaphoreTakeFromISR() will set
N * *pxHigherPriorityTaskWoken to pdTRUE if taking the semaphore caused a task
N * to unblock, and the unblocked task has a priority higher than the currently
N * running task.  If xSemaphoreTakeFromISR() sets this value to pdTRUE then
N * a context switch should be requested before the interrupt is exited.
N *
N * @return pdTRUE if the semaphore was successfully taken, otherwise
N * pdFALSE
N */
N#define xSemaphoreTakeFromISR( xSemaphore, pxHigherPriorityTaskWoken )	xQueueReceiveFromISR( ( QueueHandle_t ) ( xSemaphore ), NULL, ( pxHigherPriorityTaskWoken ) )
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateMutex( void )</pre>
N *
N * Creates a new mutex type semaphore instance, and returns a handle by which
N * the new mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, mutex semaphores use a block
N * of memory, in which the mutex structure is stored.  If a mutex is created
N * using xSemaphoreCreateMutex() then the required memory is automatically
N * dynamically allocated inside the xSemaphoreCreateMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a mutex is created using
N * xSemaphoreCreateMutexStatic() then the application writer must provided the
N * memory.  xSemaphoreCreateMutexStatic() therefore allows a mutex to be created
N * without using any dynamic memory allocation.
N *
N * Mutexes created using this function can be accessed using the xSemaphoreTake()
N * and xSemaphoreGive() macros.  The xSemaphoreTakeRecursive() and
N * xSemaphoreGiveRecursive() macros must not be used.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @return If the mutex was successfully created then a handle to the created
N * semaphore is returned.  If there was not enough heap to allocate the mutex
N * data structures then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateMutex().
N    // This is a macro so pass the variable in directly.
N    xSemaphore = xSemaphoreCreateMutex();
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateMutex xSemaphoreCreateMutex
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xSemaphoreCreateMutex() xQueueCreateMutex( queueQUEUE_TYPE_MUTEX )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateMutexStatic( StaticSemaphore_t *pxMutexBuffer )</pre>
N *
N * Creates a new mutex type semaphore instance, and returns a handle by which
N * the new mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, mutex semaphores use a block
N * of memory, in which the mutex structure is stored.  If a mutex is created
N * using xSemaphoreCreateMutex() then the required memory is automatically
N * dynamically allocated inside the xSemaphoreCreateMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a mutex is created using
N * xSemaphoreCreateMutexStatic() then the application writer must provided the
N * memory.  xSemaphoreCreateMutexStatic() therefore allows a mutex to be created
N * without using any dynamic memory allocation.
N *
N * Mutexes created using this function can be accessed using the xSemaphoreTake()
N * and xSemaphoreGive() macros.  The xSemaphoreTakeRecursive() and
N * xSemaphoreGiveRecursive() macros must not be used.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @param pxMutexBuffer Must point to a variable of type StaticSemaphore_t,
N * which will be used to hold the mutex's data structure, removing the need for
N * the memory to be allocated dynamically.
N *
N * @return If the mutex was successfully created then a handle to the created
N * mutex is returned.  If pxMutexBuffer was NULL then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N StaticSemaphore_t xMutexBuffer;
N
N void vATask( void * pvParameters )
N {
N    // A mutex cannot be used before it has been created.  xMutexBuffer is
N    // into xSemaphoreCreateMutexStatic() so no dynamic memory allocation is
N    // attempted.
N    xSemaphore = xSemaphoreCreateMutexStatic( &xMutexBuffer );
N
N    // As no dynamic memory allocation was performed, xSemaphore cannot be NULL,
N    // so there is no need to check it.
N }
N </pre>
N * \defgroup xSemaphoreCreateMutexStatic xSemaphoreCreateMutexStatic
N * \ingroup Semaphores
N */
N #if( configSUPPORT_STATIC_ALLOCATION == 1 )
X #if( 0 == 1 )
S	#define xSemaphoreCreateMutexStatic( pxMutexBuffer ) xQueueCreateMutexStatic( queueQUEUE_TYPE_MUTEX, ( pxMutexBuffer ) )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateRecursiveMutex( void )</pre>
N *
N * Creates a new recursive mutex type semaphore instance, and returns a handle
N * by which the new recursive mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, recursive mutexs use a block
N * of memory, in which the mutex structure is stored.  If a recursive mutex is
N * created using xSemaphoreCreateRecursiveMutex() then the required memory is
N * automatically dynamically allocated inside the
N * xSemaphoreCreateRecursiveMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a recursive mutex is created using
N * xSemaphoreCreateRecursiveMutexStatic() then the application writer must
N * provide the memory that will get used by the mutex.
N * xSemaphoreCreateRecursiveMutexStatic() therefore allows a recursive mutex to
N * be created without using any dynamic memory allocation.
N *
N * Mutexes created using this macro can be accessed using the
N * xSemaphoreTakeRecursive() and xSemaphoreGiveRecursive() macros.  The
N * xSemaphoreTake() and xSemaphoreGive() macros must not be used.
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @return xSemaphore Handle to the created mutex semaphore.  Should be of type
N * SemaphoreHandle_t.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N
N void vATask( void * pvParameters )
N {
N    // Semaphore cannot be used before a call to xSemaphoreCreateMutex().
N    // This is a macro so pass the variable in directly.
N    xSemaphore = xSemaphoreCreateRecursiveMutex();
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateRecursiveMutex xSemaphoreCreateRecursiveMutex
N * \ingroup Semaphores
N */
N#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configUSE_RECURSIVE_MUTEXES == 1 ) )
X#if( ( 1 == 1 ) && ( 0 == 1 ) )
S	#define xSemaphoreCreateRecursiveMutex() xQueueCreateMutex( queueQUEUE_TYPE_RECURSIVE_MUTEX )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateRecursiveMutexStatic( StaticSemaphore_t *pxMutexBuffer )</pre>
N *
N * Creates a new recursive mutex type semaphore instance, and returns a handle
N * by which the new recursive mutex can be referenced.
N *
N * Internally, within the FreeRTOS implementation, recursive mutexs use a block
N * of memory, in which the mutex structure is stored.  If a recursive mutex is
N * created using xSemaphoreCreateRecursiveMutex() then the required memory is
N * automatically dynamically allocated inside the
N * xSemaphoreCreateRecursiveMutex() function.  (see
N * http://www.freertos.org/a00111.html).  If a recursive mutex is created using
N * xSemaphoreCreateRecursiveMutexStatic() then the application writer must
N * provide the memory that will get used by the mutex.
N * xSemaphoreCreateRecursiveMutexStatic() therefore allows a recursive mutex to
N * be created without using any dynamic memory allocation.
N *
N * Mutexes created using this macro can be accessed using the
N * xSemaphoreTakeRecursive() and xSemaphoreGiveRecursive() macros.  The
N * xSemaphoreTake() and xSemaphoreGive() macros must not be used.
N *
N * A mutex used recursively can be 'taken' repeatedly by the owner. The mutex
N * doesn't become available again until the owner has called
N * xSemaphoreGiveRecursive() for each successful 'take' request.  For example,
N * if a task successfully 'takes' the same mutex 5 times then the mutex will
N * not be available to any other task until it has also  'given' the mutex back
N * exactly five times.
N *
N * This type of semaphore uses a priority inheritance mechanism so a task
N * 'taking' a semaphore MUST ALWAYS 'give' the semaphore back once the
N * semaphore it is no longer required.
N *
N * Mutex type semaphores cannot be used from within interrupt service routines.
N *
N * See xSemaphoreCreateBinary() for an alternative implementation that can be
N * used for pure synchronisation (where one task or interrupt always 'gives' the
N * semaphore and another always 'takes' the semaphore) and from within interrupt
N * service routines.
N *
N * @param pxMutexBuffer Must point to a variable of type StaticSemaphore_t,
N * which will then be used to hold the recursive mutex's data structure,
N * removing the need for the memory to be allocated dynamically.
N *
N * @return If the recursive mutex was successfully created then a handle to the
N * created recursive mutex is returned.  If pxMutexBuffer was NULL then NULL is
N * returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N StaticSemaphore_t xMutexBuffer;
N
N void vATask( void * pvParameters )
N {
N    // A recursive semaphore cannot be used before it is created.  Here a
N    // recursive mutex is created using xSemaphoreCreateRecursiveMutexStatic().
N    // The address of xMutexBuffer is passed into the function, and will hold
N    // the mutexes data structures - so no dynamic memory allocation will be
N    // attempted.
N    xSemaphore = xSemaphoreCreateRecursiveMutexStatic( &xMutexBuffer );
N
N    // As no dynamic memory allocation was performed, xSemaphore cannot be NULL,
N    // so there is no need to check it.
N }
N </pre>
N * \defgroup xSemaphoreCreateRecursiveMutexStatic xSemaphoreCreateRecursiveMutexStatic
N * \ingroup Semaphores
N */
N#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configUSE_RECURSIVE_MUTEXES == 1 ) )
X#if( ( 0 == 1 ) && ( 0 == 1 ) )
S	#define xSemaphoreCreateRecursiveMutexStatic( pxStaticSemaphore ) xQueueCreateMutexStatic( queueQUEUE_TYPE_RECURSIVE_MUTEX, pxStaticSemaphore )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateCounting( UBaseType_t uxMaxCount, UBaseType_t uxInitialCount )</pre>
N *
N * Creates a new counting semaphore instance, and returns a handle by which the
N * new counting semaphore can be referenced.
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a counting semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, counting semaphores use a
N * block of memory, in which the counting semaphore structure is stored.  If a
N * counting semaphore is created using xSemaphoreCreateCounting() then the
N * required memory is automatically dynamically allocated inside the
N * xSemaphoreCreateCounting() function.  (see
N * http://www.freertos.org/a00111.html).  If a counting semaphore is created
N * using xSemaphoreCreateCountingStatic() then the application writer can
N * instead optionally provide the memory that will get used by the counting
N * semaphore.  xSemaphoreCreateCountingStatic() therefore allows a counting
N * semaphore to be created without using any dynamic memory allocation.
N *
N * Counting semaphores are typically used for two things:
N *
N * 1) Counting events.
N *
N *    In this usage scenario an event handler will 'give' a semaphore each time
N *    an event occurs (incrementing the semaphore count value), and a handler
N *    task will 'take' a semaphore each time it processes an event
N *    (decrementing the semaphore count value).  The count value is therefore
N *    the difference between the number of events that have occurred and the
N *    number that have been processed.  In this case it is desirable for the
N *    initial count value to be zero.
N *
N * 2) Resource management.
N *
N *    In this usage scenario the count value indicates the number of resources
N *    available.  To obtain control of a resource a task must first obtain a
N *    semaphore - decrementing the semaphore count value.  When the count value
N *    reaches zero there are no free resources.  When a task finishes with the
N *    resource it 'gives' the semaphore back - incrementing the semaphore count
N *    value.  In this case it is desirable for the initial count value to be
N *    equal to the maximum count value, indicating that all resources are free.
N *
N * @param uxMaxCount The maximum count value that can be reached.  When the
N *        semaphore reaches this value it can no longer be 'given'.
N *
N * @param uxInitialCount The count value assigned to the semaphore when it is
N *        created.
N *
N * @return Handle to the created semaphore.  Null if the semaphore could not be
N *         created.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N
N void vATask( void * pvParameters )
N {
N SemaphoreHandle_t xSemaphore = NULL;
N
N    // Semaphore cannot be used before a call to xSemaphoreCreateCounting().
N    // The max value to which the semaphore can count should be 10, and the
N    // initial value assigned to the count should be 0.
N    xSemaphore = xSemaphoreCreateCounting( 10, 0 );
N
N    if( xSemaphore != NULL )
N    {
N        // The semaphore was created successfully.
N        // The semaphore can now be used.
N    }
N }
N </pre>
N * \defgroup xSemaphoreCreateCounting xSemaphoreCreateCounting
N * \ingroup Semaphores
N */
N#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
X#if( 1 == 1 )
N	#define xSemaphoreCreateCounting( uxMaxCount, uxInitialCount ) xQueueCreateCountingSemaphore( ( uxMaxCount ), ( uxInitialCount ) )
N#endif
N
N/**
N * semphr. h
N * <pre>SemaphoreHandle_t xSemaphoreCreateCountingStatic( UBaseType_t uxMaxCount, UBaseType_t uxInitialCount, StaticSemaphore_t *pxSemaphoreBuffer )</pre>
N *
N * Creates a new counting semaphore instance, and returns a handle by which the
N * new counting semaphore can be referenced.
N *
N * In many usage scenarios it is faster and more memory efficient to use a
N * direct to task notification in place of a counting semaphore!
N * http://www.freertos.org/RTOS-task-notifications.html
N *
N * Internally, within the FreeRTOS implementation, counting semaphores use a
N * block of memory, in which the counting semaphore structure is stored.  If a
N * counting semaphore is created using xSemaphoreCreateCounting() then the
N * required memory is automatically dynamically allocated inside the
N * xSemaphoreCreateCounting() function.  (see
N * http://www.freertos.org/a00111.html).  If a counting semaphore is created
N * using xSemaphoreCreateCountingStatic() then the application writer must
N * provide the memory.  xSemaphoreCreateCountingStatic() therefore allows a
N * counting semaphore to be created without using any dynamic memory allocation.
N *
N * Counting semaphores are typically used for two things:
N *
N * 1) Counting events.
N *
N *    In this usage scenario an event handler will 'give' a semaphore each time
N *    an event occurs (incrementing the semaphore count value), and a handler
N *    task will 'take' a semaphore each time it processes an event
N *    (decrementing the semaphore count value).  The count value is therefore
N *    the difference between the number of events that have occurred and the
N *    number that have been processed.  In this case it is desirable for the
N *    initial count value to be zero.
N *
N * 2) Resource management.
N *
N *    In this usage scenario the count value indicates the number of resources
N *    available.  To obtain control of a resource a task must first obtain a
N *    semaphore - decrementing the semaphore count value.  When the count value
N *    reaches zero there are no free resources.  When a task finishes with the
N *    resource it 'gives' the semaphore back - incrementing the semaphore count
N *    value.  In this case it is desirable for the initial count value to be
N *    equal to the maximum count value, indicating that all resources are free.
N *
N * @param uxMaxCount The maximum count value that can be reached.  When the
N *        semaphore reaches this value it can no longer be 'given'.
N *
N * @param uxInitialCount The count value assigned to the semaphore when it is
N *        created.
N *
N * @param pxSemaphoreBuffer Must point to a variable of type StaticSemaphore_t,
N * which will then be used to hold the semaphore's data structure, removing the
N * need for the memory to be allocated dynamically.
N *
N * @return If the counting semaphore was successfully created then a handle to
N * the created counting semaphore is returned.  If pxSemaphoreBuffer was NULL
N * then NULL is returned.
N *
N * Example usage:
N <pre>
N SemaphoreHandle_t xSemaphore;
N StaticSemaphore_t xSemaphoreBuffer;
N
N void vATask( void * pvParameters )
N {
N SemaphoreHandle_t xSemaphore = NULL;
N
N    // Counting semaphore cannot be used before they have been created.  Create
N    // a counting semaphore using xSemaphoreCreateCountingStatic().  The max
N    // value to which the semaphore can count is 10, and the initial value
N    // assigned to the count will be 0.  The address of xSemaphoreBuffer is
N    // passed in and will be used to hold the semaphore structure, so no dynamic
N    // memory allocation will be used.
N    xSemaphore = xSemaphoreCreateCounting( 10, 0, &xSemaphoreBuffer );
N
N    // No memory allocation was attempted so xSemaphore cannot be NULL, so there
N    // is no need to check its value.
N }
N </pre>
N * \defgroup xSemaphoreCreateCountingStatic xSemaphoreCreateCountingStatic
N * \ingroup Semaphores
N */
N#if( configSUPPORT_STATIC_ALLOCATION == 1 )
X#if( 0 == 1 )
S	#define xSemaphoreCreateCountingStatic( uxMaxCount, uxInitialCount, pxSemaphoreBuffer ) xQueueCreateCountingSemaphoreStatic( ( uxMaxCount ), ( uxInitialCount ), ( pxSemaphoreBuffer ) )
N#endif /* configSUPPORT_STATIC_ALLOCATION */
N
N/**
N * semphr. h
N * <pre>void vSemaphoreDelete( SemaphoreHandle_t xSemaphore );</pre>
N *
N * Delete a semaphore.  This function must be used with care.  For example,
N * do not delete a mutex type semaphore if the mutex is held by a task.
N *
N * @param xSemaphore A handle to the semaphore to be deleted.
N *
N * \defgroup vSemaphoreDelete vSemaphoreDelete
N * \ingroup Semaphores
N */
N#define vSemaphoreDelete( xSemaphore ) vQueueDelete( ( QueueHandle_t ) ( xSemaphore ) )
N
N/**
N * semphr.h
N * <pre>TaskHandle_t xSemaphoreGetMutexHolder( SemaphoreHandle_t xMutex );</pre>
N *
N * If xMutex is indeed a mutex type semaphore, return the current mutex holder.
N * If xMutex is not a mutex type semaphore, or the mutex is available (not held
N * by a task), return NULL.
N *
N * Note: This is a good way of determining if the calling task is the mutex
N * holder, but not a good way of determining the identity of the mutex holder as
N * the holder may change between the function exiting and the returned value
N * being tested.
N */
N#define xSemaphoreGetMutexHolder( xSemaphore ) xQueueGetMutexHolder( ( xSemaphore ) )
N
N/**
N * semphr.h
N * <pre>TaskHandle_t xSemaphoreGetMutexHolderFromISR( SemaphoreHandle_t xMutex );</pre>
N *
N * If xMutex is indeed a mutex type semaphore, return the current mutex holder.
N * If xMutex is not a mutex type semaphore, or the mutex is available (not held
N * by a task), return NULL.
N *
N */
N#define xSemaphoreGetMutexHolderFromISR( xSemaphore ) xQueueGetMutexHolderFromISR( ( xSemaphore ) )
N
N/**
N * semphr.h
N * <pre>UBaseType_t uxSemaphoreGetCount( SemaphoreHandle_t xSemaphore );</pre>
N *
N * If the semaphore is a counting semaphore then uxSemaphoreGetCount() returns
N * its current count value.  If the semaphore is a binary semaphore then
N * uxSemaphoreGetCount() returns 1 if the semaphore is available, and 0 if the
N * semaphore is not available.
N *
N */
N#define uxSemaphoreGetCount( xSemaphore ) uxQueueMessagesWaiting( ( QueueHandle_t ) ( xSemaphore ) )
N
N#endif /* SEMAPHORE_H */
N
N
L 9 "..\..\common\src\BSP\ThirdParty\yaffs2\include\linux\compat.h" 2
N
N#define ndelay(x)	udelay(1)
N
Nextern void sysprintf(char *pcStr,...);
N#define printk	sysprintf
N
N#define KERN_EMERG
N#define KERN_ALERT
N#define KERN_CRIT
N#define KERN_ERR
N#define KERN_WARNING
N#define KERN_NOTICE
N#define KERN_INFO
N#define KERN_DEBUG
N
N#define kmalloc(size, flags)	pvPortMalloc(size)//malloc(size)
N//#define kzalloc(size, flags)	calloc(size, 1)
N#define vmalloc(size)		pvPortMalloc(size)//malloc(size)
N#define kfree(ptr)		vPortFree(ptr)//free(ptr)
N#define vfree(ptr)		vPortFree(ptr)//free(ptr)
N
N#define DECLARE_WAITQUEUE(...)	do { } while (0)
N#define add_wait_queue(...)	do { } while (0)
N#define remove_wait_queue(...)	do { } while (0)
N
N#define KERNEL_VERSION(a,b,c)	(((a) << 16) + ((b) << 8) + (c))
N
N/*
N * ..and if you can't take the strict
N * types, you can specify one yourself.
N *
N * Or not use min/max at all, of course.
N */
N
N#define min_t(type,x,y) ((type)x < (type)y ? (type) x: (type)y)
N#define max_t(type,x,y) ((type)x > (type)y ? (type) x: (type)y)
N
N#if 0
S#define min_t(type,x,y) \
S	({ type __x = (x); type __y = (y); __x < __y ? __x: __y; })
X#define min_t(type,x,y) 	({ type __x = (x); type __y = (y); __x < __y ? __x: __y; })
S#define max_t(type,x,y) \
S	({ type __x = (x); type __y = (y); __x > __y ? __x: __y; })
X#define max_t(type,x,y) 	({ type __x = (x); type __y = (y); __x > __y ? __x: __y; })
N#endif
N    
N#ifndef BUG
N#define BUG() do { \
N	sysprintf("U-Boot BUG at %s:%d!\n", __FILE__, __LINE__); \
N} while (0)
X#define BUG() do { 	sysprintf("U-Boot BUG at %s:%d!\n", __FILE__, __LINE__); } while (0)
N
N#define BUG_ON(condition) do { if (condition) BUG(); } while(0)
N#endif /* BUG */
N
N#define WARN_ON(x) if (x) {sysprintf("WARNING in %s line %d\n" \
N				  , __FILE__, __LINE__); }
X#define WARN_ON(x) if (x) {sysprintf("WARNING in %s line %d\n" 				  , __FILE__, __LINE__); }
N
N#define PAGE_SIZE	4096
N#endif
L 21 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N
N#include "yaffs_malloc.h"
L 1 "..\..\common\src\BSP\ThirdParty\yaffs2\yaffs_malloc.h" 1
N
N
Nvoid *yaffs_malloc(size_t size);
Nvoid yaffs_free(void *ptr);
Nvoid  YAFFS_InitializeMemoryPool(void);
Nint yaffsfs_GetError(void);
N
L 23 "..\..\common\src\BSP\ThirdParty\yaffs2\mtdpart.c" 2
N
N// /**
N//  * container_of - cast a member of a structure out to the containing structure
N//  * @ptr:	the pointer to the member.
N//  * @type:	the type of the container struct this is embedded in.
N//  * @member:	the name of the member within the struct.
N//  *
N//  */
N// #define container_of(ptr, type, member) ({			\
N// 	const typeof( ((type *)0)->member ) *__mptr = (ptr);	\
N// 	(type *)( (char *)__mptr - offsetof(type,member) );})
X
N
N
N
N/* Our partition linked list */
Nstruct list_head mtd_partitions;
N
N/* Our partition node structure */
Nstruct mtd_part {
N	struct mtd_info mtd;
N	struct mtd_info *master;
N	uint64_t offset;
N	int index;
N	struct list_head list;
N	int registered;
N};
N
N/*
N * Given a pointer to the MTD object in the mtd_part structure, we can retrieve
N * the pointer to that structure with this macro.
N */
N#define PART(x)  ((struct mtd_part *)(x))
N
N
N/*
N * MTD methods which simply translate the effective address and pass through
N * to the _real_ device.
N */
N
Nstatic int part_read(struct mtd_info *mtd, loff_t from, size_t len,
N		size_t *retlen, u_char *buf)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	struct mtd_ecc_stats stats;
N	int res;
N
N	stats = part->master->ecc_stats;
N
N	if (from >= mtd->size)
N		len = 0;
N	else if (from + len > mtd->size)
N		len = mtd->size - from;
N	res = part->master->read(part->master, from + part->offset,
N				   len, retlen, buf);
N	if (res) {
N		if (res == -EUCLEAN)
X		if (res == -117)
N			mtd->ecc_stats.corrected += part->master->ecc_stats.corrected - stats.corrected;
N		if (res == -EBADMSG)
X		if (res == -74)
N			mtd->ecc_stats.failed += part->master->ecc_stats.failed - stats.failed;
N	}
N	return res;
N}
N
Nstatic int part_read_oob(struct mtd_info *mtd, loff_t from,
N		struct mtd_oob_ops *ops)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	int res;
N
N	if (from >= mtd->size)
N		return -EINVAL;
X		return -22;
N	if (ops->datbuf && from + ops->len > mtd->size)
N		return -EINVAL;
X		return -22;
N	res = part->master->read_oob(part->master, from + part->offset, ops);
N
N	if (res) {
N		if (res == -EUCLEAN)
X		if (res == -117)
N			mtd->ecc_stats.corrected++;
N		if (res == -EBADMSG)
X		if (res == -74)
N			mtd->ecc_stats.failed++;
N	}
N	return res;
N}
N
Nstatic int part_read_user_prot_reg(struct mtd_info *mtd, loff_t from,
N		size_t len, size_t *retlen, u_char *buf)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	return part->master->read_user_prot_reg(part->master, from,
N					len, retlen, buf);
N}
N
Nstatic int part_get_user_prot_info(struct mtd_info *mtd,
N		struct otp_info *buf, size_t len)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	return part->master->get_user_prot_info(part->master, buf, len);
N}
N
Nstatic int part_read_fact_prot_reg(struct mtd_info *mtd, loff_t from,
N		size_t len, size_t *retlen, u_char *buf)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	return part->master->read_fact_prot_reg(part->master, from,
N					len, retlen, buf);
N}
N
Nstatic int part_get_fact_prot_info(struct mtd_info *mtd, struct otp_info *buf,
N		size_t len)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	return part->master->get_fact_prot_info(part->master, buf, len);
N}
N
Nstatic int part_write(struct mtd_info *mtd, loff_t to, size_t len,
N		size_t *retlen, const u_char *buf)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	if (!(mtd->flags & MTD_WRITEABLE))
X	if (!(mtd->flags & 0x400))
N		return -EROFS;
X		return -30;
N	if (to >= mtd->size)
N		len = 0;
N	else if (to + len > mtd->size)
N		len = mtd->size - to;
N	return part->master->write(part->master, to + part->offset,
N				    len, retlen, buf);
N}
N
Nstatic int part_panic_write(struct mtd_info *mtd, loff_t to, size_t len,
N		size_t *retlen, const u_char *buf)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	if (!(mtd->flags & MTD_WRITEABLE))
X	if (!(mtd->flags & 0x400))
N		return -EROFS;
X		return -30;
N	if (to >= mtd->size)
N		len = 0;
N	else if (to + len > mtd->size)
N		len = mtd->size - to;
N	return part->master->panic_write(part->master, to + part->offset,
N				    len, retlen, buf);
N}
N
Nstatic int part_write_oob(struct mtd_info *mtd, loff_t to,
N		struct mtd_oob_ops *ops)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N
N	if (!(mtd->flags & MTD_WRITEABLE))
X	if (!(mtd->flags & 0x400))
N		return -EROFS;
X		return -30;
N
N	if (to >= mtd->size)
N		return -EINVAL;
X		return -22;
N	if (ops->datbuf && to + ops->len > mtd->size)
N		return -EINVAL;
X		return -22;
N	return part->master->write_oob(part->master, to + part->offset, ops);
N}
N
Nstatic int part_write_user_prot_reg(struct mtd_info *mtd, loff_t from,
N		size_t len, size_t *retlen, u_char *buf)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	return part->master->write_user_prot_reg(part->master, from,
N					len, retlen, buf);
N}
N
Nstatic int part_lock_user_prot_reg(struct mtd_info *mtd, loff_t from,
N		size_t len)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	return part->master->lock_user_prot_reg(part->master, from, len);
N}
N
Nstatic int part_erase(struct mtd_info *mtd, struct erase_info *instr)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	int ret;
N	if (!(mtd->flags & MTD_WRITEABLE))
X	if (!(mtd->flags & 0x400))
N		return -EROFS;
X		return -30;
N	if (instr->addr >= mtd->size)
N		return -EINVAL;
X		return -22;
N	instr->addr += part->offset;
N	ret = part->master->erase(part->master, instr);
N	if (ret) {
N		if (instr->fail_addr != (uint64_t)MTD_FAIL_ADDR_UNKNOWN)
X		if (instr->fail_addr != (uint64_t)-1LL)
N			instr->fail_addr -= part->offset;
N		instr->addr -= part->offset;
N	}
N	return ret;
N}
N
Nvoid mtd_erase_callback(struct erase_info *instr)
N{
N	if (instr->mtd->erase == part_erase) {
N		struct mtd_part *part = PART(instr->mtd);
X		struct mtd_part *part = ((struct mtd_part *)(instr->mtd));
N
N		if (instr->fail_addr != (uint64_t)MTD_FAIL_ADDR_UNKNOWN)
X		if (instr->fail_addr != (uint64_t)-1LL)
N			instr->fail_addr -= part->offset;
N		instr->addr -= part->offset;
N	}
N	if (instr->callback)
N		instr->callback(instr);
N}
N
Nstatic int part_lock(struct mtd_info *mtd, loff_t ofs, uint64_t len)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	if ((len + ofs) > mtd->size)
N		return -EINVAL;
X		return -22;
N	return part->master->lock(part->master, ofs + part->offset, len);
N}
N
Nstatic int part_unlock(struct mtd_info *mtd, loff_t ofs, uint64_t len)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	if ((len + ofs) > mtd->size)
N		return -EINVAL;
X		return -22;
N	return part->master->unlock(part->master, ofs + part->offset, len);
N}
N
Nstatic void part_sync(struct mtd_info *mtd)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	part->master->sync(part->master);
N}
N
Nstatic int part_block_isbad(struct mtd_info *mtd, loff_t ofs)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	if (ofs >= mtd->size)
N		return -EINVAL;
X		return -22;
N	ofs += part->offset;
N	return part->master->block_isbad(part->master, ofs);
N}
N
Nstatic int part_block_markbad(struct mtd_info *mtd, loff_t ofs)
N{
N	struct mtd_part *part = PART(mtd);
X	struct mtd_part *part = ((struct mtd_part *)(mtd));
N	int res;
N
N	if (!(mtd->flags & MTD_WRITEABLE))
X	if (!(mtd->flags & 0x400))
N		return -EROFS;
X		return -30;
N	if (ofs >= mtd->size)
N		return -EINVAL;
X		return -22;
N	ofs += part->offset;
N	res = part->master->block_markbad(part->master, ofs);
N	if (!res)
N		mtd->ecc_stats.badblocks++;
N	return res;
N}
N
N/*
N * This function unregisters and destroy all slave MTD objects which are
N * attached to the given master MTD object.
N */
N
Nint del_mtd_partitions(struct mtd_info *master)
N{
N	struct mtd_part *slave, *next;
N
N//	list_for_each_entry_safe(slave, next, &mtd_partitions, list)
N
N	for (slave = list_entry((&mtd_partitions)->next, struct mtd_part, list),
X	for (slave = ((struct mtd_part *)((char *)((&mtd_partitions)->next)-(unsigned long)(&((struct mtd_part *)0)->list))),
N		next = list_entry(slave->list.next, struct mtd_part, list);
X		next = ((struct mtd_part *)((char *)(slave ->list . next)-(unsigned long)(&((struct mtd_part *)0)->list)));
N	     &slave->list != (&mtd_partitions);
N	     slave = next, next = list_entry(next->list.next, struct mtd_part, list))
X	     slave = next, next = ((struct mtd_part *)((char *)(next->list . next)-(unsigned long)(&((struct mtd_part *)0)->list))))
N    {
N		if (slave->master == master) {
N			list_del(&slave->list);
N			if (slave->registered)
N				del_mtd_device(&slave->mtd);
N			yaffs_free(slave);
N		}
N    }
N	return 0;
N}
N
Nstatic struct mtd_part *add_one_partition(struct mtd_info *master,
N		const struct mtd_partition *part, int partno,
N		uint64_t cur_offset)
N{
N	struct mtd_part *slave;
N
N	/* allocate the partition structure */
N	slave = yaffs_malloc(sizeof(*slave));
N	if (!slave) {
N		printk(KERN_ERR"memory allocation error while creating partitions for \"%s\"\n",
X		sysprintf("memory allocation error while creating partitions for \"%s\"\n",
N			master->name);
N		del_mtd_partitions(master);
N		return NULL;
X		return 0;
N	}
N    memset(slave, 0, sizeof(*slave));
N	list_add(&slave->list, &mtd_partitions);
N
N	/* set up the MTD object for this partition */
N	slave->mtd.type = master->type;
N	slave->mtd.flags = master->flags & ~part->mask_flags;
N	slave->mtd.size = part->size;
N	slave->mtd.writesize = master->writesize;
N	slave->mtd.oobsize = master->oobsize;
N	slave->mtd.oobavail = master->oobavail;
N	slave->mtd.subpage_sft = master->subpage_sft;
N
N	slave->mtd.name = part->name;
N	slave->mtd.owner = master->owner;
N
N	slave->mtd.read = part_read;
N	slave->mtd.write = part_write;
N
N	if (master->panic_write)
N		slave->mtd.panic_write = part_panic_write;
N
N	if (master->read_oob)
N		slave->mtd.read_oob = part_read_oob;
N	if (master->write_oob)
N		slave->mtd.write_oob = part_write_oob;
N	if (master->read_user_prot_reg)
N		slave->mtd.read_user_prot_reg = part_read_user_prot_reg;
N	if (master->read_fact_prot_reg)
N		slave->mtd.read_fact_prot_reg = part_read_fact_prot_reg;
N	if (master->write_user_prot_reg)
N		slave->mtd.write_user_prot_reg = part_write_user_prot_reg;
N	if (master->lock_user_prot_reg)
N		slave->mtd.lock_user_prot_reg = part_lock_user_prot_reg;
N	if (master->get_user_prot_info)
N		slave->mtd.get_user_prot_info = part_get_user_prot_info;
N	if (master->get_fact_prot_info)
N		slave->mtd.get_fact_prot_info = part_get_fact_prot_info;
N	if (master->sync)
N		slave->mtd.sync = part_sync;
N	if (master->lock)
N		slave->mtd.lock = part_lock;
N	if (master->unlock)
N		slave->mtd.unlock = part_unlock;
N	if (master->block_isbad)
N		slave->mtd.block_isbad = part_block_isbad;
N	if (master->block_markbad)
N		slave->mtd.block_markbad = part_block_markbad;
N	slave->mtd.erase = part_erase;
N	slave->master = master;
N	slave->offset = part->offset;
N	slave->index = partno;
N
N	if (slave->offset == (uint64_t)MTDPART_OFS_APPEND)
X	if (slave->offset == (uint64_t)(-1))
N		slave->offset = cur_offset;
N	if (slave->offset == (uint64_t)MTDPART_OFS_NXTBLK) {
X	if (slave->offset == (uint64_t)(-2)) {
N		slave->offset = cur_offset;
N		if (mtd_mod_by_eb(cur_offset, master) != 0) {
N			/* Round up to next erasesize */
N			slave->offset = (mtd_div_by_eb(cur_offset, master) + 1) * master->erasesize;
N			printk(KERN_NOTICE "Moving partition %d: "
X			sysprintf( "Moving partition %d: "
N			       "0x%012llx -> 0x%012llx\n", partno,
N			       (unsigned long long)cur_offset, (unsigned long long)slave->offset);
N		}
N	}
N	if (slave->mtd.size == MTDPART_SIZ_FULL)
X	if (slave->mtd.size == (0))
N		slave->mtd.size = master->size - slave->offset;
N
N	printk(KERN_NOTICE "0x%012llx-0x%012llx : \"%s\"\n", (unsigned long long)slave->offset,
X	sysprintf( "0x%012llx-0x%012llx : \"%s\"\n", (unsigned long long)slave->offset,
N		(unsigned long long)(slave->offset + slave->mtd.size), slave->mtd.name);
N
N	/* let's do some sanity checks */
N	if (slave->offset >= master->size) {
N		/* let's register it anyway to preserve ordering */
N		slave->offset = 0;
N		slave->mtd.size = 0;
N		printk(KERN_ERR"mtd: partition \"%s\" is out of reach -- disabled\n",
X		sysprintf("mtd: partition \"%s\" is out of reach -- disabled\n",
N			part->name);
N		goto out_register;
N	}
N	if (slave->offset + slave->mtd.size > master->size) {
N		slave->mtd.size = master->size - slave->offset;
N		printk(KERN_WARNING"mtd: partition \"%s\" extends beyond the end of device \"%s\" -- size truncated to %#llx\n",
X		sysprintf("mtd: partition \"%s\" extends beyond the end of device \"%s\" -- size truncated to %#llx\n",
N			part->name, master->name, (unsigned long long)slave->mtd.size);
N	}
N	if (master->numeraseregions > 1) {
N		/* Deal with variable erase size stuff */
N		int i, max = master->numeraseregions;
N		u64 end = slave->offset + slave->mtd.size;
N		struct mtd_erase_region_info *regions = master->eraseregions;
N
N		/* Find the first erase regions which is part of this
N		 * partition. */
N		for (i = 0; i < max && regions[i].offset <= slave->offset; i++)
N			;
N		/* The loop searched for the region _behind_ the first one */
N		i--;
N
N		/* Pick biggest erasesize */
N		for (; i < max && regions[i].offset < end; i++) {
N			if (slave->mtd.erasesize < regions[i].erasesize) {
N				slave->mtd.erasesize = regions[i].erasesize;
N			}
N		}
N		BUG_ON(slave->mtd.erasesize == 0);
X		do { if (slave ->mtd . erasesize == 0) do { sysprintf("U-Boot BUG at %s:%d!\n", "..\\..\\common\\src\\BSP\\ThirdParty\\yaffs2\\mtdpart.c", 416); } while (0); } while(0);
N	} else {
N		/* Single erase size */
N		slave->mtd.erasesize = master->erasesize;
N	}
N
N	if ((slave->mtd.flags & MTD_WRITEABLE) &&
X	if ((slave->mtd.flags & 0x400) &&
N	    mtd_mod_by_eb(slave->offset, &slave->mtd)) {
N		/* Doesn't start on a boundary of major erase size */
N		/* FIXME: Let it be writable if it is on a boundary of
N		 * _minor_ erase size though */
N		slave->mtd.flags &= ~MTD_WRITEABLE;
X		slave->mtd.flags &= ~0x400;
N		printk(KERN_WARNING"mtd: partition \"%s\" doesn't start on an erase block boundary -- force read-only\n",
X		sysprintf("mtd: partition \"%s\" doesn't start on an erase block boundary -- force read-only\n",
N			part->name);
N	}
N	if ((slave->mtd.flags & MTD_WRITEABLE) &&
X	if ((slave->mtd.flags & 0x400) &&
N	    mtd_mod_by_eb(slave->mtd.size, &slave->mtd)) {
N		slave->mtd.flags &= ~MTD_WRITEABLE;
X		slave->mtd.flags &= ~0x400;
N		printk(KERN_WARNING"mtd: partition \"%s\" doesn't end on an erase block -- force read-only\n",
X		sysprintf("mtd: partition \"%s\" doesn't end on an erase block -- force read-only\n",
N			part->name);
N	}
N
N	slave->mtd.ecclayout = master->ecclayout;
N	if (master->block_isbad) {
N		uint64_t offs = 0;
N
N		while (offs < slave->mtd.size) {
N			if (master->block_isbad(master,
N						offs + slave->offset))
N				slave->mtd.ecc_stats.badblocks++;
N			offs += slave->mtd.erasesize;
N		}
N	}
N
Nout_register:
N	if (part->mtdp) {
N		/* store the object pointer (caller may or may not register it*/
N		*part->mtdp = &slave->mtd;
N		slave->registered = 0;
N	} else {
N		/* register our partition */
N		add_mtd_device(&slave->mtd);
N		slave->registered = 1;
N	}
N	return slave;
N}
N
N/*
N * This function, given a master MTD object and a partition table, creates
N * and registers slave MTD objects which are bound to the master according to
N * the partition definitions.
N *
N * We don't register the master, or expect the caller to have done so,
N * for reasons of data integrity.
N */
N
Nint add_mtd_partitions(struct mtd_info *master,
N		       const struct mtd_partition *parts,
N		       int nbparts)
N{
N	struct mtd_part *slave;
N	uint64_t cur_offset = 0;
N	int i;
N
N	/*
N	 * Need to init the list here, since LIST_INIT() does not
N	 * work on platforms where relocation has problems (like MIPS
N	 * & PPC).
N	 */
N	if (mtd_partitions.next == NULL)
X	if (mtd_partitions.next == 0)
N		INIT_LIST_HEAD(&mtd_partitions);
N
N	printk(KERN_NOTICE "Creating %d MTD partitions on \"%s\":\n", nbparts, master->name);
X	sysprintf( "Creating %d MTD partitions on \"%s\":\n", nbparts, master->name);
N
N	for (i = 0; i < nbparts; i++) {
N		slave = add_one_partition(master, parts + i, i, cur_offset);
N		if (!slave)
N			return -ENOMEM;
X			return -12;
N		cur_offset = slave->offset + slave->mtd.size;
N	}
N
N	return 0;
N}
